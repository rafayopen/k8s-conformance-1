I0421 04:37:37.850761      26 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-357945732
I0421 04:37:37.850914      26 e2e.go:92] Starting e2e run "0cf35e81-6c9f-4293-85b5-640a9d64af0f" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1587443856 - Will randomize all specs
Will run 276 of 4732 specs

Apr 21 04:37:37.865: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:37:37.868: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr 21 04:37:37.954: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr 21 04:37:38.067: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr 21 04:37:38.068: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Apr 21 04:37:38.068: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr 21 04:37:38.105: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Apr 21 04:37:38.105: INFO: e2e test version: v1.16.9
Apr 21 04:37:38.110: INFO: kube-apiserver version: v1.16.9+IKS
Apr 21 04:37:38.110: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:37:38.131: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:37:38.138: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
Apr 21 04:37:38.320: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Apr 21 04:37:38.387: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-5496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Apr 21 04:38:08.760: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0421 04:38:08.760078      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 21 04:38:08.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5496" for this suite.
Apr 21 04:38:16.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:38:17.523: INFO: namespace gc-5496 deletion completed in 8.742546286s

• [SLOW TEST:39.386 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:38:17.524: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5155
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-9937e5d2-a43c-4fbb-a696-396e4a69b642
STEP: Creating configMap with name cm-test-opt-upd-f28f752b-0770-451b-9a3f-d84a86662334
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-9937e5d2-a43c-4fbb-a696-396e4a69b642
STEP: Updating configmap cm-test-opt-upd-f28f752b-0770-451b-9a3f-d84a86662334
STEP: Creating configMap with name cm-test-opt-create-3d8ccd3b-2169-40a0-bbda-73c4d67ab3df
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:39:42.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5155" for this suite.
Apr 21 04:39:56.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:39:57.403: INFO: namespace configmap-5155 deletion completed in 14.677939496s

• [SLOW TEST:99.879 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:39:57.403: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7001
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 04:39:57.731: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d" in namespace "downward-api-7001" to be "success or failure"
Apr 21 04:39:57.749: INFO: Pod "downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d": Phase="Pending", Reason="", readiness=false. Elapsed: 18.392745ms
Apr 21 04:39:59.762: INFO: Pod "downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031184989s
STEP: Saw pod success
Apr 21 04:39:59.762: INFO: Pod "downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d" satisfied condition "success or failure"
Apr 21 04:39:59.779: INFO: Trying to get logs from node 10.177.30.144 pod downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d container client-container: <nil>
STEP: delete the pod
Apr 21 04:39:59.882: INFO: Waiting for pod downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d to disappear
Apr 21 04:39:59.901: INFO: Pod downwardapi-volume-1c8ed69d-8aa4-40a2-a62f-e6cddb647c2d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:39:59.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7001" for this suite.
Apr 21 04:40:07.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:40:08.537: INFO: namespace downward-api-7001 deletion completed in 8.611501159s

• [SLOW TEST:11.134 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:40:08.538: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 04:40:08.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 version'
Apr 21 04:40:08.948: INFO: stderr: ""
Apr 21 04:40:08.949: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.9\", GitCommit:\"a17149e1a189050796ced469dbd78d380f2ed5ef\", GitTreeState:\"clean\", BuildDate:\"2020-04-16T11:44:51Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.9+IKS\", GitCommit:\"044064595e3a0af0d71be49184f82bdfc69924ac\", GitTreeState:\"clean\", BuildDate:\"2020-04-17T15:25:39Z\", GoVersion:\"go1.13.9\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:40:08.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1939" for this suite.
Apr 21 04:40:17.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:40:17.617: INFO: namespace kubectl-1939 deletion completed in 8.650275577s

• [SLOW TEST:9.079 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:40:17.618: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 04:40:17.907: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr 21 04:40:17.945: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr 21 04:40:22.960: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 21 04:40:24.989: INFO: Creating deployment "test-rolling-update-deployment"
Apr 21 04:40:25.020: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr 21 04:40:25.052: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr 21 04:40:27.088: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr 21 04:40:27.103: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 04:40:29.126: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723040825, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 04:40:31.370: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr 21 04:40:31.424: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7664 /apis/apps/v1/namespaces/deployment-7664/deployments/test-rolling-update-deployment 54d71666-8b5f-4c83-aa0b-4614fda6c312 18634 1 2020-04-21 04:40:24 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001f29038 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-21 04:40:25 +0000 UTC,LastTransitionTime:2020-04-21 04:40:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-04-21 04:40:29 +0000 UTC,LastTransitionTime:2020-04-21 04:40:25 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 21 04:40:31.443: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-7664 /apis/apps/v1/namespaces/deployment-7664/replicasets/test-rolling-update-deployment-55d946486 4d759d09-5ab8-4707-bf05-3338c5d7d9c0 18622 1 2020-04-21 04:40:25 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 54d71666-8b5f-4c83-aa0b-4614fda6c312 0xc001f29530 0xc001f29531}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001f29598 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 21 04:40:31.443: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr 21 04:40:31.443: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7664 /apis/apps/v1/namespaces/deployment-7664/replicasets/test-rolling-update-controller cb023755-356b-45b2-bdc5-f166744ae496 18633 2 2020-04-21 04:40:17 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 54d71666-8b5f-4c83-aa0b-4614fda6c312 0xc001f29457 0xc001f29458}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001f294b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 04:40:31.457: INFO: Pod "test-rolling-update-deployment-55d946486-r9m7c" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-r9m7c test-rolling-update-deployment-55d946486- deployment-7664 /api/v1/namespaces/deployment-7664/pods/test-rolling-update-deployment-55d946486-r9m7c e5653160-b73d-46d6-bb03-9692f19292ca 18621 0 2020-04-21 04:40:25 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 4d759d09-5ab8-4707-bf05-3338c5d7d9c0 0xc001f29a30 0xc001f29a31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-827f4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-827f4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-827f4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 04:40:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 04:40:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 04:40:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 04:40:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.174,StartTime:2020-04-21 04:40:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 04:40:28 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://4cb722f1b856af124afb7a58352570f811a6c8163d7ca81fffcded3923485493,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.174,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:40:31.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7664" for this suite.
Apr 21 04:40:39.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:40:40.129: INFO: namespace deployment-7664 deletion completed in 8.64823147s

• [SLOW TEST:22.511 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:40:40.129: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-945
I0421 04:40:40.440334      26 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-945, replica count: 1
I0421 04:40:41.490864      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0421 04:40:42.491105      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0421 04:40:43.491439      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 04:40:43.652: INFO: Created: latency-svc-xr7vr
Apr 21 04:40:43.726: INFO: Got endpoints: latency-svc-xr7vr [135.077779ms]
Apr 21 04:40:43.782: INFO: Created: latency-svc-l458z
Apr 21 04:40:43.797: INFO: Got endpoints: latency-svc-l458z [70.244867ms]
Apr 21 04:40:43.847: INFO: Created: latency-svc-wgnwh
Apr 21 04:40:43.869: INFO: Got endpoints: latency-svc-wgnwh [142.551762ms]
Apr 21 04:40:43.883: INFO: Created: latency-svc-n6nvs
Apr 21 04:40:43.902: INFO: Got endpoints: latency-svc-n6nvs [175.039256ms]
Apr 21 04:40:43.949: INFO: Created: latency-svc-z99ks
Apr 21 04:40:43.975: INFO: Created: latency-svc-hnfl6
Apr 21 04:40:43.980: INFO: Got endpoints: latency-svc-z99ks [253.07153ms]
Apr 21 04:40:43.995: INFO: Got endpoints: latency-svc-hnfl6 [267.981023ms]
Apr 21 04:40:44.042: INFO: Created: latency-svc-zbdp4
Apr 21 04:40:44.063: INFO: Got endpoints: latency-svc-zbdp4 [336.205316ms]
Apr 21 04:40:44.090: INFO: Created: latency-svc-4vg4k
Apr 21 04:40:44.110: INFO: Got endpoints: latency-svc-4vg4k [383.315492ms]
Apr 21 04:40:44.136: INFO: Created: latency-svc-vvx74
Apr 21 04:40:44.194: INFO: Got endpoints: latency-svc-vvx74 [466.779997ms]
Apr 21 04:40:44.207: INFO: Created: latency-svc-9hdp4
Apr 21 04:40:44.229: INFO: Got endpoints: latency-svc-9hdp4 [501.746122ms]
Apr 21 04:40:44.279: INFO: Created: latency-svc-qgpnc
Apr 21 04:40:44.287: INFO: Got endpoints: latency-svc-qgpnc [559.857948ms]
Apr 21 04:40:44.315: INFO: Created: latency-svc-5s486
Apr 21 04:40:44.354: INFO: Created: latency-svc-wm99m
Apr 21 04:40:44.367: INFO: Got endpoints: latency-svc-5s486 [640.287461ms]
Apr 21 04:40:44.381: INFO: Got endpoints: latency-svc-wm99m [654.244315ms]
Apr 21 04:40:44.402: INFO: Created: latency-svc-nq9zw
Apr 21 04:40:44.423: INFO: Got endpoints: latency-svc-nq9zw [696.08984ms]
Apr 21 04:40:44.434: INFO: Created: latency-svc-lmkxd
Apr 21 04:40:44.473: INFO: Got endpoints: latency-svc-lmkxd [746.186795ms]
Apr 21 04:40:44.521: INFO: Created: latency-svc-lf469
Apr 21 04:40:44.571: INFO: Got endpoints: latency-svc-lf469 [844.717593ms]
Apr 21 04:40:44.650: INFO: Created: latency-svc-kcm5k
Apr 21 04:40:44.676: INFO: Got endpoints: latency-svc-kcm5k [879.330509ms]
Apr 21 04:40:44.754: INFO: Created: latency-svc-z4s4w
Apr 21 04:40:44.766: INFO: Got endpoints: latency-svc-z4s4w [896.729897ms]
Apr 21 04:40:44.841: INFO: Created: latency-svc-vdlt2
Apr 21 04:40:44.930: INFO: Got endpoints: latency-svc-vdlt2 [1.027739473s]
Apr 21 04:40:45.018: INFO: Created: latency-svc-nzdkw
Apr 21 04:40:45.056: INFO: Created: latency-svc-glndd
Apr 21 04:40:45.057: INFO: Got endpoints: latency-svc-nzdkw [1.076804719s]
Apr 21 04:40:45.081: INFO: Got endpoints: latency-svc-glndd [1.085567505s]
Apr 21 04:40:45.101: INFO: Created: latency-svc-kgj6n
Apr 21 04:40:45.123: INFO: Got endpoints: latency-svc-kgj6n [1.058824038s]
Apr 21 04:40:45.135: INFO: Created: latency-svc-g28d8
Apr 21 04:40:45.161: INFO: Got endpoints: latency-svc-g28d8 [1.050344235s]
Apr 21 04:40:45.206: INFO: Created: latency-svc-lqln2
Apr 21 04:40:45.226: INFO: Got endpoints: latency-svc-lqln2 [1.031838187s]
Apr 21 04:40:45.240: INFO: Created: latency-svc-h7dqk
Apr 21 04:40:45.275: INFO: Got endpoints: latency-svc-h7dqk [1.045963455s]
Apr 21 04:40:45.284: INFO: Created: latency-svc-z45fz
Apr 21 04:40:45.296: INFO: Got endpoints: latency-svc-z45fz [1.008908861s]
Apr 21 04:40:45.325: INFO: Created: latency-svc-gb89q
Apr 21 04:40:45.346: INFO: Got endpoints: latency-svc-gb89q [978.569619ms]
Apr 21 04:40:45.357: INFO: Created: latency-svc-dhtft
Apr 21 04:40:45.375: INFO: Got endpoints: latency-svc-dhtft [993.41842ms]
Apr 21 04:40:45.386: INFO: Created: latency-svc-nk6kf
Apr 21 04:40:45.403: INFO: Got endpoints: latency-svc-nk6kf [979.956862ms]
Apr 21 04:40:45.429: INFO: Created: latency-svc-6vwks
Apr 21 04:40:45.486: INFO: Got endpoints: latency-svc-6vwks [1.01289581s]
Apr 21 04:40:45.497: INFO: Created: latency-svc-6nm6s
Apr 21 04:40:45.515: INFO: Got endpoints: latency-svc-6nm6s [943.239862ms]
Apr 21 04:40:45.669: INFO: Created: latency-svc-v56vb
Apr 21 04:40:45.697: INFO: Got endpoints: latency-svc-v56vb [1.020954098s]
Apr 21 04:40:45.717: INFO: Created: latency-svc-5xg6p
Apr 21 04:40:45.744: INFO: Got endpoints: latency-svc-5xg6p [977.790936ms]
Apr 21 04:40:45.758: INFO: Created: latency-svc-b8vwl
Apr 21 04:40:45.783: INFO: Got endpoints: latency-svc-b8vwl [853.25908ms]
Apr 21 04:40:45.822: INFO: Created: latency-svc-st9dv
Apr 21 04:40:45.846: INFO: Got endpoints: latency-svc-st9dv [788.797284ms]
Apr 21 04:40:45.862: INFO: Created: latency-svc-4fzbz
Apr 21 04:40:45.885: INFO: Got endpoints: latency-svc-4fzbz [804.288286ms]
Apr 21 04:40:45.907: INFO: Created: latency-svc-rc49j
Apr 21 04:40:45.953: INFO: Got endpoints: latency-svc-rc49j [830.416817ms]
Apr 21 04:40:46.001: INFO: Created: latency-svc-hdwr2
Apr 21 04:40:46.031: INFO: Got endpoints: latency-svc-hdwr2 [870.481051ms]
Apr 21 04:40:46.093: INFO: Created: latency-svc-x7wkw
Apr 21 04:40:46.115: INFO: Got endpoints: latency-svc-x7wkw [888.72171ms]
Apr 21 04:40:46.131: INFO: Created: latency-svc-hwhqg
Apr 21 04:40:46.148: INFO: Got endpoints: latency-svc-hwhqg [873.108744ms]
Apr 21 04:40:46.161: INFO: Created: latency-svc-hrwrq
Apr 21 04:40:46.191: INFO: Got endpoints: latency-svc-hrwrq [895.0803ms]
Apr 21 04:40:46.222: INFO: Created: latency-svc-br8vz
Apr 21 04:40:46.247: INFO: Got endpoints: latency-svc-br8vz [901.560201ms]
Apr 21 04:40:46.277: INFO: Created: latency-svc-bcw4x
Apr 21 04:40:46.319: INFO: Got endpoints: latency-svc-bcw4x [944.702615ms]
Apr 21 04:40:46.347: INFO: Created: latency-svc-fwwdj
Apr 21 04:40:46.365: INFO: Got endpoints: latency-svc-fwwdj [962.092961ms]
Apr 21 04:40:46.382: INFO: Created: latency-svc-bd447
Apr 21 04:40:46.402: INFO: Got endpoints: latency-svc-bd447 [915.951562ms]
Apr 21 04:40:46.433: INFO: Created: latency-svc-rrf2h
Apr 21 04:40:46.462: INFO: Got endpoints: latency-svc-rrf2h [946.748896ms]
Apr 21 04:40:46.563: INFO: Created: latency-svc-pkc52
Apr 21 04:40:46.594: INFO: Got endpoints: latency-svc-pkc52 [896.868344ms]
Apr 21 04:40:46.617: INFO: Created: latency-svc-bs8dp
Apr 21 04:40:46.642: INFO: Got endpoints: latency-svc-bs8dp [897.636897ms]
Apr 21 04:40:46.658: INFO: Created: latency-svc-bpkw4
Apr 21 04:40:46.687: INFO: Got endpoints: latency-svc-bpkw4 [903.609648ms]
Apr 21 04:40:46.718: INFO: Created: latency-svc-w5wgt
Apr 21 04:40:46.760: INFO: Got endpoints: latency-svc-w5wgt [913.762701ms]
Apr 21 04:40:46.772: INFO: Created: latency-svc-hlrqw
Apr 21 04:40:46.813: INFO: Created: latency-svc-mv22h
Apr 21 04:40:46.816: INFO: Got endpoints: latency-svc-hlrqw [930.994171ms]
Apr 21 04:40:46.870: INFO: Created: latency-svc-ndgmb
Apr 21 04:40:46.925: INFO: Created: latency-svc-t4kxk
Apr 21 04:40:47.001: INFO: Got endpoints: latency-svc-ndgmb [969.755977ms]
Apr 21 04:40:47.003: INFO: Got endpoints: latency-svc-mv22h [1.049360768s]
Apr 21 04:40:47.021: INFO: Created: latency-svc-xq6lg
Apr 21 04:40:47.042: INFO: Got endpoints: latency-svc-t4kxk [927.093768ms]
Apr 21 04:40:47.050: INFO: Got endpoints: latency-svc-xq6lg [901.888095ms]
Apr 21 04:40:47.269: INFO: Created: latency-svc-49mzx
Apr 21 04:40:47.348: INFO: Got endpoints: latency-svc-49mzx [1.15659295s]
Apr 21 04:40:47.363: INFO: Created: latency-svc-kkwzj
Apr 21 04:40:47.782: INFO: Got endpoints: latency-svc-kkwzj [1.534336795s]
Apr 21 04:40:47.788: INFO: Created: latency-svc-lw2gd
Apr 21 04:40:47.835: INFO: Got endpoints: latency-svc-lw2gd [1.515428846s]
Apr 21 04:40:47.859: INFO: Created: latency-svc-v99zh
Apr 21 04:40:47.974: INFO: Got endpoints: latency-svc-v99zh [1.608269167s]
Apr 21 04:40:47.986: INFO: Created: latency-svc-4k9sw
Apr 21 04:40:48.041: INFO: Got endpoints: latency-svc-4k9sw [1.638901986s]
Apr 21 04:40:48.060: INFO: Created: latency-svc-8cgw7
Apr 21 04:40:48.087: INFO: Got endpoints: latency-svc-8cgw7 [1.625430228s]
Apr 21 04:40:48.105: INFO: Created: latency-svc-t4v4r
Apr 21 04:40:48.130: INFO: Got endpoints: latency-svc-t4v4r [1.536023103s]
Apr 21 04:40:48.247: INFO: Created: latency-svc-qxmk9
Apr 21 04:40:48.281: INFO: Got endpoints: latency-svc-qxmk9 [1.63903174s]
Apr 21 04:40:48.310: INFO: Created: latency-svc-tc22r
Apr 21 04:40:48.335: INFO: Got endpoints: latency-svc-tc22r [1.648022948s]
Apr 21 04:40:48.343: INFO: Created: latency-svc-xsklr
Apr 21 04:40:48.359: INFO: Got endpoints: latency-svc-xsklr [1.598912343s]
Apr 21 04:40:48.380: INFO: Created: latency-svc-kntlh
Apr 21 04:40:48.418: INFO: Got endpoints: latency-svc-kntlh [1.601661558s]
Apr 21 04:40:48.437: INFO: Created: latency-svc-v9vvk
Apr 21 04:40:48.478: INFO: Got endpoints: latency-svc-v9vvk [1.476689986s]
Apr 21 04:40:48.515: INFO: Created: latency-svc-9gvwb
Apr 21 04:40:48.556: INFO: Got endpoints: latency-svc-9gvwb [1.514187768s]
Apr 21 04:40:48.590: INFO: Created: latency-svc-44zcv
Apr 21 04:40:48.643: INFO: Created: latency-svc-tc5v7
Apr 21 04:40:48.644: INFO: Got endpoints: latency-svc-44zcv [1.593429311s]
Apr 21 04:40:48.698: INFO: Created: latency-svc-2fm46
Apr 21 04:40:48.745: INFO: Got endpoints: latency-svc-tc5v7 [1.742510202s]
Apr 21 04:40:48.757: INFO: Created: latency-svc-dkfrs
Apr 21 04:40:48.801: INFO: Got endpoints: latency-svc-2fm46 [1.453427622s]
Apr 21 04:40:48.846: INFO: Got endpoints: latency-svc-dkfrs [1.064226094s]
Apr 21 04:40:48.938: INFO: Created: latency-svc-zs9vq
Apr 21 04:40:48.967: INFO: Got endpoints: latency-svc-zs9vq [1.132339361s]
Apr 21 04:40:48.977: INFO: Created: latency-svc-gzp45
Apr 21 04:40:49.024: INFO: Got endpoints: latency-svc-gzp45 [1.050316264s]
Apr 21 04:40:49.087: INFO: Created: latency-svc-wn6k4
Apr 21 04:40:49.115: INFO: Got endpoints: latency-svc-wn6k4 [1.073667365s]
Apr 21 04:40:49.141: INFO: Created: latency-svc-7ngsz
Apr 21 04:40:49.200: INFO: Created: latency-svc-7nnf8
Apr 21 04:40:49.213: INFO: Got endpoints: latency-svc-7ngsz [1.126181746s]
Apr 21 04:40:49.243: INFO: Got endpoints: latency-svc-7nnf8 [1.112283357s]
Apr 21 04:40:49.313: INFO: Created: latency-svc-d29n9
Apr 21 04:40:49.344: INFO: Got endpoints: latency-svc-d29n9 [1.062732215s]
Apr 21 04:40:49.405: INFO: Created: latency-svc-qvc8f
Apr 21 04:40:49.453: INFO: Got endpoints: latency-svc-qvc8f [1.118348232s]
Apr 21 04:40:49.484: INFO: Created: latency-svc-rztxl
Apr 21 04:40:49.511: INFO: Got endpoints: latency-svc-rztxl [1.15185981s]
Apr 21 04:40:49.560: INFO: Created: latency-svc-xrx9h
Apr 21 04:40:49.606: INFO: Got endpoints: latency-svc-xrx9h [1.187679796s]
Apr 21 04:40:49.700: INFO: Created: latency-svc-47xf2
Apr 21 04:40:49.849: INFO: Got endpoints: latency-svc-47xf2 [1.37062226s]
Apr 21 04:40:49.891: INFO: Created: latency-svc-lflgf
Apr 21 04:40:49.911: INFO: Got endpoints: latency-svc-lflgf [1.354804485s]
Apr 21 04:40:49.922: INFO: Created: latency-svc-bktbr
Apr 21 04:40:49.969: INFO: Got endpoints: latency-svc-bktbr [1.324782469s]
Apr 21 04:40:50.071: INFO: Created: latency-svc-nxm5s
Apr 21 04:40:50.095: INFO: Got endpoints: latency-svc-nxm5s [1.349805824s]
Apr 21 04:40:50.165: INFO: Created: latency-svc-28cvt
Apr 21 04:40:50.194: INFO: Got endpoints: latency-svc-28cvt [1.392862025s]
Apr 21 04:40:50.209: INFO: Created: latency-svc-sk2pv
Apr 21 04:40:50.230: INFO: Got endpoints: latency-svc-sk2pv [1.383675757s]
Apr 21 04:40:50.243: INFO: Created: latency-svc-jq2xh
Apr 21 04:40:50.293: INFO: Got endpoints: latency-svc-jq2xh [1.325135322s]
Apr 21 04:40:50.306: INFO: Created: latency-svc-phx54
Apr 21 04:40:50.325: INFO: Got endpoints: latency-svc-phx54 [1.301027291s]
Apr 21 04:40:50.341: INFO: Created: latency-svc-b7xf4
Apr 21 04:40:50.368: INFO: Got endpoints: latency-svc-b7xf4 [1.253365913s]
Apr 21 04:40:50.444: INFO: Created: latency-svc-9xnvk
Apr 21 04:40:50.462: INFO: Got endpoints: latency-svc-9xnvk [1.248898742s]
Apr 21 04:40:50.493: INFO: Created: latency-svc-qc2k8
Apr 21 04:40:50.526: INFO: Got endpoints: latency-svc-qc2k8 [1.283432247s]
Apr 21 04:40:50.545: INFO: Created: latency-svc-np68w
Apr 21 04:40:50.635: INFO: Got endpoints: latency-svc-np68w [1.291053127s]
Apr 21 04:40:50.645: INFO: Created: latency-svc-z4n8t
Apr 21 04:40:50.675: INFO: Got endpoints: latency-svc-z4n8t [1.221219869s]
Apr 21 04:40:50.724: INFO: Created: latency-svc-pgxf2
Apr 21 04:40:50.749: INFO: Got endpoints: latency-svc-pgxf2 [1.238487286s]
Apr 21 04:40:50.765: INFO: Created: latency-svc-mpxds
Apr 21 04:40:50.793: INFO: Got endpoints: latency-svc-mpxds [1.187491268s]
Apr 21 04:40:50.806: INFO: Created: latency-svc-n46gh
Apr 21 04:40:50.829: INFO: Got endpoints: latency-svc-n46gh [980.399074ms]
Apr 21 04:40:50.861: INFO: Created: latency-svc-rsl8b
Apr 21 04:40:50.882: INFO: Got endpoints: latency-svc-rsl8b [971.018397ms]
Apr 21 04:40:50.907: INFO: Created: latency-svc-l7zkj
Apr 21 04:40:50.930: INFO: Got endpoints: latency-svc-l7zkj [961.382354ms]
Apr 21 04:40:50.940: INFO: Created: latency-svc-krxsq
Apr 21 04:40:50.969: INFO: Got endpoints: latency-svc-krxsq [873.857048ms]
Apr 21 04:40:50.971: INFO: Created: latency-svc-jkxjm
Apr 21 04:40:51.006: INFO: Got endpoints: latency-svc-jkxjm [812.152475ms]
Apr 21 04:40:51.021: INFO: Created: latency-svc-55bz7
Apr 21 04:40:51.048: INFO: Got endpoints: latency-svc-55bz7 [817.971474ms]
Apr 21 04:40:51.088: INFO: Created: latency-svc-fk2ll
Apr 21 04:40:51.108: INFO: Got endpoints: latency-svc-fk2ll [815.526573ms]
Apr 21 04:40:51.119: INFO: Created: latency-svc-ztk5s
Apr 21 04:40:51.135: INFO: Got endpoints: latency-svc-ztk5s [809.388914ms]
Apr 21 04:40:51.169: INFO: Created: latency-svc-xjpl8
Apr 21 04:40:51.201: INFO: Got endpoints: latency-svc-xjpl8 [832.759794ms]
Apr 21 04:40:51.215: INFO: Created: latency-svc-kjcrx
Apr 21 04:40:51.236: INFO: Got endpoints: latency-svc-kjcrx [772.930475ms]
Apr 21 04:40:51.253: INFO: Created: latency-svc-g7bjv
Apr 21 04:40:51.271: INFO: Got endpoints: latency-svc-g7bjv [744.754982ms]
Apr 21 04:40:51.288: INFO: Created: latency-svc-d6d4f
Apr 21 04:40:51.360: INFO: Got endpoints: latency-svc-d6d4f [724.95903ms]
Apr 21 04:40:51.425: INFO: Created: latency-svc-54tcj
Apr 21 04:40:51.542: INFO: Got endpoints: latency-svc-54tcj [866.992308ms]
Apr 21 04:40:51.578: INFO: Created: latency-svc-zgfmn
Apr 21 04:40:51.610: INFO: Got endpoints: latency-svc-zgfmn [860.806766ms]
Apr 21 04:40:51.760: INFO: Created: latency-svc-cfqbz
Apr 21 04:40:51.835: INFO: Got endpoints: latency-svc-cfqbz [1.041726832s]
Apr 21 04:40:51.932: INFO: Created: latency-svc-kdpfb
Apr 21 04:40:52.103: INFO: Got endpoints: latency-svc-kdpfb [1.273707127s]
Apr 21 04:40:52.128: INFO: Created: latency-svc-cp7h5
Apr 21 04:40:52.149: INFO: Got endpoints: latency-svc-cp7h5 [1.266799286s]
Apr 21 04:40:52.380: INFO: Created: latency-svc-44sgm
Apr 21 04:40:52.414: INFO: Got endpoints: latency-svc-44sgm [1.483160307s]
Apr 21 04:40:52.429: INFO: Created: latency-svc-x85tf
Apr 21 04:40:52.458: INFO: Got endpoints: latency-svc-x85tf [1.488794366s]
Apr 21 04:40:52.498: INFO: Created: latency-svc-q5rsh
Apr 21 04:40:52.528: INFO: Got endpoints: latency-svc-q5rsh [1.520960017s]
Apr 21 04:40:52.573: INFO: Created: latency-svc-llnf6
Apr 21 04:40:52.600: INFO: Got endpoints: latency-svc-llnf6 [1.551624572s]
Apr 21 04:40:52.629: INFO: Created: latency-svc-rpfmn
Apr 21 04:40:52.650: INFO: Got endpoints: latency-svc-rpfmn [1.541909055s]
Apr 21 04:40:52.671: INFO: Created: latency-svc-jb9zd
Apr 21 04:40:52.693: INFO: Got endpoints: latency-svc-jb9zd [1.558547644s]
Apr 21 04:40:52.737: INFO: Created: latency-svc-wzc9z
Apr 21 04:40:52.753: INFO: Got endpoints: latency-svc-wzc9z [1.551816209s]
Apr 21 04:40:52.789: INFO: Created: latency-svc-mkzmg
Apr 21 04:40:52.822: INFO: Got endpoints: latency-svc-mkzmg [1.58687978s]
Apr 21 04:40:52.834: INFO: Created: latency-svc-d7p6r
Apr 21 04:40:52.870: INFO: Got endpoints: latency-svc-d7p6r [1.59898013s]
Apr 21 04:40:52.932: INFO: Created: latency-svc-lpj6x
Apr 21 04:40:52.967: INFO: Got endpoints: latency-svc-lpj6x [1.606743445s]
Apr 21 04:40:52.982: INFO: Created: latency-svc-6w8pc
Apr 21 04:40:53.082: INFO: Got endpoints: latency-svc-6w8pc [1.540171817s]
Apr 21 04:40:53.094: INFO: Created: latency-svc-v5gb8
Apr 21 04:40:53.141: INFO: Got endpoints: latency-svc-v5gb8 [1.53025831s]
Apr 21 04:40:53.177: INFO: Created: latency-svc-lgfm4
Apr 21 04:40:53.194: INFO: Got endpoints: latency-svc-lgfm4 [1.358410066s]
Apr 21 04:40:53.214: INFO: Created: latency-svc-6kmlj
Apr 21 04:40:53.238: INFO: Created: latency-svc-w9mvz
Apr 21 04:40:53.244: INFO: Got endpoints: latency-svc-6kmlj [1.14022435s]
Apr 21 04:40:53.281: INFO: Got endpoints: latency-svc-w9mvz [1.131235432s]
Apr 21 04:40:53.321: INFO: Created: latency-svc-rxdbb
Apr 21 04:40:53.346: INFO: Created: latency-svc-vz998
Apr 21 04:40:53.346: INFO: Got endpoints: latency-svc-rxdbb [932.707051ms]
Apr 21 04:40:53.365: INFO: Got endpoints: latency-svc-vz998 [906.551684ms]
Apr 21 04:40:53.382: INFO: Created: latency-svc-nhlfp
Apr 21 04:40:53.404: INFO: Got endpoints: latency-svc-nhlfp [876.780345ms]
Apr 21 04:40:53.422: INFO: Created: latency-svc-zxhwh
Apr 21 04:40:53.445: INFO: Got endpoints: latency-svc-zxhwh [845.680073ms]
Apr 21 04:40:53.447: INFO: Created: latency-svc-8kjgn
Apr 21 04:40:53.466: INFO: Got endpoints: latency-svc-8kjgn [816.067632ms]
Apr 21 04:40:53.476: INFO: Created: latency-svc-sjd9l
Apr 21 04:40:53.491: INFO: Got endpoints: latency-svc-sjd9l [797.566599ms]
Apr 21 04:40:53.522: INFO: Created: latency-svc-969rr
Apr 21 04:40:53.547: INFO: Got endpoints: latency-svc-969rr [793.322181ms]
Apr 21 04:40:53.561: INFO: Created: latency-svc-q2x5l
Apr 21 04:40:53.590: INFO: Got endpoints: latency-svc-q2x5l [767.264299ms]
Apr 21 04:40:53.639: INFO: Created: latency-svc-cd9mn
Apr 21 04:40:53.663: INFO: Got endpoints: latency-svc-cd9mn [792.265288ms]
Apr 21 04:40:53.704: INFO: Created: latency-svc-sgzc6
Apr 21 04:40:53.840: INFO: Got endpoints: latency-svc-sgzc6 [872.6879ms]
Apr 21 04:40:53.872: INFO: Created: latency-svc-xbdhw
Apr 21 04:40:53.897: INFO: Got endpoints: latency-svc-xbdhw [814.776199ms]
Apr 21 04:40:54.034: INFO: Created: latency-svc-9ljnb
Apr 21 04:40:54.061: INFO: Got endpoints: latency-svc-9ljnb [920.592049ms]
Apr 21 04:40:54.091: INFO: Created: latency-svc-99flk
Apr 21 04:40:54.115: INFO: Got endpoints: latency-svc-99flk [921.489851ms]
Apr 21 04:40:54.133: INFO: Created: latency-svc-w6mpq
Apr 21 04:40:54.180: INFO: Got endpoints: latency-svc-w6mpq [935.885085ms]
Apr 21 04:40:54.191: INFO: Created: latency-svc-tfdj9
Apr 21 04:40:54.222: INFO: Got endpoints: latency-svc-tfdj9 [941.934254ms]
Apr 21 04:40:54.234: INFO: Created: latency-svc-wwmq6
Apr 21 04:40:54.270: INFO: Got endpoints: latency-svc-wwmq6 [923.373846ms]
Apr 21 04:40:54.280: INFO: Created: latency-svc-8bn6k
Apr 21 04:40:54.321: INFO: Got endpoints: latency-svc-8bn6k [956.088529ms]
Apr 21 04:40:54.330: INFO: Created: latency-svc-fwvjw
Apr 21 04:40:54.354: INFO: Got endpoints: latency-svc-fwvjw [949.852848ms]
Apr 21 04:40:54.369: INFO: Created: latency-svc-dkg8d
Apr 21 04:40:54.389: INFO: Got endpoints: latency-svc-dkg8d [943.741234ms]
Apr 21 04:40:54.404: INFO: Created: latency-svc-vlgbv
Apr 21 04:40:54.422: INFO: Got endpoints: latency-svc-vlgbv [955.606532ms]
Apr 21 04:40:54.443: INFO: Created: latency-svc-4c4n7
Apr 21 04:40:54.464: INFO: Got endpoints: latency-svc-4c4n7 [973.334491ms]
Apr 21 04:40:54.486: INFO: Created: latency-svc-r9xzq
Apr 21 04:40:54.503: INFO: Got endpoints: latency-svc-r9xzq [956.146369ms]
Apr 21 04:40:54.542: INFO: Created: latency-svc-h729d
Apr 21 04:40:54.562: INFO: Got endpoints: latency-svc-h729d [972.087294ms]
Apr 21 04:40:54.583: INFO: Created: latency-svc-2n4pn
Apr 21 04:40:54.628: INFO: Got endpoints: latency-svc-2n4pn [965.2454ms]
Apr 21 04:40:54.633: INFO: Created: latency-svc-gq2zb
Apr 21 04:40:54.672: INFO: Got endpoints: latency-svc-gq2zb [831.831478ms]
Apr 21 04:40:54.716: INFO: Created: latency-svc-b7vzz
Apr 21 04:40:54.734: INFO: Got endpoints: latency-svc-b7vzz [836.475576ms]
Apr 21 04:40:54.745: INFO: Created: latency-svc-7wrkn
Apr 21 04:40:54.778: INFO: Got endpoints: latency-svc-7wrkn [716.223303ms]
Apr 21 04:40:54.796: INFO: Created: latency-svc-p89jq
Apr 21 04:40:54.824: INFO: Got endpoints: latency-svc-p89jq [708.957465ms]
Apr 21 04:40:54.866: INFO: Created: latency-svc-nxvcx
Apr 21 04:40:54.888: INFO: Got endpoints: latency-svc-nxvcx [708.616699ms]
Apr 21 04:40:54.902: INFO: Created: latency-svc-r4xxp
Apr 21 04:40:54.928: INFO: Got endpoints: latency-svc-r4xxp [704.612719ms]
Apr 21 04:40:54.938: INFO: Created: latency-svc-rzd8f
Apr 21 04:40:54.962: INFO: Got endpoints: latency-svc-rzd8f [692.382991ms]
Apr 21 04:40:54.978: INFO: Created: latency-svc-2vxs7
Apr 21 04:40:55.032: INFO: Got endpoints: latency-svc-2vxs7 [710.587511ms]
Apr 21 04:40:55.042: INFO: Created: latency-svc-8cbgz
Apr 21 04:40:55.066: INFO: Got endpoints: latency-svc-8cbgz [712.02975ms]
Apr 21 04:40:55.129: INFO: Created: latency-svc-nd66f
Apr 21 04:40:55.147: INFO: Got endpoints: latency-svc-nd66f [757.412616ms]
Apr 21 04:40:55.205: INFO: Created: latency-svc-rc8j4
Apr 21 04:40:55.228: INFO: Got endpoints: latency-svc-rc8j4 [806.139023ms]
Apr 21 04:40:55.243: INFO: Created: latency-svc-rvcmf
Apr 21 04:40:55.274: INFO: Got endpoints: latency-svc-rvcmf [809.155717ms]
Apr 21 04:40:55.290: INFO: Created: latency-svc-mzw8h
Apr 21 04:40:55.322: INFO: Got endpoints: latency-svc-mzw8h [818.186372ms]
Apr 21 04:40:55.341: INFO: Created: latency-svc-h9vd7
Apr 21 04:40:55.379: INFO: Got endpoints: latency-svc-h9vd7 [817.091237ms]
Apr 21 04:40:55.394: INFO: Created: latency-svc-gvbtq
Apr 21 04:40:55.433: INFO: Created: latency-svc-vf94f
Apr 21 04:40:55.434: INFO: Got endpoints: latency-svc-gvbtq [806.158096ms]
Apr 21 04:40:55.457: INFO: Got endpoints: latency-svc-vf94f [785.351086ms]
Apr 21 04:40:55.493: INFO: Created: latency-svc-lnkmt
Apr 21 04:40:55.519: INFO: Got endpoints: latency-svc-lnkmt [785.201392ms]
Apr 21 04:40:55.530: INFO: Created: latency-svc-zhlxn
Apr 21 04:40:55.570: INFO: Got endpoints: latency-svc-zhlxn [792.33939ms]
Apr 21 04:40:55.582: INFO: Created: latency-svc-q5vv9
Apr 21 04:40:55.619: INFO: Got endpoints: latency-svc-q5vv9 [794.918938ms]
Apr 21 04:40:55.634: INFO: Created: latency-svc-c8wxv
Apr 21 04:40:55.678: INFO: Got endpoints: latency-svc-c8wxv [789.528724ms]
Apr 21 04:40:55.723: INFO: Created: latency-svc-j7767
Apr 21 04:40:55.745: INFO: Got endpoints: latency-svc-j7767 [817.136442ms]
Apr 21 04:40:55.756: INFO: Created: latency-svc-gxmrl
Apr 21 04:40:55.785: INFO: Got endpoints: latency-svc-gxmrl [822.645475ms]
Apr 21 04:40:55.819: INFO: Created: latency-svc-kntwq
Apr 21 04:40:55.845: INFO: Got endpoints: latency-svc-kntwq [813.345269ms]
Apr 21 04:40:55.862: INFO: Created: latency-svc-z8rg7
Apr 21 04:40:55.894: INFO: Got endpoints: latency-svc-z8rg7 [827.883687ms]
Apr 21 04:40:55.908: INFO: Created: latency-svc-99dsh
Apr 21 04:40:55.933: INFO: Got endpoints: latency-svc-99dsh [785.752192ms]
Apr 21 04:40:55.943: INFO: Created: latency-svc-h2xdm
Apr 21 04:40:55.962: INFO: Got endpoints: latency-svc-h2xdm [733.735217ms]
Apr 21 04:40:55.990: INFO: Created: latency-svc-dnqf7
Apr 21 04:40:56.033: INFO: Got endpoints: latency-svc-dnqf7 [759.153652ms]
Apr 21 04:40:56.047: INFO: Created: latency-svc-mjx9f
Apr 21 04:40:56.141: INFO: Got endpoints: latency-svc-mjx9f [817.790751ms]
Apr 21 04:40:56.181: INFO: Created: latency-svc-p6qd2
Apr 21 04:40:56.209: INFO: Got endpoints: latency-svc-p6qd2 [829.418027ms]
Apr 21 04:40:56.318: INFO: Created: latency-svc-t7jqc
Apr 21 04:40:56.350: INFO: Got endpoints: latency-svc-t7jqc [915.270262ms]
Apr 21 04:40:56.393: INFO: Created: latency-svc-lv6nb
Apr 21 04:40:56.442: INFO: Got endpoints: latency-svc-lv6nb [984.70399ms]
Apr 21 04:40:56.483: INFO: Created: latency-svc-q9976
Apr 21 04:40:56.506: INFO: Got endpoints: latency-svc-q9976 [987.363304ms]
Apr 21 04:40:56.534: INFO: Created: latency-svc-mqvph
Apr 21 04:40:56.575: INFO: Got endpoints: latency-svc-mqvph [1.004516569s]
Apr 21 04:40:56.591: INFO: Created: latency-svc-n2fvk
Apr 21 04:40:56.614: INFO: Got endpoints: latency-svc-n2fvk [993.995142ms]
Apr 21 04:40:56.629: INFO: Created: latency-svc-mf6nr
Apr 21 04:40:56.651: INFO: Got endpoints: latency-svc-mf6nr [973.251489ms]
Apr 21 04:40:56.697: INFO: Created: latency-svc-jkv2m
Apr 21 04:40:56.732: INFO: Got endpoints: latency-svc-jkv2m [986.734679ms]
Apr 21 04:40:56.741: INFO: Created: latency-svc-l2kt8
Apr 21 04:40:56.774: INFO: Created: latency-svc-c8wwr
Apr 21 04:40:56.782: INFO: Got endpoints: latency-svc-l2kt8 [996.645202ms]
Apr 21 04:40:56.805: INFO: Got endpoints: latency-svc-c8wwr [959.880624ms]
Apr 21 04:40:56.819: INFO: Created: latency-svc-bvl45
Apr 21 04:40:56.845: INFO: Got endpoints: latency-svc-bvl45 [950.200032ms]
Apr 21 04:40:56.858: INFO: Created: latency-svc-55487
Apr 21 04:40:56.887: INFO: Got endpoints: latency-svc-55487 [954.158647ms]
Apr 21 04:40:56.900: INFO: Created: latency-svc-2jb4f
Apr 21 04:40:56.921: INFO: Got endpoints: latency-svc-2jb4f [958.911348ms]
Apr 21 04:40:56.957: INFO: Created: latency-svc-xsvb7
Apr 21 04:40:56.982: INFO: Got endpoints: latency-svc-xsvb7 [948.637861ms]
Apr 21 04:40:57.009: INFO: Created: latency-svc-whbhn
Apr 21 04:40:57.078: INFO: Got endpoints: latency-svc-whbhn [937.127655ms]
Apr 21 04:40:57.094: INFO: Created: latency-svc-z2r52
Apr 21 04:40:57.117: INFO: Got endpoints: latency-svc-z2r52 [907.685443ms]
Apr 21 04:40:57.127: INFO: Created: latency-svc-692g4
Apr 21 04:40:57.153: INFO: Got endpoints: latency-svc-692g4 [803.443155ms]
Apr 21 04:40:57.169: INFO: Created: latency-svc-cnt66
Apr 21 04:40:57.207: INFO: Got endpoints: latency-svc-cnt66 [764.924512ms]
Apr 21 04:40:57.219: INFO: Created: latency-svc-wg5v7
Apr 21 04:40:57.243: INFO: Got endpoints: latency-svc-wg5v7 [736.352322ms]
Apr 21 04:40:57.259: INFO: Created: latency-svc-dd8qf
Apr 21 04:40:57.281: INFO: Got endpoints: latency-svc-dd8qf [705.868637ms]
Apr 21 04:40:57.293: INFO: Created: latency-svc-w2fzw
Apr 21 04:40:57.311: INFO: Got endpoints: latency-svc-w2fzw [697.362198ms]
Apr 21 04:40:57.311: INFO: Latencies: [70.244867ms 142.551762ms 175.039256ms 253.07153ms 267.981023ms 336.205316ms 383.315492ms 466.779997ms 501.746122ms 559.857948ms 640.287461ms 654.244315ms 692.382991ms 696.08984ms 697.362198ms 704.612719ms 705.868637ms 708.616699ms 708.957465ms 710.587511ms 712.02975ms 716.223303ms 724.95903ms 733.735217ms 736.352322ms 744.754982ms 746.186795ms 757.412616ms 759.153652ms 764.924512ms 767.264299ms 772.930475ms 785.201392ms 785.351086ms 785.752192ms 788.797284ms 789.528724ms 792.265288ms 792.33939ms 793.322181ms 794.918938ms 797.566599ms 803.443155ms 804.288286ms 806.139023ms 806.158096ms 809.155717ms 809.388914ms 812.152475ms 813.345269ms 814.776199ms 815.526573ms 816.067632ms 817.091237ms 817.136442ms 817.790751ms 817.971474ms 818.186372ms 822.645475ms 827.883687ms 829.418027ms 830.416817ms 831.831478ms 832.759794ms 836.475576ms 844.717593ms 845.680073ms 853.25908ms 860.806766ms 866.992308ms 870.481051ms 872.6879ms 873.108744ms 873.857048ms 876.780345ms 879.330509ms 888.72171ms 895.0803ms 896.729897ms 896.868344ms 897.636897ms 901.560201ms 901.888095ms 903.609648ms 906.551684ms 907.685443ms 913.762701ms 915.270262ms 915.951562ms 920.592049ms 921.489851ms 923.373846ms 927.093768ms 930.994171ms 932.707051ms 935.885085ms 937.127655ms 941.934254ms 943.239862ms 943.741234ms 944.702615ms 946.748896ms 948.637861ms 949.852848ms 950.200032ms 954.158647ms 955.606532ms 956.088529ms 956.146369ms 958.911348ms 959.880624ms 961.382354ms 962.092961ms 965.2454ms 969.755977ms 971.018397ms 972.087294ms 973.251489ms 973.334491ms 977.790936ms 978.569619ms 979.956862ms 980.399074ms 984.70399ms 986.734679ms 987.363304ms 993.41842ms 993.995142ms 996.645202ms 1.004516569s 1.008908861s 1.01289581s 1.020954098s 1.027739473s 1.031838187s 1.041726832s 1.045963455s 1.049360768s 1.050316264s 1.050344235s 1.058824038s 1.062732215s 1.064226094s 1.073667365s 1.076804719s 1.085567505s 1.112283357s 1.118348232s 1.126181746s 1.131235432s 1.132339361s 1.14022435s 1.15185981s 1.15659295s 1.187491268s 1.187679796s 1.221219869s 1.238487286s 1.248898742s 1.253365913s 1.266799286s 1.273707127s 1.283432247s 1.291053127s 1.301027291s 1.324782469s 1.325135322s 1.349805824s 1.354804485s 1.358410066s 1.37062226s 1.383675757s 1.392862025s 1.453427622s 1.476689986s 1.483160307s 1.488794366s 1.514187768s 1.515428846s 1.520960017s 1.53025831s 1.534336795s 1.536023103s 1.540171817s 1.541909055s 1.551624572s 1.551816209s 1.558547644s 1.58687978s 1.593429311s 1.598912343s 1.59898013s 1.601661558s 1.606743445s 1.608269167s 1.625430228s 1.638901986s 1.63903174s 1.648022948s 1.742510202s]
Apr 21 04:40:57.312: INFO: 50 %ile: 944.702615ms
Apr 21 04:40:57.312: INFO: 90 %ile: 1.53025831s
Apr 21 04:40:57.312: INFO: 99 %ile: 1.648022948s
Apr 21 04:40:57.312: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:40:57.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-945" for this suite.
Apr 21 04:41:45.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:41:46.022: INFO: namespace svc-latency-945 deletion completed in 48.675739708s

• [SLOW TEST:65.893 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:41:46.023: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 21 04:41:46.362: INFO: Waiting up to 5m0s for pod "pod-990c6cea-35f3-44ca-b5a8-9e24e820a968" in namespace "emptydir-3742" to be "success or failure"
Apr 21 04:41:46.378: INFO: Pod "pod-990c6cea-35f3-44ca-b5a8-9e24e820a968": Phase="Pending", Reason="", readiness=false. Elapsed: 16.650537ms
Apr 21 04:41:48.396: INFO: Pod "pod-990c6cea-35f3-44ca-b5a8-9e24e820a968": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033843708s
Apr 21 04:41:50.409: INFO: Pod "pod-990c6cea-35f3-44ca-b5a8-9e24e820a968": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047274547s
STEP: Saw pod success
Apr 21 04:41:50.409: INFO: Pod "pod-990c6cea-35f3-44ca-b5a8-9e24e820a968" satisfied condition "success or failure"
Apr 21 04:41:50.429: INFO: Trying to get logs from node 10.177.30.186 pod pod-990c6cea-35f3-44ca-b5a8-9e24e820a968 container test-container: <nil>
STEP: delete the pod
Apr 21 04:41:50.598: INFO: Waiting for pod pod-990c6cea-35f3-44ca-b5a8-9e24e820a968 to disappear
Apr 21 04:41:50.615: INFO: Pod pod-990c6cea-35f3-44ca-b5a8-9e24e820a968 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:41:50.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3742" for this suite.
Apr 21 04:41:58.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:41:59.802: INFO: namespace emptydir-3742 deletion completed in 9.160577346s

• [SLOW TEST:13.779 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:41:59.802: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-5327
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5327 to expose endpoints map[]
Apr 21 04:42:00.260: INFO: successfully validated that service multi-endpoint-test in namespace services-5327 exposes endpoints map[] (41.032443ms elapsed)
STEP: Creating pod pod1 in namespace services-5327
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5327 to expose endpoints map[pod1:[100]]
Apr 21 04:42:04.633: INFO: successfully validated that service multi-endpoint-test in namespace services-5327 exposes endpoints map[pod1:[100]] (4.339623807s elapsed)
STEP: Creating pod pod2 in namespace services-5327
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5327 to expose endpoints map[pod1:[100] pod2:[101]]
Apr 21 04:42:08.992: INFO: Unexpected endpoints: found map[2bb743e5-db92-4156-8062-5d437c0d147e:[100]], expected map[pod1:[100] pod2:[101]] (4.338228714s elapsed, will retry)
Apr 21 04:42:10.039: INFO: successfully validated that service multi-endpoint-test in namespace services-5327 exposes endpoints map[pod1:[100] pod2:[101]] (5.384307066s elapsed)
STEP: Deleting pod pod1 in namespace services-5327
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5327 to expose endpoints map[pod2:[101]]
Apr 21 04:42:10.122: INFO: successfully validated that service multi-endpoint-test in namespace services-5327 exposes endpoints map[pod2:[101]] (52.284611ms elapsed)
STEP: Deleting pod pod2 in namespace services-5327
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5327 to expose endpoints map[]
Apr 21 04:42:11.187: INFO: successfully validated that service multi-endpoint-test in namespace services-5327 exposes endpoints map[] (1.037386349s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:42:11.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5327" for this suite.
Apr 21 04:42:43.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:42:44.046: INFO: namespace services-5327 deletion completed in 32.705553439s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:44.244 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:42:44.046: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7348
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr 21 04:42:55.070: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:42:55.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0421 04:42:55.069987      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-7348" for this suite.
Apr 21 04:43:07.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:43:07.795: INFO: namespace gc-7348 deletion completed in 12.702102358s

• [SLOW TEST:23.748 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:43:07.795: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1942
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr 21 04:43:08.134: INFO: Waiting up to 5m0s for pod "downward-api-14c65629-0488-489d-bee9-110e217cb012" in namespace "downward-api-1942" to be "success or failure"
Apr 21 04:43:08.188: INFO: Pod "downward-api-14c65629-0488-489d-bee9-110e217cb012": Phase="Pending", Reason="", readiness=false. Elapsed: 53.982215ms
Apr 21 04:43:10.204: INFO: Pod "downward-api-14c65629-0488-489d-bee9-110e217cb012": Phase="Pending", Reason="", readiness=false. Elapsed: 2.070105211s
Apr 21 04:43:12.219: INFO: Pod "downward-api-14c65629-0488-489d-bee9-110e217cb012": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.085079616s
STEP: Saw pod success
Apr 21 04:43:12.219: INFO: Pod "downward-api-14c65629-0488-489d-bee9-110e217cb012" satisfied condition "success or failure"
Apr 21 04:43:12.236: INFO: Trying to get logs from node 10.177.30.186 pod downward-api-14c65629-0488-489d-bee9-110e217cb012 container dapi-container: <nil>
STEP: delete the pod
Apr 21 04:43:12.347: INFO: Waiting for pod downward-api-14c65629-0488-489d-bee9-110e217cb012 to disappear
Apr 21 04:43:12.381: INFO: Pod downward-api-14c65629-0488-489d-bee9-110e217cb012 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:43:12.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1942" for this suite.
Apr 21 04:43:20.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:43:21.082: INFO: namespace downward-api-1942 deletion completed in 8.663229821s

• [SLOW TEST:13.286 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:43:21.082: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:44:21.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3322" for this suite.
Apr 21 04:44:35.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:44:36.229: INFO: namespace container-probe-3322 deletion completed in 14.760957317s

• [SLOW TEST:75.147 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:44:36.231: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-1949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1949 to expose endpoints map[]
Apr 21 04:44:36.605: INFO: Get endpoints failed (39.125018ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Apr 21 04:44:37.623: INFO: successfully validated that service endpoint-test2 in namespace services-1949 exposes endpoints map[] (1.056843336s elapsed)
STEP: Creating pod pod1 in namespace services-1949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1949 to expose endpoints map[pod1:[80]]
Apr 21 04:44:42.533: INFO: successfully validated that service endpoint-test2 in namespace services-1949 exposes endpoints map[pod1:[80]] (4.879024491s elapsed)
STEP: Creating pod pod2 in namespace services-1949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1949 to expose endpoints map[pod1:[80] pod2:[80]]
Apr 21 04:44:45.774: INFO: successfully validated that service endpoint-test2 in namespace services-1949 exposes endpoints map[pod1:[80] pod2:[80]] (3.219752184s elapsed)
STEP: Deleting pod pod1 in namespace services-1949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1949 to expose endpoints map[pod2:[80]]
Apr 21 04:44:46.880: INFO: successfully validated that service endpoint-test2 in namespace services-1949 exposes endpoints map[pod2:[80]] (1.073051857s elapsed)
STEP: Deleting pod pod2 in namespace services-1949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-1949 to expose endpoints map[]
Apr 21 04:44:47.953: INFO: successfully validated that service endpoint-test2 in namespace services-1949 exposes endpoints map[] (1.041978655s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:44:48.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1949" for this suite.
Apr 21 04:44:56.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:44:57.447: INFO: namespace services-1949 deletion completed in 9.271430152s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.216 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:44:57.447: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 21 04:44:57.767: INFO: Waiting up to 5m0s for pod "pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0" in namespace "emptydir-2720" to be "success or failure"
Apr 21 04:44:57.782: INFO: Pod "pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0": Phase="Pending", Reason="", readiness=false. Elapsed: 14.672505ms
Apr 21 04:44:59.795: INFO: Pod "pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027639394s
Apr 21 04:45:01.809: INFO: Pod "pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042149159s
STEP: Saw pod success
Apr 21 04:45:01.809: INFO: Pod "pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0" satisfied condition "success or failure"
Apr 21 04:45:01.826: INFO: Trying to get logs from node 10.177.30.186 pod pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0 container test-container: <nil>
STEP: delete the pod
Apr 21 04:45:02.050: INFO: Waiting for pod pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0 to disappear
Apr 21 04:45:02.067: INFO: Pod pod-05c5ae4d-a0e4-449b-9a36-2086bcf738b0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:45:02.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2720" for this suite.
Apr 21 04:45:10.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:45:10.861: INFO: namespace emptydir-2720 deletion completed in 8.767035185s

• [SLOW TEST:13.414 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:45:10.862: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 04:45:11.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-7862'
Apr 21 04:45:11.460: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 21 04:45:11.460: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Apr 21 04:45:13.606: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7862'
Apr 21 04:45:13.825: INFO: stderr: ""
Apr 21 04:45:13.825: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:45:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7862" for this suite.
Apr 21 04:45:27.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:45:28.479: INFO: namespace kubectl-7862 deletion completed in 14.629600505s

• [SLOW TEST:17.617 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:45:28.479: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr 21 04:45:34.927: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:34.927: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:35.157: INFO: Exec stderr: ""
Apr 21 04:45:35.157: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:35.157: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:35.402: INFO: Exec stderr: ""
Apr 21 04:45:35.402: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:35.402: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:35.613: INFO: Exec stderr: ""
Apr 21 04:45:35.613: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:35.613: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:35.819: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr 21 04:45:35.819: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:35.819: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:36.153: INFO: Exec stderr: ""
Apr 21 04:45:36.153: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:36.153: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:36.371: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr 21 04:45:36.371: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:36.371: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:36.647: INFO: Exec stderr: ""
Apr 21 04:45:36.647: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:36.647: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:36.838: INFO: Exec stderr: ""
Apr 21 04:45:36.838: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:36.838: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:37.078: INFO: Exec stderr: ""
Apr 21 04:45:37.078: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-555 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:45:37.078: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:45:37.287: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:45:37.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-555" for this suite.
Apr 21 04:46:25.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:46:25.951: INFO: namespace e2e-kubelet-etc-hosts-555 deletion completed in 48.644376636s

• [SLOW TEST:57.472 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:46:25.951: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1764
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1764, will wait for the garbage collector to delete the pods
Apr 21 04:46:30.399: INFO: Deleting Job.batch foo took: 55.506846ms
Apr 21 04:46:30.599: INFO: Terminating Job.batch foo pods took: 200.362174ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:47:12.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1764" for this suite.
Apr 21 04:47:20.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:47:20.966: INFO: namespace job-1764 deletion completed in 8.622736692s

• [SLOW TEST:55.015 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:47:20.967: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2466
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 04:47:22.124: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 04:47:24.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041242, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041242, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041242, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041242, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 04:47:27.255: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:47:27.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2466" for this suite.
Apr 21 04:47:35.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:47:36.312: INFO: namespace webhook-2466 deletion completed in 8.667844998s
STEP: Destroying namespace "webhook-2466-markers" for this suite.
Apr 21 04:47:44.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:47:45.060: INFO: namespace webhook-2466-markers deletion completed in 8.747539384s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.457 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:47:45.424: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr 21 04:47:48.482: INFO: Successfully updated pod "labelsupdate6da296d2-79c1-4036-812a-ef589ec23b9b"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:47:51.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6257" for this suite.
Apr 21 04:48:21.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:48:22.150: INFO: namespace downward-api-6257 deletion completed in 30.74872004s

• [SLOW TEST:36.726 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:48:22.150: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 04:48:23.496: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 04:48:25.554: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041303, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041303, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041303, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041303, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 04:48:28.643: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:48:29.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1415" for this suite.
Apr 21 04:48:37.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:48:38.453: INFO: namespace webhook-1415 deletion completed in 8.771442744s
STEP: Destroying namespace "webhook-1415-markers" for this suite.
Apr 21 04:48:44.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:48:45.483: INFO: namespace webhook-1415-markers deletion completed in 7.028920405s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.448 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:48:45.598: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-d585b7a0-30ef-445d-a5dd-6ca529d2acf0
STEP: Creating a pod to test consume secrets
Apr 21 04:48:45.950: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c" in namespace "projected-1225" to be "success or failure"
Apr 21 04:48:45.970: INFO: Pod "pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.727138ms
Apr 21 04:48:47.986: INFO: Pod "pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036046959s
Apr 21 04:48:50.001: INFO: Pod "pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050793335s
STEP: Saw pod success
Apr 21 04:48:50.001: INFO: Pod "pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c" satisfied condition "success or failure"
Apr 21 04:48:50.018: INFO: Trying to get logs from node 10.177.30.186 pod pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 21 04:48:50.122: INFO: Waiting for pod pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c to disappear
Apr 21 04:48:50.141: INFO: Pod pod-projected-secrets-b05698c7-3ff8-4e0e-87a0-2fc6f01d776c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:48:50.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1225" for this suite.
Apr 21 04:48:58.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:48:58.863: INFO: namespace projected-1225 deletion completed in 8.695973475s

• [SLOW TEST:13.265 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:48:58.863: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3243
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0421 04:49:09.313091      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 21 04:49:09.313: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:49:09.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3243" for this suite.
Apr 21 04:49:17.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:49:17.992: INFO: namespace gc-3243 deletion completed in 8.659022804s

• [SLOW TEST:19.129 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:49:17.993: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Apr 21 04:49:18.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-1515'
Apr 21 04:49:18.794: INFO: stderr: ""
Apr 21 04:49:18.794: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 04:49:18.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:18.943: INFO: stderr: ""
Apr 21 04:49:18.943: INFO: stdout: "update-demo-nautilus-27h4p update-demo-nautilus-tngjc "
Apr 21 04:49:18.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:19.108: INFO: stderr: ""
Apr 21 04:49:19.108: INFO: stdout: ""
Apr 21 04:49:19.108: INFO: update-demo-nautilus-27h4p is created but not running
Apr 21 04:49:24.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:24.249: INFO: stderr: ""
Apr 21 04:49:24.250: INFO: stdout: "update-demo-nautilus-27h4p update-demo-nautilus-tngjc "
Apr 21 04:49:24.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:24.396: INFO: stderr: ""
Apr 21 04:49:24.396: INFO: stdout: "true"
Apr 21 04:49:24.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:24.558: INFO: stderr: ""
Apr 21 04:49:24.558: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:24.558: INFO: validating pod update-demo-nautilus-27h4p
Apr 21 04:49:24.595: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:24.595: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:24.595: INFO: update-demo-nautilus-27h4p is verified up and running
Apr 21 04:49:24.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-tngjc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:24.748: INFO: stderr: ""
Apr 21 04:49:24.748: INFO: stdout: "true"
Apr 21 04:49:24.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-tngjc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:24.914: INFO: stderr: ""
Apr 21 04:49:24.914: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:24.914: INFO: validating pod update-demo-nautilus-tngjc
Apr 21 04:49:24.950: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:24.950: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:24.950: INFO: update-demo-nautilus-tngjc is verified up and running
STEP: scaling down the replication controller
Apr 21 04:49:24.953: INFO: scanned /root for discovery docs: <nil>
Apr 21 04:49:24.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1515'
Apr 21 04:49:26.197: INFO: stderr: ""
Apr 21 04:49:26.197: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 04:49:26.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:26.333: INFO: stderr: ""
Apr 21 04:49:26.333: INFO: stdout: "update-demo-nautilus-27h4p update-demo-nautilus-tngjc "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr 21 04:49:31.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:31.481: INFO: stderr: ""
Apr 21 04:49:31.481: INFO: stdout: "update-demo-nautilus-27h4p "
Apr 21 04:49:31.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:31.624: INFO: stderr: ""
Apr 21 04:49:31.624: INFO: stdout: "true"
Apr 21 04:49:31.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:31.769: INFO: stderr: ""
Apr 21 04:49:31.769: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:31.769: INFO: validating pod update-demo-nautilus-27h4p
Apr 21 04:49:32.695: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:32.695: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:32.695: INFO: update-demo-nautilus-27h4p is verified up and running
STEP: scaling up the replication controller
Apr 21 04:49:32.697: INFO: scanned /root for discovery docs: <nil>
Apr 21 04:49:32.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1515'
Apr 21 04:49:33.937: INFO: stderr: ""
Apr 21 04:49:33.938: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 04:49:33.938: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:34.092: INFO: stderr: ""
Apr 21 04:49:34.092: INFO: stdout: "update-demo-nautilus-27h4p update-demo-nautilus-mhb69 "
Apr 21 04:49:34.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:34.243: INFO: stderr: ""
Apr 21 04:49:34.243: INFO: stdout: "true"
Apr 21 04:49:34.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:34.386: INFO: stderr: ""
Apr 21 04:49:34.386: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:34.386: INFO: validating pod update-demo-nautilus-27h4p
Apr 21 04:49:34.413: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:34.413: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:34.413: INFO: update-demo-nautilus-27h4p is verified up and running
Apr 21 04:49:34.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-mhb69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:34.547: INFO: stderr: ""
Apr 21 04:49:34.548: INFO: stdout: ""
Apr 21 04:49:34.548: INFO: update-demo-nautilus-mhb69 is created but not running
Apr 21 04:49:39.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1515'
Apr 21 04:49:39.855: INFO: stderr: ""
Apr 21 04:49:39.855: INFO: stdout: "update-demo-nautilus-27h4p update-demo-nautilus-mhb69 "
Apr 21 04:49:39.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:40.002: INFO: stderr: ""
Apr 21 04:49:40.002: INFO: stdout: "true"
Apr 21 04:49:40.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-27h4p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:40.157: INFO: stderr: ""
Apr 21 04:49:40.157: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:40.157: INFO: validating pod update-demo-nautilus-27h4p
Apr 21 04:49:40.183: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:40.183: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:40.183: INFO: update-demo-nautilus-27h4p is verified up and running
Apr 21 04:49:40.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-mhb69 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:40.359: INFO: stderr: ""
Apr 21 04:49:40.359: INFO: stdout: "true"
Apr 21 04:49:40.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-mhb69 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1515'
Apr 21 04:49:40.514: INFO: stderr: ""
Apr 21 04:49:40.514: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:49:40.514: INFO: validating pod update-demo-nautilus-mhb69
Apr 21 04:49:40.542: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:49:40.542: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:49:40.542: INFO: update-demo-nautilus-mhb69 is verified up and running
STEP: using delete to clean up resources
Apr 21 04:49:40.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-1515'
Apr 21 04:49:40.747: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 04:49:40.747: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 21 04:49:40.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1515'
Apr 21 04:49:40.952: INFO: stderr: "No resources found in kubectl-1515 namespace.\n"
Apr 21 04:49:40.952: INFO: stdout: ""
Apr 21 04:49:40.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -l name=update-demo --namespace=kubectl-1515 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 21 04:49:41.113: INFO: stderr: ""
Apr 21 04:49:41.113: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:49:41.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1515" for this suite.
Apr 21 04:50:13.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:50:13.803: INFO: namespace kubectl-1515 deletion completed in 32.668472763s

• [SLOW TEST:55.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:50:13.804: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 04:50:14.182: INFO: (0) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 83.171065ms)
Apr 21 04:50:14.209: INFO: (1) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.761825ms)
Apr 21 04:50:14.234: INFO: (2) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.009274ms)
Apr 21 04:50:14.259: INFO: (3) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.196073ms)
Apr 21 04:50:14.286: INFO: (4) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.722118ms)
Apr 21 04:50:14.314: INFO: (5) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.273266ms)
Apr 21 04:50:14.340: INFO: (6) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.780856ms)
Apr 21 04:50:14.364: INFO: (7) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.704838ms)
Apr 21 04:50:14.398: INFO: (8) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 34.094763ms)
Apr 21 04:50:14.426: INFO: (9) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.088637ms)
Apr 21 04:50:14.454: INFO: (10) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.963515ms)
Apr 21 04:50:14.490: INFO: (11) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 35.225422ms)
Apr 21 04:50:14.514: INFO: (12) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 24.067405ms)
Apr 21 04:50:14.538: INFO: (13) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.88136ms)
Apr 21 04:50:14.588: INFO: (14) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 49.919986ms)
Apr 21 04:50:14.614: INFO: (15) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 25.724443ms)
Apr 21 04:50:14.641: INFO: (16) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.168937ms)
Apr 21 04:50:14.664: INFO: (17) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 22.817584ms)
Apr 21 04:50:14.693: INFO: (18) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.677993ms)
Apr 21 04:50:14.725: INFO: (19) /api/v1/nodes/10.177.30.140/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.914317ms)
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:50:14.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-915" for this suite.
Apr 21 04:50:22.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:50:23.406: INFO: namespace proxy-915 deletion completed in 8.655692074s

• [SLOW TEST:9.601 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:50:23.408: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Apr 21 04:50:23.685: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4862'
Apr 21 04:50:24.110: INFO: stderr: ""
Apr 21 04:50:24.110: INFO: stdout: "pod/pause created\n"
Apr 21 04:50:24.110: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr 21 04:50:24.110: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4862" to be "running and ready"
Apr 21 04:50:24.130: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 20.326558ms
Apr 21 04:50:26.146: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.035987571s
Apr 21 04:50:26.146: INFO: Pod "pause" satisfied condition "running and ready"
Apr 21 04:50:26.146: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Apr 21 04:50:26.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 label pods pause testing-label=testing-label-value --namespace=kubectl-4862'
Apr 21 04:50:26.332: INFO: stderr: ""
Apr 21 04:50:26.333: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr 21 04:50:26.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pod pause -L testing-label --namespace=kubectl-4862'
Apr 21 04:50:26.534: INFO: stderr: ""
Apr 21 04:50:26.534: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr 21 04:50:26.534: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 label pods pause testing-label- --namespace=kubectl-4862'
Apr 21 04:50:26.705: INFO: stderr: ""
Apr 21 04:50:26.705: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr 21 04:50:26.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pod pause -L testing-label --namespace=kubectl-4862'
Apr 21 04:50:26.862: INFO: stderr: ""
Apr 21 04:50:26.862: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Apr 21 04:50:26.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4862'
Apr 21 04:50:27.058: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 04:50:27.058: INFO: stdout: "pod \"pause\" force deleted\n"
Apr 21 04:50:27.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get rc,svc -l name=pause --no-headers --namespace=kubectl-4862'
Apr 21 04:50:27.212: INFO: stderr: "No resources found in kubectl-4862 namespace.\n"
Apr 21 04:50:27.212: INFO: stdout: ""
Apr 21 04:50:27.212: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -l name=pause --namespace=kubectl-4862 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 21 04:50:27.351: INFO: stderr: ""
Apr 21 04:50:27.351: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:50:27.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4862" for this suite.
Apr 21 04:50:35.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:50:36.117: INFO: namespace kubectl-4862 deletion completed in 8.741295977s

• [SLOW TEST:12.709 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:50:36.117: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-2506
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6977
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:50:44.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4372" for this suite.
Apr 21 04:50:52.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:50:53.291: INFO: namespace namespaces-4372 deletion completed in 9.100457659s
STEP: Destroying namespace "nsdeletetest-2506" for this suite.
Apr 21 04:50:53.309: INFO: Namespace nsdeletetest-2506 was already deleted
STEP: Destroying namespace "nsdeletetest-6977" for this suite.
Apr 21 04:51:01.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:51:02.012: INFO: namespace nsdeletetest-6977 deletion completed in 8.702540618s

• [SLOW TEST:25.895 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:51:02.013: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1370
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 21 04:51:05.501: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:51:05.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1370" for this suite.
Apr 21 04:51:13.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:51:14.367: INFO: namespace container-runtime-1370 deletion completed in 8.76906351s

• [SLOW TEST:12.354 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:51:14.368: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:51:25.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5209" for this suite.
Apr 21 04:51:34.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:51:34.677: INFO: namespace resourcequota-5209 deletion completed in 8.703590875s

• [SLOW TEST:20.309 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:51:34.677: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6624
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 04:51:34.937: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:51:37.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6624" for this suite.
Apr 21 04:52:25.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:52:26.100: INFO: namespace pods-6624 deletion completed in 48.903297819s

• [SLOW TEST:51.423 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:52:26.100: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 04:52:27.135: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 04:52:29.191: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041547, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041547, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041547, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041547, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 04:52:32.276: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:52:42.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6320" for this suite.
Apr 21 04:52:50.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:52:51.678: INFO: namespace webhook-6320 deletion completed in 8.767224961s
STEP: Destroying namespace "webhook-6320-markers" for this suite.
Apr 21 04:52:59.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:53:00.369: INFO: namespace webhook-6320-markers deletion completed in 8.691469882s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:34.369 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:53:00.470: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9791
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 21 04:53:00.897: INFO: Waiting up to 5m0s for pod "pod-28d6a78e-5296-4ad4-9609-ba790de2f63f" in namespace "emptydir-9791" to be "success or failure"
Apr 21 04:53:00.921: INFO: Pod "pod-28d6a78e-5296-4ad4-9609-ba790de2f63f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.492906ms
Apr 21 04:53:02.939: INFO: Pod "pod-28d6a78e-5296-4ad4-9609-ba790de2f63f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042159508s
Apr 21 04:53:04.964: INFO: Pod "pod-28d6a78e-5296-4ad4-9609-ba790de2f63f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.067177776s
STEP: Saw pod success
Apr 21 04:53:04.964: INFO: Pod "pod-28d6a78e-5296-4ad4-9609-ba790de2f63f" satisfied condition "success or failure"
Apr 21 04:53:04.979: INFO: Trying to get logs from node 10.177.30.144 pod pod-28d6a78e-5296-4ad4-9609-ba790de2f63f container test-container: <nil>
STEP: delete the pod
Apr 21 04:53:05.120: INFO: Waiting for pod pod-28d6a78e-5296-4ad4-9609-ba790de2f63f to disappear
Apr 21 04:53:05.135: INFO: Pod pod-28d6a78e-5296-4ad4-9609-ba790de2f63f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:53:05.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9791" for this suite.
Apr 21 04:53:13.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:53:13.864: INFO: namespace emptydir-9791 deletion completed in 8.708565316s

• [SLOW TEST:13.394 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:53:13.864: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3286
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Apr 21 04:53:14.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-3286'
Apr 21 04:53:14.494: INFO: stderr: ""
Apr 21 04:53:14.494: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 04:53:14.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3286'
Apr 21 04:53:14.658: INFO: stderr: ""
Apr 21 04:53:14.658: INFO: stdout: "update-demo-nautilus-8st6j update-demo-nautilus-v42n9 "
Apr 21 04:53:14.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3286'
Apr 21 04:53:14.821: INFO: stderr: ""
Apr 21 04:53:14.821: INFO: stdout: ""
Apr 21 04:53:14.821: INFO: update-demo-nautilus-8st6j is created but not running
Apr 21 04:53:19.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3286'
Apr 21 04:53:19.968: INFO: stderr: ""
Apr 21 04:53:19.968: INFO: stdout: "update-demo-nautilus-8st6j update-demo-nautilus-v42n9 "
Apr 21 04:53:19.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st6j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3286'
Apr 21 04:53:20.126: INFO: stderr: ""
Apr 21 04:53:20.126: INFO: stdout: "true"
Apr 21 04:53:20.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st6j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3286'
Apr 21 04:53:20.391: INFO: stderr: ""
Apr 21 04:53:20.391: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:53:20.391: INFO: validating pod update-demo-nautilus-8st6j
Apr 21 04:53:20.441: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:53:20.441: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:53:20.441: INFO: update-demo-nautilus-8st6j is verified up and running
Apr 21 04:53:20.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-v42n9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3286'
Apr 21 04:53:20.592: INFO: stderr: ""
Apr 21 04:53:20.592: INFO: stdout: "true"
Apr 21 04:53:20.592: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-v42n9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3286'
Apr 21 04:53:20.767: INFO: stderr: ""
Apr 21 04:53:20.767: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 04:53:20.767: INFO: validating pod update-demo-nautilus-v42n9
Apr 21 04:53:20.798: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 04:53:20.798: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 04:53:20.798: INFO: update-demo-nautilus-v42n9 is verified up and running
STEP: using delete to clean up resources
Apr 21 04:53:20.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-3286'
Apr 21 04:53:20.972: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 04:53:20.972: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr 21 04:53:20.973: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3286'
Apr 21 04:53:21.152: INFO: stderr: "No resources found in kubectl-3286 namespace.\n"
Apr 21 04:53:21.152: INFO: stdout: ""
Apr 21 04:53:21.152: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -l name=update-demo --namespace=kubectl-3286 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 21 04:53:21.298: INFO: stderr: ""
Apr 21 04:53:21.298: INFO: stdout: "update-demo-nautilus-8st6j\nupdate-demo-nautilus-v42n9\n"
Apr 21 04:53:21.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3286'
Apr 21 04:53:21.987: INFO: stderr: "No resources found in kubectl-3286 namespace.\n"
Apr 21 04:53:21.987: INFO: stdout: ""
Apr 21 04:53:21.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -l name=update-demo --namespace=kubectl-3286 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr 21 04:53:22.148: INFO: stderr: ""
Apr 21 04:53:22.148: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:53:22.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3286" for this suite.
Apr 21 04:53:36.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:53:36.876: INFO: namespace kubectl-3286 deletion completed in 14.693673994s

• [SLOW TEST:23.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:53:36.877: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-1d80294b-39f5-4135-95ee-20f4baf8f57f
STEP: Creating a pod to test consume secrets
Apr 21 04:53:37.206: INFO: Waiting up to 5m0s for pod "pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8" in namespace "secrets-5780" to be "success or failure"
Apr 21 04:53:37.225: INFO: Pod "pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8": Phase="Pending", Reason="", readiness=false. Elapsed: 18.498829ms
Apr 21 04:53:39.240: INFO: Pod "pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034057688s
Apr 21 04:53:41.255: INFO: Pod "pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048579258s
STEP: Saw pod success
Apr 21 04:53:41.255: INFO: Pod "pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8" satisfied condition "success or failure"
Apr 21 04:53:41.274: INFO: Trying to get logs from node 10.177.30.144 pod pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8 container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 04:53:42.445: INFO: Waiting for pod pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8 to disappear
Apr 21 04:53:42.462: INFO: Pod pod-secrets-a2348a6f-f665-4e7a-bca2-f4827a5184f8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:53:42.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5780" for this suite.
Apr 21 04:53:50.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:53:51.141: INFO: namespace secrets-5780 deletion completed in 8.659138813s

• [SLOW TEST:14.265 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:53:51.143: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2087
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:53:54.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2087" for this suite.
Apr 21 04:54:08.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:54:09.744: INFO: namespace replication-controller-2087 deletion completed in 15.119877265s

• [SLOW TEST:18.601 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:54:09.746: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6910
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:54:18.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6910" for this suite.
Apr 21 04:54:26.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:54:26.783: INFO: namespace job-6910 deletion completed in 8.682888796s

• [SLOW TEST:17.037 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:54:26.784: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2857
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr 21 04:54:27.077: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:54:31.805: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:54:48.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2857" for this suite.
Apr 21 04:54:56.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:54:57.467: INFO: namespace crd-publish-openapi-2857 deletion completed in 8.635360623s

• [SLOW TEST:30.684 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:54:57.469: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6031
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-467920b5-4410-4925-a700-1d41336b1861
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-467920b5-4410-4925-a700-1d41336b1861
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:56:06.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6031" for this suite.
Apr 21 04:56:22.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:56:23.116: INFO: namespace projected-6031 deletion completed in 16.679937853s

• [SLOW TEST:85.647 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:56:23.120: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9088
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-1cda8c4c-0354-4f0c-8f66-628da58d8753
STEP: Creating a pod to test consume configMaps
Apr 21 04:56:23.514: INFO: Waiting up to 5m0s for pod "pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616" in namespace "configmap-9088" to be "success or failure"
Apr 21 04:56:23.533: INFO: Pod "pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616": Phase="Pending", Reason="", readiness=false. Elapsed: 18.655084ms
Apr 21 04:56:25.562: INFO: Pod "pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04795686s
STEP: Saw pod success
Apr 21 04:56:25.562: INFO: Pod "pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616" satisfied condition "success or failure"
Apr 21 04:56:25.578: INFO: Trying to get logs from node 10.177.30.186 pod pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 04:56:25.803: INFO: Waiting for pod pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616 to disappear
Apr 21 04:56:25.821: INFO: Pod pod-configmaps-3150dfaa-8395-460c-a998-18ee354e5616 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:56:25.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9088" for this suite.
Apr 21 04:56:33.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:56:34.592: INFO: namespace configmap-9088 deletion completed in 8.744077473s

• [SLOW TEST:11.473 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:56:34.592: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5786
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr 21 04:56:34.907: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:56:39.045: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:56:56.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5786" for this suite.
Apr 21 04:57:04.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:57:05.526: INFO: namespace crd-publish-openapi-5786 deletion completed in 8.790656463s

• [SLOW TEST:30.934 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:57:05.526: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 04:57:06.613: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 04:57:08.674: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041826, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041826, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041826, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723041826, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 04:57:12.135: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr 21 04:57:14.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 attach --namespace=webhook-9797 to-be-attached-pod -i -c=container1'
Apr 21 04:57:14.656: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:57:14.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9797" for this suite.
Apr 21 04:57:28.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:57:29.461: INFO: namespace webhook-9797 deletion completed in 14.71476433s
STEP: Destroying namespace "webhook-9797-markers" for this suite.
Apr 21 04:57:37.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:57:38.247: INFO: namespace webhook-9797-markers deletion completed in 8.785055627s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.824 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:57:38.351: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6799
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr 21 04:57:38.681: INFO: Waiting up to 5m0s for pod "pod-507742c1-c6ad-406a-b95a-be0eb110084c" in namespace "emptydir-6799" to be "success or failure"
Apr 21 04:57:38.705: INFO: Pod "pod-507742c1-c6ad-406a-b95a-be0eb110084c": Phase="Pending", Reason="", readiness=false. Elapsed: 23.670159ms
Apr 21 04:57:40.725: INFO: Pod "pod-507742c1-c6ad-406a-b95a-be0eb110084c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043949443s
STEP: Saw pod success
Apr 21 04:57:40.725: INFO: Pod "pod-507742c1-c6ad-406a-b95a-be0eb110084c" satisfied condition "success or failure"
Apr 21 04:57:40.742: INFO: Trying to get logs from node 10.177.30.186 pod pod-507742c1-c6ad-406a-b95a-be0eb110084c container test-container: <nil>
STEP: delete the pod
Apr 21 04:57:40.887: INFO: Waiting for pod pod-507742c1-c6ad-406a-b95a-be0eb110084c to disappear
Apr 21 04:57:40.903: INFO: Pod pod-507742c1-c6ad-406a-b95a-be0eb110084c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:57:40.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6799" for this suite.
Apr 21 04:57:49.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:57:49.685: INFO: namespace emptydir-6799 deletion completed in 8.751043737s

• [SLOW TEST:11.334 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:57:49.688: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2564
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-538f8aca-cfc5-4a00-9e97-6addee825323
STEP: Creating secret with name s-test-opt-upd-d0415d99-63c2-43bf-8eeb-f7e26a5692f2
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-538f8aca-cfc5-4a00-9e97-6addee825323
STEP: Updating secret s-test-opt-upd-d0415d99-63c2-43bf-8eeb-f7e26a5692f2
STEP: Creating secret with name s-test-opt-create-b97e3ac1-5397-45db-9ffe-5510dd612933
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:59:04.727: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2564" for this suite.
Apr 21 04:59:18.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:59:19.611: INFO: namespace projected-2564 deletion completed in 14.855198002s

• [SLOW TEST:89.923 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:59:19.612: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5241
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 04:59:19.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3" in namespace "downward-api-5241" to be "success or failure"
Apr 21 04:59:20.012: INFO: Pod "downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3": Phase="Pending", Reason="", readiness=false. Elapsed: 23.303557ms
Apr 21 04:59:22.033: INFO: Pod "downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044670716s
STEP: Saw pod success
Apr 21 04:59:22.033: INFO: Pod "downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3" satisfied condition "success or failure"
Apr 21 04:59:22.050: INFO: Trying to get logs from node 10.177.30.186 pod downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3 container client-container: <nil>
STEP: delete the pod
Apr 21 04:59:22.201: INFO: Waiting for pod downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3 to disappear
Apr 21 04:59:22.221: INFO: Pod downwardapi-volume-ba108c47-b983-4afa-b78b-45f88e4331f3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:59:22.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5241" for this suite.
Apr 21 04:59:30.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 04:59:31.009: INFO: namespace downward-api-5241 deletion completed in 8.754549174s

• [SLOW TEST:11.397 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 04:59:31.012: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1819
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1819
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 21 04:59:31.303: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 21 04:59:49.733: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.12.81:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1819 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:59:49.733: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:59:49.988: INFO: Found all expected endpoints: [netserver-0]
Apr 21 04:59:50.008: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.121.11:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1819 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:59:50.008: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:59:50.293: INFO: Found all expected endpoints: [netserver-1]
Apr 21 04:59:50.309: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.100.188:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-1819 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 04:59:50.309: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 04:59:51.030: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 04:59:51.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1819" for this suite.
Apr 21 05:00:07.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:00:07.844: INFO: namespace pod-network-test-1819 deletion completed in 16.788966722s

• [SLOW TEST:36.833 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:00:07.846: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-93b4dd53-dcff-41f5-ad61-edcb37d108f1
STEP: Creating a pod to test consume secrets
Apr 21 05:00:08.188: INFO: Waiting up to 5m0s for pod "pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352" in namespace "secrets-7972" to be "success or failure"
Apr 21 05:00:08.209: INFO: Pod "pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352": Phase="Pending", Reason="", readiness=false. Elapsed: 20.533326ms
Apr 21 05:00:10.229: INFO: Pod "pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040971817s
STEP: Saw pod success
Apr 21 05:00:10.230: INFO: Pod "pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352" satisfied condition "success or failure"
Apr 21 05:00:10.245: INFO: Trying to get logs from node 10.177.30.144 pod pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352 container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:00:10.358: INFO: Waiting for pod pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352 to disappear
Apr 21 05:00:10.378: INFO: Pod pod-secrets-1dab83af-c293-4a16-a143-a630dc85d352 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:00:10.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7972" for this suite.
Apr 21 05:00:18.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:00:19.222: INFO: namespace secrets-7972 deletion completed in 8.818002555s

• [SLOW TEST:11.376 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:00:19.224: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4653
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 21 05:00:19.545: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 21 05:00:42.067: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.12.87 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4653 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:00:42.067: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:00:43.302: INFO: Found all expected endpoints: [netserver-0]
Apr 21 05:00:43.320: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.121.14 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4653 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:00:43.320: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:00:44.530: INFO: Found all expected endpoints: [netserver-1]
Apr 21 05:00:44.546: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.100.189 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4653 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:00:44.546: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:00:45.771: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:00:45.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4653" for this suite.
Apr 21 05:00:59.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:01:01.151: INFO: namespace pod-network-test-4653 deletion completed in 15.337133222s

• [SLOW TEST:41.927 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:01:01.154: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-e6b237bf-adb3-4663-b067-260e8d1e0b78
STEP: Creating a pod to test consume secrets
Apr 21 05:01:01.511: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77" in namespace "projected-6974" to be "success or failure"
Apr 21 05:01:01.526: INFO: Pod "pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77": Phase="Pending", Reason="", readiness=false. Elapsed: 15.403777ms
Apr 21 05:01:05.910: INFO: Pod "pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77": Phase="Pending", Reason="", readiness=false. Elapsed: 4.399628604s
Apr 21 05:01:07.929: INFO: Pod "pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.418668902s
STEP: Saw pod success
Apr 21 05:01:07.929: INFO: Pod "pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77" satisfied condition "success or failure"
Apr 21 05:01:07.944: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:01:08.094: INFO: Waiting for pod pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77 to disappear
Apr 21 05:01:08.115: INFO: Pod pod-projected-secrets-e5efe7db-600c-4dee-afff-2521cc67cd77 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:01:08.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6974" for this suite.
Apr 21 05:01:16.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:01:16.891: INFO: namespace projected-6974 deletion completed in 8.747916271s

• [SLOW TEST:15.738 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:01:16.892: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1505
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:01:17.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1505" for this suite.
Apr 21 05:01:25.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:01:26.194: INFO: namespace resourcequota-1505 deletion completed in 8.786630853s

• [SLOW TEST:9.302 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:01:26.195: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 21 05:01:26.976: INFO: Waiting up to 5m0s for pod "pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4" in namespace "emptydir-347" to be "success or failure"
Apr 21 05:01:27.006: INFO: Pod "pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4": Phase="Pending", Reason="", readiness=false. Elapsed: 29.959879ms
Apr 21 05:01:29.025: INFO: Pod "pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04900145s
Apr 21 05:01:31.042: INFO: Pod "pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065800077s
STEP: Saw pod success
Apr 21 05:01:31.042: INFO: Pod "pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4" satisfied condition "success or failure"
Apr 21 05:01:31.061: INFO: Trying to get logs from node 10.177.30.144 pod pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4 container test-container: <nil>
STEP: delete the pod
Apr 21 05:01:31.158: INFO: Waiting for pod pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4 to disappear
Apr 21 05:01:31.175: INFO: Pod pod-a2a1bc05-c65d-452e-a4aa-5d3bd3b768f4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:01:31.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-347" for this suite.
Apr 21 05:01:39.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:01:40.097: INFO: namespace emptydir-347 deletion completed in 8.880551358s

• [SLOW TEST:13.903 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:01:40.098: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5899
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr 21 05:01:40.416: INFO: Waiting up to 5m0s for pod "downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce" in namespace "downward-api-5899" to be "success or failure"
Apr 21 05:01:40.434: INFO: Pod "downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce": Phase="Pending", Reason="", readiness=false. Elapsed: 17.930628ms
Apr 21 05:01:42.456: INFO: Pod "downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039805067s
STEP: Saw pod success
Apr 21 05:01:42.456: INFO: Pod "downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce" satisfied condition "success or failure"
Apr 21 05:01:42.473: INFO: Trying to get logs from node 10.177.30.140 pod downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce container dapi-container: <nil>
STEP: delete the pod
Apr 21 05:01:42.642: INFO: Waiting for pod downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce to disappear
Apr 21 05:01:42.657: INFO: Pod downward-api-7e40a4a7-afbe-4703-bfdd-b8ff0b87c8ce no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:01:42.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5899" for this suite.
Apr 21 05:01:50.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:01:51.450: INFO: namespace downward-api-5899 deletion completed in 8.76669787s

• [SLOW TEST:11.352 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:01:51.450: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-aeaf10ac-8431-4a04-b871-dd9bcd7ab205
STEP: Creating a pod to test consume configMaps
Apr 21 05:01:51.835: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4" in namespace "projected-6628" to be "success or failure"
Apr 21 05:01:51.856: INFO: Pod "pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.847769ms
Apr 21 05:01:53.872: INFO: Pod "pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036879513s
Apr 21 05:01:55.890: INFO: Pod "pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055337383s
STEP: Saw pod success
Apr 21 05:01:55.890: INFO: Pod "pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4" satisfied condition "success or failure"
Apr 21 05:01:55.905: INFO: Trying to get logs from node 10.177.30.186 pod pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:01:56.084: INFO: Waiting for pod pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4 to disappear
Apr 21 05:01:56.106: INFO: Pod pod-projected-configmaps-403ef7a1-eabf-48c6-a222-017a492d77c4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:01:56.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6628" for this suite.
Apr 21 05:02:04.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:02:05.174: INFO: namespace projected-6628 deletion completed in 9.041112666s

• [SLOW TEST:13.724 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:02:05.174: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2039
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-8907b59c-719f-40ce-9b74-bf8fe631cc27
STEP: Creating a pod to test consume configMaps
Apr 21 05:02:05.537: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7" in namespace "projected-2039" to be "success or failure"
Apr 21 05:02:05.565: INFO: Pod "pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.401667ms
Apr 21 05:02:07.582: INFO: Pod "pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044405011s
STEP: Saw pod success
Apr 21 05:02:07.582: INFO: Pod "pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7" satisfied condition "success or failure"
Apr 21 05:02:07.638: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:02:07.790: INFO: Waiting for pod pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7 to disappear
Apr 21 05:02:07.813: INFO: Pod pod-projected-configmaps-11b7e790-b193-4352-b275-20208e8f82d7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:02:07.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2039" for this suite.
Apr 21 05:02:15.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:02:16.795: INFO: namespace projected-2039 deletion completed in 8.953360068s

• [SLOW TEST:11.621 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:02:16.795: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:02:17.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291" in namespace "downward-api-1049" to be "success or failure"
Apr 21 05:02:17.146: INFO: Pod "downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291": Phase="Pending", Reason="", readiness=false. Elapsed: 24.613371ms
Apr 21 05:02:19.162: INFO: Pod "downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041454357s
Apr 21 05:02:21.180: INFO: Pod "downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059473178s
STEP: Saw pod success
Apr 21 05:02:21.181: INFO: Pod "downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291" satisfied condition "success or failure"
Apr 21 05:02:21.197: INFO: Trying to get logs from node 10.177.30.144 pod downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291 container client-container: <nil>
STEP: delete the pod
Apr 21 05:02:21.309: INFO: Waiting for pod downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291 to disappear
Apr 21 05:02:21.327: INFO: Pod downwardapi-volume-8a48a0a5-90fe-419e-94f5-a304fed17291 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:02:21.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1049" for this suite.
Apr 21 05:02:29.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:02:30.117: INFO: namespace downward-api-1049 deletion completed in 8.765312465s

• [SLOW TEST:13.323 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:02:30.118: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:02:30.638: INFO: Create a RollingUpdate DaemonSet
Apr 21 05:02:30.660: INFO: Check that daemon pods launch on every node of the cluster
Apr 21 05:02:30.707: INFO: Number of nodes with available pods: 0
Apr 21 05:02:30.707: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:31.780: INFO: Number of nodes with available pods: 0
Apr 21 05:02:31.780: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:32.763: INFO: Number of nodes with available pods: 1
Apr 21 05:02:32.763: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:33.755: INFO: Number of nodes with available pods: 1
Apr 21 05:02:33.755: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:34.759: INFO: Number of nodes with available pods: 1
Apr 21 05:02:34.759: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:35.759: INFO: Number of nodes with available pods: 1
Apr 21 05:02:35.759: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:36.756: INFO: Number of nodes with available pods: 1
Apr 21 05:02:36.756: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:02:37.754: INFO: Number of nodes with available pods: 3
Apr 21 05:02:37.754: INFO: Number of running nodes: 3, number of available pods: 3
Apr 21 05:02:37.754: INFO: Update the DaemonSet to trigger a rollout
Apr 21 05:02:37.807: INFO: Updating DaemonSet daemon-set
Apr 21 05:02:52.907: INFO: Roll back the DaemonSet before rollout is complete
Apr 21 05:02:52.948: INFO: Updating DaemonSet daemon-set
Apr 21 05:02:52.948: INFO: Make sure DaemonSet rollback is complete
Apr 21 05:02:52.966: INFO: Wrong image for pod: daemon-set-bvrnl. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 21 05:02:52.966: INFO: Pod daemon-set-bvrnl is not available
Apr 21 05:02:54.035: INFO: Wrong image for pod: daemon-set-bvrnl. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr 21 05:02:54.035: INFO: Pod daemon-set-bvrnl is not available
Apr 21 05:02:55.019: INFO: Pod daemon-set-f9cll is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1937, will wait for the garbage collector to delete the pods
Apr 21 05:02:55.234: INFO: Deleting DaemonSet.extensions daemon-set took: 35.405519ms
Apr 21 05:02:55.535: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.286987ms
Apr 21 05:03:04.659: INFO: Number of nodes with available pods: 0
Apr 21 05:03:04.659: INFO: Number of running nodes: 0, number of available pods: 0
Apr 21 05:03:04.680: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1937/daemonsets","resourceVersion":"24827"},"items":null}

Apr 21 05:03:04.712: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1937/pods","resourceVersion":"24827"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:03:04.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1937" for this suite.
Apr 21 05:03:14.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:03:15.561: INFO: namespace daemonsets-1937 deletion completed in 10.719664651s

• [SLOW TEST:45.443 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:03:15.561: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:03:42.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5266" for this suite.
Apr 21 05:03:50.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:03:50.865: INFO: namespace container-runtime-5266 deletion completed in 8.789443193s

• [SLOW TEST:35.304 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:03:50.866: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 21 05:03:52.984: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 05:03:56.150: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:03:56.177: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:03:57.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4363" for this suite.
Apr 21 05:04:05.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:04:06.592: INFO: namespace crd-webhook-4363 deletion completed in 8.806402208s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:15.827 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:04:06.692: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1304
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9b91feec-19d8-4f4e-aea0-3eaeed7e5329
STEP: Creating a pod to test consume configMaps
Apr 21 05:04:07.053: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524" in namespace "configmap-1304" to be "success or failure"
Apr 21 05:04:07.082: INFO: Pod "pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524": Phase="Pending", Reason="", readiness=false. Elapsed: 28.929701ms
Apr 21 05:04:09.101: INFO: Pod "pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047789968s
Apr 21 05:04:11.118: INFO: Pod "pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065357692s
STEP: Saw pod success
Apr 21 05:04:11.118: INFO: Pod "pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524" satisfied condition "success or failure"
Apr 21 05:04:11.135: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:04:11.317: INFO: Waiting for pod pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524 to disappear
Apr 21 05:04:11.339: INFO: Pod pod-configmaps-9c8697c8-c8db-4c6d-b4dd-1711eb462524 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:04:11.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1304" for this suite.
Apr 21 05:04:19.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:04:20.230: INFO: namespace configmap-1304 deletion completed in 8.86186605s

• [SLOW TEST:13.538 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:04:20.231: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 05:04:20.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6709'
Apr 21 05:04:20.749: INFO: stderr: ""
Apr 21 05:04:20.749: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Apr 21 05:04:20.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete pods e2e-test-httpd-pod --namespace=kubectl-6709'
Apr 21 05:04:23.673: INFO: stderr: ""
Apr 21 05:04:23.673: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:04:23.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6709" for this suite.
Apr 21 05:04:31.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:04:32.548: INFO: namespace kubectl-6709 deletion completed in 8.844800554s

• [SLOW TEST:12.317 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:04:32.552: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:04:32.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1089" for this suite.
Apr 21 05:05:03.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:05:03.712: INFO: namespace pods-1089 deletion completed in 30.750919609s

• [SLOW TEST:31.160 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:05:03.712: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1430
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Apr 21 05:05:04.056: INFO: Waiting up to 5m0s for pod "pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca" in namespace "emptydir-1430" to be "success or failure"
Apr 21 05:05:04.081: INFO: Pod "pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca": Phase="Pending", Reason="", readiness=false. Elapsed: 25.048633ms
Apr 21 05:05:06.099: INFO: Pod "pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042835644s
STEP: Saw pod success
Apr 21 05:05:06.099: INFO: Pod "pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca" satisfied condition "success or failure"
Apr 21 05:05:06.129: INFO: Trying to get logs from node 10.177.30.144 pod pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca container test-container: <nil>
STEP: delete the pod
Apr 21 05:05:06.295: INFO: Waiting for pod pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca to disappear
Apr 21 05:05:06.319: INFO: Pod pod-fbd7ec30-2c9f-4509-8d6b-fbc9f51683ca no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:05:06.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1430" for this suite.
Apr 21 05:05:14.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:05:15.097: INFO: namespace emptydir-1430 deletion completed in 8.752828851s

• [SLOW TEST:11.385 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:05:15.100: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr 21 05:05:15.480: INFO: Waiting up to 5m0s for pod "pod-9eeb3737-36e7-433c-b74e-22e958c45b7f" in namespace "emptydir-5757" to be "success or failure"
Apr 21 05:05:15.501: INFO: Pod "pod-9eeb3737-36e7-433c-b74e-22e958c45b7f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.608427ms
Apr 21 05:05:17.523: INFO: Pod "pod-9eeb3737-36e7-433c-b74e-22e958c45b7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043267256s
Apr 21 05:05:19.539: INFO: Pod "pod-9eeb3737-36e7-433c-b74e-22e958c45b7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.059280875s
STEP: Saw pod success
Apr 21 05:05:19.540: INFO: Pod "pod-9eeb3737-36e7-433c-b74e-22e958c45b7f" satisfied condition "success or failure"
Apr 21 05:05:19.558: INFO: Trying to get logs from node 10.177.30.186 pod pod-9eeb3737-36e7-433c-b74e-22e958c45b7f container test-container: <nil>
STEP: delete the pod
Apr 21 05:05:19.779: INFO: Waiting for pod pod-9eeb3737-36e7-433c-b74e-22e958c45b7f to disappear
Apr 21 05:05:19.827: INFO: Pod pod-9eeb3737-36e7-433c-b74e-22e958c45b7f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:05:19.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5757" for this suite.
Apr 21 05:05:27.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:05:28.613: INFO: namespace emptydir-5757 deletion completed in 8.748661958s

• [SLOW TEST:13.513 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:05:28.613: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2054
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:05:28.952: INFO: Waiting up to 5m0s for pod "downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c" in namespace "downward-api-2054" to be "success or failure"
Apr 21 05:05:28.975: INFO: Pod "downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c": Phase="Pending", Reason="", readiness=false. Elapsed: 23.055006ms
Apr 21 05:05:30.991: INFO: Pod "downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038997034s
Apr 21 05:05:33.012: INFO: Pod "downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060486046s
STEP: Saw pod success
Apr 21 05:05:33.012: INFO: Pod "downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c" satisfied condition "success or failure"
Apr 21 05:05:33.027: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c container client-container: <nil>
STEP: delete the pod
Apr 21 05:05:33.144: INFO: Waiting for pod downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c to disappear
Apr 21 05:05:33.168: INFO: Pod downwardapi-volume-61360ffe-afd3-46ef-a922-f9c7bc6d544c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:05:33.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2054" for this suite.
Apr 21 05:05:41.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:05:41.994: INFO: namespace downward-api-2054 deletion completed in 8.791211655s

• [SLOW TEST:13.381 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:05:41.995: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 21 05:05:42.403: INFO: Waiting up to 5m0s for pod "pod-d479c763-15fd-47b7-a237-6f61190eb7e4" in namespace "emptydir-2125" to be "success or failure"
Apr 21 05:05:42.443: INFO: Pod "pod-d479c763-15fd-47b7-a237-6f61190eb7e4": Phase="Pending", Reason="", readiness=false. Elapsed: 39.609116ms
Apr 21 05:05:44.460: INFO: Pod "pod-d479c763-15fd-47b7-a237-6f61190eb7e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056619612s
Apr 21 05:05:46.478: INFO: Pod "pod-d479c763-15fd-47b7-a237-6f61190eb7e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075021639s
STEP: Saw pod success
Apr 21 05:05:46.478: INFO: Pod "pod-d479c763-15fd-47b7-a237-6f61190eb7e4" satisfied condition "success or failure"
Apr 21 05:05:46.497: INFO: Trying to get logs from node 10.177.30.186 pod pod-d479c763-15fd-47b7-a237-6f61190eb7e4 container test-container: <nil>
STEP: delete the pod
Apr 21 05:05:46.589: INFO: Waiting for pod pod-d479c763-15fd-47b7-a237-6f61190eb7e4 to disappear
Apr 21 05:05:46.607: INFO: Pod pod-d479c763-15fd-47b7-a237-6f61190eb7e4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:05:46.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2125" for this suite.
Apr 21 05:05:54.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:05:55.365: INFO: namespace emptydir-2125 deletion completed in 8.722430618s

• [SLOW TEST:13.371 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:05:55.366: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4319
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 21 05:05:55.708: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 21 05:06:18.167: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.12.96:8080/dial?request=hostName&protocol=udp&host=172.30.100.147&port=8081&tries=1'] Namespace:pod-network-test-4319 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:06:18.167: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:06:18.440: INFO: Waiting for endpoints: map[]
Apr 21 05:06:18.462: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.12.96:8080/dial?request=hostName&protocol=udp&host=172.30.121.24&port=8081&tries=1'] Namespace:pod-network-test-4319 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:06:18.462: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:06:18.695: INFO: Waiting for endpoints: map[]
Apr 21 05:06:18.709: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.12.96:8080/dial?request=hostName&protocol=udp&host=172.30.12.95&port=8081&tries=1'] Namespace:pod-network-test-4319 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:06:18.709: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:06:18.941: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:06:18.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4319" for this suite.
Apr 21 05:06:35.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:06:36.226: INFO: namespace pod-network-test-4319 deletion completed in 17.247975726s

• [SLOW TEST:40.861 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:06:36.228: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4688
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:06:36.538: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 21 05:06:41.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-4688 create -f -'
Apr 21 05:06:42.475: INFO: stderr: ""
Apr 21 05:06:42.475: INFO: stdout: "e2e-test-crd-publish-openapi-2960-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 21 05:06:42.475: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-4688 delete e2e-test-crd-publish-openapi-2960-crds test-cr'
Apr 21 05:06:42.703: INFO: stderr: ""
Apr 21 05:06:42.703: INFO: stdout: "e2e-test-crd-publish-openapi-2960-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr 21 05:06:42.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-4688 apply -f -'
Apr 21 05:06:43.215: INFO: stderr: ""
Apr 21 05:06:43.215: INFO: stdout: "e2e-test-crd-publish-openapi-2960-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr 21 05:06:43.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-4688 delete e2e-test-crd-publish-openapi-2960-crds test-cr'
Apr 21 05:06:43.403: INFO: stderr: ""
Apr 21 05:06:43.403: INFO: stdout: "e2e-test-crd-publish-openapi-2960-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 21 05:06:43.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-2960-crds'
Apr 21 05:06:43.828: INFO: stderr: ""
Apr 21 05:06:43.828: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2960-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:06:48.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4688" for this suite.
Apr 21 05:06:56.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:06:57.129: INFO: namespace crd-publish-openapi-4688 deletion completed in 8.694358903s

• [SLOW TEST:20.902 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:06:57.132: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr 21 05:07:00.058: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5991 pod-service-account-0547332c-e89f-4aa1-aa2f-a87963be5b13 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr 21 05:07:00.461: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5991 pod-service-account-0547332c-e89f-4aa1-aa2f-a87963be5b13 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr 21 05:07:00.861: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5991 pod-service-account-0547332c-e89f-4aa1-aa2f-a87963be5b13 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:07:01.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5991" for this suite.
Apr 21 05:07:09.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:07:09.995: INFO: namespace svcaccounts-5991 deletion completed in 8.676127186s

• [SLOW TEST:12.863 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:07:09.997: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7123
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 05:07:10.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7123'
Apr 21 05:07:10.497: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 21 05:07:10.497: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Apr 21 05:07:10.527: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Apr 21 05:07:10.561: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Apr 21 05:07:10.588: INFO: scanned /root for discovery docs: <nil>
Apr 21 05:07:10.588: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7123'
Apr 21 05:07:26.911: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 21 05:07:26.911: INFO: stdout: "Created e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758\nScaling up e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Apr 21 05:07:26.911: INFO: stdout: "Created e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758\nScaling up e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Apr 21 05:07:26.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-7123'
Apr 21 05:07:27.067: INFO: stderr: ""
Apr 21 05:07:27.067: INFO: stdout: "e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758-wm7tk "
Apr 21 05:07:27.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758-wm7tk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7123'
Apr 21 05:07:27.238: INFO: stderr: ""
Apr 21 05:07:27.238: INFO: stdout: "true"
Apr 21 05:07:27.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758-wm7tk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7123'
Apr 21 05:07:27.416: INFO: stderr: ""
Apr 21 05:07:27.416: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Apr 21 05:07:27.416: INFO: e2e-test-httpd-rc-66d53dbf5e9e51728fc0343cc67e6758-wm7tk is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Apr 21 05:07:27.417: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete rc e2e-test-httpd-rc --namespace=kubectl-7123'
Apr 21 05:07:27.644: INFO: stderr: ""
Apr 21 05:07:27.644: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:07:27.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7123" for this suite.
Apr 21 05:07:41.742: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:07:42.355: INFO: namespace kubectl-7123 deletion completed in 14.687925095s

• [SLOW TEST:32.358 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:07:42.358: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr 21 05:07:42.741: INFO: Waiting up to 5m0s for pod "downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03" in namespace "downward-api-6326" to be "success or failure"
Apr 21 05:07:42.766: INFO: Pod "downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03": Phase="Pending", Reason="", readiness=false. Elapsed: 24.593147ms
Apr 21 05:07:44.781: INFO: Pod "downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039872984s
Apr 21 05:07:46.808: INFO: Pod "downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066214612s
STEP: Saw pod success
Apr 21 05:07:46.808: INFO: Pod "downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03" satisfied condition "success or failure"
Apr 21 05:07:46.829: INFO: Trying to get logs from node 10.177.30.140 pod downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03 container dapi-container: <nil>
STEP: delete the pod
Apr 21 05:07:46.986: INFO: Waiting for pod downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03 to disappear
Apr 21 05:07:47.008: INFO: Pod downward-api-9f5e2f30-1dba-416e-9889-13d3a6d76f03 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:07:47.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6326" for this suite.
Apr 21 05:07:55.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:07:56.137: INFO: namespace downward-api-6326 deletion completed in 9.104971917s

• [SLOW TEST:13.779 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:07:56.137: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3721
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3721
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3721
STEP: creating replication controller externalsvc in namespace services-3721
I0421 05:07:56.589990      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3721, replica count: 2
I0421 05:07:59.640945      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr 21 05:07:59.778: INFO: Creating new exec pod
Apr 21 05:08:03.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-3721 execpodllhkn -- /bin/sh -x -c nslookup clusterip-service'
Apr 21 05:08:04.223: INFO: stderr: "+ nslookup clusterip-service\n"
Apr 21 05:08:04.223: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-3721.svc.cluster.local\tcanonical name = externalsvc.services-3721.svc.cluster.local.\nName:\texternalsvc.services-3721.svc.cluster.local\nAddress: 172.21.105.251\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3721, will wait for the garbage collector to delete the pods
Apr 21 05:08:04.335: INFO: Deleting ReplicationController externalsvc took: 44.664427ms
Apr 21 05:08:04.536: INFO: Terminating ReplicationController externalsvc pods took: 200.341539ms
Apr 21 05:08:12.474: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:08:12.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3721" for this suite.
Apr 21 05:08:20.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:08:21.332: INFO: namespace services-3721 deletion completed in 8.730206992s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.195 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:08:21.332: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 05:08:22.575: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 05:08:24.634: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723042502, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723042502, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723042502, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723042502, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 05:08:27.748: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:08:27.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2881" for this suite.
Apr 21 05:08:36.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:08:36.674: INFO: namespace webhook-2881 deletion completed in 8.666055337s
STEP: Destroying namespace "webhook-2881-markers" for this suite.
Apr 21 05:08:44.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:08:45.480: INFO: namespace webhook-2881-markers deletion completed in 8.806356226s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.248 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:08:45.581: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-xj8p
STEP: Creating a pod to test atomic-volume-subpath
Apr 21 05:08:45.945: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xj8p" in namespace "subpath-3211" to be "success or failure"
Apr 21 05:08:45.966: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Pending", Reason="", readiness=false. Elapsed: 21.69578ms
Apr 21 05:08:47.981: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036622313s
Apr 21 05:08:50.005: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 4.060582657s
Apr 21 05:08:52.031: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 6.086392583s
Apr 21 05:08:54.355: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 8.410018487s
Apr 21 05:08:56.371: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 10.426430378s
Apr 21 05:08:58.386: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 12.441297787s
Apr 21 05:09:00.416: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 14.471772724s
Apr 21 05:09:02.432: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 16.487804802s
Apr 21 05:09:04.446: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 18.501068161s
Apr 21 05:09:06.471: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Running", Reason="", readiness=true. Elapsed: 20.526418121s
Apr 21 05:09:08.492: INFO: Pod "pod-subpath-test-downwardapi-xj8p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.547197804s
STEP: Saw pod success
Apr 21 05:09:08.492: INFO: Pod "pod-subpath-test-downwardapi-xj8p" satisfied condition "success or failure"
Apr 21 05:09:08.506: INFO: Trying to get logs from node 10.177.30.186 pod pod-subpath-test-downwardapi-xj8p container test-container-subpath-downwardapi-xj8p: <nil>
STEP: delete the pod
Apr 21 05:09:08.659: INFO: Waiting for pod pod-subpath-test-downwardapi-xj8p to disappear
Apr 21 05:09:08.673: INFO: Pod pod-subpath-test-downwardapi-xj8p no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xj8p
Apr 21 05:09:08.673: INFO: Deleting pod "pod-subpath-test-downwardapi-xj8p" in namespace "subpath-3211"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:09:08.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3211" for this suite.
Apr 21 05:09:16.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:09:18.330: INFO: namespace subpath-3211 deletion completed in 9.598756317s

• [SLOW TEST:32.749 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:09:18.330: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr 21 05:09:18.668: INFO: Waiting up to 5m0s for pod "pod-f055d524-c3ab-4c4b-bfae-679f1751f030" in namespace "emptydir-9633" to be "success or failure"
Apr 21 05:09:18.681: INFO: Pod "pod-f055d524-c3ab-4c4b-bfae-679f1751f030": Phase="Pending", Reason="", readiness=false. Elapsed: 13.361895ms
Apr 21 05:09:20.700: INFO: Pod "pod-f055d524-c3ab-4c4b-bfae-679f1751f030": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032720758s
Apr 21 05:09:22.720: INFO: Pod "pod-f055d524-c3ab-4c4b-bfae-679f1751f030": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052689606s
STEP: Saw pod success
Apr 21 05:09:22.721: INFO: Pod "pod-f055d524-c3ab-4c4b-bfae-679f1751f030" satisfied condition "success or failure"
Apr 21 05:09:22.733: INFO: Trying to get logs from node 10.177.30.144 pod pod-f055d524-c3ab-4c4b-bfae-679f1751f030 container test-container: <nil>
STEP: delete the pod
Apr 21 05:09:22.873: INFO: Waiting for pod pod-f055d524-c3ab-4c4b-bfae-679f1751f030 to disappear
Apr 21 05:09:22.901: INFO: Pod pod-f055d524-c3ab-4c4b-bfae-679f1751f030 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:09:22.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9633" for this suite.
Apr 21 05:09:31.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:09:31.775: INFO: namespace emptydir-9633 deletion completed in 8.847238256s

• [SLOW TEST:13.445 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:09:31.775: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Apr 21 05:09:32.053: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357945732 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:09:32.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5974" for this suite.
Apr 21 05:09:40.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:09:40.857: INFO: namespace kubectl-5974 deletion completed in 8.649027116s

• [SLOW TEST:9.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:09:40.859: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 05:09:41.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-8239'
Apr 21 05:09:41.383: INFO: stderr: ""
Apr 21 05:09:41.383: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr 21 05:09:46.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pod e2e-test-httpd-pod --namespace=kubectl-8239 -o json'
Apr 21 05:09:46.612: INFO: stderr: ""
Apr 21 05:09:46.612: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-04-21T05:09:41Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-8239\",\n        \"resourceVersion\": \"26462\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-8239/pods/e2e-test-httpd-pod\",\n        \"uid\": \"e3e56d16-da06-4f96-8819-c9683fe4d8e2\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-9rlst\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.177.30.144\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-9rlst\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-9rlst\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-21T05:09:41Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-21T05:09:43Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-21T05:09:43Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-21T05:09:41Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://f73a079125c82198770ded54d1312e26c75ea70bb072876906a4051792214d26\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-21T05:09:42Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.177.30.144\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.121.25\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.121.25\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-21T05:09:41Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr 21 05:09:46.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 replace -f - --namespace=kubectl-8239'
Apr 21 05:09:47.001: INFO: stderr: ""
Apr 21 05:09:47.001: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Apr 21 05:09:47.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete pods e2e-test-httpd-pod --namespace=kubectl-8239'
Apr 21 05:09:52.317: INFO: stderr: ""
Apr 21 05:09:52.317: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:09:52.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8239" for this suite.
Apr 21 05:10:00.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:10:01.212: INFO: namespace kubectl-8239 deletion completed in 8.869967712s

• [SLOW TEST:20.353 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:10:01.214: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr 21 05:10:04.130: INFO: Successfully updated pod "adopt-release-9ccxx"
STEP: Checking that the Job readopts the Pod
Apr 21 05:10:04.130: INFO: Waiting up to 15m0s for pod "adopt-release-9ccxx" in namespace "job-4298" to be "adopted"
Apr 21 05:10:04.160: INFO: Pod "adopt-release-9ccxx": Phase="Running", Reason="", readiness=true. Elapsed: 30.16773ms
Apr 21 05:10:06.176: INFO: Pod "adopt-release-9ccxx": Phase="Running", Reason="", readiness=true. Elapsed: 2.045493634s
Apr 21 05:10:06.176: INFO: Pod "adopt-release-9ccxx" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr 21 05:10:06.710: INFO: Successfully updated pod "adopt-release-9ccxx"
STEP: Checking that the Job releases the Pod
Apr 21 05:10:06.710: INFO: Waiting up to 15m0s for pod "adopt-release-9ccxx" in namespace "job-4298" to be "released"
Apr 21 05:10:06.726: INFO: Pod "adopt-release-9ccxx": Phase="Running", Reason="", readiness=true. Elapsed: 16.0756ms
Apr 21 05:10:08.743: INFO: Pod "adopt-release-9ccxx": Phase="Running", Reason="", readiness=true. Elapsed: 2.032789274s
Apr 21 05:10:08.743: INFO: Pod "adopt-release-9ccxx" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:10:08.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4298" for this suite.
Apr 21 05:10:58.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:10:59.902: INFO: namespace job-4298 deletion completed in 51.135937091s

• [SLOW TEST:58.688 seconds]
[sig-apps] Job
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:10:59.903: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:11:00.186: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:11:04.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2055" for this suite.
Apr 21 05:11:52.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:11:53.252: INFO: namespace pods-2055 deletion completed in 48.745836754s

• [SLOW TEST:53.350 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:11:53.253: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7931
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:11:53.550: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 21 05:11:58.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-7931 create -f -'
Apr 21 05:11:58.840: INFO: stderr: ""
Apr 21 05:11:58.840: INFO: stdout: "e2e-test-crd-publish-openapi-9636-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 21 05:11:58.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-7931 delete e2e-test-crd-publish-openapi-9636-crds test-cr'
Apr 21 05:11:59.175: INFO: stderr: ""
Apr 21 05:11:59.175: INFO: stdout: "e2e-test-crd-publish-openapi-9636-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr 21 05:11:59.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-7931 apply -f -'
Apr 21 05:11:59.732: INFO: stderr: ""
Apr 21 05:11:59.732: INFO: stdout: "e2e-test-crd-publish-openapi-9636-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr 21 05:11:59.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-7931 delete e2e-test-crd-publish-openapi-9636-crds test-cr'
Apr 21 05:11:59.971: INFO: stderr: ""
Apr 21 05:11:59.971: INFO: stdout: "e2e-test-crd-publish-openapi-9636-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr 21 05:11:59.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-9636-crds'
Apr 21 05:12:00.381: INFO: stderr: ""
Apr 21 05:12:00.381: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9636-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:12:04.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7931" for this suite.
Apr 21 05:12:13.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:12:13.851: INFO: namespace crd-publish-openapi-7931 deletion completed in 8.855937027s

• [SLOW TEST:20.598 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:12:13.852: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1755
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:12:14.199: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr 21 05:12:16.399: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:12:16.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1755" for this suite.
Apr 21 05:12:24.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:12:25.736: INFO: namespace replication-controller-1755 deletion completed in 9.288720202s

• [SLOW TEST:11.885 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:12:25.738: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0421 05:12:32.239091      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 21 05:12:32.239: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:12:32.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8163" for this suite.
Apr 21 05:12:42.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:12:43.050: INFO: namespace gc-8163 deletion completed in 10.780401253s

• [SLOW TEST:17.313 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:12:43.050: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-57b4a800-78a5-4919-a9b0-b7238e3592b7
STEP: Creating a pod to test consume secrets
Apr 21 05:12:43.427: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e" in namespace "projected-2515" to be "success or failure"
Apr 21 05:12:43.461: INFO: Pod "pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e": Phase="Pending", Reason="", readiness=false. Elapsed: 33.138266ms
Apr 21 05:12:45.476: INFO: Pod "pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048191295s
Apr 21 05:12:47.493: INFO: Pod "pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065772105s
STEP: Saw pod success
Apr 21 05:12:47.493: INFO: Pod "pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e" satisfied condition "success or failure"
Apr 21 05:12:47.510: INFO: Trying to get logs from node 10.177.30.186 pod pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:12:47.669: INFO: Waiting for pod pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e to disappear
Apr 21 05:12:47.691: INFO: Pod pod-projected-secrets-9454ba91-44b9-44eb-a562-229f376dc91e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:12:47.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2515" for this suite.
Apr 21 05:12:55.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:12:56.459: INFO: namespace projected-2515 deletion completed in 8.744440011s

• [SLOW TEST:13.409 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:12:56.460: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr 21 05:12:59.906: INFO: Successfully updated pod "labelsupdate6ccb2d35-4eae-4af3-911d-9053b2e2c088"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:13:04.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9143" for this suite.
Apr 21 05:13:18.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:13:18.874: INFO: namespace projected-9143 deletion completed in 14.767657107s

• [SLOW TEST:22.415 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:13:18.875: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3788
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:13:19.266: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b" in namespace "projected-3788" to be "success or failure"
Apr 21 05:13:19.302: INFO: Pod "downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b": Phase="Pending", Reason="", readiness=false. Elapsed: 36.447253ms
Apr 21 05:13:21.320: INFO: Pod "downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b": Phase="Running", Reason="", readiness=true. Elapsed: 2.053671275s
Apr 21 05:13:23.339: INFO: Pod "downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.073428141s
STEP: Saw pod success
Apr 21 05:13:23.340: INFO: Pod "downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b" satisfied condition "success or failure"
Apr 21 05:13:23.357: INFO: Trying to get logs from node 10.177.30.144 pod downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b container client-container: <nil>
STEP: delete the pod
Apr 21 05:13:23.511: INFO: Waiting for pod downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b to disappear
Apr 21 05:13:23.532: INFO: Pod downwardapi-volume-3b9b28de-c60a-436a-aa7c-da86b7d18e3b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:13:23.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3788" for this suite.
Apr 21 05:13:31.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:13:32.336: INFO: namespace projected-3788 deletion completed in 8.743515914s

• [SLOW TEST:13.462 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:13:32.337: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9758
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr 21 05:13:32.673: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr 21 05:13:53.476: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.121.34:8080/dial?request=hostName&protocol=http&host=172.30.12.112&port=8080&tries=1'] Namespace:pod-network-test-9758 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:13:53.476: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:13:53.750: INFO: Waiting for endpoints: map[]
Apr 21 05:13:53.771: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.121.34:8080/dial?request=hostName&protocol=http&host=172.30.100.156&port=8080&tries=1'] Namespace:pod-network-test-9758 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:13:53.771: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:13:54.035: INFO: Waiting for endpoints: map[]
Apr 21 05:13:54.054: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.121.34:8080/dial?request=hostName&protocol=http&host=172.30.121.33&port=8080&tries=1'] Namespace:pod-network-test-9758 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr 21 05:13:54.054: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:13:54.334: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:13:54.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9758" for this suite.
Apr 21 05:14:10.439: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:14:11.108: INFO: namespace pod-network-test-9758 deletion completed in 16.745645686s

• [SLOW TEST:38.772 seconds]
[sig-network] Networking
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:14:11.110: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9554
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-f4d17131-d04c-4c48-8b89-7ef1cfacde10
STEP: Creating a pod to test consume configMaps
Apr 21 05:14:11.509: INFO: Waiting up to 5m0s for pod "pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b" in namespace "configmap-9554" to be "success or failure"
Apr 21 05:14:11.529: INFO: Pod "pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b": Phase="Pending", Reason="", readiness=false. Elapsed: 20.236985ms
Apr 21 05:14:13.546: INFO: Pod "pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03685821s
Apr 21 05:14:15.570: INFO: Pod "pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060944978s
STEP: Saw pod success
Apr 21 05:14:15.570: INFO: Pod "pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b" satisfied condition "success or failure"
Apr 21 05:14:15.610: INFO: Trying to get logs from node 10.177.30.144 pod pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:14:15.735: INFO: Waiting for pod pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b to disappear
Apr 21 05:14:15.755: INFO: Pod pod-configmaps-05d20d72-69d0-4eea-9120-8f56e38f091b no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:14:15.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9554" for this suite.
Apr 21 05:14:23.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:14:24.550: INFO: namespace configmap-9554 deletion completed in 8.765235134s

• [SLOW TEST:13.440 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:14:24.551: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2846
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr 21 05:14:24.885: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 21 05:14:24.963: INFO: Waiting for terminating namespaces to be deleted...
Apr 21 05:14:24.994: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.140 before test
Apr 21 05:14:25.213: INFO: kubernetes-dashboard-69f9478454-5zrw2 from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 21 05:14:25.213: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-2xgwh from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:14:25.213: INFO: ibm-keepalived-watcher-6zs8n from kube-system started at 2020-04-21 03:03:32 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:14:25.213: INFO: ibm-storage-watcher-79b9bc9b7f-kwgsf from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 21 05:14:25.213: INFO: coredns-autoscaler-65c89858bf-m797t from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container autoscaler ready: true, restart count 0
Apr 21 05:14:25.213: INFO: metrics-server-878cfbdbd-p6vds from kube-system started at 2020-04-21 03:04:33 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container metrics-server ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 21 05:14:25.213: INFO: catalog-operator-645796fbdf-f9xlq from ibm-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container catalog-operator ready: true, restart count 0
Apr 21 05:14:25.213: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-9tr5l from ibm-system started at 2020-04-21 03:04:57 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:14:25.213: INFO: ibm-master-proxy-static-10.177.30.140 from kube-system started at 2020-04-21 03:03:31 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:14:25.213: INFO: dashboard-metrics-scraper-76756886dc-75b2w from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 21 05:14:25.213: INFO: calico-node-65w2l from kube-system started at 2020-04-21 03:03:33 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:14:25.213: INFO: vpn-79845b6f9d-ttgng from kube-system started at 2020-04-21 03:27:41 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container vpn ready: true, restart count 0
Apr 21 05:14:25.213: INFO: coredns-55db5d97fb-n6njz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:14:25.213: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:14:25.213: INFO: calico-kube-controllers-598ddbf99d-sjckj from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 21 05:14:25.213: INFO: ibm-file-plugin-b8d7f5977-kr78m from kube-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 21 05:14:25.213: INFO: olm-operator-7bf4dbc978-xlbj8 from ibm-system started at 2020-04-21 03:03:42 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.213: INFO: 	Container olm-operator ready: true, restart count 0
Apr 21 05:14:25.213: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.144 before test
Apr 21 05:14:25.277: INFO: addon-catalog-source-7cs9m from ibm-system started at 2020-04-21 03:05:54 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.277: INFO: 	Container configmap-registry-server ready: true, restart count 0
Apr 21 05:14:25.278: INFO: ibm-master-proxy-static-10.177.30.144 from kube-system started at 2020-04-21 03:04:52 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:14:25.278: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:14:25.278: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk from ibm-system started at 2020-04-21 03:05:11 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:14:25.278: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:14:25.278: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:14:25.278: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:14:25.278: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:14:25.278: INFO: calico-node-hz6bw from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:14:25.278: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:14:25.278: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:14:25.278: INFO: ibm-keepalived-watcher-n5w2g from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.278: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:14:25.279: INFO: coredns-55db5d97fb-8qn5q from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.279: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:14:25.279: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.186 before test
Apr 21 05:14:25.382: INFO: calico-node-ngcph from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:14:25.382: INFO: ibm-keepalived-watcher-9czcf from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:14:25.382: INFO: coredns-55db5d97fb-59ltz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:14:25.382: INFO: sonobuoy from sonobuoy started at 2020-04-21 04:37:03 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 21 05:14:25.382: INFO: ibm-master-proxy-static-10.177.30.186 from kube-system started at 2020-04-21 03:06:34 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:14:25.382: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:14:25.382: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-04-21 03:09:19 +0000 UTC (1 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Apr 21 05:14:25.382: INFO: sonobuoy-e2e-job-4f59fb8664564855 from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container e2e ready: true, restart count 0
Apr 21 05:14:25.382: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:14:25.382: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:14:25.382: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:14:25.382: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-d698abb8-ba92-47b2-b202-d1d950ed90cf 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-d698abb8-ba92-47b2-b202-d1d950ed90cf off the node 10.177.30.140
STEP: verifying the node doesn't have the label kubernetes.io/e2e-d698abb8-ba92-47b2-b202-d1d950ed90cf
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:19:31.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2846" for this suite.
Apr 21 05:19:54.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:19:54.821: INFO: namespace sched-pred-2846 deletion completed in 22.887643043s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:330.270 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:19:54.821: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Apr 21 05:19:55.127: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 21 05:20:55.225: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:20:55.247: INFO: Starting informer...
STEP: Starting pods...
Apr 21 05:20:55.559: INFO: Pod1 is running on 10.177.30.140. Tainting Node
Apr 21 05:20:59.877: INFO: Pod2 is running on 10.177.30.140. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Apr 21 05:21:12.346: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Apr 21 05:21:31.298: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:21:31.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9263" for this suite.
Apr 21 05:22:13.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:22:14.131: INFO: namespace taint-multiple-pods-9263 deletion completed in 42.726757228s

• [SLOW TEST:139.310 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:22:14.131: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-9684
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Apr 21 05:22:15.102: INFO: created pod pod-service-account-defaultsa
Apr 21 05:22:15.102: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr 21 05:22:15.156: INFO: created pod pod-service-account-mountsa
Apr 21 05:22:15.156: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr 21 05:22:15.186: INFO: created pod pod-service-account-nomountsa
Apr 21 05:22:15.186: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr 21 05:22:15.207: INFO: created pod pod-service-account-defaultsa-mountspec
Apr 21 05:22:15.207: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr 21 05:22:15.244: INFO: created pod pod-service-account-mountsa-mountspec
Apr 21 05:22:15.244: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr 21 05:22:15.269: INFO: created pod pod-service-account-nomountsa-mountspec
Apr 21 05:22:15.269: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr 21 05:22:15.297: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr 21 05:22:15.297: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr 21 05:22:15.325: INFO: created pod pod-service-account-mountsa-nomountspec
Apr 21 05:22:15.325: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr 21 05:22:15.348: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr 21 05:22:15.348: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:22:15.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-9684" for this suite.
Apr 21 05:22:23.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:22:24.169: INFO: namespace svcaccounts-9684 deletion completed in 8.787430268s

• [SLOW TEST:10.038 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:22:24.170: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-6gcb
STEP: Creating a pod to test atomic-volume-subpath
Apr 21 05:22:24.567: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-6gcb" in namespace "subpath-4726" to be "success or failure"
Apr 21 05:22:24.601: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Pending", Reason="", readiness=false. Elapsed: 33.984104ms
Apr 21 05:22:26.621: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 2.053983782s
Apr 21 05:22:28.647: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 4.079817899s
Apr 21 05:22:30.665: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 6.097606603s
Apr 21 05:22:32.697: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 8.129738773s
Apr 21 05:22:34.715: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 10.14724665s
Apr 21 05:22:36.733: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 12.165332414s
Apr 21 05:22:38.751: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 14.182995097s
Apr 21 05:22:40.770: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 16.202551074s
Apr 21 05:22:42.788: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 18.220862097s
Apr 21 05:22:44.804: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Running", Reason="", readiness=true. Elapsed: 20.236311128s
Apr 21 05:22:46.823: INFO: Pod "pod-subpath-test-configmap-6gcb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.255495068s
STEP: Saw pod success
Apr 21 05:22:46.823: INFO: Pod "pod-subpath-test-configmap-6gcb" satisfied condition "success or failure"
Apr 21 05:22:46.839: INFO: Trying to get logs from node 10.177.30.140 pod pod-subpath-test-configmap-6gcb container test-container-subpath-configmap-6gcb: <nil>
STEP: delete the pod
Apr 21 05:22:47.597: INFO: Waiting for pod pod-subpath-test-configmap-6gcb to disappear
Apr 21 05:22:47.617: INFO: Pod pod-subpath-test-configmap-6gcb no longer exists
STEP: Deleting pod pod-subpath-test-configmap-6gcb
Apr 21 05:22:47.617: INFO: Deleting pod "pod-subpath-test-configmap-6gcb" in namespace "subpath-4726"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:22:47.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4726" for this suite.
Apr 21 05:22:55.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:22:56.388: INFO: namespace subpath-4726 deletion completed in 8.722844707s

• [SLOW TEST:32.219 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:22:56.389: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-2562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:22:56.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-2562" for this suite.
Apr 21 05:23:04.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:23:05.548: INFO: namespace tables-2562 deletion completed in 8.776588865s

• [SLOW TEST:9.159 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:23:05.548: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5445.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5445.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5445.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5445.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5445.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5445.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:23:16.196: INFO: DNS probes using dns-5445/dns-test-7cec7df1-c083-46ed-9720-48d864f397ee succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:23:16.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5445" for this suite.
Apr 21 05:23:26.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:23:27.082: INFO: namespace dns-5445 deletion completed in 10.710910891s

• [SLOW TEST:21.534 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:23:27.083: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2894
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2894
STEP: creating replication controller externalsvc in namespace services-2894
I0421 05:23:27.543461      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2894, replica count: 2
I0421 05:23:30.594066      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr 21 05:23:30.709: INFO: Creating new exec pod
Apr 21 05:23:32.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-2894 execpodpzwks -- /bin/sh -x -c nslookup nodeport-service'
Apr 21 05:23:33.328: INFO: stderr: "+ nslookup nodeport-service\n"
Apr 21 05:23:33.328: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-2894.svc.cluster.local\tcanonical name = externalsvc.services-2894.svc.cluster.local.\nName:\texternalsvc.services-2894.svc.cluster.local\nAddress: 172.21.4.138\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2894, will wait for the garbage collector to delete the pods
Apr 21 05:23:33.453: INFO: Deleting ReplicationController externalsvc took: 44.842395ms
Apr 21 05:23:33.653: INFO: Terminating ReplicationController externalsvc pods took: 200.330549ms
Apr 21 05:23:42.455: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:23:42.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2894" for this suite.
Apr 21 05:23:50.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:23:51.322: INFO: namespace services-2894 deletion completed in 8.773605689s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:24.239 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:23:51.322: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-937/configmap-test-662c55b9-b44b-4b16-be51-d2e7ba08b422
STEP: Creating a pod to test consume configMaps
Apr 21 05:23:51.685: INFO: Waiting up to 5m0s for pod "pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3" in namespace "configmap-937" to be "success or failure"
Apr 21 05:23:51.705: INFO: Pod "pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.122797ms
Apr 21 05:23:53.720: INFO: Pod "pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3": Phase="Running", Reason="", readiness=true. Elapsed: 2.03515397s
Apr 21 05:23:55.737: INFO: Pod "pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051542166s
STEP: Saw pod success
Apr 21 05:23:55.737: INFO: Pod "pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3" satisfied condition "success or failure"
Apr 21 05:23:55.751: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3 container env-test: <nil>
STEP: delete the pod
Apr 21 05:23:55.850: INFO: Waiting for pod pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3 to disappear
Apr 21 05:23:55.869: INFO: Pod pod-configmaps-86f8a275-8224-47f4-9a66-e882ce1da5f3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:23:55.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-937" for this suite.
Apr 21 05:24:03.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:24:04.809: INFO: namespace configmap-937 deletion completed in 8.910744489s

• [SLOW TEST:13.487 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:24:04.810: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8164
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr 21 05:24:05.146: INFO: Waiting up to 5m0s for pod "pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3" in namespace "emptydir-8164" to be "success or failure"
Apr 21 05:24:05.161: INFO: Pod "pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3": Phase="Pending", Reason="", readiness=false. Elapsed: 14.315666ms
Apr 21 05:24:07.176: INFO: Pod "pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03003945s
Apr 21 05:24:09.194: INFO: Pod "pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047632831s
STEP: Saw pod success
Apr 21 05:24:09.194: INFO: Pod "pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3" satisfied condition "success or failure"
Apr 21 05:24:09.211: INFO: Trying to get logs from node 10.177.30.140 pod pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3 container test-container: <nil>
STEP: delete the pod
Apr 21 05:24:09.312: INFO: Waiting for pod pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3 to disappear
Apr 21 05:24:09.327: INFO: Pod pod-ba137d3c-5ab2-4464-9acf-4e6226f29bb3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:24:09.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8164" for this suite.
Apr 21 05:24:17.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:24:18.385: INFO: namespace emptydir-8164 deletion completed in 9.030221954s

• [SLOW TEST:13.576 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:24:18.386: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1963
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr 21 05:24:22.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec pod-sharedvolume-bcb11d58-5e8e-4437-9b1c-fc86d742302f -c busybox-main-container --namespace=emptydir-1963 -- cat /usr/share/volumeshare/shareddata.txt'
Apr 21 05:24:23.196: INFO: stderr: ""
Apr 21 05:24:23.196: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:24:23.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1963" for this suite.
Apr 21 05:24:31.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:24:31.964: INFO: namespace emptydir-1963 deletion completed in 8.73057977s

• [SLOW TEST:13.577 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:24:31.965: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr 21 05:24:32.307: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29578 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 21 05:24:32.307: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29578 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr 21 05:24:42.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29594 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 21 05:24:42.360: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29594 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr 21 05:24:52.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29607 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 21 05:24:52.711: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29607 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr 21 05:25:02.751: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29621 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 21 05:25:02.751: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-a 0609de4f-7598-4a07-b12e-87048fa61da9 29621 0 2020-04-21 05:24:32 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr 21 05:25:12.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-b 6105c90b-56c4-456e-9e98-0750f0575005 29636 0 2020-04-21 05:25:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 21 05:25:12.783: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-b 6105c90b-56c4-456e-9e98-0750f0575005 29636 0 2020-04-21 05:25:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr 21 05:25:22.832: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-b 6105c90b-56c4-456e-9e98-0750f0575005 29649 0 2020-04-21 05:25:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 21 05:25:22.833: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-414 /api/v1/namespaces/watch-414/configmaps/e2e-watch-test-configmap-b 6105c90b-56c4-456e-9e98-0750f0575005 29649 0 2020-04-21 05:25:12 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:25:32.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-414" for this suite.
Apr 21 05:25:40.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:25:41.619: INFO: namespace watch-414 deletion completed in 8.738266278s

• [SLOW TEST:69.654 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:25:41.619: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3615
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 05:25:41.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3615'
Apr 21 05:25:42.122: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 21 05:25:42.122: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Apr 21 05:25:42.168: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-ntxf7]
Apr 21 05:25:42.168: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-ntxf7" in namespace "kubectl-3615" to be "running and ready"
Apr 21 05:25:42.183: INFO: Pod "e2e-test-httpd-rc-ntxf7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.448282ms
Apr 21 05:25:44.205: INFO: Pod "e2e-test-httpd-rc-ntxf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037098854s
Apr 21 05:25:46.222: INFO: Pod "e2e-test-httpd-rc-ntxf7": Phase="Running", Reason="", readiness=true. Elapsed: 4.053803706s
Apr 21 05:25:46.222: INFO: Pod "e2e-test-httpd-rc-ntxf7" satisfied condition "running and ready"
Apr 21 05:25:46.222: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-ntxf7]
Apr 21 05:25:46.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs rc/e2e-test-httpd-rc --namespace=kubectl-3615'
Apr 21 05:25:46.522: INFO: stderr: ""
Apr 21 05:25:46.522: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.100.175. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.100.175. Set the 'ServerName' directive globally to suppress this message\n[Tue Apr 21 05:25:43.583746 2020] [mpm_event:notice] [pid 1:tid 140167361485672] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Apr 21 05:25:43.583813 2020] [core:notice] [pid 1:tid 140167361485672] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Apr 21 05:25:46.523: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete rc e2e-test-httpd-rc --namespace=kubectl-3615'
Apr 21 05:25:46.840: INFO: stderr: ""
Apr 21 05:25:46.840: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:25:46.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3615" for this suite.
Apr 21 05:25:54.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:25:55.605: INFO: namespace kubectl-3615 deletion completed in 8.732036485s

• [SLOW TEST:13.986 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:25:55.605: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3153
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:25:55.983: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr 21 05:26:00.998: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 21 05:26:00.998: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr 21 05:26:01.104: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3153 /apis/apps/v1/namespaces/deployment-3153/deployments/test-cleanup-deployment ba5aa1c3-777f-42c3-8836-3c26d81ff922 29777 1 2020-04-21 05:26:01 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004bafdf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr 21 05:26:01.121: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-3153 /apis/apps/v1/namespaces/deployment-3153/replicasets/test-cleanup-deployment-65db99849b 73c5b62f-94a8-4c39-a0b1-a8b502e75817 29779 1 2020-04-21 05:26:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment ba5aa1c3-777f-42c3-8836-3c26d81ff922 0xc002f2c257 0xc002f2c258}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002f2c2b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 05:26:01.121: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr 21 05:26:01.121: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3153 /apis/apps/v1/namespaces/deployment-3153/replicasets/test-cleanup-controller dba23fd6-e416-482f-9f23-bbf24f2674ad 29778 1 2020-04-21 05:25:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment ba5aa1c3-777f-42c3-8836-3c26d81ff922 0xc002f2c187 0xc002f2c188}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002f2c1e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 21 05:26:01.142: INFO: Pod "test-cleanup-controller-9hf7b" is available:
&Pod{ObjectMeta:{test-cleanup-controller-9hf7b test-cleanup-controller- deployment-3153 /api/v1/namespaces/deployment-3153/pods/test-cleanup-controller-9hf7b 2c8b2da6-b400-4d22-a8da-9d7801702a50 29769 0 2020-04-21 05:25:55 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller dba23fd6-e416-482f-9f23-bbf24f2674ad 0xc002f2c817 0xc002f2c818}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-794xw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-794xw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-794xw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:25:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:25:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:25:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:25:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.176,StartTime:2020-04-21 05:25:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 05:25:57 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://c4be00e6e301cadf3f1adaed537cb0fad2067459b6ebcc6283cb6f884a181203,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 05:26:01.142: INFO: Pod "test-cleanup-deployment-65db99849b-hwvwc" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-hwvwc test-cleanup-deployment-65db99849b- deployment-3153 /api/v1/namespaces/deployment-3153/pods/test-cleanup-deployment-65db99849b-hwvwc b6ea6d89-4f65-47f5-a9d5-5a75ebe1bc0c 29780 0 2020-04-21 05:26:01 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 73c5b62f-94a8-4c39-a0b1-a8b502e75817 0xc002f2c9a7 0xc002f2c9a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-794xw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-794xw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-794xw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:26:01.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3153" for this suite.
Apr 21 05:26:09.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:26:09.947: INFO: namespace deployment-3153 deletion completed in 8.780039309s

• [SLOW TEST:14.342 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:26:09.947: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-276
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1836cc1e-0406-4532-9b55-b78c7f4a5bd2
STEP: Creating a pod to test consume configMaps
Apr 21 05:26:10.325: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a" in namespace "projected-276" to be "success or failure"
Apr 21 05:26:10.346: INFO: Pod "pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a": Phase="Pending", Reason="", readiness=false. Elapsed: 20.725222ms
Apr 21 05:26:12.377: INFO: Pod "pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051565294s
Apr 21 05:26:14.397: INFO: Pod "pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071574197s
STEP: Saw pod success
Apr 21 05:26:14.397: INFO: Pod "pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a" satisfied condition "success or failure"
Apr 21 05:26:14.415: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:26:14.872: INFO: Waiting for pod pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a to disappear
Apr 21 05:26:14.890: INFO: Pod pod-projected-configmaps-9f6ea26a-d0a1-4cf8-ab44-fa660051495a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:26:14.891: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-276" for this suite.
Apr 21 05:26:23.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:26:23.718: INFO: namespace projected-276 deletion completed in 8.794514282s

• [SLOW TEST:13.771 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:26:23.719: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-gkvs
STEP: Creating a pod to test atomic-volume-subpath
Apr 21 05:26:24.180: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-gkvs" in namespace "subpath-6246" to be "success or failure"
Apr 21 05:26:24.200: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Pending", Reason="", readiness=false. Elapsed: 19.721705ms
Apr 21 05:26:26.216: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 2.036034942s
Apr 21 05:26:28.235: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 4.054738053s
Apr 21 05:26:30.255: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 6.074625081s
Apr 21 05:26:32.274: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 8.094245437s
Apr 21 05:26:34.291: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 10.1106483s
Apr 21 05:26:36.318: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 12.138115155s
Apr 21 05:26:38.334: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 14.15441174s
Apr 21 05:26:40.351: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 16.170912288s
Apr 21 05:26:42.368: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 18.188417778s
Apr 21 05:26:44.389: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Running", Reason="", readiness=true. Elapsed: 20.208611729s
Apr 21 05:26:46.407: INFO: Pod "pod-subpath-test-configmap-gkvs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.227171798s
STEP: Saw pod success
Apr 21 05:26:46.407: INFO: Pod "pod-subpath-test-configmap-gkvs" satisfied condition "success or failure"
Apr 21 05:26:46.429: INFO: Trying to get logs from node 10.177.30.140 pod pod-subpath-test-configmap-gkvs container test-container-subpath-configmap-gkvs: <nil>
STEP: delete the pod
Apr 21 05:26:46.573: INFO: Waiting for pod pod-subpath-test-configmap-gkvs to disappear
Apr 21 05:26:46.598: INFO: Pod pod-subpath-test-configmap-gkvs no longer exists
STEP: Deleting pod pod-subpath-test-configmap-gkvs
Apr 21 05:26:46.598: INFO: Deleting pod "pod-subpath-test-configmap-gkvs" in namespace "subpath-6246"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:26:46.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6246" for this suite.
Apr 21 05:26:54.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:26:55.498: INFO: namespace subpath-6246 deletion completed in 8.855941345s

• [SLOW TEST:31.780 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:26:55.499: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr 21 05:26:55.809: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 21 05:26:55.923: INFO: Waiting for terminating namespaces to be deleted...
Apr 21 05:26:55.951: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.140 before test
Apr 21 05:26:56.004: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.004: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:26:56.004: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:26:56.004: INFO: ibm-keepalived-watcher-6zs8n from kube-system started at 2020-04-21 03:03:32 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.004: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:26:56.004: INFO: ibm-master-proxy-static-10.177.30.140 from kube-system started at 2020-04-21 03:03:31 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.004: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:26:56.004: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:26:56.004: INFO: calico-node-65w2l from kube-system started at 2020-04-21 03:03:33 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.004: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:26:56.004: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.144 before test
Apr 21 05:26:56.132: INFO: kubernetes-dashboard-69f9478454-fzzpb from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 21 05:26:56.133: INFO: ibm-storage-watcher-79b9bc9b7f-4k67d from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 21 05:26:56.133: INFO: calico-node-hz6bw from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:26:56.133: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:26:56.133: INFO: vpn-79845b6f9d-887s2 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container vpn ready: true, restart count 0
Apr 21 05:26:56.133: INFO: coredns-55db5d97fb-q6jbf from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:26:56.133: INFO: catalog-operator-645796fbdf-lsqqt from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container catalog-operator ready: true, restart count 0
Apr 21 05:26:56.133: INFO: ibm-keepalived-watcher-n5w2g from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:26:56.133: INFO: coredns-55db5d97fb-8qn5q from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:26:56.133: INFO: addon-catalog-source-7cs9m from ibm-system started at 2020-04-21 03:05:54 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container configmap-registry-server ready: true, restart count 0
Apr 21 05:26:56.133: INFO: metrics-server-878cfbdbd-dkk8m from kube-system started at 2020-04-21 05:21:00 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container metrics-server ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 21 05:26:56.133: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:26:56.133: INFO: ibm-master-proxy-static-10.177.30.144 from kube-system started at 2020-04-21 03:04:52 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:26:56.133: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk from ibm-system started at 2020-04-21 03:05:11 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.133: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:26:56.133: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.186 before test
Apr 21 05:26:56.283: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:26:56.283: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-qfdjj from kube-system started at 2020-04-21 05:21:00 +0000 UTC (4 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:26:56.283: INFO: ibm-file-plugin-b8d7f5977-fkjtw from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 21 05:26:56.283: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-04-21 03:09:19 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Apr 21 05:26:56.283: INFO: ibm-keepalived-watcher-9czcf from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:26:56.283: INFO: coredns-autoscaler-65c89858bf-f4qc4 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container autoscaler ready: true, restart count 0
Apr 21 05:26:56.283: INFO: calico-node-ngcph from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:26:56.283: INFO: sonobuoy-e2e-job-4f59fb8664564855 from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container e2e ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:26:56.283: INFO: olm-operator-7bf4dbc978-kgjlz from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container olm-operator ready: true, restart count 0
Apr 21 05:26:56.283: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-m8x2p from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:26:56.283: INFO: ibm-master-proxy-static-10.177.30.186 from kube-system started at 2020-04-21 03:06:34 +0000 UTC (2 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:26:56.283: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:26:56.283: INFO: sonobuoy from sonobuoy started at 2020-04-21 04:37:03 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 21 05:26:56.283: INFO: calico-kube-controllers-598ddbf99d-mzh5s from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.283: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 21 05:26:56.284: INFO: dashboard-metrics-scraper-76756886dc-dp2kh from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.284: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 21 05:26:56.284: INFO: coredns-55db5d97fb-59ltz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:26:56.284: INFO: 	Container coredns ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.1607be7805e6f77b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:26:57.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-819" for this suite.
Apr 21 05:27:05.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:27:06.276: INFO: namespace sched-pred-819 deletion completed in 8.857546845s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:10.777 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:27:06.278: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3829
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:27:23.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3829" for this suite.
Apr 21 05:27:31.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:27:32.746: INFO: namespace resourcequota-3829 deletion completed in 8.868937728s

• [SLOW TEST:26.469 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:27:32.750: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1434
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr 21 05:27:33.218: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30084 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 21 05:27:33.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30085 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr 21 05:27:33.219: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30087 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr 21 05:27:43.387: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30103 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 21 05:27:43.388: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30104 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr 21 05:27:43.388: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-1434 /api/v1/namespaces/watch-1434/configmaps/e2e-watch-test-label-changed f217cbd5-16e7-4a8d-82b0-b8b4bdd809d4 30105 0 2020-04-21 05:27:33 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:27:43.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1434" for this suite.
Apr 21 05:27:51.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:27:52.250: INFO: namespace watch-1434 deletion completed in 8.833004677s

• [SLOW TEST:19.501 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:27:52.252: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 21 05:27:59.515: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 21 05:27:59.539: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 21 05:28:01.539: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 21 05:28:01.559: INFO: Pod pod-with-prestop-exec-hook still exists
Apr 21 05:28:03.539: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr 21 05:28:03.561: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:28:03.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3439" for this suite.
Apr 21 05:28:33.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:28:34.438: INFO: namespace container-lifecycle-hook-3439 deletion completed in 30.797332894s

• [SLOW TEST:42.185 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:28:34.438: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4870
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Apr 21 05:28:38.874: INFO: Pod pod-hostip-9d26072f-024e-4cb4-873f-259d065dadc4 has hostIP: 10.177.30.140
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:28:38.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4870" for this suite.
Apr 21 05:29:08.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:29:10.062: INFO: namespace pods-4870 deletion completed in 31.150398803s

• [SLOW TEST:35.624 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:29:10.063: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7946
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 21 05:29:13.575: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:29:13.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7946" for this suite.
Apr 21 05:29:21.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:29:22.497: INFO: namespace container-runtime-7946 deletion completed in 8.816744116s

• [SLOW TEST:12.435 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:29:22.497: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1889
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-131b051d-b519-4502-8634-e56827b4b906
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:29:25.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1889" for this suite.
Apr 21 05:29:39.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:29:39.892: INFO: namespace configmap-1889 deletion completed in 14.754253005s

• [SLOW TEST:17.394 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:29:39.892: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:29:40.198: INFO: Creating deployment "test-recreate-deployment"
Apr 21 05:29:40.223: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr 21 05:29:40.262: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr 21 05:29:42.294: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr 21 05:29:42.310: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr 21 05:29:42.352: INFO: Updating deployment test-recreate-deployment
Apr 21 05:29:42.352: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr 21 05:29:42.746: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9051 /apis/apps/v1/namespaces/deployment-9051/deployments/test-recreate-deployment bf17b9ea-fcfa-42be-a49d-0fff6a2f92c4 30500 2 2020-04-21 05:29:40 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004df4f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-21 05:29:42 +0000 UTC,LastTransitionTime:2020-04-21 05:29:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-04-21 05:29:42 +0000 UTC,LastTransitionTime:2020-04-21 05:29:40 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr 21 05:29:42.762: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-9051 /apis/apps/v1/namespaces/deployment-9051/replicasets/test-recreate-deployment-5f94c574ff 672ea83c-1403-4403-bd35-d78aa0351b16 30499 1 2020-04-21 05:29:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment bf17b9ea-fcfa-42be-a49d-0fff6a2f92c4 0xc004b63067 0xc004b63068}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b630c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 05:29:42.762: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr 21 05:29:42.762: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-9051 /apis/apps/v1/namespaces/deployment-9051/replicasets/test-recreate-deployment-68fc85c7bb aacb3211-1394-492a-aa6c-dcb594566951 30487 2 2020-04-21 05:29:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment bf17b9ea-fcfa-42be-a49d-0fff6a2f92c4 0xc004b63137 0xc004b63138}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b63198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 05:29:42.779: INFO: Pod "test-recreate-deployment-5f94c574ff-tb8m5" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-tb8m5 test-recreate-deployment-5f94c574ff- deployment-9051 /api/v1/namespaces/deployment-9051/pods/test-recreate-deployment-5f94c574ff-tb8m5 21bfa30c-ba30-411f-b4d1-594417cd328e 30498 0 2020-04-21 05:29:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 672ea83c-1403-4403-bd35-d78aa0351b16 0xc004b63607 0xc004b63608}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8hs2f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8hs2f,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8hs2f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:29:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:29:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:29:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:29:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:,StartTime:2020-04-21 05:29:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:29:42.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9051" for this suite.
Apr 21 05:29:50.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:29:51.552: INFO: namespace deployment-9051 deletion completed in 8.737764625s

• [SLOW TEST:11.660 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:29:51.553: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6480
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:29:51.877: INFO: Creating ReplicaSet my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84
Apr 21 05:29:51.925: INFO: Pod name my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84: Found 0 pods out of 1
Apr 21 05:29:56.942: INFO: Pod name my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84: Found 1 pods out of 1
Apr 21 05:29:56.943: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84" is running
Apr 21 05:29:56.958: INFO: Pod "my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84-p5khb" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 05:29:51 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 05:29:53 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 05:29:53 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 05:29:51 +0000 UTC Reason: Message:}])
Apr 21 05:29:56.958: INFO: Trying to dial the pod
Apr 21 05:30:02.048: INFO: Controller my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84: Got expected result from replica 1 [my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84-p5khb]: "my-hostname-basic-505b0795-a5a5-48fc-993a-e9f2e4e9dd84-p5khb", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:30:02.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6480" for this suite.
Apr 21 05:30:10.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:30:11.008: INFO: namespace replicaset-6480 deletion completed in 8.934434294s

• [SLOW TEST:19.455 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:30:11.009: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1472
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Apr 21 05:30:11.358: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:30:35.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1472" for this suite.
Apr 21 05:30:43.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:30:44.913: INFO: namespace crd-publish-openapi-1472 deletion completed in 9.459527463s

• [SLOW TEST:33.904 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:30:44.913: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4288
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-f513afb9-f291-403f-8f2c-988a9536831f in namespace container-probe-4288
Apr 21 05:30:47.331: INFO: Started pod test-webserver-f513afb9-f291-403f-8f2c-988a9536831f in namespace container-probe-4288
STEP: checking the pod's current state and verifying that restartCount is present
Apr 21 05:30:47.348: INFO: Initial restart count of pod test-webserver-f513afb9-f291-403f-8f2c-988a9536831f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:34:48.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4288" for this suite.
Apr 21 05:34:56.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:34:57.083: INFO: namespace container-probe-4288 deletion completed in 8.777894653s

• [SLOW TEST:252.170 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:34:57.084: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:34:58.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8661" for this suite.
Apr 21 05:35:06.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:35:06.947: INFO: namespace custom-resource-definition-8661 deletion completed in 8.815205435s

• [SLOW TEST:9.863 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:35:06.947: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3380
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-3e9fc690-32db-4415-9909-a99b6e02aa0a in namespace container-probe-3380
Apr 21 05:35:11.391: INFO: Started pod liveness-3e9fc690-32db-4415-9909-a99b6e02aa0a in namespace container-probe-3380
STEP: checking the pod's current state and verifying that restartCount is present
Apr 21 05:35:11.409: INFO: Initial restart count of pod liveness-3e9fc690-32db-4415-9909-a99b6e02aa0a is 0
Apr 21 05:35:28.135: INFO: Restart count of pod container-probe-3380/liveness-3e9fc690-32db-4415-9909-a99b6e02aa0a is now 1 (16.725771844s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:35:28.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3380" for this suite.
Apr 21 05:35:36.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:35:36.979: INFO: namespace container-probe-3380 deletion completed in 8.740748256s

• [SLOW TEST:30.032 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:35:36.981: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2078
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr 21 05:35:37.475: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2078 /api/v1/namespaces/watch-2078/configmaps/e2e-watch-test-resource-version fc2ca25c-db47-4130-a099-41e1873c0722 31187 0 2020-04-21 05:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 21 05:35:37.475: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2078 /api/v1/namespaces/watch-2078/configmaps/e2e-watch-test-resource-version fc2ca25c-db47-4130-a099-41e1873c0722 31188 0 2020-04-21 05:35:37 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:35:37.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2078" for this suite.
Apr 21 05:35:45.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:35:46.255: INFO: namespace watch-2078 deletion completed in 8.754581691s

• [SLOW TEST:9.274 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:35:46.257: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8823
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-220d1103-4ca4-4f00-be82-07a60fe22e09
STEP: Creating a pod to test consume secrets
Apr 21 05:35:46.700: INFO: Waiting up to 5m0s for pod "pod-secrets-56229110-10d5-445c-a203-db85b009dfb0" in namespace "secrets-8823" to be "success or failure"
Apr 21 05:35:46.718: INFO: Pod "pod-secrets-56229110-10d5-445c-a203-db85b009dfb0": Phase="Pending", Reason="", readiness=false. Elapsed: 18.738859ms
Apr 21 05:35:48.735: INFO: Pod "pod-secrets-56229110-10d5-445c-a203-db85b009dfb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035414526s
STEP: Saw pod success
Apr 21 05:35:48.735: INFO: Pod "pod-secrets-56229110-10d5-445c-a203-db85b009dfb0" satisfied condition "success or failure"
Apr 21 05:35:48.753: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-56229110-10d5-445c-a203-db85b009dfb0 container secret-env-test: <nil>
STEP: delete the pod
Apr 21 05:35:49.733: INFO: Waiting for pod pod-secrets-56229110-10d5-445c-a203-db85b009dfb0 to disappear
Apr 21 05:35:49.751: INFO: Pod pod-secrets-56229110-10d5-445c-a203-db85b009dfb0 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:35:49.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8823" for this suite.
Apr 21 05:35:57.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:35:58.577: INFO: namespace secrets-8823 deletion completed in 8.798885375s

• [SLOW TEST:12.321 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:35:58.578: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9844
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr 21 05:35:58.908: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr 21 05:36:16.438: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
Apr 21 05:36:21.105: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:36:38.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9844" for this suite.
Apr 21 05:36:46.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:36:47.685: INFO: namespace crd-publish-openapi-9844 deletion completed in 8.78208064s

• [SLOW TEST:49.108 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:36:47.691: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5003
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6232
STEP: Creating secret with name secret-test-014c506c-b11b-4f1d-a780-cab553670a68
STEP: Creating a pod to test consume secrets
Apr 21 05:36:48.413: INFO: Waiting up to 5m0s for pod "pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7" in namespace "secrets-5003" to be "success or failure"
Apr 21 05:36:48.437: INFO: Pod "pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.292101ms
Apr 21 05:36:50.457: INFO: Pod "pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044318063s
Apr 21 05:36:52.484: INFO: Pod "pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071495799s
STEP: Saw pod success
Apr 21 05:36:52.484: INFO: Pod "pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7" satisfied condition "success or failure"
Apr 21 05:36:52.513: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7 container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:36:52.619: INFO: Waiting for pod pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7 to disappear
Apr 21 05:36:52.662: INFO: Pod pod-secrets-6d14aa7b-4e4f-4c23-a268-31c0d02a2fd7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:36:52.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5003" for this suite.
Apr 21 05:37:01.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:37:02.036: INFO: namespace secrets-5003 deletion completed in 9.346477739s
STEP: Destroying namespace "secret-namespace-6232" for this suite.
Apr 21 05:37:10.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:37:11.425: INFO: namespace secret-namespace-6232 deletion completed in 9.389093525s

• [SLOW TEST:23.734 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:37:11.425: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-1b01c391-24d9-4a3d-9223-b16e97b73428
STEP: Creating a pod to test consume configMaps
Apr 21 05:37:11.864: INFO: Waiting up to 5m0s for pod "pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1" in namespace "configmap-9266" to be "success or failure"
Apr 21 05:37:11.886: INFO: Pod "pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.147493ms
Apr 21 05:37:13.909: INFO: Pod "pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044880891s
STEP: Saw pod success
Apr 21 05:37:13.909: INFO: Pod "pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1" satisfied condition "success or failure"
Apr 21 05:37:13.927: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 05:37:14.060: INFO: Waiting for pod pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1 to disappear
Apr 21 05:37:14.102: INFO: Pod pod-configmaps-c5e72aa8-8108-44db-99d9-706bfaecd6d1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:37:14.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9266" for this suite.
Apr 21 05:37:22.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:37:23.015: INFO: namespace configmap-9266 deletion completed in 8.887529711s

• [SLOW TEST:11.591 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:37:23.016: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr 21 05:37:24.693: INFO: Pod name wrapped-volume-race-48f62d51-06ef-4e20-a55f-39dbb496e19a: Found 0 pods out of 5
Apr 21 05:37:29.721: INFO: Pod name wrapped-volume-race-48f62d51-06ef-4e20-a55f-39dbb496e19a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-48f62d51-06ef-4e20-a55f-39dbb496e19a in namespace emptydir-wrapper-9661, will wait for the garbage collector to delete the pods
Apr 21 05:37:29.926: INFO: Deleting ReplicationController wrapped-volume-race-48f62d51-06ef-4e20-a55f-39dbb496e19a took: 46.836527ms
Apr 21 05:37:30.227: INFO: Terminating ReplicationController wrapped-volume-race-48f62d51-06ef-4e20-a55f-39dbb496e19a pods took: 300.289794ms
STEP: Creating RC which spawns configmap-volume pods
Apr 21 05:38:11.931: INFO: Pod name wrapped-volume-race-6c336f2d-ccdf-4261-acbf-ecccfc346653: Found 0 pods out of 5
Apr 21 05:38:16.964: INFO: Pod name wrapped-volume-race-6c336f2d-ccdf-4261-acbf-ecccfc346653: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-6c336f2d-ccdf-4261-acbf-ecccfc346653 in namespace emptydir-wrapper-9661, will wait for the garbage collector to delete the pods
Apr 21 05:38:17.197: INFO: Deleting ReplicationController wrapped-volume-race-6c336f2d-ccdf-4261-acbf-ecccfc346653 took: 54.081027ms
Apr 21 05:38:17.698: INFO: Terminating ReplicationController wrapped-volume-race-6c336f2d-ccdf-4261-acbf-ecccfc346653 pods took: 500.321743ms
STEP: Creating RC which spawns configmap-volume pods
Apr 21 05:39:02.065: INFO: Pod name wrapped-volume-race-9075b0e5-1e81-4e6f-b45d-a00f67b23fbe: Found 0 pods out of 5
Apr 21 05:39:07.096: INFO: Pod name wrapped-volume-race-9075b0e5-1e81-4e6f-b45d-a00f67b23fbe: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9075b0e5-1e81-4e6f-b45d-a00f67b23fbe in namespace emptydir-wrapper-9661, will wait for the garbage collector to delete the pods
Apr 21 05:39:07.324: INFO: Deleting ReplicationController wrapped-volume-race-9075b0e5-1e81-4e6f-b45d-a00f67b23fbe took: 61.55718ms
Apr 21 05:39:07.524: INFO: Terminating ReplicationController wrapped-volume-race-9075b0e5-1e81-4e6f-b45d-a00f67b23fbe pods took: 200.345995ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:39:54.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9661" for this suite.
Apr 21 05:40:08.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:40:09.081: INFO: namespace emptydir-wrapper-9661 deletion completed in 14.774075261s

• [SLOW TEST:166.066 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:40:09.082: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4119
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9412
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1276
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:40:25.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4119" for this suite.
Apr 21 05:40:33.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:40:34.072: INFO: namespace namespaces-4119 deletion completed in 8.879212213s
STEP: Destroying namespace "nsdeletetest-9412" for this suite.
Apr 21 05:40:34.091: INFO: Namespace nsdeletetest-9412 was already deleted
STEP: Destroying namespace "nsdeletetest-1276" for this suite.
Apr 21 05:40:42.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:40:42.885: INFO: namespace nsdeletetest-1276 deletion completed in 8.793680901s

• [SLOW TEST:33.802 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:40:42.885: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4475
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:40:43.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4475'
Apr 21 05:40:43.832: INFO: stderr: ""
Apr 21 05:40:43.832: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr 21 05:40:43.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4475'
Apr 21 05:40:44.283: INFO: stderr: ""
Apr 21 05:40:44.283: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 21 05:40:45.307: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 05:40:45.307: INFO: Found 0 / 1
Apr 21 05:40:46.312: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 05:40:46.312: INFO: Found 0 / 1
Apr 21 05:40:47.304: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 05:40:47.304: INFO: Found 1 / 1
Apr 21 05:40:47.304: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 21 05:40:47.325: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 05:40:47.325: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 21 05:40:47.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 describe pod redis-master-hp44r --namespace=kubectl-4475'
Apr 21 05:40:47.568: INFO: stderr: ""
Apr 21 05:40:47.568: INFO: stdout: "Name:         redis-master-hp44r\nNamespace:    kubectl-4475\nPriority:     0\nNode:         10.177.30.140/10.177.30.140\nStart Time:   Tue, 21 Apr 2020 05:40:43 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.100.159\nIPs:\n  IP:           172.30.100.159\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://272b59840ce5095fead575fa1dbab8da0249f521c597de94705a47bea32a7209\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 21 Apr 2020 05:40:45 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-bdvsj (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-bdvsj:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-bdvsj\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  4s    default-scheduler       Successfully assigned kubectl-4475/redis-master-hp44r to 10.177.30.140\n  Normal  Pulled     2s    kubelet, 10.177.30.140  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s    kubelet, 10.177.30.140  Created container redis-master\n  Normal  Started    2s    kubelet, 10.177.30.140  Started container redis-master\n"
Apr 21 05:40:47.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 describe rc redis-master --namespace=kubectl-4475'
Apr 21 05:40:47.811: INFO: stderr: ""
Apr 21 05:40:47.811: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4475\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-hp44r\n"
Apr 21 05:40:47.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 describe service redis-master --namespace=kubectl-4475'
Apr 21 05:40:48.036: INFO: stderr: ""
Apr 21 05:40:48.036: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4475\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.5.127\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.100.159:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr 21 05:40:48.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 describe node 10.177.30.140'
Apr 21 05:40:48.337: INFO: stderr: ""
Apr 21 05:40:48.337: INFO: stdout: "Name:               10.177.30.140\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal10\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=150.238.39.40\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.177.30.140\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=test-bqf5pqk20faa838g4qpg-kubee2epvga-default-00000144\n                    ibm-cloud.kubernetes.io/worker-pool-id=bqf5pqk20faa838g4qpg-e6977ac\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.8_1528\n                    ibm-cloud.kubernetes.io/zone=dal10\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.177.30.140\n                    kubernetes.io/os=linux\n                    privateVLAN=2778398\n                    publicVLAN=2766480\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 21 Apr 2020 03:03:32 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 21 Apr 2020 05:40:40 +0000   Tue, 21 Apr 2020 03:03:32 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 21 Apr 2020 05:40:40 +0000   Tue, 21 Apr 2020 03:03:32 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 21 Apr 2020 05:40:40 +0000   Tue, 21 Apr 2020 03:03:32 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 21 Apr 2020 05:40:40 +0000   Tue, 21 Apr 2020 03:03:42 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.177.30.140\n  ExternalIP:  150.238.39.40\n  Hostname:    10.177.30.140\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419688Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627240Ki\n pods:               110\nSystem Info:\n Machine ID:                 5b9b5bc0a2e94a9a998fde5a122faea1\n System UUID:                E547222F-BE5C-BCDE-A801-690FEA534E2D\n Boot ID:                    ade81d20-7aad-4d35-a3ab-82977078d647\n Kernel Version:             4.15.0-96-generic\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.3\n Kubelet Version:            v1.16.8+IKS\n Kube-Proxy Version:         v1.16.8+IKS\nProviderID:                  ibm://856f38977b8848e0a6a67f09be3e597c///bqf5pqk20faa838g4qpg/test-bqf5pqk20faa838g4qpg-kubee2epvga-default-00000144\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-65w2l                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         157m\n  kube-system                ibm-keepalived-watcher-6zs8n                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         157m\n  kube-system                ibm-master-proxy-static-10.177.30.140                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      157m\n  kubectl-4475               redis-master-hp44r                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         5s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n    0 (0%)        0 (0%)      0 (0%)           0 (0%)         63m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                280m (7%)      300m (7%)\n  memory             123410Ki (0%)  512M (3%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Apr 21 05:40:48.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 describe namespace kubectl-4475'
Apr 21 05:40:48.545: INFO: stderr: ""
Apr 21 05:40:48.545: INFO: stdout: "Name:         kubectl-4475\nLabels:       e2e-framework=kubectl\n              e2e-run=0cf35e81-6c9f-4293-85b5-640a9d64af0f\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:40:48.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4475" for this suite.
Apr 21 05:41:02.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:41:03.350: INFO: namespace kubectl-4475 deletion completed in 14.77830976s

• [SLOW TEST:20.465 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:41:03.351: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4136
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:41:19.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4136" for this suite.
Apr 21 05:41:28.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:41:28.875: INFO: namespace resourcequota-4136 deletion completed in 8.785653667s

• [SLOW TEST:25.525 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:41:28.877: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:41:29.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41" in namespace "projected-266" to be "success or failure"
Apr 21 05:41:29.262: INFO: Pod "downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41": Phase="Pending", Reason="", readiness=false. Elapsed: 21.663522ms
Apr 21 05:41:31.281: INFO: Pod "downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040141489s
Apr 21 05:41:33.298: INFO: Pod "downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057602074s
STEP: Saw pod success
Apr 21 05:41:33.298: INFO: Pod "downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41" satisfied condition "success or failure"
Apr 21 05:41:33.315: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41 container client-container: <nil>
STEP: delete the pod
Apr 21 05:41:33.496: INFO: Waiting for pod downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41 to disappear
Apr 21 05:41:33.512: INFO: Pod downwardapi-volume-c87ca471-f3f0-4678-bb02-bad35c6e4b41 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:41:33.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-266" for this suite.
Apr 21 05:41:41.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:41:42.415: INFO: namespace projected-266 deletion completed in 8.879348986s

• [SLOW TEST:13.538 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:41:42.419: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr 21 05:41:46.887: INFO: &Pod{ObjectMeta:{send-events-8a843eba-1316-4290-839b-99d08d13c156  events-1638 /api/v1/namespaces/events-1638/pods/send-events-8a843eba-1316-4290-839b-99d08d13c156 b18968b3-d034-482f-a1d9-f10d41aaec46 32622 0 2020-04-21 05:41:42 +0000 UTC <nil> <nil> map[name:foo time:769754747] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-595hg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-595hg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-595hg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:41:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:41:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 05:41:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.132,StartTime:2020-04-21 05:41:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 05:41:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://667381b32a97e45338519556a6211f66baeb055f7e961901e38bb45ba3a07f72,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.132,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr 21 05:41:48.912: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr 21 05:41:50.938: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:41:50.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1638" for this suite.
Apr 21 05:42:39.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:42:39.781: INFO: namespace events-1638 deletion completed in 48.769859304s

• [SLOW TEST:57.362 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:42:39.784: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:42:44.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9774" for this suite.
Apr 21 05:42:52.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:42:53.709: INFO: namespace emptydir-wrapper-9774 deletion completed in 9.25224665s

• [SLOW TEST:13.925 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:42:53.710: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6934
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6934.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6934.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:42:58.458: INFO: DNS probes using dns-6934/dns-test-8a6e1d56-7b9b-4c16-bbc2-6a81d0e03f40 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:42:58.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6934" for this suite.
Apr 21 05:43:06.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:43:07.285: INFO: namespace dns-6934 deletion completed in 8.743104279s

• [SLOW TEST:13.574 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:43:07.285: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3342.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3342.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3342.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3342.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.226.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.226.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.226.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.226.133_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3342.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3342.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3342.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3342.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3342.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3342.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 133.226.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.226.133_udp@PTR;check="$$(dig +tcp +noall +answer +search 133.226.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.226.133_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:43:09.847: INFO: Unable to read wheezy_udp@dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:09.877: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:09.903: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:09.931: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:10.122: INFO: Unable to read jessie_udp@dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:10.149: INFO: Unable to read jessie_tcp@dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:10.175: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:10.204: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:10.367: INFO: Lookups using dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3 failed for: [wheezy_udp@dns-test-service.dns-3342.svc.cluster.local wheezy_tcp@dns-test-service.dns-3342.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local jessie_udp@dns-test-service.dns-3342.svc.cluster.local jessie_tcp@dns-test-service.dns-3342.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3342.svc.cluster.local]

Apr 21 05:43:15.423: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3342.svc.cluster.local from pod dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3: the server could not find the requested resource (get pods dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3)
Apr 21 05:43:15.931: INFO: Lookups using dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3 failed for: [wheezy_tcp@dns-test-service.dns-3342.svc.cluster.local]

Apr 21 05:43:20.929: INFO: DNS probes using dns-3342/dns-test-d5f4eadd-f58a-4b2b-b669-d38fc1a2d3e3 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:43:21.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3342" for this suite.
Apr 21 05:43:29.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:43:29.967: INFO: namespace dns-3342 deletion completed in 8.726164313s

• [SLOW TEST:22.682 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:43:29.968: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:43:30.321: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635" in namespace "projected-4785" to be "success or failure"
Apr 21 05:43:30.353: INFO: Pod "downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635": Phase="Pending", Reason="", readiness=false. Elapsed: 32.235401ms
Apr 21 05:43:32.368: INFO: Pod "downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046925888s
Apr 21 05:43:34.385: INFO: Pod "downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063542377s
STEP: Saw pod success
Apr 21 05:43:34.385: INFO: Pod "downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635" satisfied condition "success or failure"
Apr 21 05:43:34.400: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635 container client-container: <nil>
STEP: delete the pod
Apr 21 05:43:34.567: INFO: Waiting for pod downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635 to disappear
Apr 21 05:43:34.606: INFO: Pod downwardapi-volume-abd94e18-b024-415b-a524-3a7b6004e635 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:43:34.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4785" for this suite.
Apr 21 05:43:42.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:43:43.391: INFO: namespace projected-4785 deletion completed in 8.75796416s

• [SLOW TEST:13.423 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:43:43.392: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:43:43.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5713" for this suite.
Apr 21 05:43:52.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:43:52.700: INFO: namespace services-5713 deletion completed in 8.723943633s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:9.309 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:43:52.703: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-d3721d41-3fba-4a76-9c6f-5180c25ac31e
STEP: Creating a pod to test consume secrets
Apr 21 05:43:53.122: INFO: Waiting up to 5m0s for pod "pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e" in namespace "secrets-5639" to be "success or failure"
Apr 21 05:43:53.153: INFO: Pod "pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e": Phase="Pending", Reason="", readiness=false. Elapsed: 31.113136ms
Apr 21 05:43:55.175: INFO: Pod "pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052504175s
STEP: Saw pod success
Apr 21 05:43:55.175: INFO: Pod "pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e" satisfied condition "success or failure"
Apr 21 05:43:55.192: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:43:55.305: INFO: Waiting for pod pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e to disappear
Apr 21 05:43:55.323: INFO: Pod pod-secrets-7c97cc27-5e1a-41e7-a9b4-517ba800265e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:43:55.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5639" for this suite.
Apr 21 05:44:03.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:44:04.171: INFO: namespace secrets-5639 deletion completed in 8.814276908s

• [SLOW TEST:11.468 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:44:04.172: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Apr 21 05:44:04.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-6664 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr 21 05:44:04.651: INFO: stderr: ""
Apr 21 05:44:04.651: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Apr 21 05:44:04.651: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr 21 05:44:04.651: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6664" to be "running and ready, or succeeded"
Apr 21 05:44:04.671: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 20.034447ms
Apr 21 05:44:06.694: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042181459s
Apr 21 05:44:08.711: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.059498169s
Apr 21 05:44:08.711: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr 21 05:44:08.711: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr 21 05:44:08.711: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664'
Apr 21 05:44:08.938: INFO: stderr: ""
Apr 21 05:44:08.938: INFO: stdout: "I0421 05:44:06.088819       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/pp8d 223\nI0421 05:44:06.288979       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/8rqd 466\nI0421 05:44:06.488919       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/fl8x 489\nI0421 05:44:06.688954       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/q2m9 251\nI0421 05:44:06.889089       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/vp6n 561\nI0421 05:44:07.089083       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/cht 438\nI0421 05:44:07.289100       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tgc 454\nI0421 05:44:07.489077       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/r5kd 507\nI0421 05:44:07.689003       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/cfv 570\nI0421 05:44:07.889063       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/xrl4 553\nI0421 05:44:08.089067       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/jzn 341\nI0421 05:44:08.289096       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/nzpp 421\nI0421 05:44:08.489043       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/84n 516\nI0421 05:44:08.689013       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/cgz 554\nI0421 05:44:08.889093       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/sdb 550\n"
STEP: limiting log lines
Apr 21 05:44:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664 --tail=1'
Apr 21 05:44:09.199: INFO: stderr: ""
Apr 21 05:44:09.200: INFO: stdout: "I0421 05:44:09.089027       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/cp8 521\n"
STEP: limiting log bytes
Apr 21 05:44:09.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664 --limit-bytes=1'
Apr 21 05:44:09.403: INFO: stderr: ""
Apr 21 05:44:09.403: INFO: stdout: "I"
STEP: exposing timestamps
Apr 21 05:44:09.403: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664 --tail=1 --timestamps'
Apr 21 05:44:09.599: INFO: stderr: ""
Apr 21 05:44:09.599: INFO: stdout: "2020-04-21T05:44:09.48923102Z I0421 05:44:09.489034       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/27tm 296\n"
STEP: restricting to a time range
Apr 21 05:44:12.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664 --since=1s'
Apr 21 05:44:12.294: INFO: stderr: ""
Apr 21 05:44:12.294: INFO: stdout: "I0421 05:44:11.288993       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/4n9 410\nI0421 05:44:11.489014       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/z4x9 212\nI0421 05:44:11.689003       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/kube-system/pods/2kn 254\nI0421 05:44:11.889000       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/sxbb 548\nI0421 05:44:12.089035       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/jmxv 446\n"
Apr 21 05:44:12.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs logs-generator logs-generator --namespace=kubectl-6664 --since=24h'
Apr 21 05:44:12.490: INFO: stderr: ""
Apr 21 05:44:12.490: INFO: stdout: "I0421 05:44:06.088819       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/pp8d 223\nI0421 05:44:06.288979       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/8rqd 466\nI0421 05:44:06.488919       1 logs_generator.go:76] 2 POST /api/v1/namespaces/kube-system/pods/fl8x 489\nI0421 05:44:06.688954       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/q2m9 251\nI0421 05:44:06.889089       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/vp6n 561\nI0421 05:44:07.089083       1 logs_generator.go:76] 5 POST /api/v1/namespaces/ns/pods/cht 438\nI0421 05:44:07.289100       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/tgc 454\nI0421 05:44:07.489077       1 logs_generator.go:76] 7 POST /api/v1/namespaces/default/pods/r5kd 507\nI0421 05:44:07.689003       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/default/pods/cfv 570\nI0421 05:44:07.889063       1 logs_generator.go:76] 9 GET /api/v1/namespaces/ns/pods/xrl4 553\nI0421 05:44:08.089067       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/jzn 341\nI0421 05:44:08.289096       1 logs_generator.go:76] 11 GET /api/v1/namespaces/default/pods/nzpp 421\nI0421 05:44:08.489043       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/84n 516\nI0421 05:44:08.689013       1 logs_generator.go:76] 13 POST /api/v1/namespaces/default/pods/cgz 554\nI0421 05:44:08.889093       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/sdb 550\nI0421 05:44:09.089027       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/cp8 521\nI0421 05:44:09.289017       1 logs_generator.go:76] 16 GET /api/v1/namespaces/default/pods/9nmx 403\nI0421 05:44:09.489034       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/ns/pods/27tm 296\nI0421 05:44:09.688992       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/hjkh 347\nI0421 05:44:09.889049       1 logs_generator.go:76] 19 GET /api/v1/namespaces/ns/pods/hjc 283\nI0421 05:44:10.089098       1 logs_generator.go:76] 20 GET /api/v1/namespaces/default/pods/d2fz 236\nI0421 05:44:10.289004       1 logs_generator.go:76] 21 GET /api/v1/namespaces/default/pods/kq5 573\nI0421 05:44:10.489006       1 logs_generator.go:76] 22 GET /api/v1/namespaces/ns/pods/pjcq 402\nI0421 05:44:10.689022       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/zcl 378\nI0421 05:44:10.889023       1 logs_generator.go:76] 24 POST /api/v1/namespaces/ns/pods/zmq 338\nI0421 05:44:11.089046       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/wjd 457\nI0421 05:44:11.288993       1 logs_generator.go:76] 26 PUT /api/v1/namespaces/ns/pods/4n9 410\nI0421 05:44:11.489014       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/kube-system/pods/z4x9 212\nI0421 05:44:11.689003       1 logs_generator.go:76] 28 PUT /api/v1/namespaces/kube-system/pods/2kn 254\nI0421 05:44:11.889000       1 logs_generator.go:76] 29 POST /api/v1/namespaces/kube-system/pods/sxbb 548\nI0421 05:44:12.089035       1 logs_generator.go:76] 30 GET /api/v1/namespaces/default/pods/jmxv 446\nI0421 05:44:12.289042       1 logs_generator.go:76] 31 GET /api/v1/namespaces/default/pods/7rc6 257\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Apr 21 05:44:12.490: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete pod logs-generator --namespace=kubectl-6664'
Apr 21 05:44:21.304: INFO: stderr: ""
Apr 21 05:44:21.304: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:44:21.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6664" for this suite.
Apr 21 05:44:29.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:44:30.075: INFO: namespace kubectl-6664 deletion completed in 8.741157545s

• [SLOW TEST:25.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:44:30.080: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8962
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8962
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-8962
Apr 21 05:44:30.462: INFO: Found 0 stateful pods, waiting for 1
Apr 21 05:44:40.480: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 05:44:40.612: INFO: Deleting all statefulset in ns statefulset-8962
Apr 21 05:44:40.650: INFO: Scaling statefulset ss to 0
Apr 21 05:45:10.757: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 05:45:10.774: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:45:10.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8962" for this suite.
Apr 21 05:45:18.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:45:19.647: INFO: namespace statefulset-8962 deletion completed in 8.757408842s

• [SLOW TEST:49.567 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:45:19.647: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5100
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Apr 21 05:45:19.989: INFO: Waiting up to 5m0s for pod "client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8" in namespace "containers-5100" to be "success or failure"
Apr 21 05:45:20.009: INFO: Pod "client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8": Phase="Pending", Reason="", readiness=false. Elapsed: 19.937414ms
Apr 21 05:45:22.026: INFO: Pod "client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03716574s
STEP: Saw pod success
Apr 21 05:45:22.027: INFO: Pod "client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8" satisfied condition "success or failure"
Apr 21 05:45:22.047: INFO: Trying to get logs from node 10.177.30.140 pod client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8 container test-container: <nil>
STEP: delete the pod
Apr 21 05:45:22.153: INFO: Waiting for pod client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8 to disappear
Apr 21 05:45:22.170: INFO: Pod client-containers-f91d7f83-3c3c-4dae-85da-e446b99753d8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:45:22.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5100" for this suite.
Apr 21 05:45:30.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:45:30.991: INFO: namespace containers-5100 deletion completed in 8.792829822s

• [SLOW TEST:11.344 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:45:30.993: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:45:31.351: INFO: Waiting up to 5m0s for pod "downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f" in namespace "downward-api-6708" to be "success or failure"
Apr 21 05:45:31.381: INFO: Pod "downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f": Phase="Pending", Reason="", readiness=false. Elapsed: 29.269641ms
Apr 21 05:45:33.399: INFO: Pod "downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047139815s
STEP: Saw pod success
Apr 21 05:45:33.399: INFO: Pod "downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f" satisfied condition "success or failure"
Apr 21 05:45:33.416: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f container client-container: <nil>
STEP: delete the pod
Apr 21 05:45:33.509: INFO: Waiting for pod downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f to disappear
Apr 21 05:45:33.528: INFO: Pod downwardapi-volume-113b8d35-06ce-4f99-a6fc-befa5b11389f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:45:33.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6708" for this suite.
Apr 21 05:45:41.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:45:42.420: INFO: namespace downward-api-6708 deletion completed in 8.858742604s

• [SLOW TEST:11.428 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:45:42.430: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2204
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:45:42.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200" in namespace "projected-2204" to be "success or failure"
Apr 21 05:45:42.819: INFO: Pod "downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200": Phase="Pending", Reason="", readiness=false. Elapsed: 16.967159ms
Apr 21 05:45:44.843: INFO: Pod "downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040406185s
Apr 21 05:45:46.859: INFO: Pod "downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057020989s
STEP: Saw pod success
Apr 21 05:45:46.859: INFO: Pod "downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200" satisfied condition "success or failure"
Apr 21 05:45:46.879: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200 container client-container: <nil>
STEP: delete the pod
Apr 21 05:45:46.996: INFO: Waiting for pod downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200 to disappear
Apr 21 05:45:47.015: INFO: Pod downwardapi-volume-edecbe1e-5443-44f7-a3f7-ac7f41624200 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:45:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2204" for this suite.
Apr 21 05:45:55.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:45:55.821: INFO: namespace projected-2204 deletion completed in 8.777027678s

• [SLOW TEST:13.391 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:45:55.821: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr 21 05:45:59.171: INFO: Successfully updated pod "annotationupdateab4c4274-dd0b-49c4-9417-338816ef3fcf"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:46:03.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5777" for this suite.
Apr 21 05:46:35.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:46:36.254: INFO: namespace downward-api-5777 deletion completed in 32.855319695s

• [SLOW TEST:40.433 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:46:36.262: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6146
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr 21 05:46:36.718: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:46:51.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6146" for this suite.
Apr 21 05:46:59.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:47:00.258: INFO: namespace pods-6146 deletion completed in 8.910424352s

• [SLOW TEST:23.997 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:47:00.259: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:47:04.838: INFO: DNS probes using dns-test-4db14185-3042-417b-8a65-677751126586 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:47:07.188: INFO: File jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:07.189: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:12.245: INFO: File jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:12.245: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:17.252: INFO: File jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:17.252: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:22.247: INFO: File jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:22.247: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:27.213: INFO: File wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:27.244: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:32.219: INFO: File wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr 21 05:47:32.260: INFO: File jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local from pod  dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf contains '' instead of 'bar.example.com.'
Apr 21 05:47:32.260: INFO: Lookups using dns-8492/dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf failed for: [wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local]

Apr 21 05:47:37.242: INFO: DNS probes using dns-test-a4cb3740-caab-4b41-be89-4f3b5760b8bf succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8492.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8492.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:47:39.574: INFO: DNS probes using dns-test-42995aaf-dc34-4897-ab1a-6e57c206e443 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:47:39.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8492" for this suite.
Apr 21 05:47:49.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:47:50.486: INFO: namespace dns-8492 deletion completed in 10.72040336s

• [SLOW TEST:50.227 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:47:50.486: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f570c784-9d2a-418e-987f-5efeae866109
STEP: Creating a pod to test consume secrets
Apr 21 05:47:50.847: INFO: Waiting up to 5m0s for pod "pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e" in namespace "secrets-8721" to be "success or failure"
Apr 21 05:47:50.868: INFO: Pod "pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e": Phase="Pending", Reason="", readiness=false. Elapsed: 21.24547ms
Apr 21 05:47:52.884: INFO: Pod "pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037063843s
Apr 21 05:47:54.905: INFO: Pod "pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05861032s
STEP: Saw pod success
Apr 21 05:47:54.906: INFO: Pod "pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e" satisfied condition "success or failure"
Apr 21 05:47:54.930: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:47:55.585: INFO: Waiting for pod pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e to disappear
Apr 21 05:47:55.601: INFO: Pod pod-secrets-c2ba40e0-1c89-4476-aaa2-b0d81bd3e63e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:47:55.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8721" for this suite.
Apr 21 05:48:03.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:48:04.473: INFO: namespace secrets-8721 deletion completed in 8.841694057s

• [SLOW TEST:13.987 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:48:04.476: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5317
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 21 05:48:07.432: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2f511689-d6de-4890-a87b-d39cb24c5337"
Apr 21 05:48:07.433: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2f511689-d6de-4890-a87b-d39cb24c5337" in namespace "pods-5317" to be "terminated due to deadline exceeded"
Apr 21 05:48:07.448: INFO: Pod "pod-update-activedeadlineseconds-2f511689-d6de-4890-a87b-d39cb24c5337": Phase="Running", Reason="", readiness=true. Elapsed: 15.139444ms
Apr 21 05:48:09.464: INFO: Pod "pod-update-activedeadlineseconds-2f511689-d6de-4890-a87b-d39cb24c5337": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.031290404s
Apr 21 05:48:09.464: INFO: Pod "pod-update-activedeadlineseconds-2f511689-d6de-4890-a87b-d39cb24c5337" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:48:09.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5317" for this suite.
Apr 21 05:48:17.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:48:18.238: INFO: namespace pods-5317 deletion completed in 8.747706132s

• [SLOW TEST:13.762 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:48:18.241: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-573
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:48:18.731: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr 21 05:48:18.769: INFO: Number of nodes with available pods: 0
Apr 21 05:48:18.769: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr 21 05:48:18.862: INFO: Number of nodes with available pods: 0
Apr 21 05:48:18.862: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:19.883: INFO: Number of nodes with available pods: 0
Apr 21 05:48:19.883: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:20.879: INFO: Number of nodes with available pods: 0
Apr 21 05:48:20.879: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:21.881: INFO: Number of nodes with available pods: 1
Apr 21 05:48:21.881: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr 21 05:48:21.969: INFO: Number of nodes with available pods: 1
Apr 21 05:48:21.969: INFO: Number of running nodes: 0, number of available pods: 1
Apr 21 05:48:22.990: INFO: Number of nodes with available pods: 0
Apr 21 05:48:22.990: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr 21 05:48:23.037: INFO: Number of nodes with available pods: 0
Apr 21 05:48:23.037: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:24.056: INFO: Number of nodes with available pods: 0
Apr 21 05:48:24.056: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:25.054: INFO: Number of nodes with available pods: 0
Apr 21 05:48:25.054: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:26.053: INFO: Number of nodes with available pods: 0
Apr 21 05:48:26.053: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:27.055: INFO: Number of nodes with available pods: 0
Apr 21 05:48:27.055: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 05:48:28.056: INFO: Number of nodes with available pods: 1
Apr 21 05:48:28.056: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-573, will wait for the garbage collector to delete the pods
Apr 21 05:48:28.206: INFO: Deleting DaemonSet.extensions daemon-set took: 42.315564ms
Apr 21 05:48:28.406: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.330342ms
Apr 21 05:48:31.429: INFO: Number of nodes with available pods: 0
Apr 21 05:48:31.429: INFO: Number of running nodes: 0, number of available pods: 0
Apr 21 05:48:31.445: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-573/daemonsets","resourceVersion":"34041"},"items":null}

Apr 21 05:48:31.464: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-573/pods","resourceVersion":"34041"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:48:31.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-573" for this suite.
Apr 21 05:48:39.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:48:40.373: INFO: namespace daemonsets-573 deletion completed in 8.763528731s

• [SLOW TEST:22.132 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:48:40.375: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2974.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2974.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2974.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2974.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2974.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2974.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 05:48:45.013: INFO: DNS probes using dns-2974/dns-test-604fbe4e-4e7b-4ed9-bdba-c0cfa5ed6f0e succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:48:45.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2974" for this suite.
Apr 21 05:48:53.179: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:48:53.810: INFO: namespace dns-2974 deletion completed in 8.713787208s

• [SLOW TEST:13.435 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:48:53.811: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:49:10.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2986" for this suite.
Apr 21 05:49:18.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:49:19.299: INFO: namespace resourcequota-2986 deletion completed in 8.746226778s

• [SLOW TEST:25.489 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:49:19.301: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8094
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 05:49:19.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8094'
Apr 21 05:49:19.798: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 21 05:49:19.798: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Apr 21 05:49:19.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete jobs e2e-test-httpd-job --namespace=kubectl-8094'
Apr 21 05:49:20.016: INFO: stderr: ""
Apr 21 05:49:20.016: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:49:20.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8094" for this suite.
Apr 21 05:49:28.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:49:28.840: INFO: namespace kubectl-8094 deletion completed in 8.798966884s

• [SLOW TEST:9.539 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:49:28.840: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9570
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:49:29.170: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:49:33.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9570" for this suite.
Apr 21 05:49:42.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:49:42.776: INFO: namespace custom-resource-definition-9570 deletion completed in 8.780133266s

• [SLOW TEST:13.936 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:49:42.777: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 21 05:49:46.229: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:49:46.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8938" for this suite.
Apr 21 05:49:54.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:49:55.479: INFO: namespace container-runtime-8938 deletion completed in 9.14332314s

• [SLOW TEST:12.702 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:49:55.481: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1079
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr 21 05:49:55.836: INFO: Waiting up to 5m0s for pod "pod-c4ec684b-a841-44e0-8785-3f21874dfac6" in namespace "emptydir-1079" to be "success or failure"
Apr 21 05:49:55.864: INFO: Pod "pod-c4ec684b-a841-44e0-8785-3f21874dfac6": Phase="Pending", Reason="", readiness=false. Elapsed: 27.199555ms
Apr 21 05:49:57.887: INFO: Pod "pod-c4ec684b-a841-44e0-8785-3f21874dfac6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050629893s
STEP: Saw pod success
Apr 21 05:49:57.887: INFO: Pod "pod-c4ec684b-a841-44e0-8785-3f21874dfac6" satisfied condition "success or failure"
Apr 21 05:49:57.907: INFO: Trying to get logs from node 10.177.30.140 pod pod-c4ec684b-a841-44e0-8785-3f21874dfac6 container test-container: <nil>
STEP: delete the pod
Apr 21 05:49:58.072: INFO: Waiting for pod pod-c4ec684b-a841-44e0-8785-3f21874dfac6 to disappear
Apr 21 05:49:58.110: INFO: Pod pod-c4ec684b-a841-44e0-8785-3f21874dfac6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:49:58.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1079" for this suite.
Apr 21 05:50:06.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:50:07.731: INFO: namespace emptydir-1079 deletion completed in 9.595383565s

• [SLOW TEST:12.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:50:07.734: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4008
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Apr 21 05:50:08.054: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr 21 05:50:08.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:08.512: INFO: stderr: ""
Apr 21 05:50:08.512: INFO: stdout: "service/redis-slave created\n"
Apr 21 05:50:08.513: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr 21 05:50:08.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:08.938: INFO: stderr: ""
Apr 21 05:50:08.938: INFO: stdout: "service/redis-master created\n"
Apr 21 05:50:08.939: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr 21 05:50:08.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:09.201: INFO: stderr: ""
Apr 21 05:50:09.201: INFO: stdout: "service/frontend created\n"
Apr 21 05:50:09.201: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr 21 05:50:09.201: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:09.676: INFO: stderr: ""
Apr 21 05:50:09.676: INFO: stdout: "deployment.apps/frontend created\n"
Apr 21 05:50:09.676: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr 21 05:50:09.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:10.157: INFO: stderr: ""
Apr 21 05:50:10.157: INFO: stdout: "deployment.apps/redis-master created\n"
Apr 21 05:50:10.157: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr 21 05:50:10.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-4008'
Apr 21 05:50:10.609: INFO: stderr: ""
Apr 21 05:50:10.609: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr 21 05:50:10.609: INFO: Waiting for all frontend pods to be Running.
Apr 21 05:50:25.660: INFO: Waiting for frontend to serve content.
Apr 21 05:50:25.758: INFO: Trying to add a new entry to the guestbook.
Apr 21 05:50:25.815: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr 21 05:50:25.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:26.153: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:26.153: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr 21 05:50:26.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:26.410: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:26.410: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 21 05:50:26.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:26.692: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:26.692: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 21 05:50:26.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:26.899: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:26.899: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr 21 05:50:26.900: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:27.094: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:27.094: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr 21 05:50:27.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete --grace-period=0 --force -f - --namespace=kubectl-4008'
Apr 21 05:50:27.664: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr 21 05:50:27.664: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:50:27.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4008" for this suite.
Apr 21 05:50:59.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:51:00.461: INFO: namespace kubectl-4008 deletion completed in 32.767373425s

• [SLOW TEST:52.728 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:51:00.461: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3910
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:51:00.778: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:51:01.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3910" for this suite.
Apr 21 05:51:09.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:51:10.337: INFO: namespace custom-resource-definition-3910 deletion completed in 8.833699843s

• [SLOW TEST:9.876 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:51:10.339: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4192
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr 21 05:51:10.682: INFO: PodSpec: initContainers in spec.initContainers
Apr 21 05:51:52.699: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-a7d4c862-3d95-4e98-a494-13c84656f206", GenerateName:"", Namespace:"init-container-4192", SelfLink:"/api/v1/namespaces/init-container-4192/pods/pod-init-a7d4c862-3d95-4e98-a494-13c84656f206", UID:"ab154c54-3c91-4607-a902-45ac430e446c", ResourceVersion:"34935", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63723045070, loc:(*time.Location)(0x78a2900)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"682852225"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-j5fmr", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002fb5940), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5fmr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5fmr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-j5fmr", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002cc02c8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.177.30.140", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0031dc120), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002cc0350)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002cc0370)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002cc0378), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002cc037c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723045070, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723045070, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723045070, loc:(*time.Location)(0x78a2900)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723045070, loc:(*time.Location)(0x78a2900)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.177.30.140", PodIP:"172.30.100.179", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.100.179"}}, StartTime:(*v1.Time)(0xc0049b43c0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00257b030)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00257b0a0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://b676ee4bfe6356e0bbf40e70c4e2b3ebf221e48806d3fc326a4695333ef8dd8a", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0049b4400), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0049b43e0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002cc03f4)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:51:52.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4192" for this suite.
Apr 21 05:52:06.816: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:52:07.523: INFO: namespace init-container-4192 deletion completed in 14.793044608s

• [SLOW TEST:57.184 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:52:07.523: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:52:07.917: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e9e592de-7999-4040-9a64-30f6063b89eb" in namespace "security-context-test-7705" to be "success or failure"
Apr 21 05:52:07.942: INFO: Pod "busybox-user-65534-e9e592de-7999-4040-9a64-30f6063b89eb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.725158ms
Apr 21 05:52:09.965: INFO: Pod "busybox-user-65534-e9e592de-7999-4040-9a64-30f6063b89eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047807682s
Apr 21 05:52:09.965: INFO: Pod "busybox-user-65534-e9e592de-7999-4040-9a64-30f6063b89eb" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:52:09.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7705" for this suite.
Apr 21 05:52:18.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:52:18.815: INFO: namespace security-context-test-7705 deletion completed in 8.815051133s

• [SLOW TEST:11.292 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:52:18.815: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6396
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6396
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6396
STEP: Creating statefulset with conflicting port in namespace statefulset-6396
STEP: Waiting until pod test-pod will start running in namespace statefulset-6396
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6396
Apr 21 05:52:21.332: INFO: Observed stateful pod in namespace: statefulset-6396, name: ss-0, uid: 04b074f6-f13b-4eae-b2ce-29a5b07d2b64, status phase: Pending. Waiting for statefulset controller to delete.
Apr 21 05:52:21.372: INFO: Observed stateful pod in namespace: statefulset-6396, name: ss-0, uid: 04b074f6-f13b-4eae-b2ce-29a5b07d2b64, status phase: Failed. Waiting for statefulset controller to delete.
Apr 21 05:52:21.410: INFO: Observed stateful pod in namespace: statefulset-6396, name: ss-0, uid: 04b074f6-f13b-4eae-b2ce-29a5b07d2b64, status phase: Failed. Waiting for statefulset controller to delete.
Apr 21 05:52:21.437: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6396
STEP: Removing pod with conflicting port in namespace statefulset-6396
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6396 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 05:52:25.560: INFO: Deleting all statefulset in ns statefulset-6396
Apr 21 05:52:25.576: INFO: Scaling statefulset ss to 0
Apr 21 05:52:35.658: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 05:52:35.674: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:52:35.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6396" for this suite.
Apr 21 05:52:43.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:52:44.503: INFO: namespace statefulset-6396 deletion completed in 8.723431116s

• [SLOW TEST:25.688 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:52:44.504: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-5bjs
STEP: Creating a pod to test atomic-volume-subpath
Apr 21 05:52:44.921: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5bjs" in namespace "subpath-4337" to be "success or failure"
Apr 21 05:52:44.941: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Pending", Reason="", readiness=false. Elapsed: 19.497118ms
Apr 21 05:52:46.963: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 2.041850699s
Apr 21 05:52:48.995: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 4.072988528s
Apr 21 05:52:51.013: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 6.091233182s
Apr 21 05:52:53.360: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 8.438657608s
Apr 21 05:52:55.383: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 10.461787065s
Apr 21 05:52:57.405: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 12.482976756s
Apr 21 05:52:59.423: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 14.501494253s
Apr 21 05:53:01.439: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 16.517674715s
Apr 21 05:53:03.458: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 18.536498998s
Apr 21 05:53:05.474: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Running", Reason="", readiness=true. Elapsed: 20.552402512s
Apr 21 05:53:07.490: INFO: Pod "pod-subpath-test-projected-5bjs": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.568177725s
STEP: Saw pod success
Apr 21 05:53:07.490: INFO: Pod "pod-subpath-test-projected-5bjs" satisfied condition "success or failure"
Apr 21 05:53:07.505: INFO: Trying to get logs from node 10.177.30.140 pod pod-subpath-test-projected-5bjs container test-container-subpath-projected-5bjs: <nil>
STEP: delete the pod
Apr 21 05:53:07.677: INFO: Waiting for pod pod-subpath-test-projected-5bjs to disappear
Apr 21 05:53:07.693: INFO: Pod pod-subpath-test-projected-5bjs no longer exists
STEP: Deleting pod pod-subpath-test-projected-5bjs
Apr 21 05:53:07.693: INFO: Deleting pod "pod-subpath-test-projected-5bjs" in namespace "subpath-4337"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:53:07.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4337" for this suite.
Apr 21 05:53:15.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:53:16.579: INFO: namespace subpath-4337 deletion completed in 8.83978238s

• [SLOW TEST:32.075 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:53:16.580: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-3091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr 21 05:53:16.912: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:53:20.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3091" for this suite.
Apr 21 05:53:29.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:53:29.892: INFO: namespace init-container-3091 deletion completed in 9.006281626s

• [SLOW TEST:13.313 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:53:29.893: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1583
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:53:41.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1583" for this suite.
Apr 21 05:53:49.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:53:50.165: INFO: namespace resourcequota-1583 deletion completed in 8.763493954s

• [SLOW TEST:20.272 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:53:50.167: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3015
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:53:50.521: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623" in namespace "projected-3015" to be "success or failure"
Apr 21 05:53:50.545: INFO: Pod "downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623": Phase="Pending", Reason="", readiness=false. Elapsed: 24.311989ms
Apr 21 05:53:52.561: INFO: Pod "downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03993014s
Apr 21 05:53:54.577: INFO: Pod "downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056587147s
STEP: Saw pod success
Apr 21 05:53:54.577: INFO: Pod "downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623" satisfied condition "success or failure"
Apr 21 05:53:54.596: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623 container client-container: <nil>
STEP: delete the pod
Apr 21 05:53:54.705: INFO: Waiting for pod downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623 to disappear
Apr 21 05:53:54.720: INFO: Pod downwardapi-volume-0f660f9e-cc99-46f8-ba80-9fc6f82b4623 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:53:54.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3015" for this suite.
Apr 21 05:54:02.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:54:03.582: INFO: namespace projected-3015 deletion completed in 8.833492509s

• [SLOW TEST:13.415 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:54:03.584: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-62a284f8-8e34-46ee-8a3c-d4754a25d0a2
STEP: Creating a pod to test consume secrets
Apr 21 05:54:03.990: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284" in namespace "projected-9991" to be "success or failure"
Apr 21 05:54:04.010: INFO: Pod "pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284": Phase="Pending", Reason="", readiness=false. Elapsed: 20.208941ms
Apr 21 05:54:06.027: INFO: Pod "pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036736523s
STEP: Saw pod success
Apr 21 05:54:06.027: INFO: Pod "pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284" satisfied condition "success or failure"
Apr 21 05:54:06.045: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 21 05:54:06.168: INFO: Waiting for pod pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284 to disappear
Apr 21 05:54:06.185: INFO: Pod pod-projected-secrets-8c304252-d091-4dcf-b73c-44dfbd87b284 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:54:06.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9991" for this suite.
Apr 21 05:54:14.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:54:15.089: INFO: namespace projected-9991 deletion completed in 8.870721785s

• [SLOW TEST:11.506 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:54:15.089: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Apr 21 05:54:15.443: INFO: Waiting up to 5m0s for pod "var-expansion-044e61b8-dc45-496a-a27f-f036733b1605" in namespace "var-expansion-1894" to be "success or failure"
Apr 21 05:54:15.466: INFO: Pod "var-expansion-044e61b8-dc45-496a-a27f-f036733b1605": Phase="Pending", Reason="", readiness=false. Elapsed: 23.145478ms
Apr 21 05:54:17.486: INFO: Pod "var-expansion-044e61b8-dc45-496a-a27f-f036733b1605": Phase="Running", Reason="", readiness=true. Elapsed: 2.042898798s
Apr 21 05:54:19.503: INFO: Pod "var-expansion-044e61b8-dc45-496a-a27f-f036733b1605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060310863s
STEP: Saw pod success
Apr 21 05:54:19.504: INFO: Pod "var-expansion-044e61b8-dc45-496a-a27f-f036733b1605" satisfied condition "success or failure"
Apr 21 05:54:19.521: INFO: Trying to get logs from node 10.177.30.140 pod var-expansion-044e61b8-dc45-496a-a27f-f036733b1605 container dapi-container: <nil>
STEP: delete the pod
Apr 21 05:54:19.626: INFO: Waiting for pod var-expansion-044e61b8-dc45-496a-a27f-f036733b1605 to disappear
Apr 21 05:54:19.645: INFO: Pod var-expansion-044e61b8-dc45-496a-a27f-f036733b1605 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:54:19.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1894" for this suite.
Apr 21 05:54:27.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:54:28.455: INFO: namespace var-expansion-1894 deletion completed in 8.785708236s

• [SLOW TEST:13.366 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:54:28.456: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr 21 05:54:28.777: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 21 05:54:28.849: INFO: Waiting for terminating namespaces to be deleted...
Apr 21 05:54:28.867: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.140 before test
Apr 21 05:54:28.942: INFO: calico-node-65w2l from kube-system started at 2020-04-21 03:03:33 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:28.942: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:54:28.942: INFO: ibm-master-proxy-static-10.177.30.140 from kube-system started at 2020-04-21 03:03:31 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:28.942: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:54:28.942: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:54:28.942: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:28.942: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 05:54:28.942: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:54:28.942: INFO: ibm-keepalived-watcher-6zs8n from kube-system started at 2020-04-21 03:03:32 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:28.942: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:54:28.943: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.144 before test
Apr 21 05:54:29.111: INFO: catalog-operator-645796fbdf-lsqqt from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container catalog-operator ready: true, restart count 0
Apr 21 05:54:29.111: INFO: ibm-keepalived-watcher-n5w2g from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:54:29.111: INFO: coredns-55db5d97fb-8qn5q from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:54:29.111: INFO: vpn-79845b6f9d-887s2 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container vpn ready: true, restart count 0
Apr 21 05:54:29.111: INFO: coredns-55db5d97fb-q6jbf from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:54:29.111: INFO: addon-catalog-source-7cs9m from ibm-system started at 2020-04-21 03:05:54 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container configmap-registry-server ready: true, restart count 0
Apr 21 05:54:29.111: INFO: metrics-server-878cfbdbd-dkk8m from kube-system started at 2020-04-21 05:21:00 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container metrics-server ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 21 05:54:29.111: INFO: ibm-master-proxy-static-10.177.30.144 from kube-system started at 2020-04-21 03:04:52 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:54:29.111: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk from ibm-system started at 2020-04-21 03:05:11 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:54:29.111: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:54:29.111: INFO: calico-node-hz6bw from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 05:54:29.111: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 05:54:29.111: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:54:29.111: INFO: kubernetes-dashboard-69f9478454-fzzpb from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 21 05:54:29.111: INFO: ibm-storage-watcher-79b9bc9b7f-4k67d from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.111: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 21 05:54:29.111: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.186 before test
Apr 21 05:54:29.250: INFO: sonobuoy-e2e-job-4f59fb8664564855 from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container e2e ready: true, restart count 0
Apr 21 05:54:29.250: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 05:54:29.250: INFO: olm-operator-7bf4dbc978-kgjlz from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container olm-operator ready: true, restart count 0
Apr 21 05:54:29.250: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-m8x2p from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 05:54:29.250: INFO: ibm-master-proxy-static-10.177.30.186 from kube-system started at 2020-04-21 03:06:34 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 05:54:29.250: INFO: 	Container pause ready: true, restart count 0
Apr 21 05:54:29.250: INFO: sonobuoy from sonobuoy started at 2020-04-21 04:37:03 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 21 05:54:29.250: INFO: calico-kube-controllers-598ddbf99d-mzh5s from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 21 05:54:29.250: INFO: dashboard-metrics-scraper-76756886dc-dp2kh from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 21 05:54:29.250: INFO: coredns-55db5d97fb-59ltz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container coredns ready: true, restart count 0
Apr 21 05:54:29.250: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 05:54:29.250: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 05:54:29.250: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-qfdjj from kube-system started at 2020-04-21 05:21:00 +0000 UTC (4 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 05:54:29.250: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 05:54:29.250: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 05:54:29.250: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 05:54:29.250: INFO: ibm-file-plugin-b8d7f5977-fkjtw from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 21 05:54:29.250: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-04-21 03:09:19 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Apr 21 05:54:29.250: INFO: ibm-keepalived-watcher-9czcf from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 05:54:29.250: INFO: coredns-autoscaler-65c89858bf-f4qc4 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container autoscaler ready: true, restart count 0
Apr 21 05:54:29.250: INFO: calico-node-ngcph from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 05:54:29.250: INFO: 	Container calico-node ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.177.30.140
STEP: verifying the node has the label node 10.177.30.144
STEP: verifying the node has the label node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod addon-catalog-source-7cs9m requesting resource cpu=10m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod catalog-operator-645796fbdf-lsqqt requesting resource cpu=10m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-m8x2p requesting resource cpu=5m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk requesting resource cpu=5m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod olm-operator-7bf4dbc978-kgjlz requesting resource cpu=10m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod calico-kube-controllers-598ddbf99d-mzh5s requesting resource cpu=10m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod calico-node-65w2l requesting resource cpu=250m on Node 10.177.30.140
Apr 21 05:54:29.509: INFO: Pod calico-node-hz6bw requesting resource cpu=250m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod calico-node-ngcph requesting resource cpu=250m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod coredns-55db5d97fb-59ltz requesting resource cpu=100m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod coredns-55db5d97fb-8qn5q requesting resource cpu=100m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod coredns-55db5d97fb-q6jbf requesting resource cpu=100m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod coredns-autoscaler-65c89858bf-f4qc4 requesting resource cpu=20m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod dashboard-metrics-scraper-76756886dc-dp2kh requesting resource cpu=1m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod ibm-file-plugin-b8d7f5977-fkjtw requesting resource cpu=50m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod ibm-keepalived-watcher-6zs8n requesting resource cpu=5m on Node 10.177.30.140
Apr 21 05:54:29.509: INFO: Pod ibm-keepalived-watcher-9czcf requesting resource cpu=5m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod ibm-keepalived-watcher-n5w2g requesting resource cpu=5m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod ibm-master-proxy-static-10.177.30.140 requesting resource cpu=25m on Node 10.177.30.140
Apr 21 05:54:29.509: INFO: Pod ibm-master-proxy-static-10.177.30.144 requesting resource cpu=25m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod ibm-master-proxy-static-10.177.30.186 requesting resource cpu=25m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod ibm-storage-watcher-79b9bc9b7f-4k67d requesting resource cpu=50m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod kubernetes-dashboard-69f9478454-fzzpb requesting resource cpu=50m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod metrics-server-878cfbdbd-dkk8m requesting resource cpu=113m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j requesting resource cpu=10m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-qfdjj requesting resource cpu=10m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod vpn-79845b6f9d-887s2 requesting resource cpu=5m on Node 10.177.30.144
Apr 21 05:54:29.509: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod sonobuoy-e2e-job-4f59fb8664564855 requesting resource cpu=0m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n requesting resource cpu=0m on Node 10.177.30.140
Apr 21 05:54:29.509: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v requesting resource cpu=0m on Node 10.177.30.186
Apr 21 05:54:29.509: INFO: Pod sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz requesting resource cpu=0m on Node 10.177.30.144
STEP: Starting Pods to consume most of the cluster CPU.
Apr 21 05:54:29.509: INFO: Creating a pod which consumes cpu=2541m on Node 10.177.30.140
Apr 21 05:54:29.547: INFO: Creating a pod which consumes cpu=2223m on Node 10.177.30.144
Apr 21 05:54:29.570: INFO: Creating a pod which consumes cpu=2396m on Node 10.177.30.186
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3.1607bff8f16eb0c1], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7549/filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3 to 10.177.30.144]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3.1607bff936eeaad8], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3.1607bff93a67277f], Reason = [Created], Message = [Created container filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3.1607bff94339100d], Reason = [Started], Message = [Started container filler-pod-a79debde-ff6b-43ad-97d9-8fefc71aeca3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d.1607bff8efbc936b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7549/filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d to 10.177.30.140]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d.1607bff933a4cd10], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d.1607bff936d22533], Reason = [Created], Message = [Created container filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d.1607bff93f0d3a1a], Reason = [Started], Message = [Started container filler-pod-beaddfa9-395d-4789-9848-a217870b8b3d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a.1607bff8f34c7401], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7549/filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a to 10.177.30.186]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a.1607bff939f217c7], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a.1607bff93d188bac], Reason = [Created], Message = [Created container filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a.1607bff9483f5815], Reason = [Started], Message = [Started container filler-pod-face48f2-a931-4992-b6ec-328c9ea50f2a]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.1607bff9e813984b], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.177.30.140
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.177.30.144
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.177.30.186
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:54:35.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7549" for this suite.
Apr 21 05:54:43.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:54:43.903: INFO: namespace sched-pred-7549 deletion completed in 8.88037941s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:15.448 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:54:43.905: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:54:44.244: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3" in namespace "downward-api-4423" to be "success or failure"
Apr 21 05:54:44.265: INFO: Pod "downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.911598ms
Apr 21 05:54:46.284: INFO: Pod "downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040562875s
STEP: Saw pod success
Apr 21 05:54:46.285: INFO: Pod "downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3" satisfied condition "success or failure"
Apr 21 05:54:46.303: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3 container client-container: <nil>
STEP: delete the pod
Apr 21 05:54:46.431: INFO: Waiting for pod downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3 to disappear
Apr 21 05:54:46.450: INFO: Pod downwardapi-volume-ef339103-481c-4b8a-8ff1-ba2366b154b3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:54:46.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4423" for this suite.
Apr 21 05:54:54.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:54:55.247: INFO: namespace downward-api-4423 deletion completed in 8.768143299s

• [SLOW TEST:11.341 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:54:55.247: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:54:59.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7480" for this suite.
Apr 21 05:55:07.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:55:08.390: INFO: namespace kubelet-test-7480 deletion completed in 8.687908952s

• [SLOW TEST:13.143 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:55:08.390: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4072
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4072
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Apr 21 05:55:08.760: INFO: Found 0 stateful pods, waiting for 3
Apr 21 05:55:18.782: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 05:55:18.783: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 05:55:18.783: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 05:55:18.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-4072 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 05:55:19.374: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 05:55:19.374: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 05:55:19.374: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 21 05:55:29.511: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr 21 05:55:39.848: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-4072 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 05:55:40.249: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 05:55:40.249: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 05:55:40.249: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 05:55:50.347: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:55:50.347: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 05:55:50.347: INFO: Waiting for Pod statefulset-4072/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 05:56:00.382: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:56:00.382: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 05:56:00.382: INFO: Waiting for Pod statefulset-4072/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 05:56:10.409: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:56:10.409: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 05:56:20.389: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:56:20.389: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Apr 21 05:56:30.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-4072 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 05:56:30.756: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 05:56:30.756: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 05:56:30.756: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 05:56:40.875: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr 21 05:56:51.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-4072 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 05:56:51.597: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 05:56:51.597: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 05:56:51.597: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 05:57:01.702: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:57:01.702: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 21 05:57:01.702: INFO: Waiting for Pod statefulset-4072/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 21 05:57:01.702: INFO: Waiting for Pod statefulset-4072/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 21 05:57:11.800: INFO: Waiting for StatefulSet statefulset-4072/ss2 to complete update
Apr 21 05:57:11.800: INFO: Waiting for Pod statefulset-4072/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Apr 21 05:57:11.800: INFO: Waiting for Pod statefulset-4072/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 05:57:21.739: INFO: Deleting all statefulset in ns statefulset-4072
Apr 21 05:57:21.756: INFO: Scaling statefulset ss2 to 0
Apr 21 05:57:51.832: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 05:57:51.849: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:57:51.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4072" for this suite.
Apr 21 05:58:02.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:58:02.856: INFO: namespace statefulset-4072 deletion completed in 10.892344646s

• [SLOW TEST:174.465 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:58:02.856: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4145
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 05:58:03.215: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-bccfb3c1-0236-47bf-838a-6a0c40a9a489" in namespace "security-context-test-4145" to be "success or failure"
Apr 21 05:58:03.251: INFO: Pod "busybox-readonly-false-bccfb3c1-0236-47bf-838a-6a0c40a9a489": Phase="Pending", Reason="", readiness=false. Elapsed: 35.532087ms
Apr 21 05:58:05.273: INFO: Pod "busybox-readonly-false-bccfb3c1-0236-47bf-838a-6a0c40a9a489": Phase="Pending", Reason="", readiness=false. Elapsed: 2.057572402s
Apr 21 05:58:07.290: INFO: Pod "busybox-readonly-false-bccfb3c1-0236-47bf-838a-6a0c40a9a489": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07408789s
Apr 21 05:58:07.290: INFO: Pod "busybox-readonly-false-bccfb3c1-0236-47bf-838a-6a0c40a9a489" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:58:07.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4145" for this suite.
Apr 21 05:58:15.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:58:16.141: INFO: namespace security-context-test-4145 deletion completed in 8.816254579s

• [SLOW TEST:13.285 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:58:16.141: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 05:58:16.505: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc" in namespace "projected-3826" to be "success or failure"
Apr 21 05:58:16.533: INFO: Pod "downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc": Phase="Pending", Reason="", readiness=false. Elapsed: 27.354474ms
Apr 21 05:58:18.549: INFO: Pod "downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044080023s
STEP: Saw pod success
Apr 21 05:58:18.549: INFO: Pod "downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc" satisfied condition "success or failure"
Apr 21 05:58:18.567: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc container client-container: <nil>
STEP: delete the pod
Apr 21 05:58:18.753: INFO: Waiting for pod downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc to disappear
Apr 21 05:58:18.773: INFO: Pod downwardapi-volume-2ddcc9bd-be98-4e7c-ada3-d0c269afe5dc no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:58:18.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3826" for this suite.
Apr 21 05:58:26.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:58:27.548: INFO: namespace projected-3826 deletion completed in 8.737789451s

• [SLOW TEST:11.407 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:58:27.549: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-4181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:58:30.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4181" for this suite.
Apr 21 05:59:18.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 05:59:18.990: INFO: namespace kubelet-test-4181 deletion completed in 48.83704271s

• [SLOW TEST:51.441 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 05:59:18.991: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 05:59:21.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6656" for this suite.
Apr 21 06:00:03.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:00:05.831: INFO: namespace kubelet-test-6656 deletion completed in 43.983207108s

• [SLOW TEST:46.840 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:00:05.831: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1453
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a7b1ee36-a4cf-47ac-8993-8467519a5536
STEP: Creating a pod to test consume secrets
Apr 21 06:00:06.220: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12" in namespace "projected-1453" to be "success or failure"
Apr 21 06:00:06.253: INFO: Pod "pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12": Phase="Pending", Reason="", readiness=false. Elapsed: 33.161293ms
Apr 21 06:00:08.269: INFO: Pod "pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048861762s
Apr 21 06:00:10.296: INFO: Pod "pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.075772016s
STEP: Saw pod success
Apr 21 06:00:10.296: INFO: Pod "pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12" satisfied condition "success or failure"
Apr 21 06:00:10.315: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr 21 06:00:10.447: INFO: Waiting for pod pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12 to disappear
Apr 21 06:00:10.483: INFO: Pod pod-projected-secrets-8053676f-ed47-4ab3-8846-3395fb0cbb12 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:00:10.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1453" for this suite.
Apr 21 06:00:18.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:00:19.283: INFO: namespace projected-1453 deletion completed in 8.770878418s

• [SLOW TEST:13.452 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:00:19.285: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2329
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr 21 06:00:19.587: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 21 06:00:19.678: INFO: Waiting for terminating namespaces to be deleted...
Apr 21 06:00:19.701: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.140 before test
Apr 21 06:00:19.747: INFO: ibm-master-proxy-static-10.177.30.140 from kube-system started at 2020-04-21 03:03:31 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:19.748: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:00:19.748: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:00:19.748: INFO: calico-node-65w2l from kube-system started at 2020-04-21 03:03:33 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.748: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:00:19.748: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:19.748: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 06:00:19.748: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:00:19.748: INFO: ibm-keepalived-watcher-6zs8n from kube-system started at 2020-04-21 03:03:32 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.748: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:00:19.748: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.144 before test
Apr 21 06:00:19.888: INFO: addon-catalog-source-7cs9m from ibm-system started at 2020-04-21 03:05:54 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container configmap-registry-server ready: true, restart count 0
Apr 21 06:00:19.888: INFO: metrics-server-878cfbdbd-dkk8m from kube-system started at 2020-04-21 05:21:00 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container metrics-server ready: true, restart count 0
Apr 21 06:00:19.888: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 21 06:00:19.888: INFO: ibm-master-proxy-static-10.177.30.144 from kube-system started at 2020-04-21 03:04:52 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:00:19.888: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:00:19.888: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk from ibm-system started at 2020-04-21 03:05:11 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 06:00:19.888: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 06:00:19.888: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 06:00:19.888: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 06:00:19.888: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 06:00:19.888: INFO: ibm-storage-watcher-79b9bc9b7f-4k67d from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.888: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 21 06:00:19.888: INFO: calico-node-hz6bw from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:00:19.889: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 06:00:19.889: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:00:19.889: INFO: kubernetes-dashboard-69f9478454-fzzpb from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 21 06:00:19.889: INFO: coredns-55db5d97fb-q6jbf from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:00:19.889: INFO: catalog-operator-645796fbdf-lsqqt from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container catalog-operator ready: true, restart count 0
Apr 21 06:00:19.889: INFO: ibm-keepalived-watcher-n5w2g from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:00:19.889: INFO: coredns-55db5d97fb-8qn5q from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:00:19.889: INFO: vpn-79845b6f9d-887s2 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:19.889: INFO: 	Container vpn ready: true, restart count 0
Apr 21 06:00:19.889: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.186 before test
Apr 21 06:00:20.095: INFO: calico-node-ngcph from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.095: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:00:20.095: INFO: ibm-keepalived-watcher-9czcf from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.095: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:00:20.095: INFO: coredns-autoscaler-65c89858bf-f4qc4 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container autoscaler ready: true, restart count 0
Apr 21 06:00:20.096: INFO: ibm-master-proxy-static-10.177.30.186 from kube-system started at 2020-04-21 03:06:34 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:00:20.096: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:00:20.096: INFO: sonobuoy-e2e-job-4f59fb8664564855 from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container e2e ready: true, restart count 0
Apr 21 06:00:20.096: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 06:00:20.096: INFO: olm-operator-7bf4dbc978-kgjlz from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container olm-operator ready: true, restart count 0
Apr 21 06:00:20.096: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-m8x2p from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 06:00:20.096: INFO: coredns-55db5d97fb-59ltz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.096: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:00:20.096: INFO: sonobuoy from sonobuoy started at 2020-04-21 04:37:03 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 21 06:00:20.097: INFO: calico-kube-controllers-598ddbf99d-mzh5s from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 21 06:00:20.097: INFO: dashboard-metrics-scraper-76756886dc-dp2kh from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 21 06:00:20.097: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-04-21 03:09:19 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Apr 21 06:00:20.097: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr 21 06:00:20.097: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:00:20.097: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-qfdjj from kube-system started at 2020-04-21 05:21:00 +0000 UTC (4 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 06:00:20.097: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 06:00:20.097: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 06:00:20.097: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 06:00:20.097: INFO: ibm-file-plugin-b8d7f5977-fkjtw from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:00:20.097: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-71d12ed1-39a7-4443-a864-1b30d4529e6b 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-71d12ed1-39a7-4443-a864-1b30d4529e6b off the node 10.177.30.140
STEP: verifying the node doesn't have the label kubernetes.io/e2e-71d12ed1-39a7-4443-a864-1b30d4529e6b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:00:26.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2329" for this suite.
Apr 21 06:00:38.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:00:39.359: INFO: namespace sched-pred-2329 deletion completed in 12.818132804s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:20.075 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:00:39.359: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7867
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Apr 21 06:00:39.678: INFO: namespace kubectl-7867
Apr 21 06:00:39.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-7867'
Apr 21 06:00:40.132: INFO: stderr: ""
Apr 21 06:00:40.132: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 21 06:00:41.152: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:00:41.152: INFO: Found 0 / 1
Apr 21 06:00:42.149: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:00:42.149: INFO: Found 1 / 1
Apr 21 06:00:42.149: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr 21 06:00:42.167: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:00:42.167: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 21 06:00:42.167: INFO: wait on redis-master startup in kubectl-7867 
Apr 21 06:00:42.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 logs redis-master-vfz9s redis-master --namespace=kubectl-7867'
Apr 21 06:00:42.425: INFO: stderr: ""
Apr 21 06:00:42.425: INFO: stdout: "1:C 21 Apr 2020 06:00:41.592 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 21 Apr 2020 06:00:41.592 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 21 Apr 2020 06:00:41.592 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 21 Apr 2020 06:00:41.594 * Running mode=standalone, port=6379.\n1:M 21 Apr 2020 06:00:41.594 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 21 Apr 2020 06:00:41.594 # Server initialized\n1:M 21 Apr 2020 06:00:41.594 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 21 Apr 2020 06:00:41.594 * Ready to accept connections\n"
STEP: exposing RC
Apr 21 06:00:42.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7867'
Apr 21 06:00:42.660: INFO: stderr: ""
Apr 21 06:00:42.660: INFO: stdout: "service/rm2 exposed\n"
Apr 21 06:00:42.675: INFO: Service rm2 in namespace kubectl-7867 found.
STEP: exposing service
Apr 21 06:00:44.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7867'
Apr 21 06:00:45.058: INFO: stderr: ""
Apr 21 06:00:45.058: INFO: stdout: "service/rm3 exposed\n"
Apr 21 06:00:45.079: INFO: Service rm3 in namespace kubectl-7867 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:00:47.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7867" for this suite.
Apr 21 06:01:21.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:01:21.938: INFO: namespace kubectl-7867 deletion completed in 34.793862389s

• [SLOW TEST:42.578 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:01:21.938: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2150
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-2150/secret-test-8010c1d3-1a42-4dc3-82a3-0b531782b23b
STEP: Creating a pod to test consume secrets
Apr 21 06:01:22.351: INFO: Waiting up to 5m0s for pod "pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8" in namespace "secrets-2150" to be "success or failure"
Apr 21 06:01:22.374: INFO: Pod "pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8": Phase="Pending", Reason="", readiness=false. Elapsed: 22.787841ms
Apr 21 06:01:24.390: INFO: Pod "pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8": Phase="Running", Reason="", readiness=true. Elapsed: 2.038844315s
Apr 21 06:01:26.409: INFO: Pod "pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058343561s
STEP: Saw pod success
Apr 21 06:01:26.409: INFO: Pod "pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8" satisfied condition "success or failure"
Apr 21 06:01:26.426: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8 container env-test: <nil>
STEP: delete the pod
Apr 21 06:01:26.537: INFO: Waiting for pod pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8 to disappear
Apr 21 06:01:26.555: INFO: Pod pod-configmaps-dfcc4c1a-7600-471d-9d98-276e98e643c8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:01:26.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2150" for this suite.
Apr 21 06:01:34.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:01:35.329: INFO: namespace secrets-2150 deletion completed in 8.733182381s

• [SLOW TEST:13.391 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:01:35.332: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2876
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2876
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2876
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2876
Apr 21 06:01:35.735: INFO: Found 0 stateful pods, waiting for 1
Apr 21 06:01:45.936: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr 21 06:01:45.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:01:46.394: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:01:46.394: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:01:46.394: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:01:46.411: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 21 06:01:56.431: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:01:56.431: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:01:56.519: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999997676s
Apr 21 06:01:57.538: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.970295776s
Apr 21 06:01:58.561: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.950843134s
Apr 21 06:01:59.578: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.927880004s
Apr 21 06:02:00.601: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.910638184s
Apr 21 06:02:01.620: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.887985313s
Apr 21 06:02:02.638: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.868377305s
Apr 21 06:02:03.657: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.850873201s
Apr 21 06:02:04.673: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.832173037s
Apr 21 06:02:05.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 815.743965ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2876
Apr 21 06:02:06.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:02:07.612: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 06:02:07.612: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:02:07.612: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:02:07.722: INFO: Found 1 stateful pods, waiting for 3
Apr 21 06:02:17.751: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 06:02:17.751: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 06:02:17.751: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr 21 06:02:17.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:02:18.184: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:02:18.185: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:02:18.185: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:02:18.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:02:18.582: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:02:18.583: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:02:18.583: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:02:18.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:02:18.970: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:02:18.971: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:02:18.971: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:02:18.971: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:02:19.007: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Apr 21 06:02:29.048: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:02:29.048: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:02:29.048: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:02:29.127: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997688s
Apr 21 06:02:30.151: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.977726329s
Apr 21 06:02:31.169: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.953609718s
Apr 21 06:02:32.187: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.935513142s
Apr 21 06:02:33.204: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.918265952s
Apr 21 06:02:34.222: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.900471709s
Apr 21 06:02:35.239: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.883265868s
Apr 21 06:02:36.258: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.865750889s
Apr 21 06:02:37.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.846849266s
Apr 21 06:02:38.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 817.363205ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2876
Apr 21 06:02:39.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:02:39.740: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 06:02:39.740: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:02:39.740: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:02:39.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:02:40.147: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 06:02:40.147: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:02:40.147: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:02:40.147: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:02:40.499: INFO: rc: 1
Apr 21 06:02:40.499: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Apr 21 06:02:50.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:02:50.672: INFO: rc: 1
Apr 21 06:02:50.672: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:00.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:00.834: INFO: rc: 1
Apr 21 06:03:00.834: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:10.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:11.013: INFO: rc: 1
Apr 21 06:03:11.014: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:21.014: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:21.204: INFO: rc: 1
Apr 21 06:03:21.204: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:31.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:31.377: INFO: rc: 1
Apr 21 06:03:31.377: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:41.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:41.536: INFO: rc: 1
Apr 21 06:03:41.536: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:03:51.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:03:51.697: INFO: rc: 1
Apr 21 06:03:51.697: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:01.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:01.864: INFO: rc: 1
Apr 21 06:04:01.864: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:11.864: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:12.042: INFO: rc: 1
Apr 21 06:04:12.042: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:22.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:22.204: INFO: rc: 1
Apr 21 06:04:22.204: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:32.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:32.392: INFO: rc: 1
Apr 21 06:04:32.392: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:42.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:42.549: INFO: rc: 1
Apr 21 06:04:42.549: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:04:52.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:04:52.726: INFO: rc: 1
Apr 21 06:04:52.726: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:02.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:02.914: INFO: rc: 1
Apr 21 06:05:02.914: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:12.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:13.097: INFO: rc: 1
Apr 21 06:05:13.097: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:23.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:23.379: INFO: rc: 1
Apr 21 06:05:23.379: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:33.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:33.582: INFO: rc: 1
Apr 21 06:05:33.583: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:43.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:43.772: INFO: rc: 1
Apr 21 06:05:43.773: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:05:53.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:05:53.955: INFO: rc: 1
Apr 21 06:05:53.955: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:03.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:04.128: INFO: rc: 1
Apr 21 06:06:04.128: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:14.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:14.291: INFO: rc: 1
Apr 21 06:06:14.291: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:24.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:24.474: INFO: rc: 1
Apr 21 06:06:24.474: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:34.474: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:34.640: INFO: rc: 1
Apr 21 06:06:34.640: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:44.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:44.799: INFO: rc: 1
Apr 21 06:06:44.799: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:06:54.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:06:54.952: INFO: rc: 1
Apr 21 06:06:54.952: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:07:04.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:07:05.147: INFO: rc: 1
Apr 21 06:07:05.147: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:07:15.148: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:07:15.327: INFO: rc: 1
Apr 21 06:07:15.327: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:07:25.330: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:07:25.520: INFO: rc: 1
Apr 21 06:07:25.520: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:07:35.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:07:35.684: INFO: rc: 1
Apr 21 06:07:35.684: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Apr 21 06:07:45.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-2876 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:07:45.847: INFO: rc: 1
Apr 21 06:07:45.847: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Apr 21 06:07:45.847: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 06:07:45.908: INFO: Deleting all statefulset in ns statefulset-2876
Apr 21 06:07:45.927: INFO: Scaling statefulset ss to 0
Apr 21 06:07:45.986: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:07:46.006: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:07:46.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2876" for this suite.
Apr 21 06:07:54.231: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:07:54.965: INFO: namespace statefulset-2876 deletion completed in 8.83257364s

• [SLOW TEST:379.633 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:07:54.966: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-18fcca7f-cc06-492c-bc9b-cbfd4531eea5
STEP: Creating a pod to test consume secrets
Apr 21 06:07:55.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e" in namespace "projected-609" to be "success or failure"
Apr 21 06:07:55.558: INFO: Pod "pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e": Phase="Pending", Reason="", readiness=false. Elapsed: 36.776771ms
Apr 21 06:07:57.582: INFO: Pod "pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.060867158s
STEP: Saw pod success
Apr 21 06:07:57.582: INFO: Pod "pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e" satisfied condition "success or failure"
Apr 21 06:07:57.602: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 06:07:57.782: INFO: Waiting for pod pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e to disappear
Apr 21 06:07:57.808: INFO: Pod pod-projected-secrets-7244e55b-13ff-42db-9a67-57670b950b6e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:07:57.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-609" for this suite.
Apr 21 06:08:05.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:08:06.622: INFO: namespace projected-609 deletion completed in 8.790408472s

• [SLOW TEST:11.656 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:08:06.623: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 21 06:08:06.983: INFO: Waiting up to 5m0s for pod "pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea" in namespace "emptydir-6745" to be "success or failure"
Apr 21 06:08:07.003: INFO: Pod "pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea": Phase="Pending", Reason="", readiness=false. Elapsed: 20.044653ms
Apr 21 06:08:11.109: INFO: Pod "pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.125977571s
STEP: Saw pod success
Apr 21 06:08:11.109: INFO: Pod "pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea" satisfied condition "success or failure"
Apr 21 06:08:11.172: INFO: Trying to get logs from node 10.177.30.140 pod pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea container test-container: <nil>
STEP: delete the pod
Apr 21 06:08:11.316: INFO: Waiting for pod pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea to disappear
Apr 21 06:08:11.332: INFO: Pod pod-dd74f4fa-fcc4-44f3-a3d0-cc57380a85ea no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:08:11.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6745" for this suite.
Apr 21 06:08:19.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:08:20.203: INFO: namespace emptydir-6745 deletion completed in 8.84015843s

• [SLOW TEST:13.580 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:08:20.204: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr 21 06:08:20.592: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:08:23.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4066" for this suite.
Apr 21 06:08:32.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:08:33.433: INFO: namespace init-container-4066 deletion completed in 9.40257369s

• [SLOW TEST:13.229 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:08:33.433: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4753
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:08:34.527: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:08:36.602: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046114, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046114, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046114, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046114, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:08:39.677: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:08:39.694: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:08:41.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4753" for this suite.
Apr 21 06:08:49.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:08:50.370: INFO: namespace webhook-4753 deletion completed in 8.81481663s
STEP: Destroying namespace "webhook-4753-markers" for this suite.
Apr 21 06:08:58.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:08:59.131: INFO: namespace webhook-4753-markers deletion completed in 8.760595816s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.799 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:08:59.233: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr 21 06:09:02.759: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:09:02.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9044" for this suite.
Apr 21 06:09:34.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:09:35.811: INFO: namespace replicaset-9044 deletion completed in 32.937086609s

• [SLOW TEST:36.578 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:09:35.813: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1394
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:09:49.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1394" for this suite.
Apr 21 06:09:57.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:09:58.433: INFO: namespace resourcequota-1394 deletion completed in 8.95571934s

• [SLOW TEST:22.620 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:09:58.435: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b3bee26f-f2fb-4f2c-96f4-773ddf700c73
STEP: Creating a pod to test consume secrets
Apr 21 06:09:58.823: INFO: Waiting up to 5m0s for pod "pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0" in namespace "secrets-7098" to be "success or failure"
Apr 21 06:09:58.843: INFO: Pod "pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0": Phase="Pending", Reason="", readiness=false. Elapsed: 19.785528ms
Apr 21 06:10:00.859: INFO: Pod "pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035709217s
STEP: Saw pod success
Apr 21 06:10:00.859: INFO: Pod "pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0" satisfied condition "success or failure"
Apr 21 06:10:00.875: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0 container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 06:10:01.053: INFO: Waiting for pod pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0 to disappear
Apr 21 06:10:01.073: INFO: Pod pod-secrets-a23c6fb6-ad17-4b8b-8c33-438e1e9da6e0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:10:01.073: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7098" for this suite.
Apr 21 06:10:09.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:10:09.968: INFO: namespace secrets-7098 deletion completed in 8.865113772s

• [SLOW TEST:11.533 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:10:09.969: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:10:10.326: INFO: Waiting up to 5m0s for pod "downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5" in namespace "projected-6982" to be "success or failure"
Apr 21 06:10:10.352: INFO: Pod "downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5": Phase="Pending", Reason="", readiness=false. Elapsed: 25.875562ms
Apr 21 06:10:12.369: INFO: Pod "downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042943089s
Apr 21 06:10:14.388: INFO: Pod "downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061122759s
STEP: Saw pod success
Apr 21 06:10:14.388: INFO: Pod "downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5" satisfied condition "success or failure"
Apr 21 06:10:14.432: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5 container client-container: <nil>
STEP: delete the pod
Apr 21 06:10:14.564: INFO: Waiting for pod downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5 to disappear
Apr 21 06:10:14.589: INFO: Pod downwardapi-volume-551677cf-a562-457e-a2b2-69a64ea455b5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:10:14.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6982" for this suite.
Apr 21 06:10:22.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:10:23.453: INFO: namespace projected-6982 deletion completed in 8.835296782s

• [SLOW TEST:13.484 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:10:23.453: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:10:23.812: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-9bd8af82-1da1-48cb-ad0a-b23465f28b10" in namespace "security-context-test-4733" to be "success or failure"
Apr 21 06:10:23.835: INFO: Pod "busybox-privileged-false-9bd8af82-1da1-48cb-ad0a-b23465f28b10": Phase="Pending", Reason="", readiness=false. Elapsed: 22.123408ms
Apr 21 06:10:25.853: INFO: Pod "busybox-privileged-false-9bd8af82-1da1-48cb-ad0a-b23465f28b10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040181814s
Apr 21 06:10:25.853: INFO: Pod "busybox-privileged-false-9bd8af82-1da1-48cb-ad0a-b23465f28b10" satisfied condition "success or failure"
Apr 21 06:10:25.922: INFO: Got logs for pod "busybox-privileged-false-9bd8af82-1da1-48cb-ad0a-b23465f28b10": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:10:25.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4733" for this suite.
Apr 21 06:10:34.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:10:34.710: INFO: namespace security-context-test-4733 deletion completed in 8.758971075s

• [SLOW TEST:11.257 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:10:34.712: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5064
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:10:37.260: INFO: Waiting up to 5m0s for pod "client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c" in namespace "pods-5064" to be "success or failure"
Apr 21 06:10:37.295: INFO: Pod "client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c": Phase="Pending", Reason="", readiness=false. Elapsed: 34.275806ms
Apr 21 06:10:39.314: INFO: Pod "client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053713409s
STEP: Saw pod success
Apr 21 06:10:39.314: INFO: Pod "client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c" satisfied condition "success or failure"
Apr 21 06:10:39.334: INFO: Trying to get logs from node 10.177.30.140 pod client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c container env3cont: <nil>
STEP: delete the pod
Apr 21 06:10:39.498: INFO: Waiting for pod client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c to disappear
Apr 21 06:10:39.519: INFO: Pod client-envvars-3fc94891-f530-4fa3-8edc-d2bc4309ea0c no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:10:39.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5064" for this suite.
Apr 21 06:10:53.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:10:54.377: INFO: namespace pods-5064 deletion completed in 14.809376644s

• [SLOW TEST:19.665 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:10:54.377: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7266
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-3763d33b-9990-41a8-9266-ec84d95baa22
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3763d33b-9990-41a8-9266-ec84d95baa22
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:10:59.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7266" for this suite.
Apr 21 06:11:29.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:11:29.823: INFO: namespace configmap-7266 deletion completed in 30.751172981s

• [SLOW TEST:35.446 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:11:29.824: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6577
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6577
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6577
I0421 06:11:30.314433      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6577, replica count: 2
Apr 21 06:11:33.365: INFO: Creating new exec pod
I0421 06:11:33.365257      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 06:11:38.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 21 06:11:38.854: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 21 06:11:38.854: INFO: stdout: ""
Apr 21 06:11:38.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 172.21.65.225 80'
Apr 21 06:11:39.213: INFO: stderr: "+ nc -zv -t -w 2 172.21.65.225 80\nConnection to 172.21.65.225 80 port [tcp/http] succeeded!\n"
Apr 21 06:11:39.214: INFO: stdout: ""
Apr 21 06:11:39.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 10.177.30.140 30002'
Apr 21 06:11:39.603: INFO: stderr: "+ nc -zv -t -w 2 10.177.30.140 30002\nConnection to 10.177.30.140 30002 port [tcp/30002] succeeded!\n"
Apr 21 06:11:39.603: INFO: stdout: ""
Apr 21 06:11:39.603: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 10.177.30.144 30002'
Apr 21 06:11:39.979: INFO: stderr: "+ nc -zv -t -w 2 10.177.30.144 30002\nConnection to 10.177.30.144 30002 port [tcp/30002] succeeded!\n"
Apr 21 06:11:39.979: INFO: stdout: ""
Apr 21 06:11:39.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 150.238.39.40 30002'
Apr 21 06:11:40.380: INFO: stderr: "+ nc -zv -t -w 2 150.238.39.40 30002\nConnection to 150.238.39.40 30002 port [tcp/30002] succeeded!\n"
Apr 21 06:11:40.380: INFO: stdout: ""
Apr 21 06:11:40.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-6577 execpod5th9x -- /bin/sh -x -c nc -zv -t -w 2 150.238.36.91 30002'
Apr 21 06:11:40.785: INFO: stderr: "+ nc -zv -t -w 2 150.238.36.91 30002\nConnection to 150.238.36.91 30002 port [tcp/30002] succeeded!\n"
Apr 21 06:11:40.785: INFO: stdout: ""
Apr 21 06:11:40.785: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:11:40.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6577" for this suite.
Apr 21 06:11:49.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:11:49.723: INFO: namespace services-6577 deletion completed in 8.769285242s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.899 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:11:49.723: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6565
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr 21 06:11:50.100: INFO: Waiting up to 5m0s for pod "downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5" in namespace "downward-api-6565" to be "success or failure"
Apr 21 06:11:50.135: INFO: Pod "downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5": Phase="Pending", Reason="", readiness=false. Elapsed: 34.729997ms
Apr 21 06:11:52.152: INFO: Pod "downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051240931s
STEP: Saw pod success
Apr 21 06:11:52.152: INFO: Pod "downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5" satisfied condition "success or failure"
Apr 21 06:11:52.173: INFO: Trying to get logs from node 10.177.30.140 pod downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5 container dapi-container: <nil>
STEP: delete the pod
Apr 21 06:11:52.306: INFO: Waiting for pod downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5 to disappear
Apr 21 06:11:52.331: INFO: Pod downward-api-da0dae05-0c25-4c9d-8caf-eacf590530d5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:11:52.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6565" for this suite.
Apr 21 06:12:00.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:12:01.195: INFO: namespace downward-api-6565 deletion completed in 8.83830351s

• [SLOW TEST:11.472 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:12:01.195: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-9501
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:12:01.496: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Creating first CR 
Apr 21 06:12:02.359: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:02Z generation:1 name:name1 resourceVersion:38850 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb055736-f48e-41a3-bc7f-6193c53657fb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr 21 06:12:12.386: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:12Z generation:1 name:name2 resourceVersion:38866 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:18a9e5c8-b405-41b2-87d0-e778b9d8dd0a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr 21 06:12:22.418: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:02Z generation:2 name:name1 resourceVersion:38879 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb055736-f48e-41a3-bc7f-6193c53657fb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr 21 06:12:32.443: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:12Z generation:2 name:name2 resourceVersion:38892 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:18a9e5c8-b405-41b2-87d0-e778b9d8dd0a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr 21 06:12:43.009: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:02Z generation:2 name:name1 resourceVersion:38909 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cb055736-f48e-41a3-bc7f-6193c53657fb] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr 21 06:12:53.051: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-21T06:12:12Z generation:2 name:name2 resourceVersion:38923 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:18a9e5c8-b405-41b2-87d0-e778b9d8dd0a] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:13:03.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-9501" for this suite.
Apr 21 06:13:11.731: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:13:12.442: INFO: namespace crd-watch-9501 deletion completed in 8.800180131s

• [SLOW TEST:71.247 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:13:12.443: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2089
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:13:12.807: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48" in namespace "downward-api-2089" to be "success or failure"
Apr 21 06:13:12.829: INFO: Pod "downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48": Phase="Pending", Reason="", readiness=false. Elapsed: 21.214497ms
Apr 21 06:13:14.847: INFO: Pod "downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039492145s
Apr 21 06:13:16.863: INFO: Pod "downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055334372s
STEP: Saw pod success
Apr 21 06:13:16.863: INFO: Pod "downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48" satisfied condition "success or failure"
Apr 21 06:13:16.878: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48 container client-container: <nil>
STEP: delete the pod
Apr 21 06:13:16.997: INFO: Waiting for pod downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48 to disappear
Apr 21 06:13:17.019: INFO: Pod downwardapi-volume-9452b69d-0b6d-448e-9a16-b61c3358ab48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:13:17.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2089" for this suite.
Apr 21 06:13:25.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:13:25.778: INFO: namespace downward-api-2089 deletion completed in 8.732716167s

• [SLOW TEST:13.336 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:13:25.782: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8096
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a885c77b-b416-4a03-a26e-2cd5f5a4ccaf
STEP: Creating a pod to test consume secrets
Apr 21 06:13:26.167: INFO: Waiting up to 5m0s for pod "pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c" in namespace "secrets-8096" to be "success or failure"
Apr 21 06:13:26.187: INFO: Pod "pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c": Phase="Pending", Reason="", readiness=false. Elapsed: 20.040041ms
Apr 21 06:13:28.203: INFO: Pod "pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035428098s
STEP: Saw pod success
Apr 21 06:13:28.203: INFO: Pod "pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c" satisfied condition "success or failure"
Apr 21 06:13:28.220: INFO: Trying to get logs from node 10.177.30.140 pod pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c container secret-volume-test: <nil>
STEP: delete the pod
Apr 21 06:13:28.324: INFO: Waiting for pod pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c to disappear
Apr 21 06:13:28.346: INFO: Pod pod-secrets-331304e6-4d5d-476a-b805-7c9a6cc4ff3c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:13:28.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8096" for this suite.
Apr 21 06:13:36.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:13:37.140: INFO: namespace secrets-8096 deletion completed in 8.770917062s

• [SLOW TEST:11.358 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:13:37.140: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1195
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1195
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-1195
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1195
Apr 21 06:13:37.536: INFO: Found 0 stateful pods, waiting for 1
Apr 21 06:13:47.555: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr 21 06:13:47.575: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:13:47.984: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:13:47.984: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:13:47.984: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:13:48.003: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr 21 06:13:58.023: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:13:58.023: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:13:58.094: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:13:58.094: INFO: ss-0  10.177.30.140  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:13:58.094: INFO: 
Apr 21 06:13:58.094: INFO: StatefulSet ss has not reached scale 3, at 1
Apr 21 06:13:59.123: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.979930198s
Apr 21 06:14:00.153: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.951641363s
Apr 21 06:14:01.171: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.921390833s
Apr 21 06:14:02.188: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.903555137s
Apr 21 06:14:03.212: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.885726876s
Apr 21 06:14:04.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.861932822s
Apr 21 06:14:05.250: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.844744884s
Apr 21 06:14:06.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.824074849s
Apr 21 06:14:07.287: INFO: Verifying statefulset ss doesn't scale past 3 for another 806.271866ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1195
Apr 21 06:14:08.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:14:08.952: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr 21 06:14:08.952: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:14:08.952: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:14:08.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:14:09.354: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 21 06:14:09.354: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:14:09.355: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:14:09.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:14:09.740: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr 21 06:14:09.740: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr 21 06:14:09.740: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr 21 06:14:09.757: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr 21 06:14:19.780: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 06:14:19.780: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 06:14:19.780: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr 21 06:14:19.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:14:20.198: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:14:20.198: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:14:20.198: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:14:20.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:14:20.643: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:14:20.643: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:14:20.643: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:14:20.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr 21 06:14:21.092: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr 21 06:14:21.092: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr 21 06:14:21.092: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr 21 06:14:21.092: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:14:21.143: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr 21 06:14:31.183: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:14:31.183: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:14:31.183: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr 21 06:14:31.238: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:31.238: INFO: ss-0  10.177.30.140  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:31.238: INFO: ss-1  10.177.30.144  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:31.238: INFO: ss-2  10.177.30.186  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:31.238: INFO: 
Apr 21 06:14:31.238: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 21 06:14:32.320: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:32.320: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:32.321: INFO: ss-1  10.177.30.144  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:32.321: INFO: ss-2  10.177.30.186  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:32.321: INFO: 
Apr 21 06:14:32.321: INFO: StatefulSet ss has not reached scale 0, at 3
Apr 21 06:14:33.341: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:33.341: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:33.341: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:33.341: INFO: 
Apr 21 06:14:33.341: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:34.358: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:34.358: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:34.358: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:34.358: INFO: 
Apr 21 06:14:34.358: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:35.375: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:35.375: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:35.375: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:35.375: INFO: 
Apr 21 06:14:35.375: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:36.392: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:36.392: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:36.392: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:36.392: INFO: 
Apr 21 06:14:36.392: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:37.458: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:37.458: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:37.458: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:37.458: INFO: 
Apr 21 06:14:37.458: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:38.477: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:38.477: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:38.477: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:38.477: INFO: 
Apr 21 06:14:38.477: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:39.496: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:39.496: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:39.497: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:39.497: INFO: 
Apr 21 06:14:39.497: INFO: StatefulSet ss has not reached scale 0, at 2
Apr 21 06:14:40.514: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Apr 21 06:14:40.514: INFO: ss-0  10.177.30.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:37 +0000 UTC  }]
Apr 21 06:14:40.514: INFO: ss-1  10.177.30.144  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:14:21 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-21 06:13:58 +0000 UTC  }]
Apr 21 06:14:40.514: INFO: 
Apr 21 06:14:40.514: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1195
Apr 21 06:14:41.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:14:41.861: INFO: rc: 1
Apr 21 06:14:41.861: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Apr 21 06:14:51.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:14:52.026: INFO: rc: 1
Apr 21 06:14:52.026: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:02.026: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:02.190: INFO: rc: 1
Apr 21 06:15:02.190: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:12.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:12.380: INFO: rc: 1
Apr 21 06:15:12.380: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:22.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:22.554: INFO: rc: 1
Apr 21 06:15:22.554: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:32.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:32.849: INFO: rc: 1
Apr 21 06:15:32.849: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:42.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:43.035: INFO: rc: 1
Apr 21 06:15:43.035: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:15:53.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:15:53.191: INFO: rc: 1
Apr 21 06:15:53.191: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:03.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:03.367: INFO: rc: 1
Apr 21 06:16:03.367: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:13.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:13.541: INFO: rc: 1
Apr 21 06:16:13.542: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:23.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:23.717: INFO: rc: 1
Apr 21 06:16:23.717: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:33.717: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:33.907: INFO: rc: 1
Apr 21 06:16:33.907: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:43.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:44.103: INFO: rc: 1
Apr 21 06:16:44.103: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:16:54.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:16:54.287: INFO: rc: 1
Apr 21 06:16:54.287: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:04.287: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:04.503: INFO: rc: 1
Apr 21 06:17:04.503: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:14.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:14.675: INFO: rc: 1
Apr 21 06:17:14.675: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:24.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:24.855: INFO: rc: 1
Apr 21 06:17:24.855: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:34.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:35.024: INFO: rc: 1
Apr 21 06:17:35.024: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:45.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:45.199: INFO: rc: 1
Apr 21 06:17:45.199: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:17:55.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:17:55.377: INFO: rc: 1
Apr 21 06:17:55.377: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:05.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:05.560: INFO: rc: 1
Apr 21 06:18:05.561: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:15.561: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:15.744: INFO: rc: 1
Apr 21 06:18:15.744: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:25.744: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:25.910: INFO: rc: 1
Apr 21 06:18:25.910: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:35.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:36.072: INFO: rc: 1
Apr 21 06:18:36.072: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:46.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:46.237: INFO: rc: 1
Apr 21 06:18:46.237: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:18:56.237: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:18:56.395: INFO: rc: 1
Apr 21 06:18:56.395: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:19:06.395: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:19:06.567: INFO: rc: 1
Apr 21 06:19:06.567: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:19:16.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:19:16.729: INFO: rc: 1
Apr 21 06:19:16.729: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:19:26.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:19:26.893: INFO: rc: 1
Apr 21 06:19:26.893: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:19:36.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:19:37.061: INFO: rc: 1
Apr 21 06:19:37.061: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Apr 21 06:19:47.062: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=statefulset-1195 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr 21 06:19:47.232: INFO: rc: 1
Apr 21 06:19:47.232: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Apr 21 06:19:47.232: INFO: Scaling statefulset ss to 0
Apr 21 06:19:47.289: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 06:19:47.322: INFO: Deleting all statefulset in ns statefulset-1195
Apr 21 06:19:47.351: INFO: Scaling statefulset ss to 0
Apr 21 06:19:47.408: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 06:19:47.423: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:19:47.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1195" for this suite.
Apr 21 06:19:55.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:19:56.492: INFO: namespace statefulset-1195 deletion completed in 8.764869446s

• [SLOW TEST:379.352 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:19:56.493: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2882
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-da870ebe-a0fc-46dd-b96c-ba4534458716
STEP: Creating a pod to test consume configMaps
Apr 21 06:19:56.914: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d" in namespace "projected-2882" to be "success or failure"
Apr 21 06:19:56.952: INFO: Pod "pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d": Phase="Pending", Reason="", readiness=false. Elapsed: 37.656363ms
Apr 21 06:19:58.967: INFO: Pod "pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052510859s
STEP: Saw pod success
Apr 21 06:19:58.967: INFO: Pod "pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d" satisfied condition "success or failure"
Apr 21 06:19:58.983: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:19:59.150: INFO: Waiting for pod pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d to disappear
Apr 21 06:19:59.164: INFO: Pod pod-projected-configmaps-bb547ccb-af5f-4aca-bc64-51605904cc2d no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:19:59.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2882" for this suite.
Apr 21 06:20:09.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:20:09.960: INFO: namespace projected-2882 deletion completed in 10.759208043s

• [SLOW TEST:13.468 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:20:09.961: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-701
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:20:11.188: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:20:14.294: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:20:14.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-701" for this suite.
Apr 21 06:20:22.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:20:23.373: INFO: namespace webhook-701 deletion completed in 8.875510257s
STEP: Destroying namespace "webhook-701-markers" for this suite.
Apr 21 06:20:31.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:20:32.768: INFO: namespace webhook-701-markers deletion completed in 9.395423652s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.922 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:20:32.883: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Apr 21 06:20:33.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 cluster-info'
Apr 21 06:20:33.383: INFO: stderr: ""
Apr 21 06:20:33.383: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:20:33.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7809" for this suite.
Apr 21 06:20:41.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:20:42.220: INFO: namespace kubectl-7809 deletion completed in 8.812634581s

• [SLOW TEST:9.337 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:20:42.221: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-862
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-d5qh6 in namespace proxy-862
I0421 06:20:42.633677      26 runners.go:184] Created replication controller with name: proxy-service-d5qh6, namespace: proxy-862, replica count: 1
I0421 06:20:43.684211      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0421 06:20:44.684745      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0421 06:20:45.685131      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0421 06:20:46.685409      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0421 06:20:47.685660      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0421 06:20:48.685958      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0421 06:20:49.686273      26 runners.go:184] proxy-service-d5qh6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 06:20:49.705: INFO: setup took 7.184049274s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr 21 06:20:49.745: INFO: (0) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 40.34538ms)
Apr 21 06:20:49.748: INFO: (0) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 42.934334ms)
Apr 21 06:20:49.748: INFO: (0) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 43.140622ms)
Apr 21 06:20:49.749: INFO: (0) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 43.461817ms)
Apr 21 06:20:49.753: INFO: (0) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 47.819784ms)
Apr 21 06:20:49.753: INFO: (0) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 47.42411ms)
Apr 21 06:20:49.756: INFO: (0) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 50.365438ms)
Apr 21 06:20:49.756: INFO: (0) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 51.657154ms)
Apr 21 06:20:49.766: INFO: (0) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 61.007228ms)
Apr 21 06:20:49.766: INFO: (0) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 61.227436ms)
Apr 21 06:20:49.767: INFO: (0) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 61.431405ms)
Apr 21 06:20:49.776: INFO: (0) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 71.44281ms)
Apr 21 06:20:49.781: INFO: (0) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 75.530249ms)
Apr 21 06:20:49.781: INFO: (0) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 75.779646ms)
Apr 21 06:20:49.784: INFO: (0) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 78.899575ms)
Apr 21 06:20:49.784: INFO: (0) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 79.605564ms)
Apr 21 06:20:49.816: INFO: (1) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 30.495809ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 40.716867ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 41.414208ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 41.870133ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 40.661922ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 41.099161ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 41.690336ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 41.216314ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 41.602397ms)
Apr 21 06:20:49.827: INFO: (1) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 41.846241ms)
Apr 21 06:20:49.832: INFO: (1) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 47.068963ms)
Apr 21 06:20:49.835: INFO: (1) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 50.373898ms)
Apr 21 06:20:49.838: INFO: (1) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 52.90486ms)
Apr 21 06:20:49.839: INFO: (1) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 54.745883ms)
Apr 21 06:20:49.840: INFO: (1) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 53.713505ms)
Apr 21 06:20:49.840: INFO: (1) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 54.043518ms)
Apr 21 06:20:49.874: INFO: (2) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 33.803319ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 37.401204ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 36.633724ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 37.04341ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 36.344691ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 37.811428ms)
Apr 21 06:20:49.878: INFO: (2) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 36.613468ms)
Apr 21 06:20:49.879: INFO: (2) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 38.380526ms)
Apr 21 06:20:49.879: INFO: (2) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 38.042909ms)
Apr 21 06:20:49.879: INFO: (2) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 38.694843ms)
Apr 21 06:20:49.904: INFO: (2) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 63.961944ms)
Apr 21 06:20:49.908: INFO: (2) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 67.666288ms)
Apr 21 06:20:49.908: INFO: (2) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 66.325713ms)
Apr 21 06:20:49.908: INFO: (2) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 66.096816ms)
Apr 21 06:20:49.909: INFO: (2) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 67.346039ms)
Apr 21 06:20:49.912: INFO: (2) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 71.542676ms)
Apr 21 06:20:49.956: INFO: (3) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 43.069732ms)
Apr 21 06:20:49.956: INFO: (3) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 43.676526ms)
Apr 21 06:20:49.956: INFO: (3) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 44.293183ms)
Apr 21 06:20:49.957: INFO: (3) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 44.339299ms)
Apr 21 06:20:49.957: INFO: (3) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 43.921686ms)
Apr 21 06:20:49.969: INFO: (3) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 56.153627ms)
Apr 21 06:20:49.970: INFO: (3) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 57.534188ms)
Apr 21 06:20:49.971: INFO: (3) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 57.425768ms)
Apr 21 06:20:49.971: INFO: (3) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 57.257743ms)
Apr 21 06:20:49.986: INFO: (3) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 72.901826ms)
Apr 21 06:20:49.986: INFO: (3) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 73.483069ms)
Apr 21 06:20:49.987: INFO: (3) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 73.667597ms)
Apr 21 06:20:49.987: INFO: (3) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 73.282404ms)
Apr 21 06:20:49.987: INFO: (3) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 73.614856ms)
Apr 21 06:20:49.987: INFO: (3) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 74.714444ms)
Apr 21 06:20:49.987: INFO: (3) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 74.712218ms)
Apr 21 06:20:50.035: INFO: (4) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 47.250171ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 48.471825ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 48.336274ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 48.36757ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 48.233434ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 48.124937ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 48.412252ms)
Apr 21 06:20:50.036: INFO: (4) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 48.399996ms)
Apr 21 06:20:50.037: INFO: (4) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 49.029424ms)
Apr 21 06:20:50.037: INFO: (4) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 49.229626ms)
Apr 21 06:20:50.043: INFO: (4) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 55.254646ms)
Apr 21 06:20:50.046: INFO: (4) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 58.843445ms)
Apr 21 06:20:50.051: INFO: (4) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 63.250281ms)
Apr 21 06:20:50.052: INFO: (4) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 63.848689ms)
Apr 21 06:20:50.068: INFO: (4) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 80.173067ms)
Apr 21 06:20:50.068: INFO: (4) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 80.669148ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 54.045248ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 54.72106ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 54.13752ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 54.262329ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 54.10675ms)
Apr 21 06:20:50.123: INFO: (5) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 54.809701ms)
Apr 21 06:20:50.124: INFO: (5) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 55.391242ms)
Apr 21 06:20:50.124: INFO: (5) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 55.275774ms)
Apr 21 06:20:50.124: INFO: (5) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 54.68912ms)
Apr 21 06:20:50.124: INFO: (5) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 55.371726ms)
Apr 21 06:20:50.124: INFO: (5) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 55.525876ms)
Apr 21 06:20:50.152: INFO: (5) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 83.210009ms)
Apr 21 06:20:50.152: INFO: (5) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 83.46245ms)
Apr 21 06:20:50.153: INFO: (5) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 83.798188ms)
Apr 21 06:20:50.153: INFO: (5) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 83.295807ms)
Apr 21 06:20:50.153: INFO: (5) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 83.25086ms)
Apr 21 06:20:50.180: INFO: (6) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 27.107374ms)
Apr 21 06:20:50.184: INFO: (6) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 30.633449ms)
Apr 21 06:20:50.184: INFO: (6) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 30.612205ms)
Apr 21 06:20:50.184: INFO: (6) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 30.229267ms)
Apr 21 06:20:50.184: INFO: (6) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 31.046201ms)
Apr 21 06:20:50.184: INFO: (6) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 31.023661ms)
Apr 21 06:20:50.192: INFO: (6) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 38.664812ms)
Apr 21 06:20:50.192: INFO: (6) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 38.782421ms)
Apr 21 06:20:50.192: INFO: (6) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 39.224159ms)
Apr 21 06:20:50.192: INFO: (6) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 38.961557ms)
Apr 21 06:20:50.209: INFO: (6) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 56.288864ms)
Apr 21 06:20:50.210: INFO: (6) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 57.190085ms)
Apr 21 06:20:50.211: INFO: (6) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 57.30802ms)
Apr 21 06:20:50.211: INFO: (6) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 57.902212ms)
Apr 21 06:20:50.211: INFO: (6) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 58.014011ms)
Apr 21 06:20:50.221: INFO: (6) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 68.11596ms)
Apr 21 06:20:50.256: INFO: (7) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 34.825546ms)
Apr 21 06:20:50.264: INFO: (7) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 42.576136ms)
Apr 21 06:20:50.264: INFO: (7) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 41.98315ms)
Apr 21 06:20:50.264: INFO: (7) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 42.078741ms)
Apr 21 06:20:50.264: INFO: (7) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 42.06312ms)
Apr 21 06:20:50.265: INFO: (7) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 42.975995ms)
Apr 21 06:20:50.265: INFO: (7) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 43.586698ms)
Apr 21 06:20:50.265: INFO: (7) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 43.606203ms)
Apr 21 06:20:50.265: INFO: (7) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 43.766523ms)
Apr 21 06:20:50.266: INFO: (7) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 44.049082ms)
Apr 21 06:20:50.273: INFO: (7) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 52.377643ms)
Apr 21 06:20:50.274: INFO: (7) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 52.426254ms)
Apr 21 06:20:50.276: INFO: (7) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 54.762851ms)
Apr 21 06:20:50.277: INFO: (7) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 55.490184ms)
Apr 21 06:20:50.277: INFO: (7) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 55.90247ms)
Apr 21 06:20:50.280: INFO: (7) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 58.644983ms)
Apr 21 06:20:50.306: INFO: (8) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 25.928113ms)
Apr 21 06:20:50.311: INFO: (8) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 29.936988ms)
Apr 21 06:20:50.311: INFO: (8) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 30.171306ms)
Apr 21 06:20:50.315: INFO: (8) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 33.734783ms)
Apr 21 06:20:50.315: INFO: (8) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 34.301862ms)
Apr 21 06:20:50.315: INFO: (8) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 34.66928ms)
Apr 21 06:20:50.316: INFO: (8) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 35.222322ms)
Apr 21 06:20:50.316: INFO: (8) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 35.322756ms)
Apr 21 06:20:50.318: INFO: (8) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 37.375882ms)
Apr 21 06:20:50.318: INFO: (8) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 37.560651ms)
Apr 21 06:20:50.328: INFO: (8) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 47.573204ms)
Apr 21 06:20:50.336: INFO: (8) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 54.828141ms)
Apr 21 06:20:50.336: INFO: (8) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 54.876649ms)
Apr 21 06:20:50.336: INFO: (8) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 55.033475ms)
Apr 21 06:20:50.336: INFO: (8) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 55.015959ms)
Apr 21 06:20:50.339: INFO: (8) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 58.635698ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 42.364939ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 42.343ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 42.19319ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 42.323134ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 42.399788ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 42.452942ms)
Apr 21 06:20:50.382: INFO: (9) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 42.438831ms)
Apr 21 06:20:50.383: INFO: (9) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 42.726614ms)
Apr 21 06:20:50.383: INFO: (9) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 42.98411ms)
Apr 21 06:20:50.383: INFO: (9) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 43.073365ms)
Apr 21 06:20:50.393: INFO: (9) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 52.717975ms)
Apr 21 06:20:50.420: INFO: (9) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 79.790984ms)
Apr 21 06:20:50.422: INFO: (9) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 82.353101ms)
Apr 21 06:20:50.422: INFO: (9) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 82.167553ms)
Apr 21 06:20:50.422: INFO: (9) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 82.533459ms)
Apr 21 06:20:50.422: INFO: (9) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 82.551723ms)
Apr 21 06:20:50.454: INFO: (10) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 31.064921ms)
Apr 21 06:20:50.455: INFO: (10) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 31.662544ms)
Apr 21 06:20:50.459: INFO: (10) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 35.821385ms)
Apr 21 06:20:50.459: INFO: (10) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 35.937182ms)
Apr 21 06:20:50.461: INFO: (10) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 37.324209ms)
Apr 21 06:20:50.461: INFO: (10) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 37.232ms)
Apr 21 06:20:50.461: INFO: (10) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 37.690171ms)
Apr 21 06:20:50.463: INFO: (10) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 40.335679ms)
Apr 21 06:20:50.463: INFO: (10) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 39.879501ms)
Apr 21 06:20:50.463: INFO: (10) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 40.430739ms)
Apr 21 06:20:50.464: INFO: (10) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 40.764511ms)
Apr 21 06:20:50.467: INFO: (10) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 44.292571ms)
Apr 21 06:20:50.470: INFO: (10) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 46.389169ms)
Apr 21 06:20:50.470: INFO: (10) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 46.890123ms)
Apr 21 06:20:50.472: INFO: (10) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 49.363253ms)
Apr 21 06:20:50.474: INFO: (10) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 50.911554ms)
Apr 21 06:20:50.520: INFO: (11) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 46.078716ms)
Apr 21 06:20:50.526: INFO: (11) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 50.885303ms)
Apr 21 06:20:50.527: INFO: (11) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 52.219003ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 52.608057ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 52.817513ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 52.539699ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 53.431105ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 53.153375ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 53.315543ms)
Apr 21 06:20:50.528: INFO: (11) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 52.674086ms)
Apr 21 06:20:50.533: INFO: (11) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 57.754421ms)
Apr 21 06:20:50.535: INFO: (11) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 60.675371ms)
Apr 21 06:20:50.537: INFO: (11) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 61.493745ms)
Apr 21 06:20:50.545: INFO: (11) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 70.14685ms)
Apr 21 06:20:50.552: INFO: (11) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 76.741559ms)
Apr 21 06:20:50.558: INFO: (11) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 83.014509ms)
Apr 21 06:20:50.598: INFO: (12) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 39.697382ms)
Apr 21 06:20:50.598: INFO: (12) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 39.999105ms)
Apr 21 06:20:50.598: INFO: (12) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 40.119957ms)
Apr 21 06:20:50.599: INFO: (12) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 40.033991ms)
Apr 21 06:20:50.599: INFO: (12) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 40.224876ms)
Apr 21 06:20:50.599: INFO: (12) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 40.350219ms)
Apr 21 06:20:50.599: INFO: (12) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 40.50772ms)
Apr 21 06:20:50.599: INFO: (12) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 41.01891ms)
Apr 21 06:20:50.600: INFO: (12) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 40.67438ms)
Apr 21 06:20:50.600: INFO: (12) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 41.077779ms)
Apr 21 06:20:50.606: INFO: (12) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 47.622271ms)
Apr 21 06:20:50.609: INFO: (12) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 50.242715ms)
Apr 21 06:20:50.609: INFO: (12) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 51.227859ms)
Apr 21 06:20:50.609: INFO: (12) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 50.725124ms)
Apr 21 06:20:50.613: INFO: (12) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 55.253859ms)
Apr 21 06:20:50.613: INFO: (12) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 54.525284ms)
Apr 21 06:20:50.651: INFO: (13) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 36.990908ms)
Apr 21 06:20:50.651: INFO: (13) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 37.026578ms)
Apr 21 06:20:50.651: INFO: (13) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 37.209237ms)
Apr 21 06:20:50.655: INFO: (13) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 40.794378ms)
Apr 21 06:20:50.656: INFO: (13) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 41.678759ms)
Apr 21 06:20:50.656: INFO: (13) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 41.89565ms)
Apr 21 06:20:50.656: INFO: (13) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 41.568893ms)
Apr 21 06:20:50.656: INFO: (13) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 41.688728ms)
Apr 21 06:20:50.656: INFO: (13) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 42.293829ms)
Apr 21 06:20:50.657: INFO: (13) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 42.951915ms)
Apr 21 06:20:50.662: INFO: (13) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 47.464118ms)
Apr 21 06:20:50.662: INFO: (13) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 48.04122ms)
Apr 21 06:20:50.665: INFO: (13) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 50.566722ms)
Apr 21 06:20:50.665: INFO: (13) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 50.551483ms)
Apr 21 06:20:50.665: INFO: (13) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 50.959855ms)
Apr 21 06:20:50.665: INFO: (13) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 51.247365ms)
Apr 21 06:20:50.703: INFO: (14) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 37.253851ms)
Apr 21 06:20:50.703: INFO: (14) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 37.671835ms)
Apr 21 06:20:50.704: INFO: (14) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 38.176765ms)
Apr 21 06:20:50.703: INFO: (14) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 37.634979ms)
Apr 21 06:20:50.703: INFO: (14) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 37.511506ms)
Apr 21 06:20:50.704: INFO: (14) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 37.955664ms)
Apr 21 06:20:50.704: INFO: (14) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 38.402664ms)
Apr 21 06:20:50.705: INFO: (14) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 39.09743ms)
Apr 21 06:20:50.705: INFO: (14) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 39.518143ms)
Apr 21 06:20:50.715: INFO: (14) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 49.539546ms)
Apr 21 06:20:50.721: INFO: (14) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 55.472145ms)
Apr 21 06:20:50.728: INFO: (14) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 62.867361ms)
Apr 21 06:20:50.728: INFO: (14) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 62.69668ms)
Apr 21 06:20:50.729: INFO: (14) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 63.457902ms)
Apr 21 06:20:50.729: INFO: (14) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 63.863925ms)
Apr 21 06:20:50.730: INFO: (14) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 63.56791ms)
Apr 21 06:20:50.757: INFO: (15) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 27.504192ms)
Apr 21 06:20:50.760: INFO: (15) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 30.276718ms)
Apr 21 06:20:50.761: INFO: (15) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 30.40039ms)
Apr 21 06:20:50.761: INFO: (15) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 30.724136ms)
Apr 21 06:20:50.761: INFO: (15) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 30.421631ms)
Apr 21 06:20:50.762: INFO: (15) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 31.897047ms)
Apr 21 06:20:50.822: INFO: (15) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 91.541055ms)
Apr 21 06:20:50.822: INFO: (15) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 91.5577ms)
Apr 21 06:20:50.822: INFO: (15) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 91.717233ms)
Apr 21 06:20:50.822: INFO: (15) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 91.845883ms)
Apr 21 06:20:50.822: INFO: (15) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 91.568925ms)
Apr 21 06:20:50.823: INFO: (15) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 92.908598ms)
Apr 21 06:20:50.823: INFO: (15) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 93.554415ms)
Apr 21 06:20:50.825: INFO: (15) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 94.465166ms)
Apr 21 06:20:50.829: INFO: (15) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 99.090087ms)
Apr 21 06:20:50.829: INFO: (15) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 99.32578ms)
Apr 21 06:20:50.859: INFO: (16) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 28.523709ms)
Apr 21 06:20:50.865: INFO: (16) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 35.68622ms)
Apr 21 06:20:50.866: INFO: (16) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 35.913427ms)
Apr 21 06:20:50.867: INFO: (16) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 36.62826ms)
Apr 21 06:20:50.867: INFO: (16) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 37.344221ms)
Apr 21 06:20:50.869: INFO: (16) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 38.391814ms)
Apr 21 06:20:50.869: INFO: (16) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 39.061461ms)
Apr 21 06:20:50.869: INFO: (16) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 38.540087ms)
Apr 21 06:20:50.869: INFO: (16) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 38.707949ms)
Apr 21 06:20:50.870: INFO: (16) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 39.895166ms)
Apr 21 06:20:50.870: INFO: (16) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 40.300085ms)
Apr 21 06:20:50.876: INFO: (16) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 45.75064ms)
Apr 21 06:20:50.876: INFO: (16) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 45.903895ms)
Apr 21 06:20:50.876: INFO: (16) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 46.056482ms)
Apr 21 06:20:50.884: INFO: (16) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 54.169575ms)
Apr 21 06:20:50.885: INFO: (16) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 55.711613ms)
Apr 21 06:20:50.917: INFO: (17) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 30.582673ms)
Apr 21 06:20:50.917: INFO: (17) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 31.134548ms)
Apr 21 06:20:50.918: INFO: (17) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 31.415779ms)
Apr 21 06:20:50.919: INFO: (17) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 32.134404ms)
Apr 21 06:20:50.943: INFO: (17) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 57.151066ms)
Apr 21 06:20:50.945: INFO: (17) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 57.640902ms)
Apr 21 06:20:50.945: INFO: (17) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 57.581702ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 60.618905ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 60.320934ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 61.251284ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 60.505542ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 60.341877ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 60.630055ms)
Apr 21 06:20:50.947: INFO: (17) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 60.085236ms)
Apr 21 06:20:50.961: INFO: (17) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 74.294843ms)
Apr 21 06:20:50.965: INFO: (17) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 77.829483ms)
Apr 21 06:20:51.000: INFO: (18) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 35.203456ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 35.582645ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 35.89045ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 35.648668ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 35.826901ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 36.07264ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 36.10385ms)
Apr 21 06:20:51.001: INFO: (18) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 36.281213ms)
Apr 21 06:20:51.002: INFO: (18) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 36.783893ms)
Apr 21 06:20:51.006: INFO: (18) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 40.515702ms)
Apr 21 06:20:51.016: INFO: (18) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 51.523555ms)
Apr 21 06:20:51.034: INFO: (18) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 68.973334ms)
Apr 21 06:20:51.034: INFO: (18) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 69.259321ms)
Apr 21 06:20:51.034: INFO: (18) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 69.190322ms)
Apr 21 06:20:51.038: INFO: (18) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 73.115934ms)
Apr 21 06:20:51.038: INFO: (18) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 73.269575ms)
Apr 21 06:20:51.063: INFO: (19) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">test</... (200; 23.506288ms)
Apr 21 06:20:51.070: INFO: (19) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:443/proxy/tlsrewriteme... (200; 30.954437ms)
Apr 21 06:20:51.070: INFO: (19) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:460/proxy/: tls baz (200; 30.745642ms)
Apr 21 06:20:51.070: INFO: (19) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 30.489684ms)
Apr 21 06:20:51.070: INFO: (19) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw/proxy/rewriteme">test</a> (200; 29.929614ms)
Apr 21 06:20:51.070: INFO: (19) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:162/proxy/: bar (200; 31.780865ms)
Apr 21 06:20:51.074: INFO: (19) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/: <a href="/api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:1080/proxy/rewriteme">t... (200; 34.623398ms)
Apr 21 06:20:51.076: INFO: (19) /api/v1/namespaces/proxy-862/pods/http:proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 36.12374ms)
Apr 21 06:20:51.076: INFO: (19) /api/v1/namespaces/proxy-862/pods/proxy-service-d5qh6-5gdsw:160/proxy/: foo (200; 35.970684ms)
Apr 21 06:20:51.076: INFO: (19) /api/v1/namespaces/proxy-862/pods/https:proxy-service-d5qh6-5gdsw:462/proxy/: tls qux (200; 35.885687ms)
Apr 21 06:20:51.076: INFO: (19) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname2/proxy/: bar (200; 36.730575ms)
Apr 21 06:20:51.082: INFO: (19) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname1/proxy/: tls baz (200; 41.877248ms)
Apr 21 06:20:51.088: INFO: (19) /api/v1/namespaces/proxy-862/services/proxy-service-d5qh6:portname1/proxy/: foo (200; 48.205207ms)
Apr 21 06:20:51.088: INFO: (19) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname1/proxy/: foo (200; 49.713855ms)
Apr 21 06:20:51.088: INFO: (19) /api/v1/namespaces/proxy-862/services/https:proxy-service-d5qh6:tlsportname2/proxy/: tls qux (200; 49.106891ms)
Apr 21 06:20:51.093: INFO: (19) /api/v1/namespaces/proxy-862/services/http:proxy-service-d5qh6:portname2/proxy/: bar (200; 53.884808ms)
STEP: deleting ReplicationController proxy-service-d5qh6 in namespace proxy-862, will wait for the garbage collector to delete the pods
Apr 21 06:20:51.501: INFO: Deleting ReplicationController proxy-service-d5qh6 took: 47.067604ms
Apr 21 06:20:51.901: INFO: Terminating ReplicationController proxy-service-d5qh6 pods took: 400.385924ms
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:20:54.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-862" for this suite.
Apr 21 06:21:02.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:21:02.823: INFO: namespace proxy-862 deletion completed in 8.790028276s

• [SLOW TEST:20.603 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:21:02.824: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:21:03.802: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:21:05.861: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046863, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046863, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046863, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723046863, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:21:08.950: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:21:08.970: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2186-crds.webhook.example.com via the AdmissionRegistration API
Apr 21 06:21:19.680: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:21:21.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-748" for this suite.
Apr 21 06:21:29.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:21:29.860: INFO: namespace webhook-748 deletion completed in 8.733155679s
STEP: Destroying namespace "webhook-748-markers" for this suite.
Apr 21 06:21:37.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:21:38.580: INFO: namespace webhook-748-markers deletion completed in 8.720061601s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:35.859 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:21:38.684: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr 21 06:21:41.145: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:21:41.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7495" for this suite.
Apr 21 06:21:49.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:21:50.040: INFO: namespace container-runtime-7495 deletion completed in 8.773192155s

• [SLOW TEST:11.356 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:21:50.040: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2706/configmap-test-82d92420-57d1-4c90-b2a3-70d1e54739e7
STEP: Creating a pod to test consume configMaps
Apr 21 06:21:50.421: INFO: Waiting up to 5m0s for pod "pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5" in namespace "configmap-2706" to be "success or failure"
Apr 21 06:21:50.457: INFO: Pod "pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5": Phase="Pending", Reason="", readiness=false. Elapsed: 36.113992ms
Apr 21 06:21:52.476: INFO: Pod "pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.05537063s
STEP: Saw pod success
Apr 21 06:21:52.476: INFO: Pod "pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5" satisfied condition "success or failure"
Apr 21 06:21:52.494: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5 container env-test: <nil>
STEP: delete the pod
Apr 21 06:21:52.672: INFO: Waiting for pod pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5 to disappear
Apr 21 06:21:52.689: INFO: Pod pod-configmaps-f9bdb725-6fee-4fef-a411-059144e6e2f5 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:21:52.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2706" for this suite.
Apr 21 06:22:00.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:22:01.444: INFO: namespace configmap-2706 deletion completed in 8.723567968s

• [SLOW TEST:11.405 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:22:01.445: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Apr 21 06:22:01.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=kubectl-6728 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr 21 06:22:04.282: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr 21 06:22:04.282: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:22:06.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6728" for this suite.
Apr 21 06:22:14.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:22:15.757: INFO: namespace kubectl-6728 deletion completed in 9.412064211s

• [SLOW TEST:14.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:22:15.759: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 in namespace container-probe-5078
Apr 21 06:22:18.289: INFO: Started pod liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 in namespace container-probe-5078
STEP: checking the pod's current state and verifying that restartCount is present
Apr 21 06:22:18.305: INFO: Initial restart count of pod liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is 0
Apr 21 06:22:36.525: INFO: Restart count of pod container-probe-5078/liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is now 1 (18.22043699s elapsed)
Apr 21 06:22:56.725: INFO: Restart count of pod container-probe-5078/liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is now 2 (38.420227281s elapsed)
Apr 21 06:23:16.909: INFO: Restart count of pod container-probe-5078/liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is now 3 (58.604714163s elapsed)
Apr 21 06:23:35.220: INFO: Restart count of pod container-probe-5078/liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is now 4 (1m16.915069652s elapsed)
Apr 21 06:24:38.462: INFO: Restart count of pod container-probe-5078/liveness-5cc9ffcc-e9e7-48af-ad2b-61a1ac947960 is now 5 (2m20.157076116s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:24:38.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5078" for this suite.
Apr 21 06:24:46.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:24:47.451: INFO: namespace container-probe-5078 deletion completed in 8.777998462s

• [SLOW TEST:151.693 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:24:47.454: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-4967
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Apr 21 06:24:47.791: INFO: Waiting up to 1m0s for all nodes to be ready
Apr 21 06:25:47.881: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:25:47.900: INFO: Starting informer...
STEP: Starting pod...
Apr 21 06:25:48.159: INFO: Pod is running on 10.177.30.140. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Apr 21 06:25:48.225: INFO: Pod wasn't evicted. Proceeding
Apr 21 06:25:48.225: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Apr 21 06:27:03.283: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:27:03.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-4967" for this suite.
Apr 21 06:27:35.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:27:36.025: INFO: namespace taint-single-pod-4967 deletion completed in 32.713233351s

• [SLOW TEST:168.572 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:27:36.026: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:27:37.259: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:27:39.323: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047257, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047257, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047257, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047257, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:27:42.392: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:27:42.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5504" for this suite.
Apr 21 06:27:50.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:27:51.653: INFO: namespace webhook-5504 deletion completed in 8.850639043s
STEP: Destroying namespace "webhook-5504-markers" for this suite.
Apr 21 06:27:59.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:28:00.469: INFO: namespace webhook-5504-markers deletion completed in 8.815313279s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.640 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:28:00.666: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr 21 06:28:01.085: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5742 /api/v1/namespaces/watch-5742/configmaps/e2e-watch-test-watch-closed 28bc09e3-a353-4419-ae37-03429e2782ab 41008 0 2020-04-21 06:28:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr 21 06:28:01.085: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5742 /api/v1/namespaces/watch-5742/configmaps/e2e-watch-test-watch-closed 28bc09e3-a353-4419-ae37-03429e2782ab 41009 0 2020-04-21 06:28:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr 21 06:28:01.186: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5742 /api/v1/namespaces/watch-5742/configmaps/e2e-watch-test-watch-closed 28bc09e3-a353-4419-ae37-03429e2782ab 41010 0 2020-04-21 06:28:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr 21 06:28:01.186: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5742 /api/v1/namespaces/watch-5742/configmaps/e2e-watch-test-watch-closed 28bc09e3-a353-4419-ae37-03429e2782ab 41011 0 2020-04-21 06:28:01 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:28:01.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5742" for this suite.
Apr 21 06:28:09.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:28:10.035: INFO: namespace watch-5742 deletion completed in 8.821063244s

• [SLOW TEST:9.369 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:28:10.035: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4341
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Apr 21 06:28:14.547: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357945732 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr 21 06:28:19.911: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:28:19.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4341" for this suite.
Apr 21 06:28:28.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:28:29.535: INFO: namespace pods-4341 deletion completed in 9.585912765s

• [SLOW TEST:19.500 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:28:29.536: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3084
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr 21 06:28:29.886: INFO: Pod name pod-release: Found 0 pods out of 1
Apr 21 06:28:34.910: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:28:34.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3084" for this suite.
Apr 21 06:28:43.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:28:45.568: INFO: namespace replication-controller-3084 deletion completed in 10.244916211s

• [SLOW TEST:16.032 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:28:45.569: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6720
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:28:46.986: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:28:49.064: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047327, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047327, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047327, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047326, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:28:52.154: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:28:53.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6720" for this suite.
Apr 21 06:29:01.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:29:02.119: INFO: namespace webhook-6720 deletion completed in 8.756377611s
STEP: Destroying namespace "webhook-6720-markers" for this suite.
Apr 21 06:29:10.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:29:10.889: INFO: namespace webhook-6720-markers deletion completed in 8.769751212s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.425 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:29:10.994: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:29:12.147: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:29:15.980: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr 21 06:29:16.077: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:29:16.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3270" for this suite.
Apr 21 06:29:24.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:29:25.371: INFO: namespace webhook-3270 deletion completed in 9.182165312s
STEP: Destroying namespace "webhook-3270-markers" for this suite.
Apr 21 06:29:33.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:29:34.155: INFO: namespace webhook-3270-markers deletion completed in 8.784537547s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.280 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:29:34.274: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-238
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:29:34.589: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr 21 06:29:39.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-238 create -f -'
Apr 21 06:29:40.001: INFO: stderr: ""
Apr 21 06:29:40.001: INFO: stdout: "e2e-test-crd-publish-openapi-3619-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 21 06:29:40.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-238 delete e2e-test-crd-publish-openapi-3619-crds test-cr'
Apr 21 06:29:40.207: INFO: stderr: ""
Apr 21 06:29:40.207: INFO: stdout: "e2e-test-crd-publish-openapi-3619-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr 21 06:29:40.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-238 apply -f -'
Apr 21 06:29:40.761: INFO: stderr: ""
Apr 21 06:29:40.761: INFO: stdout: "e2e-test-crd-publish-openapi-3619-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr 21 06:29:40.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-238 delete e2e-test-crd-publish-openapi-3619-crds test-cr'
Apr 21 06:29:40.975: INFO: stderr: ""
Apr 21 06:29:40.975: INFO: stdout: "e2e-test-crd-publish-openapi-3619-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr 21 06:29:40.975: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-3619-crds'
Apr 21 06:29:41.394: INFO: stderr: ""
Apr 21 06:29:41.394: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3619-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:29:45.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-238" for this suite.
Apr 21 06:29:53.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:29:54.493: INFO: namespace crd-publish-openapi-238 deletion completed in 8.938201745s

• [SLOW TEST:20.219 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:29:54.493: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr 21 06:29:56.103: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0421 06:29:56.103311      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr 21 06:29:56.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1555" for this suite.
Apr 21 06:30:04.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:30:04.883: INFO: namespace gc-1555 deletion completed in 8.760035455s

• [SLOW TEST:10.389 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:30:04.883: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:30:05.279: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr 21 06:30:10.300: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr 21 06:30:10.300: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr 21 06:30:12.317: INFO: Creating deployment "test-rollover-deployment"
Apr 21 06:30:12.355: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr 21 06:30:14.396: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr 21 06:30:14.434: INFO: Ensure that both replica sets have 1 created replica
Apr 21 06:30:14.477: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr 21 06:30:14.530: INFO: Updating deployment test-rollover-deployment
Apr 21 06:30:14.530: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr 21 06:30:16.571: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr 21 06:30:16.606: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr 21 06:30:16.644: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:16.645: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047414, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:18.682: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:18.682: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047416, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:20.693: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:20.693: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047416, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:22.681: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:22.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047416, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:24.692: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:24.692: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047416, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:26.676: INFO: all replica sets need to contain the pod-template-hash label
Apr 21 06:30:26.676: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047416, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047412, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:30:28.720: INFO: 
Apr 21 06:30:28.720: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr 21 06:30:28.768: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-6775 /apis/apps/v1/namespaces/deployment-6775/deployments/test-rollover-deployment ca9ecffd-03d9-4cf7-9f90-aab1d389152d 41683 2 2020-04-21 06:30:12 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00420a268 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-21 06:30:12 +0000 UTC,LastTransitionTime:2020-04-21 06:30:12 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-04-21 06:30:27 +0000 UTC,LastTransitionTime:2020-04-21 06:30:12 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr 21 06:30:28.794: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-6775 /apis/apps/v1/namespaces/deployment-6775/replicasets/test-rollover-deployment-7d7dc6548c be3ae17b-b97e-42fb-a9e3-00447cabfe2f 41672 2 2020-04-21 06:30:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment ca9ecffd-03d9-4cf7-9f90-aab1d389152d 0xc00420aa07 0xc00420aa08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00420aa78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr 21 06:30:28.794: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr 21 06:30:28.794: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-6775 /apis/apps/v1/namespaces/deployment-6775/replicasets/test-rollover-controller a5c0ee2b-1c8e-48f0-99e5-60e4ceb9dd0f 41682 2 2020-04-21 06:30:05 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment ca9ecffd-03d9-4cf7-9f90-aab1d389152d 0xc00420a8e7 0xc00420a8e8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00420a998 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 06:30:28.794: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-6775 /apis/apps/v1/namespaces/deployment-6775/replicasets/test-rollover-deployment-f6c94f66c e0ca0e6d-1faa-4b32-85bb-0021534c3fbd 41641 2 2020-04-21 06:30:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment ca9ecffd-03d9-4cf7-9f90-aab1d389152d 0xc00420aae0 0xc00420aae1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00420aba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 06:30:28.813: INFO: Pod "test-rollover-deployment-7d7dc6548c-szz5l" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-szz5l test-rollover-deployment-7d7dc6548c- deployment-6775 /api/v1/namespaces/deployment-6775/pods/test-rollover-deployment-7d7dc6548c-szz5l 5aeb6ebf-20c0-45eb-8944-8d58763bf35b 41654 0 2020-04-21 06:30:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c be3ae17b-b97e-42fb-a9e3-00447cabfe2f 0xc00420b4b7 0xc00420b4b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-42z7f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-42z7f,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-42z7f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 06:30:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 06:30:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 06:30:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 06:30:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.176,StartTime:2020-04-21 06:30:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 06:30:16 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://19b5397a847a3fe4aacfc31aef31fa504c4d56bdb3b3742994b133c9c251253e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:30:28.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6775" for this suite.
Apr 21 06:30:36.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:30:37.601: INFO: namespace deployment-6775 deletion completed in 8.763819931s

• [SLOW TEST:32.718 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:30:37.602: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1558
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:30:38.027: INFO: (0) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 97.123357ms)
Apr 21 06:30:38.062: INFO: (1) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 34.995478ms)
Apr 21 06:30:38.098: INFO: (2) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 35.284205ms)
Apr 21 06:30:38.130: INFO: (3) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.693965ms)
Apr 21 06:30:38.165: INFO: (4) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 34.907323ms)
Apr 21 06:30:38.195: INFO: (5) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 30.548447ms)
Apr 21 06:30:38.223: INFO: (6) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.625867ms)
Apr 21 06:30:38.274: INFO: (7) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 50.382407ms)
Apr 21 06:30:38.306: INFO: (8) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 32.139943ms)
Apr 21 06:30:38.350: INFO: (9) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 43.768392ms)
Apr 21 06:30:38.383: INFO: (10) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.20749ms)
Apr 21 06:30:38.411: INFO: (11) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 28.200567ms)
Apr 21 06:30:38.443: INFO: (12) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.644729ms)
Apr 21 06:30:38.475: INFO: (13) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.758508ms)
Apr 21 06:30:38.504: INFO: (14) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 29.44069ms)
Apr 21 06:30:38.536: INFO: (15) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.450268ms)
Apr 21 06:30:38.564: INFO: (16) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.767332ms)
Apr 21 06:30:38.597: INFO: (17) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.213327ms)
Apr 21 06:30:38.633: INFO: (18) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 34.978521ms)
Apr 21 06:30:38.663: INFO: (19) /api/v1/nodes/10.177.30.140:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 30.416447ms)
[AfterEach] version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:30:38.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1558" for this suite.
Apr 21 06:30:46.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:30:47.520: INFO: namespace proxy-1558 deletion completed in 8.826383408s

• [SLOW TEST:9.918 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:30:47.520: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1051
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Apr 21 06:30:47.823: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 api-versions'
Apr 21 06:30:47.978: INFO: stderr: ""
Apr 21 06:30:47.978: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:30:47.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1051" for this suite.
Apr 21 06:30:56.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:30:57.093: INFO: namespace kubectl-1051 deletion completed in 9.096725733s

• [SLOW TEST:9.573 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:30:57.093: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr 21 06:31:38.051: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0421 06:31:38.051916      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:31:38.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8776" for this suite.
Apr 21 06:31:50.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:31:50.947: INFO: namespace gc-8776 deletion completed in 12.859249746s

• [SLOW TEST:53.854 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:31:50.948: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ea1452cd-6681-4aaa-a4a8-7da72af8c303
STEP: Creating a pod to test consume configMaps
Apr 21 06:31:51.346: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b" in namespace "projected-6409" to be "success or failure"
Apr 21 06:31:51.377: INFO: Pod "pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b": Phase="Pending", Reason="", readiness=false. Elapsed: 31.442603ms
Apr 21 06:31:53.402: INFO: Pod "pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056316199s
STEP: Saw pod success
Apr 21 06:31:53.402: INFO: Pod "pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b" satisfied condition "success or failure"
Apr 21 06:31:53.438: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:31:53.590: INFO: Waiting for pod pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b to disappear
Apr 21 06:31:53.607: INFO: Pod pod-projected-configmaps-549171ee-744a-41f8-b94f-bff95762fe4b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:31:53.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6409" for this suite.
Apr 21 06:32:01.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:32:02.528: INFO: namespace projected-6409 deletion completed in 8.893945483s

• [SLOW TEST:11.580 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:32:02.529: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-3945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:32:03.616: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e99a1eee-823a-4533-8771-53c9aaef1eb9" in namespace "security-context-test-3945" to be "success or failure"
Apr 21 06:32:03.651: INFO: Pod "alpine-nnp-false-e99a1eee-823a-4533-8771-53c9aaef1eb9": Phase="Pending", Reason="", readiness=false. Elapsed: 35.043292ms
Apr 21 06:32:05.671: INFO: Pod "alpine-nnp-false-e99a1eee-823a-4533-8771-53c9aaef1eb9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054945449s
Apr 21 06:32:07.689: INFO: Pod "alpine-nnp-false-e99a1eee-823a-4533-8771-53c9aaef1eb9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.072984395s
Apr 21 06:32:07.689: INFO: Pod "alpine-nnp-false-e99a1eee-823a-4533-8771-53c9aaef1eb9" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:32:07.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3945" for this suite.
Apr 21 06:32:15.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:32:16.523: INFO: namespace security-context-test-3945 deletion completed in 8.775934172s

• [SLOW TEST:13.994 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:32:16.524: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3618
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-d90115d4-347e-4421-893a-d082d18a420c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:32:16.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3618" for this suite.
Apr 21 06:32:25.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:32:25.670: INFO: namespace secrets-3618 deletion completed in 8.731355792s

• [SLOW TEST:9.146 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:32:25.671: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-2f250ed1-b1cb-43be-b8c3-9100dc0340b8
STEP: Creating a pod to test consume configMaps
Apr 21 06:32:26.039: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37" in namespace "projected-4469" to be "success or failure"
Apr 21 06:32:26.070: INFO: Pod "pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37": Phase="Pending", Reason="", readiness=false. Elapsed: 31.335484ms
Apr 21 06:32:28.101: INFO: Pod "pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.062246566s
Apr 21 06:32:30.124: INFO: Pod "pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084566163s
STEP: Saw pod success
Apr 21 06:32:30.124: INFO: Pod "pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37" satisfied condition "success or failure"
Apr 21 06:32:30.140: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:32:30.264: INFO: Waiting for pod pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37 to disappear
Apr 21 06:32:30.280: INFO: Pod pod-projected-configmaps-403a9e34-900e-4663-9ee2-e1831ef44c37 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:32:30.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4469" for this suite.
Apr 21 06:32:38.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:32:39.178: INFO: namespace projected-4469 deletion completed in 8.870863774s

• [SLOW TEST:13.507 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:32:39.178: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6693
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:32:39.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6693" for this suite.
Apr 21 06:32:47.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:32:48.583: INFO: namespace kubelet-test-6693 deletion completed in 8.830880681s

• [SLOW TEST:9.405 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:32:48.586: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:32:49.855: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:32:51.914: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047569, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047569, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047569, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047569, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:32:55.015: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:33:07.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1979" for this suite.
Apr 21 06:33:16.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:33:16.748: INFO: namespace webhook-1979 deletion completed in 8.760051978s
STEP: Destroying namespace "webhook-1979-markers" for this suite.
Apr 21 06:33:24.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:33:25.491: INFO: namespace webhook-1979-markers deletion completed in 8.742949744s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:37.001 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:33:25.587: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8917
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Apr 21 06:33:25.924: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:33:57.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8917" for this suite.
Apr 21 06:34:05.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:34:06.477: INFO: namespace crd-publish-openapi-8917 deletion completed in 8.782994572s

• [SLOW TEST:40.891 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:34:06.479: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6798
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f
Apr 21 06:34:06.874: INFO: Pod name my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f: Found 0 pods out of 1
Apr 21 06:34:12.334: INFO: Pod name my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f: Found 1 pods out of 1
Apr 21 06:34:12.334: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f" are running
Apr 21 06:34:12.358: INFO: Pod "my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f-ptnpz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 06:34:06 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 06:34:08 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 06:34:08 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-21 06:34:06 +0000 UTC Reason: Message:}])
Apr 21 06:34:12.358: INFO: Trying to dial the pod
Apr 21 06:34:17.439: INFO: Controller my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f: Got expected result from replica 1 [my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f-ptnpz]: "my-hostname-basic-20a98ed6-a33a-4a96-8d3a-30fac38a9f0f-ptnpz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:34:17.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6798" for this suite.
Apr 21 06:34:25.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:34:26.345: INFO: namespace replication-controller-6798 deletion completed in 8.880349978s

• [SLOW TEST:19.866 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:34:26.345: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1314
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:34:26.648: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr 21 06:34:31.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 create -f -'
Apr 21 06:34:31.956: INFO: stderr: ""
Apr 21 06:34:31.956: INFO: stdout: "e2e-test-crd-publish-openapi-7096-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 21 06:34:31.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 delete e2e-test-crd-publish-openapi-7096-crds test-foo'
Apr 21 06:34:32.219: INFO: stderr: ""
Apr 21 06:34:32.220: INFO: stdout: "e2e-test-crd-publish-openapi-7096-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr 21 06:34:32.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 apply -f -'
Apr 21 06:34:32.686: INFO: stderr: ""
Apr 21 06:34:32.686: INFO: stdout: "e2e-test-crd-publish-openapi-7096-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr 21 06:34:32.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 delete e2e-test-crd-publish-openapi-7096-crds test-foo'
Apr 21 06:34:33.716: INFO: stderr: ""
Apr 21 06:34:33.716: INFO: stdout: "e2e-test-crd-publish-openapi-7096-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr 21 06:34:33.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 create -f -'
Apr 21 06:34:34.120: INFO: rc: 1
Apr 21 06:34:34.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 apply -f -'
Apr 21 06:34:34.369: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr 21 06:34:34.370: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 create -f -'
Apr 21 06:34:34.793: INFO: rc: 1
Apr 21 06:34:34.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 --namespace=crd-publish-openapi-1314 apply -f -'
Apr 21 06:34:35.015: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr 21 06:34:35.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-7096-crds'
Apr 21 06:34:35.407: INFO: stderr: ""
Apr 21 06:34:35.407: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7096-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr 21 06:34:35.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-7096-crds.metadata'
Apr 21 06:34:35.789: INFO: stderr: ""
Apr 21 06:34:35.789: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7096-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr 21 06:34:35.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-7096-crds.spec'
Apr 21 06:34:36.216: INFO: stderr: ""
Apr 21 06:34:36.216: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7096-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr 21 06:34:36.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-7096-crds.spec.bars'
Apr 21 06:34:36.601: INFO: stderr: ""
Apr 21 06:34:36.601: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7096-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr 21 06:34:36.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 explain e2e-test-crd-publish-openapi-7096-crds.spec.bars2'
Apr 21 06:34:37.037: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:34:41.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1314" for this suite.
Apr 21 06:34:49.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:34:50.417: INFO: namespace crd-publish-openapi-1314 deletion completed in 8.769435138s

• [SLOW TEST:24.072 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:34:50.418: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr 21 06:34:50.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1534'
Apr 21 06:34:50.925: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr 21 06:34:50.925: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Apr 21 06:34:53.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1534'
Apr 21 06:34:53.428: INFO: stderr: ""
Apr 21 06:34:53.428: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:34:53.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1534" for this suite.
Apr 21 06:35:07.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:35:08.322: INFO: namespace kubectl-1534 deletion completed in 14.863228217s

• [SLOW TEST:17.904 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:35:08.323: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6130
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:35:08.765: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr 21 06:35:08.823: INFO: Number of nodes with available pods: 0
Apr 21 06:35:08.823: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:35:09.926: INFO: Number of nodes with available pods: 0
Apr 21 06:35:09.926: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:35:10.876: INFO: Number of nodes with available pods: 1
Apr 21 06:35:10.877: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:35:11.871: INFO: Number of nodes with available pods: 3
Apr 21 06:35:11.871: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr 21 06:35:12.009: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:12.010: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:12.010: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:13.058: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:13.058: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:13.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:14.062: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:14.063: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:14.063: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:15.061: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:15.061: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:15.061: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:15.061: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:16.056: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:16.056: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:16.056: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:16.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:17.060: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:17.060: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:17.060: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:17.060: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:18.062: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:18.062: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:18.062: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:18.062: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:19.056: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:19.056: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:19.056: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:19.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:20.056: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:20.056: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:20.056: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:20.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:21.055: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:21.055: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:21.055: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:21.055: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:22.055: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:22.055: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:22.055: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:22.055: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:23.058: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:23.058: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:23.058: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:23.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:24.057: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:24.057: INFO: Wrong image for pod: daemon-set-sd4kv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:24.057: INFO: Pod daemon-set-sd4kv is not available
Apr 21 06:35:24.057: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:25.060: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:25.060: INFO: Pod daemon-set-kgs5r is not available
Apr 21 06:35:25.060: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:26.058: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:26.058: INFO: Pod daemon-set-kgs5r is not available
Apr 21 06:35:26.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:27.055: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:27.055: INFO: Pod daemon-set-kgs5r is not available
Apr 21 06:35:27.055: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:28.057: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:28.057: INFO: Pod daemon-set-kgs5r is not available
Apr 21 06:35:28.057: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:29.056: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:29.056: INFO: Pod daemon-set-kgs5r is not available
Apr 21 06:35:29.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:30.055: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:30.055: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:31.059: INFO: Wrong image for pod: daemon-set-fcbbj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:31.059: INFO: Pod daemon-set-fcbbj is not available
Apr 21 06:35:31.059: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:32.056: INFO: Pod daemon-set-9pvnm is not available
Apr 21 06:35:32.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:33.058: INFO: Pod daemon-set-9pvnm is not available
Apr 21 06:35:33.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:34.062: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:35.055: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:35.055: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:36.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:36.058: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:37.058: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:37.058: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:38.057: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:38.057: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:39.056: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:39.056: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:40.064: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:40.064: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:41.057: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:41.057: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:42.059: INFO: Wrong image for pod: daemon-set-zxp89. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr 21 06:35:42.059: INFO: Pod daemon-set-zxp89 is not available
Apr 21 06:35:43.059: INFO: Pod daemon-set-zxz9f is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Apr 21 06:35:43.129: INFO: Number of nodes with available pods: 2
Apr 21 06:35:43.129: INFO: Node 10.177.30.144 is running more than one daemon pod
Apr 21 06:35:44.191: INFO: Number of nodes with available pods: 2
Apr 21 06:35:44.191: INFO: Node 10.177.30.144 is running more than one daemon pod
Apr 21 06:35:45.178: INFO: Number of nodes with available pods: 3
Apr 21 06:35:45.178: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6130, will wait for the garbage collector to delete the pods
Apr 21 06:35:45.433: INFO: Deleting DaemonSet.extensions daemon-set took: 61.442041ms
Apr 21 06:35:45.634: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.320963ms
Apr 21 06:35:54.659: INFO: Number of nodes with available pods: 0
Apr 21 06:35:54.659: INFO: Number of running nodes: 0, number of available pods: 0
Apr 21 06:35:54.681: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6130/daemonsets","resourceVersion":"43014"},"items":null}

Apr 21 06:35:54.697: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6130/pods","resourceVersion":"43014"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:35:54.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6130" for this suite.
Apr 21 06:36:04.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:36:05.490: INFO: namespace daemonsets-6130 deletion completed in 10.680014337s

• [SLOW TEST:57.168 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:36:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:36:05.824: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d" in namespace "projected-6777" to be "success or failure"
Apr 21 06:36:05.849: INFO: Pod "downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d": Phase="Pending", Reason="", readiness=false. Elapsed: 24.463685ms
Apr 21 06:36:07.876: INFO: Pod "downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051842651s
STEP: Saw pod success
Apr 21 06:36:07.876: INFO: Pod "downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d" satisfied condition "success or failure"
Apr 21 06:36:07.909: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d container client-container: <nil>
STEP: delete the pod
Apr 21 06:36:08.067: INFO: Waiting for pod downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d to disappear
Apr 21 06:36:08.091: INFO: Pod downwardapi-volume-9dc70a27-2f07-4e1b-ab5f-c726b718ac7d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:36:08.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6777" for this suite.
Apr 21 06:36:16.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:36:16.904: INFO: namespace projected-6777 deletion completed in 8.782760089s

• [SLOW TEST:11.414 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:36:16.905: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-4bbf20a7-6b9f-47ca-82c4-ad5a04532c88
STEP: Creating a pod to test consume configMaps
Apr 21 06:36:17.342: INFO: Waiting up to 5m0s for pod "pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8" in namespace "configmap-886" to be "success or failure"
Apr 21 06:36:17.363: INFO: Pod "pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8": Phase="Pending", Reason="", readiness=false. Elapsed: 20.448917ms
Apr 21 06:36:19.388: INFO: Pod "pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045925839s
Apr 21 06:36:21.406: INFO: Pod "pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063812781s
STEP: Saw pod success
Apr 21 06:36:21.406: INFO: Pod "pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8" satisfied condition "success or failure"
Apr 21 06:36:21.425: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:36:21.540: INFO: Waiting for pod pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8 to disappear
Apr 21 06:36:21.558: INFO: Pod pod-configmaps-533ba8b6-b817-4620-a0b2-3f5bf0fad3c8 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:36:21.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-886" for this suite.
Apr 21 06:36:29.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:36:30.364: INFO: namespace configmap-886 deletion completed in 8.772863125s

• [SLOW TEST:13.459 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:36:30.371: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-9593
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:36:31.703: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:36:34.854: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:36:34.875: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:36:36.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9593" for this suite.
Apr 21 06:36:44.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:36:45.638: INFO: namespace crd-webhook-9593 deletion completed in 8.800646536s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:15.366 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:36:45.737: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:36:46.767: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:36:48.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047806, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047806, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047806, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047806, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:36:51.880: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Apr 21 06:37:02.005: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:37:02.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3258" for this suite.
Apr 21 06:37:16.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:37:17.114: INFO: namespace webhook-3258 deletion completed in 14.728557318s
STEP: Destroying namespace "webhook-3258-markers" for this suite.
Apr 21 06:37:25.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:37:25.925: INFO: namespace webhook-3258-markers deletion completed in 8.811088677s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:40.297 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:37:26.035: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:37:44.470: INFO: Container started at 2020-04-21 06:37:27 +0000 UTC, pod became ready at 2020-04-21 06:37:44 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:37:44.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7049" for this suite.
Apr 21 06:37:58.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:37:59.686: INFO: namespace container-probe-7049 deletion completed in 15.172830273s

• [SLOW TEST:33.651 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:37:59.686: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 21 06:38:00.675: INFO: Number of nodes with available pods: 0
Apr 21 06:38:00.675: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:38:01.733: INFO: Number of nodes with available pods: 0
Apr 21 06:38:01.733: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:38:02.722: INFO: Number of nodes with available pods: 0
Apr 21 06:38:02.722: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:38:03.716: INFO: Number of nodes with available pods: 3
Apr 21 06:38:03.717: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr 21 06:38:03.828: INFO: Number of nodes with available pods: 2
Apr 21 06:38:03.829: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:38:04.874: INFO: Number of nodes with available pods: 2
Apr 21 06:38:04.874: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:38:05.877: INFO: Number of nodes with available pods: 3
Apr 21 06:38:05.877: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3980, will wait for the garbage collector to delete the pods
Apr 21 06:38:06.043: INFO: Deleting DaemonSet.extensions daemon-set took: 62.335097ms
Apr 21 06:38:06.244: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.298965ms
Apr 21 06:38:14.680: INFO: Number of nodes with available pods: 0
Apr 21 06:38:14.680: INFO: Number of running nodes: 0, number of available pods: 0
Apr 21 06:38:14.697: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3980/daemonsets","resourceVersion":"43660"},"items":null}

Apr 21 06:38:14.719: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3980/pods","resourceVersion":"43660"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:38:14.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3980" for this suite.
Apr 21 06:38:22.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:38:23.552: INFO: namespace daemonsets-3980 deletion completed in 8.729611781s

• [SLOW TEST:23.865 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:38:23.552: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Apr 21 06:38:23.905: INFO: Waiting up to 5m0s for pod "var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052" in namespace "var-expansion-1429" to be "success or failure"
Apr 21 06:38:23.927: INFO: Pod "var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052": Phase="Pending", Reason="", readiness=false. Elapsed: 21.707173ms
Apr 21 06:38:25.954: INFO: Pod "var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.048341165s
STEP: Saw pod success
Apr 21 06:38:25.954: INFO: Pod "var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052" satisfied condition "success or failure"
Apr 21 06:38:25.984: INFO: Trying to get logs from node 10.177.30.140 pod var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052 container dapi-container: <nil>
STEP: delete the pod
Apr 21 06:38:26.145: INFO: Waiting for pod var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052 to disappear
Apr 21 06:38:26.167: INFO: Pod var-expansion-26a55c26-7f4e-48be-bab4-ecbdca412052 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:38:26.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1429" for this suite.
Apr 21 06:38:34.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:38:35.235: INFO: namespace var-expansion-1429 deletion completed in 9.04204363s

• [SLOW TEST:11.683 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:38:35.235: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:38:39.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8431" for this suite.
Apr 21 06:38:53.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:38:54.408: INFO: namespace containers-8431 deletion completed in 14.715408442s

• [SLOW TEST:19.173 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:38:54.409: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3904
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Apr 21 06:38:54.820: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3904" to be "success or failure"
Apr 21 06:38:54.837: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 17.098757ms
Apr 21 06:38:56.853: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033264536s
Apr 21 06:38:58.869: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.04888255s
STEP: Saw pod success
Apr 21 06:38:58.869: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr 21 06:38:58.890: INFO: Trying to get logs from node 10.177.30.140 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr 21 06:38:59.007: INFO: Waiting for pod pod-host-path-test to disappear
Apr 21 06:38:59.025: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:38:59.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3904" for this suite.
Apr 21 06:39:07.143: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:39:07.822: INFO: namespace hostpath-3904 deletion completed in 8.762141651s

• [SLOW TEST:13.413 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:39:07.823: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Apr 21 06:39:08.139: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Apr 21 06:39:08.991: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr 21 06:39:11.222: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047948, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:39:13.243: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047948, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:39:15.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047948, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:39:17.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047949, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723047948, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr 21 06:39:20.836: INFO: Waited 1.562355258s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:39:21.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9672" for this suite.
Apr 21 06:39:29.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:39:30.543: INFO: namespace aggregator-9672 deletion completed in 8.674241089s

• [SLOW TEST:22.720 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:39:30.547: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9339
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:39:37.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9339" for this suite.
Apr 21 06:39:46.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:39:46.746: INFO: namespace resourcequota-9339 deletion completed in 8.780155426s

• [SLOW TEST:16.198 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:39:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1144
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:39:47.297: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"5bae5e6f-ef3f-4a42-af76-fe3a85811847", Controller:(*bool)(0xc003b20a1a), BlockOwnerDeletion:(*bool)(0xc003b20a1b)}}
Apr 21 06:39:47.337: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"bcbea358-872d-405a-8ecc-84f742db1dee", Controller:(*bool)(0xc003b20bf6), BlockOwnerDeletion:(*bool)(0xc003b20bf7)}}
Apr 21 06:39:47.382: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"f0bd36b8-b418-4831-88b4-c841d9626d0f", Controller:(*bool)(0xc003b9a726), BlockOwnerDeletion:(*bool)(0xc003b9a727)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:39:52.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1144" for this suite.
Apr 21 06:40:00.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:40:01.349: INFO: namespace gc-1144 deletion completed in 8.882679504s

• [SLOW TEST:14.603 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:40:01.350: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1212
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-f2464198-7234-4d17-91b1-8fd19d303751
STEP: Creating configMap with name cm-test-opt-upd-76e62e64-9be9-49f2-b755-a42b08834f8c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-f2464198-7234-4d17-91b1-8fd19d303751
STEP: Updating configmap cm-test-opt-upd-76e62e64-9be9-49f2-b755-a42b08834f8c
STEP: Creating configMap with name cm-test-opt-create-2e001acb-c96f-4567-b9d5-0ed35b48b5a0
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:41:26.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1212" for this suite.
Apr 21 06:41:56.943: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:41:57.646: INFO: namespace projected-1212 deletion completed in 30.796883906s

• [SLOW TEST:116.295 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:41:57.646: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:41:57.991: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a" in namespace "projected-2534" to be "success or failure"
Apr 21 06:41:58.010: INFO: Pod "downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.629528ms
Apr 21 06:42:00.026: INFO: Pod "downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034686301s
Apr 21 06:42:02.045: INFO: Pod "downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053268289s
STEP: Saw pod success
Apr 21 06:42:02.045: INFO: Pod "downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a" satisfied condition "success or failure"
Apr 21 06:42:02.061: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a container client-container: <nil>
STEP: delete the pod
Apr 21 06:42:02.163: INFO: Waiting for pod downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a to disappear
Apr 21 06:42:02.183: INFO: Pod downwardapi-volume-e6479a39-cd72-4de8-a4b8-c9731717814a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:42:02.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2534" for this suite.
Apr 21 06:42:10.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:42:10.934: INFO: namespace projected-2534 deletion completed in 8.727590862s

• [SLOW TEST:13.288 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:42:10.935: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Apr 21 06:42:11.301: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-357945732 proxy --unix-socket=/tmp/kubectl-proxy-unix973132627/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:42:11.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4141" for this suite.
Apr 21 06:42:19.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:42:20.255: INFO: namespace kubectl-4141 deletion completed in 8.844429145s

• [SLOW TEST:9.320 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:42:20.256: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7832
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:42:21.583: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:42:23.853: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048141, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048141, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048141, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048141, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:42:26.940: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:42:27.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7832" for this suite.
Apr 21 06:42:35.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:42:36.048: INFO: namespace webhook-7832 deletion completed in 8.733611224s
STEP: Destroying namespace "webhook-7832-markers" for this suite.
Apr 21 06:42:44.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:42:44.856: INFO: namespace webhook-7832-markers deletion completed in 8.808266217s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.699 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:42:44.955: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7903
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-6af3cf67-1636-4bfc-8ee8-84586430f9de
STEP: Creating secret with name secret-projected-all-test-volume-98c9e76e-db9a-4c8b-bd6d-2c075b319d3c
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr 21 06:42:45.344: INFO: Waiting up to 5m0s for pod "projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4" in namespace "projected-7903" to be "success or failure"
Apr 21 06:42:45.365: INFO: Pod "projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4": Phase="Pending", Reason="", readiness=false. Elapsed: 21.247928ms
Apr 21 06:42:47.387: INFO: Pod "projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042661181s
STEP: Saw pod success
Apr 21 06:42:47.387: INFO: Pod "projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4" satisfied condition "success or failure"
Apr 21 06:42:47.404: INFO: Trying to get logs from node 10.177.30.140 pod projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr 21 06:42:47.498: INFO: Waiting for pod projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4 to disappear
Apr 21 06:42:47.520: INFO: Pod projected-volume-1a2dadda-86ae-4cd3-9540-187e2eb8c2a4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:42:47.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7903" for this suite.
Apr 21 06:42:55.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:42:56.628: INFO: namespace projected-7903 deletion completed in 9.074226484s

• [SLOW TEST:11.673 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:42:56.630: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4054
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-kk9h
STEP: Creating a pod to test atomic-volume-subpath
Apr 21 06:42:57.031: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-kk9h" in namespace "subpath-4054" to be "success or failure"
Apr 21 06:42:57.050: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Pending", Reason="", readiness=false. Elapsed: 18.679037ms
Apr 21 06:42:59.068: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036679785s
Apr 21 06:43:01.092: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 4.060440648s
Apr 21 06:43:03.119: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 6.087689603s
Apr 21 06:43:05.137: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 8.105346903s
Apr 21 06:43:07.154: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 10.122723852s
Apr 21 06:43:09.171: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 12.139616207s
Apr 21 06:43:11.189: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 14.157423438s
Apr 21 06:43:13.213: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 16.181884493s
Apr 21 06:43:15.229: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 18.197729589s
Apr 21 06:43:17.248: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 20.216348859s
Apr 21 06:43:19.265: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Running", Reason="", readiness=true. Elapsed: 22.233093519s
Apr 21 06:43:21.283: INFO: Pod "pod-subpath-test-secret-kk9h": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.251218162s
STEP: Saw pod success
Apr 21 06:43:21.283: INFO: Pod "pod-subpath-test-secret-kk9h" satisfied condition "success or failure"
Apr 21 06:43:21.308: INFO: Trying to get logs from node 10.177.30.140 pod pod-subpath-test-secret-kk9h container test-container-subpath-secret-kk9h: <nil>
STEP: delete the pod
Apr 21 06:43:21.445: INFO: Waiting for pod pod-subpath-test-secret-kk9h to disappear
Apr 21 06:43:21.463: INFO: Pod pod-subpath-test-secret-kk9h no longer exists
STEP: Deleting pod pod-subpath-test-secret-kk9h
Apr 21 06:43:21.464: INFO: Deleting pod "pod-subpath-test-secret-kk9h" in namespace "subpath-4054"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:43:21.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4054" for this suite.
Apr 21 06:43:29.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:43:30.223: INFO: namespace subpath-4054 deletion completed in 8.706256313s

• [SLOW TEST:33.593 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:43:30.224: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-7421
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:43:30.525: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:43:31.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-7421" for this suite.
Apr 21 06:43:39.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:43:41.223: INFO: namespace custom-resource-definition-7421 deletion completed in 9.556388419s

• [SLOW TEST:10.999 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:43:41.223: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-5387
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-5387
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5387
STEP: Deleting pre-stop pod
Apr 21 06:43:51.424: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:43:51.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5387" for this suite.
Apr 21 06:44:23.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:44:24.431: INFO: namespace prestop-5387 deletion completed in 32.900599187s

• [SLOW TEST:43.208 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:44:24.431: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:44:24.836: INFO: Waiting up to 5m0s for pod "downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96" in namespace "downward-api-1769" to be "success or failure"
Apr 21 06:44:24.861: INFO: Pod "downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96": Phase="Pending", Reason="", readiness=false. Elapsed: 24.826251ms
Apr 21 06:44:26.877: INFO: Pod "downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96": Phase="Running", Reason="", readiness=true. Elapsed: 2.040557488s
Apr 21 06:44:28.896: INFO: Pod "downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060232866s
STEP: Saw pod success
Apr 21 06:44:28.896: INFO: Pod "downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96" satisfied condition "success or failure"
Apr 21 06:44:28.918: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96 container client-container: <nil>
STEP: delete the pod
Apr 21 06:44:29.015: INFO: Waiting for pod downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96 to disappear
Apr 21 06:44:29.032: INFO: Pod downwardapi-volume-05996e88-c285-4161-a473-9b89d80abd96 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:44:29.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1769" for this suite.
Apr 21 06:44:37.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:44:37.800: INFO: namespace downward-api-1769 deletion completed in 8.731149841s

• [SLOW TEST:13.369 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:44:37.800: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:44:38.952: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:44:41.004: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048278, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048278, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048279, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048278, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:44:44.077: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:44:44.094: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6097-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:44:45.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3695" for this suite.
Apr 21 06:44:53.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:44:54.006: INFO: namespace webhook-3695 deletion completed in 8.763778441s
STEP: Destroying namespace "webhook-3695-markers" for this suite.
Apr 21 06:45:02.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:45:02.767: INFO: namespace webhook-3695-markers deletion completed in 8.761681318s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.058 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:45:02.858: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4761
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr 21 06:45:03.197: INFO: Waiting up to 5m0s for pod "pod-c856c60b-da46-4b05-b3a2-44b38040a85a" in namespace "emptydir-4761" to be "success or failure"
Apr 21 06:45:03.217: INFO: Pod "pod-c856c60b-da46-4b05-b3a2-44b38040a85a": Phase="Pending", Reason="", readiness=false. Elapsed: 19.372993ms
Apr 21 06:45:05.232: INFO: Pod "pod-c856c60b-da46-4b05-b3a2-44b38040a85a": Phase="Running", Reason="", readiness=true. Elapsed: 2.035105848s
Apr 21 06:45:07.249: INFO: Pod "pod-c856c60b-da46-4b05-b3a2-44b38040a85a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051911661s
STEP: Saw pod success
Apr 21 06:45:07.249: INFO: Pod "pod-c856c60b-da46-4b05-b3a2-44b38040a85a" satisfied condition "success or failure"
Apr 21 06:45:07.267: INFO: Trying to get logs from node 10.177.30.140 pod pod-c856c60b-da46-4b05-b3a2-44b38040a85a container test-container: <nil>
STEP: delete the pod
Apr 21 06:45:07.356: INFO: Waiting for pod pod-c856c60b-da46-4b05-b3a2-44b38040a85a to disappear
Apr 21 06:45:07.374: INFO: Pod pod-c856c60b-da46-4b05-b3a2-44b38040a85a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:45:07.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4761" for this suite.
Apr 21 06:45:15.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:45:16.182: INFO: namespace emptydir-4761 deletion completed in 8.786074523s

• [SLOW TEST:13.324 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:45:16.183: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3271
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr 21 06:45:16.547: INFO: Waiting up to 5m0s for pod "downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9" in namespace "downward-api-3271" to be "success or failure"
Apr 21 06:45:16.568: INFO: Pod "downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.281626ms
Apr 21 06:45:18.585: INFO: Pod "downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037919265s
Apr 21 06:45:20.855: INFO: Pod "downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.307291179s
STEP: Saw pod success
Apr 21 06:45:20.855: INFO: Pod "downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9" satisfied condition "success or failure"
Apr 21 06:45:20.875: INFO: Trying to get logs from node 10.177.30.140 pod downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9 container dapi-container: <nil>
STEP: delete the pod
Apr 21 06:45:20.974: INFO: Waiting for pod downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9 to disappear
Apr 21 06:45:20.996: INFO: Pod downward-api-4b9dddd3-165b-47c3-ba07-fd193ace0ba9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:45:20.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3271" for this suite.
Apr 21 06:45:29.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:45:29.794: INFO: namespace downward-api-3271 deletion completed in 8.767545429s

• [SLOW TEST:13.610 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:45:29.794: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8495
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-de2f7539-2b7e-4438-a2df-38823aa224ea
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:45:30.141: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8495" for this suite.
Apr 21 06:45:38.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:45:39.086: INFO: namespace configmap-8495 deletion completed in 8.91637647s

• [SLOW TEST:9.292 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:45:39.087: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr 21 06:45:39.612: INFO: Number of nodes with available pods: 0
Apr 21 06:45:39.612: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:40.661: INFO: Number of nodes with available pods: 0
Apr 21 06:45:40.661: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:41.656: INFO: Number of nodes with available pods: 0
Apr 21 06:45:41.656: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:42.653: INFO: Number of nodes with available pods: 3
Apr 21 06:45:42.653: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr 21 06:45:42.790: INFO: Number of nodes with available pods: 2
Apr 21 06:45:42.790: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:43.835: INFO: Number of nodes with available pods: 2
Apr 21 06:45:43.835: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:44.835: INFO: Number of nodes with available pods: 2
Apr 21 06:45:44.835: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:45.852: INFO: Number of nodes with available pods: 2
Apr 21 06:45:45.852: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:46.833: INFO: Number of nodes with available pods: 2
Apr 21 06:45:46.833: INFO: Node 10.177.30.140 is running more than one daemon pod
Apr 21 06:45:47.829: INFO: Number of nodes with available pods: 3
Apr 21 06:45:47.829: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8446, will wait for the garbage collector to delete the pods
Apr 21 06:45:47.951: INFO: Deleting DaemonSet.extensions daemon-set took: 39.33445ms
Apr 21 06:45:48.151: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.386222ms
Apr 21 06:45:54.769: INFO: Number of nodes with available pods: 0
Apr 21 06:45:54.769: INFO: Number of running nodes: 0, number of available pods: 0
Apr 21 06:45:54.796: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8446/daemonsets","resourceVersion":"45257"},"items":null}

Apr 21 06:45:54.814: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8446/pods","resourceVersion":"45257"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:45:54.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8446" for this suite.
Apr 21 06:46:03.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:46:03.835: INFO: namespace daemonsets-8446 deletion completed in 8.884781767s

• [SLOW TEST:24.748 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:46:03.837: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:46:09.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3538" for this suite.
Apr 21 06:46:58.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:46:58.929: INFO: namespace kubelet-test-3538 deletion completed in 48.783238213s

• [SLOW TEST:55.092 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:46:58.929: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-026fe343-2062-4a2f-8e8d-2233067917c8
STEP: Creating a pod to test consume configMaps
Apr 21 06:46:59.343: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9" in namespace "configmap-4690" to be "success or failure"
Apr 21 06:46:59.360: INFO: Pod "pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.833912ms
Apr 21 06:47:01.378: INFO: Pod "pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034003627s
Apr 21 06:47:03.410: INFO: Pod "pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066044543s
STEP: Saw pod success
Apr 21 06:47:03.410: INFO: Pod "pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9" satisfied condition "success or failure"
Apr 21 06:47:03.439: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:47:03.654: INFO: Waiting for pod pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9 to disappear
Apr 21 06:47:03.675: INFO: Pod pod-configmaps-a3545539-0f19-467d-ac56-aa26d5f094f9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:47:03.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4690" for this suite.
Apr 21 06:47:11.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:47:12.491: INFO: namespace configmap-4690 deletion completed in 8.781161198s

• [SLOW TEST:13.561 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:47:12.491: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7277
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-cd7d60b2-f04e-4ba0-9ddf-24675ecde47f
STEP: Creating a pod to test consume configMaps
Apr 21 06:47:12.894: INFO: Waiting up to 5m0s for pod "pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127" in namespace "configmap-7277" to be "success or failure"
Apr 21 06:47:12.920: INFO: Pod "pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127": Phase="Pending", Reason="", readiness=false. Elapsed: 26.797165ms
Apr 21 06:47:14.939: INFO: Pod "pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045172779s
Apr 21 06:47:17.097: INFO: Pod "pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.203891411s
STEP: Saw pod success
Apr 21 06:47:17.098: INFO: Pod "pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127" satisfied condition "success or failure"
Apr 21 06:47:17.124: INFO: Trying to get logs from node 10.177.30.140 pod pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127 container configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:47:17.253: INFO: Waiting for pod pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127 to disappear
Apr 21 06:47:17.270: INFO: Pod pod-configmaps-16c3cb4e-0799-43eb-b384-d89b4416c127 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:47:17.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7277" for this suite.
Apr 21 06:47:25.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:47:26.112: INFO: namespace configmap-7277 deletion completed in 8.809031402s

• [SLOW TEST:13.621 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:47:26.113: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr 21 06:47:26.419: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:47:30.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2378" for this suite.
Apr 21 06:47:45.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:47:45.844: INFO: namespace init-container-2378 deletion completed in 14.837093239s

• [SLOW TEST:19.731 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:47:45.844: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-4076
STEP: creating replication controller nodeport-test in namespace services-4076
I0421 06:47:46.669306      26 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-4076, replica count: 2
I0421 06:47:49.721226      26 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 06:47:52.721: INFO: Creating new exec pod
I0421 06:47:52.721493      26 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 06:47:57.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr 21 06:47:58.534: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr 21 06:47:58.534: INFO: stdout: ""
Apr 21 06:47:58.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 172.21.132.94 80'
Apr 21 06:47:58.909: INFO: stderr: "+ nc -zv -t -w 2 172.21.132.94 80\nConnection to 172.21.132.94 80 port [tcp/http] succeeded!\n"
Apr 21 06:47:58.909: INFO: stdout: ""
Apr 21 06:47:58.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 10.177.30.140 30183'
Apr 21 06:47:59.300: INFO: stderr: "+ nc -zv -t -w 2 10.177.30.140 30183\nConnection to 10.177.30.140 30183 port [tcp/30183] succeeded!\n"
Apr 21 06:47:59.300: INFO: stdout: ""
Apr 21 06:47:59.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 10.177.30.144 30183'
Apr 21 06:47:59.669: INFO: stderr: "+ nc -zv -t -w 2 10.177.30.144 30183\nConnection to 10.177.30.144 30183 port [tcp/30183] succeeded!\n"
Apr 21 06:47:59.669: INFO: stdout: ""
Apr 21 06:47:59.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 150.238.39.40 30183'
Apr 21 06:48:00.056: INFO: stderr: "+ nc -zv -t -w 2 150.238.39.40 30183\nConnection to 150.238.39.40 30183 port [tcp/30183] succeeded!\n"
Apr 21 06:48:00.056: INFO: stdout: ""
Apr 21 06:48:00.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-4076 execpod4f7pw -- /bin/sh -x -c nc -zv -t -w 2 150.238.36.91 30183'
Apr 21 06:48:00.509: INFO: stderr: "+ nc -zv -t -w 2 150.238.36.91 30183\nConnection to 150.238.36.91 30183 port [tcp/30183] succeeded!\n"
Apr 21 06:48:00.509: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:48:00.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4076" for this suite.
Apr 21 06:48:08.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:48:09.744: INFO: namespace services-4076 deletion completed in 9.202899035s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:23.900 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:48:09.745: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:48:21.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5726" for this suite.
Apr 21 06:48:29.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:48:30.254: INFO: namespace resourcequota-5726 deletion completed in 8.750456627s

• [SLOW TEST:20.509 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:48:30.256: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4833.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4833.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4833.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr 21 06:48:34.801: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:34.832: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:34.914: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:34.969: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:36.106: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:36.160: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:48:41.258: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:41.284: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:41.435: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:41.462: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:41.522: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:48:46.244: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:46.270: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:46.432: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:46.457: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:46.517: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:48:51.249: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:51.274: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:51.438: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:51.477: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:51.532: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:48:56.564: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:56.594: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:56.755: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:56.780: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:48:56.830: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:49:01.268: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:49:01.306: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:49:01.478: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:49:01.528: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local from pod dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7: the server could not find the requested resource (get pods dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7)
Apr 21 06:49:01.586: INFO: Lookups using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 failed for: [wheezy_udp@dns-test-service-2.dns-4833.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4833.svc.cluster.local jessie_udp@dns-test-service-2.dns-4833.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4833.svc.cluster.local]

Apr 21 06:49:06.544: INFO: DNS probes using dns-4833/dns-test-ed0b6352-ee36-4841-b5ac-27a173a2b8a7 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:49:06.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4833" for this suite.
Apr 21 06:49:14.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:49:15.517: INFO: namespace dns-4833 deletion completed in 8.739511134s

• [SLOW TEST:45.262 seconds]
[sig-network] DNS
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:49:15.518: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2722
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-2722
I0421 06:49:16.045238      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2722, replica count: 2
Apr 21 06:49:19.095: INFO: Creating new exec pod
I0421 06:49:19.095872      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr 21 06:49:22.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-2722 execpod86nt8 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr 21 06:49:22.761: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr 21 06:49:22.761: INFO: stdout: ""
Apr 21 06:49:22.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 exec --namespace=services-2722 execpod86nt8 -- /bin/sh -x -c nc -zv -t -w 2 172.21.85.60 80'
Apr 21 06:49:23.211: INFO: stderr: "+ nc -zv -t -w 2 172.21.85.60 80\nConnection to 172.21.85.60 80 port [tcp/http] succeeded!\n"
Apr 21 06:49:23.211: INFO: stdout: ""
Apr 21 06:49:23.211: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:49:23.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2722" for this suite.
Apr 21 06:49:31.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:49:32.685: INFO: namespace services-2722 deletion completed in 9.329891413s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.168 seconds]
[sig-network] Services
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:49:32.692: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:49:34.186: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:49:36.239: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048574, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048574, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048574, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723048574, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:49:39.334: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:49:39.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4325" for this suite.
Apr 21 06:49:47.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:49:49.210: INFO: namespace webhook-4325 deletion completed in 9.607673854s
STEP: Destroying namespace "webhook-4325-markers" for this suite.
Apr 21 06:49:57.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:49:58.013: INFO: namespace webhook-4325-markers deletion completed in 8.802569012s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.427 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:49:58.119: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-9503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Apr 21 06:49:58.509: INFO: Waiting up to 5m0s for pod "var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162" in namespace "var-expansion-9503" to be "success or failure"
Apr 21 06:49:58.523: INFO: Pod "var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162": Phase="Pending", Reason="", readiness=false. Elapsed: 14.841941ms
Apr 21 06:50:00.546: INFO: Pod "var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037553994s
STEP: Saw pod success
Apr 21 06:50:00.546: INFO: Pod "var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162" satisfied condition "success or failure"
Apr 21 06:50:00.569: INFO: Trying to get logs from node 10.177.30.140 pod var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162 container dapi-container: <nil>
STEP: delete the pod
Apr 21 06:50:00.751: INFO: Waiting for pod var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162 to disappear
Apr 21 06:50:00.769: INFO: Pod var-expansion-3e72776a-1b24-44a9-b542-9a2ddb3f9162 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:50:00.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-9503" for this suite.
Apr 21 06:50:08.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:50:09.661: INFO: namespace var-expansion-9503 deletion completed in 8.867035799s

• [SLOW TEST:11.542 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:50:09.663: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3477
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Apr 21 06:50:10.012: INFO: Waiting up to 5m0s for pod "client-containers-8803ab5c-f222-4457-8243-af5b80134565" in namespace "containers-3477" to be "success or failure"
Apr 21 06:50:10.027: INFO: Pod "client-containers-8803ab5c-f222-4457-8243-af5b80134565": Phase="Pending", Reason="", readiness=false. Elapsed: 15.274192ms
Apr 21 06:50:12.048: INFO: Pod "client-containers-8803ab5c-f222-4457-8243-af5b80134565": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035641057s
Apr 21 06:50:14.063: INFO: Pod "client-containers-8803ab5c-f222-4457-8243-af5b80134565": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051073147s
STEP: Saw pod success
Apr 21 06:50:14.063: INFO: Pod "client-containers-8803ab5c-f222-4457-8243-af5b80134565" satisfied condition "success or failure"
Apr 21 06:50:14.078: INFO: Trying to get logs from node 10.177.30.140 pod client-containers-8803ab5c-f222-4457-8243-af5b80134565 container test-container: <nil>
STEP: delete the pod
Apr 21 06:50:14.176: INFO: Waiting for pod client-containers-8803ab5c-f222-4457-8243-af5b80134565 to disappear
Apr 21 06:50:14.192: INFO: Pod client-containers-8803ab5c-f222-4457-8243-af5b80134565 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:50:14.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3477" for this suite.
Apr 21 06:50:22.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:50:23.195: INFO: namespace containers-3477 deletion completed in 8.786050071s

• [SLOW TEST:13.532 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:50:23.200: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2903
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 21 06:50:27.756: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 21 06:50:27.791: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 21 06:50:29.791: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 21 06:50:29.808: INFO: Pod pod-with-poststart-exec-hook still exists
Apr 21 06:50:31.791: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr 21 06:50:31.812: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:50:31.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2903" for this suite.
Apr 21 06:50:45.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:50:46.746: INFO: namespace container-lifecycle-hook-2903 deletion completed in 14.903852202s

• [SLOW TEST:23.547 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:50:46.747: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr 21 06:50:47.077: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr 21 06:50:47.172: INFO: Waiting for terminating namespaces to be deleted...
Apr 21 06:50:47.201: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.140 before test
Apr 21 06:50:47.261: INFO: ibm-master-proxy-static-10.177.30.140 from kube-system started at 2020-04-21 03:03:31 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.261: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:50:47.261: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:50:47.261: INFO: calico-node-65w2l from kube-system started at 2020-04-21 03:03:33 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.261: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:50:47.261: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-g5b6n from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.261: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Apr 21 06:50:47.261: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:50:47.261: INFO: ibm-keepalived-watcher-6zs8n from kube-system started at 2020-04-21 03:03:32 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.261: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:50:47.261: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.144 before test
Apr 21 06:50:47.636: INFO: kubernetes-dashboard-69f9478454-fzzpb from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Apr 21 06:50:47.636: INFO: ibm-storage-watcher-79b9bc9b7f-4k67d from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Apr 21 06:50:47.636: INFO: calico-node-hz6bw from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:50:47.636: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-z67gz from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Apr 21 06:50:47.636: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:50:47.636: INFO: vpn-79845b6f9d-887s2 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container vpn ready: true, restart count 0
Apr 21 06:50:47.636: INFO: coredns-55db5d97fb-q6jbf from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:50:47.636: INFO: catalog-operator-645796fbdf-lsqqt from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.636: INFO: 	Container catalog-operator ready: true, restart count 0
Apr 21 06:50:47.637: INFO: ibm-keepalived-watcher-n5w2g from kube-system started at 2020-04-21 03:04:53 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:50:47.637: INFO: coredns-55db5d97fb-8qn5q from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:50:47.637: INFO: addon-catalog-source-7cs9m from ibm-system started at 2020-04-21 03:05:54 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container configmap-registry-server ready: true, restart count 0
Apr 21 06:50:47.637: INFO: metrics-server-878cfbdbd-dkk8m from kube-system started at 2020-04-21 05:21:00 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container metrics-server ready: true, restart count 0
Apr 21 06:50:47.637: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Apr 21 06:50:47.637: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-89n8j from kube-system started at 2020-04-21 03:05:48 +0000 UTC (4 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 06:50:47.637: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 06:50:47.637: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 06:50:47.637: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 06:50:47.637: INFO: ibm-master-proxy-static-10.177.30.144 from kube-system started at 2020-04-21 03:04:52 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:50:47.637: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:50:47.637: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-tbpgk from ibm-system started at 2020-04-21 03:05:11 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.637: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 06:50:47.638: INFO: 
Logging pods the kubelet thinks is on node 10.177.30.186 before test
Apr 21 06:50:47.804: INFO: ibm-master-proxy-static-10.177.30.186 from kube-system started at 2020-04-21 03:06:34 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.804: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Apr 21 06:50:47.804: INFO: 	Container pause ready: true, restart count 0
Apr 21 06:50:47.804: INFO: sonobuoy-e2e-job-4f59fb8664564855 from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.804: INFO: 	Container e2e ready: true, restart count 0
Apr 21 06:50:47.804: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr 21 06:50:47.804: INFO: olm-operator-7bf4dbc978-kgjlz from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container olm-operator ready: true, restart count 0
Apr 21 06:50:47.805: INFO: ibm-cloud-provider-ip-169-60-196-229-584bf5b85f-m8x2p from ibm-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container ibm-cloud-provider-ip-169-60-196-229 ready: true, restart count 0
Apr 21 06:50:47.805: INFO: coredns-55db5d97fb-59ltz from kube-system started at 2020-04-21 03:27:59 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container coredns ready: true, restart count 0
Apr 21 06:50:47.805: INFO: sonobuoy from sonobuoy started at 2020-04-21 04:37:03 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr 21 06:50:47.805: INFO: calico-kube-controllers-598ddbf99d-mzh5s from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Apr 21 06:50:47.805: INFO: dashboard-metrics-scraper-76756886dc-dp2kh from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Apr 21 06:50:47.805: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-04-21 03:09:19 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.805: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Apr 21 06:50:47.805: INFO: sonobuoy-systemd-logs-daemon-set-89b55052fb374fe1-msf2v from sonobuoy started at 2020-04-21 04:37:09 +0000 UTC (2 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Apr 21 06:50:47.806: INFO: 	Container systemd-logs ready: true, restart count 0
Apr 21 06:50:47.806: INFO: public-crbqf5pqk20faa838g4qpg-alb1-59999f685f-qfdjj from kube-system started at 2020-04-21 05:21:00 +0000 UTC (4 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Apr 21 06:50:47.806: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Apr 21 06:50:47.806: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Apr 21 06:50:47.806: INFO: 	Container nginx-ingress ready: true, restart count 0
Apr 21 06:50:47.806: INFO: ibm-file-plugin-b8d7f5977-fkjtw from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Apr 21 06:50:47.806: INFO: calico-node-ngcph from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container calico-node ready: true, restart count 0
Apr 21 06:50:47.806: INFO: ibm-keepalived-watcher-9czcf from kube-system started at 2020-04-21 03:06:40 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container keepalived-watcher ready: true, restart count 0
Apr 21 06:50:47.806: INFO: coredns-autoscaler-65c89858bf-f4qc4 from kube-system started at 2020-04-21 05:21:00 +0000 UTC (1 container statuses recorded)
Apr 21 06:50:47.806: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b6393002-4adb-41ba-b039-c01721fd1da7 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-b6393002-4adb-41ba-b039-c01721fd1da7 off the node 10.177.30.140
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b6393002-4adb-41ba-b039-c01721fd1da7
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:51:02.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5678" for this suite.
Apr 21 06:51:24.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:51:25.203: INFO: namespace sched-pred-5678 deletion completed in 22.860777492s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:38.456 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:51:25.205: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-523
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr 21 06:51:28.278: INFO: Successfully updated pod "annotationupdatec9016884-4421-45c2-9d4d-440da9455a13"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:51:30.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-523" for this suite.
Apr 21 06:51:44.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:51:45.478: INFO: namespace projected-523 deletion completed in 15.041844041s

• [SLOW TEST:20.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:51:45.480: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4581
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:52:02.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4581" for this suite.
Apr 21 06:52:10.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:52:10.982: INFO: namespace resourcequota-4581 deletion completed in 8.725526533s

• [SLOW TEST:25.503 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:52:10.983: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2635
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr 21 06:52:11.371: INFO: Waiting up to 5m0s for pod "pod-03e77dd8-3027-4757-8ab2-655c47d3fae6" in namespace "emptydir-2635" to be "success or failure"
Apr 21 06:52:11.391: INFO: Pod "pod-03e77dd8-3027-4757-8ab2-655c47d3fae6": Phase="Pending", Reason="", readiness=false. Elapsed: 20.014859ms
Apr 21 06:52:13.407: INFO: Pod "pod-03e77dd8-3027-4757-8ab2-655c47d3fae6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036230318s
Apr 21 06:52:15.437: INFO: Pod "pod-03e77dd8-3027-4757-8ab2-655c47d3fae6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065695739s
STEP: Saw pod success
Apr 21 06:52:15.437: INFO: Pod "pod-03e77dd8-3027-4757-8ab2-655c47d3fae6" satisfied condition "success or failure"
Apr 21 06:52:15.454: INFO: Trying to get logs from node 10.177.30.140 pod pod-03e77dd8-3027-4757-8ab2-655c47d3fae6 container test-container: <nil>
STEP: delete the pod
Apr 21 06:52:15.569: INFO: Waiting for pod pod-03e77dd8-3027-4757-8ab2-655c47d3fae6 to disappear
Apr 21 06:52:15.595: INFO: Pod pod-03e77dd8-3027-4757-8ab2-655c47d3fae6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:52:15.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2635" for this suite.
Apr 21 06:52:23.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:52:24.581: INFO: namespace emptydir-2635 deletion completed in 8.955167462s

• [SLOW TEST:13.599 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:52:24.582: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5493
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr 21 06:52:29.111: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:29.140: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:31.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:31.157: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:33.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:33.161: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:35.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:35.231: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:37.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:37.157: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:39.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:39.164: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:41.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:41.172: INFO: Pod pod-with-prestop-http-hook still exists
Apr 21 06:52:43.141: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr 21 06:52:43.159: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:52:43.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5493" for this suite.
Apr 21 06:53:15.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:53:15.954: INFO: namespace container-lifecycle-hook-5493 deletion completed in 32.731254953s

• [SLOW TEST:51.373 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:53:15.957: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-4a96e0a1-f688-4d06-a9b4-a49756cb7640 in namespace container-probe-9159
Apr 21 06:53:20.349: INFO: Started pod busybox-4a96e0a1-f688-4d06-a9b4-a49756cb7640 in namespace container-probe-9159
STEP: checking the pod's current state and verifying that restartCount is present
Apr 21 06:53:20.364: INFO: Initial restart count of pod busybox-4a96e0a1-f688-4d06-a9b4-a49756cb7640 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:57:22.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9159" for this suite.
Apr 21 06:57:30.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:57:30.968: INFO: namespace container-probe-9159 deletion completed in 8.765151749s

• [SLOW TEST:255.011 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:57:30.969: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8020
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr 21 06:57:32.403: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr 21 06:57:34.460: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723049052, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723049052, loc:(*time.Location)(0x78a2900)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63723049052, loc:(*time.Location)(0x78a2900)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63723049052, loc:(*time.Location)(0x78a2900)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr 21 06:57:37.524: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 06:57:37.549: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6257-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:57:44.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8020" for this suite.
Apr 21 06:57:52.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:57:53.015: INFO: namespace webhook-8020 deletion completed in 8.784810469s
STEP: Destroying namespace "webhook-8020-markers" for this suite.
Apr 21 06:58:01.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:58:01.774: INFO: namespace webhook-8020-markers deletion completed in 8.759438318s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.907 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:58:01.877: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1320
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Apr 21 06:58:02.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-1320'
Apr 21 06:58:02.783: INFO: stderr: ""
Apr 21 06:58:02.783: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr 21 06:58:03.801: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:58:03.801: INFO: Found 0 / 1
Apr 21 06:58:04.799: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:58:04.799: INFO: Found 0 / 1
Apr 21 06:58:05.807: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:58:05.807: INFO: Found 1 / 1
Apr 21 06:58:05.807: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr 21 06:58:05.829: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:58:05.829: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr 21 06:58:05.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 patch pod redis-master-t5l5p --namespace=kubectl-1320 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr 21 06:58:06.010: INFO: stderr: ""
Apr 21 06:58:06.010: INFO: stdout: "pod/redis-master-t5l5p patched\n"
STEP: checking annotations
Apr 21 06:58:06.037: INFO: Selector matched 1 pods for map[app:redis]
Apr 21 06:58:06.037: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:58:06.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1320" for this suite.
Apr 21 06:58:34.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:58:34.814: INFO: namespace kubectl-1320 deletion completed in 28.741513766s

• [SLOW TEST:32.937 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:58:34.818: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ddf90454-dbc9-47f8-ae84-6ef89c3321c2
STEP: Creating a pod to test consume configMaps
Apr 21 06:58:35.415: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18" in namespace "projected-2972" to be "success or failure"
Apr 21 06:58:35.437: INFO: Pod "pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18": Phase="Pending", Reason="", readiness=false. Elapsed: 21.397061ms
Apr 21 06:58:37.453: INFO: Pod "pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037389952s
STEP: Saw pod success
Apr 21 06:58:37.453: INFO: Pod "pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18" satisfied condition "success or failure"
Apr 21 06:58:37.469: INFO: Trying to get logs from node 10.177.30.140 pod pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr 21 06:58:37.655: INFO: Waiting for pod pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18 to disappear
Apr 21 06:58:37.684: INFO: Pod pod-projected-configmaps-edcf96ec-27f9-49d9-b5fe-65737da2bb18 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:58:37.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2972" for this suite.
Apr 21 06:58:45.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:58:47.002: INFO: namespace projected-2972 deletion completed in 9.287381966s

• [SLOW TEST:12.185 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:58:47.009: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2410
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-3726a73a-aa7f-4926-a750-8c48557467e4 in namespace container-probe-2410
Apr 21 06:58:49.471: INFO: Started pod busybox-3726a73a-aa7f-4926-a750-8c48557467e4 in namespace container-probe-2410
STEP: checking the pod's current state and verifying that restartCount is present
Apr 21 06:58:49.493: INFO: Initial restart count of pod busybox-3726a73a-aa7f-4926-a750-8c48557467e4 is 0
Apr 21 06:59:41.978: INFO: Restart count of pod container-probe-2410/busybox-3726a73a-aa7f-4926-a750-8c48557467e4 is now 1 (52.485071739s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:59:42.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2410" for this suite.
Apr 21 06:59:50.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 06:59:50.821: INFO: namespace container-probe-2410 deletion completed in 8.75466084s

• [SLOW TEST:63.813 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 06:59:50.821: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr 21 06:59:51.172: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f" in namespace "downward-api-5239" to be "success or failure"
Apr 21 06:59:51.198: INFO: Pod "downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f": Phase="Pending", Reason="", readiness=false. Elapsed: 25.778277ms
Apr 21 06:59:53.218: INFO: Pod "downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045554159s
Apr 21 06:59:55.236: INFO: Pod "downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063753883s
STEP: Saw pod success
Apr 21 06:59:55.236: INFO: Pod "downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f" satisfied condition "success or failure"
Apr 21 06:59:55.258: INFO: Trying to get logs from node 10.177.30.140 pod downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f container client-container: <nil>
STEP: delete the pod
Apr 21 06:59:55.355: INFO: Waiting for pod downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f to disappear
Apr 21 06:59:55.378: INFO: Pod downwardapi-volume-fbf82705-81ac-4a17-9643-9317544e104f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 06:59:55.378: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5239" for this suite.
Apr 21 07:00:03.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:00:04.370: INFO: namespace downward-api-5239 deletion completed in 8.716349222s

• [SLOW TEST:13.548 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:00:04.370: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6656
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Apr 21 07:00:04.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 create -f - --namespace=kubectl-6656'
Apr 21 07:00:05.107: INFO: stderr: ""
Apr 21 07:00:05.107: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 07:00:05.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6656'
Apr 21 07:00:05.272: INFO: stderr: ""
Apr 21 07:00:05.272: INFO: stdout: "update-demo-nautilus-8st2x update-demo-nautilus-hmvwj "
Apr 21 07:00:05.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:05.465: INFO: stderr: ""
Apr 21 07:00:05.465: INFO: stdout: ""
Apr 21 07:00:05.465: INFO: update-demo-nautilus-8st2x is created but not running
Apr 21 07:00:10.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6656'
Apr 21 07:00:10.630: INFO: stderr: ""
Apr 21 07:00:10.630: INFO: stdout: "update-demo-nautilus-8st2x update-demo-nautilus-hmvwj "
Apr 21 07:00:10.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st2x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:10.769: INFO: stderr: ""
Apr 21 07:00:10.769: INFO: stdout: "true"
Apr 21 07:00:10.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-8st2x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:10.923: INFO: stderr: ""
Apr 21 07:00:10.923: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 07:00:10.923: INFO: validating pod update-demo-nautilus-8st2x
Apr 21 07:00:10.955: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 07:00:10.956: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 07:00:10.956: INFO: update-demo-nautilus-8st2x is verified up and running
Apr 21 07:00:10.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-hmvwj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:11.114: INFO: stderr: ""
Apr 21 07:00:11.114: INFO: stdout: "true"
Apr 21 07:00:11.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-nautilus-hmvwj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:11.283: INFO: stderr: ""
Apr 21 07:00:11.283: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr 21 07:00:11.283: INFO: validating pod update-demo-nautilus-hmvwj
Apr 21 07:00:11.322: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr 21 07:00:11.322: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr 21 07:00:11.322: INFO: update-demo-nautilus-hmvwj is verified up and running
STEP: rolling-update to new replication controller
Apr 21 07:00:11.325: INFO: scanned /root for discovery docs: <nil>
Apr 21 07:00:11.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6656'
Apr 21 07:00:34.626: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr 21 07:00:34.626: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr 21 07:00:34.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6656'
Apr 21 07:00:34.791: INFO: stderr: ""
Apr 21 07:00:34.791: INFO: stdout: "update-demo-kitten-vdr55 update-demo-kitten-zmcwn "
Apr 21 07:00:34.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-kitten-vdr55 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:34.939: INFO: stderr: ""
Apr 21 07:00:34.939: INFO: stdout: "true"
Apr 21 07:00:34.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-kitten-vdr55 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:35.118: INFO: stderr: ""
Apr 21 07:00:35.118: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 21 07:00:35.118: INFO: validating pod update-demo-kitten-vdr55
Apr 21 07:00:35.153: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 21 07:00:35.154: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 21 07:00:35.154: INFO: update-demo-kitten-vdr55 is verified up and running
Apr 21 07:00:35.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-kitten-zmcwn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:36.343: INFO: stderr: ""
Apr 21 07:00:36.343: INFO: stdout: "true"
Apr 21 07:00:36.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-357945732 get pods update-demo-kitten-zmcwn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6656'
Apr 21 07:00:36.503: INFO: stderr: ""
Apr 21 07:00:36.503: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr 21 07:00:36.503: INFO: validating pod update-demo-kitten-zmcwn
Apr 21 07:00:36.537: INFO: got data: {
  "image": "kitten.jpg"
}

Apr 21 07:00:36.537: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr 21 07:00:36.537: INFO: update-demo-kitten-zmcwn is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:00:36.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6656" for this suite.
Apr 21 07:01:08.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:01:09.360: INFO: namespace kubectl-6656 deletion completed in 32.799435139s

• [SLOW TEST:64.990 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:01:09.360: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Apr 21 07:01:09.723: INFO: Waiting up to 5m0s for pod "client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8" in namespace "containers-1757" to be "success or failure"
Apr 21 07:01:09.752: INFO: Pod "client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8": Phase="Pending", Reason="", readiness=false. Elapsed: 28.570551ms
Apr 21 07:01:11.770: INFO: Pod "client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046877122s
STEP: Saw pod success
Apr 21 07:01:11.770: INFO: Pod "client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8" satisfied condition "success or failure"
Apr 21 07:01:11.787: INFO: Trying to get logs from node 10.177.30.140 pod client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8 container test-container: <nil>
STEP: delete the pod
Apr 21 07:01:11.923: INFO: Waiting for pod client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8 to disappear
Apr 21 07:01:11.943: INFO: Pod client-containers-f28d0d32-6a1a-4fa1-bb1a-e0e712f8c2f8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:01:11.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1757" for this suite.
Apr 21 07:01:20.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:01:20.736: INFO: namespace containers-1757 deletion completed in 8.76897592s

• [SLOW TEST:11.376 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:01:20.737: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1873
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-c1dc7ff5-e6b4-4475-a398-f8550edb3d1f
STEP: Creating secret with name s-test-opt-upd-2c0518c4-149d-4b40-8c89-97a8bde5d9f5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c1dc7ff5-e6b4-4475-a398-f8550edb3d1f
STEP: Updating secret s-test-opt-upd-2c0518c4-149d-4b40-8c89-97a8bde5d9f5
STEP: Creating secret with name s-test-opt-create-937d86fd-e308-4891-b35c-5776b2928ac8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:02:30.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1873" for this suite.
Apr 21 07:02:44.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:02:45.334: INFO: namespace secrets-1873 deletion completed in 14.796827586s

• [SLOW TEST:84.598 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:02:45.334: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-284
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr 21 07:02:48.672: INFO: Successfully updated pod "pod-update-e22a0d38-da45-4ec7-aa75-92a816e1f64b"
STEP: verifying the updated pod is in kubernetes
Apr 21 07:02:48.735: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:02:48.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-284" for this suite.
Apr 21 07:03:18.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:03:19.601: INFO: namespace pods-284 deletion completed in 30.825352895s

• [SLOW TEST:34.267 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:03:19.602: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6124
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:03:25.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6124" for this suite.
Apr 21 07:03:33.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:03:35.080: INFO: namespace watch-6124 deletion completed in 9.999519212s

• [SLOW TEST:15.478 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:03:35.081: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7223
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7223
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Apr 21 07:03:35.478: INFO: Found 0 stateful pods, waiting for 3
Apr 21 07:03:45.497: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 07:03:45.497: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 07:03:45.497: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr 21 07:03:45.631: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr 21 07:03:55.777: INFO: Updating stateful set ss2
Apr 21 07:03:55.831: INFO: Waiting for Pod statefulset-7223/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr 21 07:04:06.054: INFO: Found 2 stateful pods, waiting for 3
Apr 21 07:04:16.073: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 07:04:16.073: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr 21 07:04:16.073: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr 21 07:04:16.165: INFO: Updating stateful set ss2
Apr 21 07:04:16.204: INFO: Waiting for Pod statefulset-7223/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr 21 07:04:26.301: INFO: Updating stateful set ss2
Apr 21 07:04:26.343: INFO: Waiting for StatefulSet statefulset-7223/ss2 to complete update
Apr 21 07:04:26.343: INFO: Waiting for Pod statefulset-7223/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr 21 07:04:36.438: INFO: Deleting all statefulset in ns statefulset-7223
Apr 21 07:04:36.458: INFO: Scaling statefulset ss2 to 0
Apr 21 07:04:56.541: INFO: Waiting for statefulset status.replicas updated to 0
Apr 21 07:04:56.564: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:04:56.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7223" for this suite.
Apr 21 07:05:06.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:05:07.439: INFO: namespace statefulset-7223 deletion completed in 10.764186409s

• [SLOW TEST:92.358 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:05:07.439: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr 21 07:05:14.113: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 21 07:05:14.132: INFO: Pod pod-with-poststart-http-hook still exists
Apr 21 07:05:16.132: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 21 07:05:16.149: INFO: Pod pod-with-poststart-http-hook still exists
Apr 21 07:05:18.132: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr 21 07:05:18.169: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:05:18.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2580" for this suite.
Apr 21 07:05:50.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:05:51.046: INFO: namespace container-lifecycle-hook-2580 deletion completed in 32.843590318s

• [SLOW TEST:43.607 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr 21 07:05:51.048: INFO: >>> kubeConfig: /tmp/kubeconfig-357945732
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr 21 07:05:51.372: INFO: Creating deployment "webserver-deployment"
Apr 21 07:05:51.395: INFO: Waiting for observed generation 1
Apr 21 07:05:53.432: INFO: Waiting for all required pods to come up
Apr 21 07:05:53.484: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr 21 07:05:55.555: INFO: Waiting for deployment "webserver-deployment" to complete
Apr 21 07:05:55.597: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr 21 07:05:55.638: INFO: Updating deployment webserver-deployment
Apr 21 07:05:55.638: INFO: Waiting for observed generation 2
Apr 21 07:05:57.677: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr 21 07:05:57.692: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr 21 07:05:57.707: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 21 07:05:57.752: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr 21 07:05:57.752: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr 21 07:05:57.773: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr 21 07:05:57.808: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr 21 07:05:57.808: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr 21 07:05:57.842: INFO: Updating deployment webserver-deployment
Apr 21 07:05:57.842: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr 21 07:05:57.882: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr 21 07:05:57.911: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr 21 07:05:58.052: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/deployments/webserver-deployment 8f294be7-3a65-480c-b906-19a383cdf333 49212 3 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003b4aff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-04-21 07:05:56 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-21 07:05:57 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr 21 07:05:58.079: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/replicasets/webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 49195 3 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 8f294be7-3a65-480c-b906-19a383cdf333 0xc003b4b567 0xc003b4b568}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003b4b5d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr 21 07:05:58.079: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr 21 07:05:58.079: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-7956 /apis/apps/v1/namespaces/deployment-7956/replicasets/webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 49192 3 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 8f294be7-3a65-480c-b906-19a383cdf333 0xc003b4b4a7 0xc003b4b4a8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003b4b508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr 21 07:05:58.108: INFO: Pod "webserver-deployment-595b5b9587-47hqh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-47hqh webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-47hqh 7e2a7b72-efa9-47d2-855e-9c8358dd5f86 49238 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb0a77 0xc003eb0a78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.108: INFO: Pod "webserver-deployment-595b5b9587-4slk4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4slk4 webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-4slk4 2d47c24e-706b-46a0-b7b0-437bd7f307a2 49220 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb0b67 0xc003eb0b68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:,StartTime:2020-04-21 07:05:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.108: INFO: Pod "webserver-deployment-595b5b9587-5m4vv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5m4vv webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-5m4vv 43565900-4d96-4c4f-93e1-aa5ce8ab21cd 49082 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb0cc7 0xc003eb0cc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.145,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://5ec13838f42a59382761fbec6b5a3ccba408134246b261de2dd5270eea31a91b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.108: INFO: Pod "webserver-deployment-595b5b9587-64nm7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-64nm7 webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-64nm7 5c577b57-b1d0-4c96-a779-5ffe6ba46c7c 49071 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb0e47 0xc003eb0e48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.144,PodIP:172.30.121.7,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ec5f241398da9e07ee6fbb1107991648e2985cfa83c0649ef154978a92c6f457,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.121.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.109: INFO: Pod "webserver-deployment-595b5b9587-6wgs2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6wgs2 webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-6wgs2 a82f0a01-c180-42b4-a032-13fde8432f71 49228 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb0fc7 0xc003eb0fc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.144,PodIP:,StartTime:2020-04-21 07:05:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.109: INFO: Pod "webserver-deployment-595b5b9587-99x6z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-99x6z webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-99x6z 5a3a824a-a4dd-4961-8302-919418a717cd 49084 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1127 0xc003eb1128}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.140,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ab1af33701635beb5e0cba70197df94ab618266ce199d6eda453e88105dd71c3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.109: INFO: Pod "webserver-deployment-595b5b9587-9qtxq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9qtxq webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-9qtxq 669fed56-9342-4008-9ed9-f6868a9d899b 49078 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb12b7 0xc003eb12b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.144,PodIP:172.30.121.8,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://7ae8980b16d9fcf85c09ec32cd77b7bd7b5ba8773b79c6eff8027392f2765377,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.121.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.109: INFO: Pod "webserver-deployment-595b5b9587-dsktr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dsktr webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-dsktr 6a1a9d54-8fc3-47db-8891-2e37230baae0 49240 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1437 0xc003eb1438}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.110: INFO: Pod "webserver-deployment-595b5b9587-j5bvl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j5bvl webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-j5bvl 7bc1ef2c-c544-4f42-8fe4-49e458cf299f 49227 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1550 0xc003eb1551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.110: INFO: Pod "webserver-deployment-595b5b9587-jj5gm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jj5gm webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-jj5gm 93127858-f08a-499f-825d-49c5eb3930e2 49028 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1660 0xc003eb1661}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.135,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e4fcd3a29476c21ce4cdb09d04bf599fd17b721c829a1f5d5b300e7dae5495ad,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.135,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.110: INFO: Pod "webserver-deployment-595b5b9587-ltfhq" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ltfhq webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-ltfhq 0534b6a4-e00f-4045-9030-12ee4f99224e 49233 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb17f7 0xc003eb17f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.110: INFO: Pod "webserver-deployment-595b5b9587-mnd5l" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mnd5l webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-mnd5l 84c5c6ad-e597-4a27-8a06-d53c3c53790a 49217 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb18e7 0xc003eb18e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.111: INFO: Pod "webserver-deployment-595b5b9587-s9gns" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s9gns webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-s9gns 08b792bf-bbcf-4e70-a90b-71445f9782c5 49225 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1a10 0xc003eb1a11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.111: INFO: Pod "webserver-deployment-595b5b9587-t4db9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t4db9 webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-t4db9 8facf390-b2e4-4582-a633-f86080f26c0f 49237 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1af7 0xc003eb1af8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.186,PodIP:,StartTime:2020-04-21 07:05:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.111: INFO: Pod "webserver-deployment-595b5b9587-tck2p" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tck2p webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-tck2p 07a18f11-62de-4809-a489-6ab755f43250 49074 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1c57 0xc003eb1c58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.146,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://dd5ee390dad484d00be6c61ed4974d7464ee9891a21163663665c74c81e752e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.111: INFO: Pod "webserver-deployment-595b5b9587-tqbql" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tqbql webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-tqbql 9b2f85da-e2d7-4ba8-ba7c-2d688c4c8030 49219 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1dd7 0xc003eb1dd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.111: INFO: Pod "webserver-deployment-595b5b9587-ttp5j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ttp5j webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-ttp5j 17adcb7c-4e2d-4427-8876-c5a4c819e32a 49085 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc003eb1f10 0xc003eb1f11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:172.30.100.136,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://799c99c7c693e6a05ef24bddd7c1fdbb124f15e91259cd0c8f6eef61651d62e4,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.100.136,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.112: INFO: Pod "webserver-deployment-595b5b9587-v7dz6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-v7dz6 webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-v7dz6 b1585c0c-972a-4fae-862b-e47300d32d3b 49226 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc004d8a087 0xc004d8a088}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.112: INFO: Pod "webserver-deployment-595b5b9587-zxpmm" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zxpmm webserver-deployment-595b5b9587- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-595b5b9587-zxpmm 088f72f0-5a8a-4d37-839f-6cbdd432f492 49090 0 2020-04-21 07:05:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 abafe5cf-8d3a-4090-bd90-2705556612b4 0xc004d8a1a0 0xc004d8a1a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.186,PodIP:172.30.12.70,StartTime:2020-04-21 07:05:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-21 07:05:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://98223880696c240da4e48e9f030765b8c22ef8b93e20d411995a2c36281a53e2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.12.70,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.112: INFO: Pod "webserver-deployment-c7997dcc8-2qvwq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2qvwq webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-2qvwq bbf46fa7-bb7c-47c0-8d7b-db330ccf1d8b 49215 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a317 0xc004d8a318}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.112: INFO: Pod "webserver-deployment-c7997dcc8-8jw9q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8jw9q webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-8jw9q 49c38787-5cf7-4bb6-b36d-aa732a942c41 49236 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a440 0xc004d8a441}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.113: INFO: Pod "webserver-deployment-c7997dcc8-98bg4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-98bg4 webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-98bg4 b628fd98-5fa9-4282-97a0-aedd83fd57ba 49230 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a537 0xc004d8a538}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.113: INFO: Pod "webserver-deployment-c7997dcc8-ftpt9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ftpt9 webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-ftpt9 da1810fd-8632-454b-a249-c6ab7fb2065e 49150 0 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a637 0xc004d8a638}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:,StartTime:2020-04-21 07:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.113: INFO: Pod "webserver-deployment-c7997dcc8-j2kqr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-j2kqr webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-j2kqr dc19fe7f-e3cb-460c-8e1f-4d1dc9432bfc 49231 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a7c7 0xc004d8a7c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.113: INFO: Pod "webserver-deployment-c7997dcc8-kvzz6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kvzz6 webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-kvzz6 92e816eb-43e2-4716-872c-d71d1b5f2652 49239 0 2020-04-21 07:05:58 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a8c7 0xc004d8a8c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.114: INFO: Pod "webserver-deployment-c7997dcc8-m798w" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m798w webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-m798w fa2ef9c8-846e-4e85-acd6-2b4d872ae0f7 49229 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8a9f0 0xc004d8a9f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.114: INFO: Pod "webserver-deployment-c7997dcc8-msxwt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-msxwt webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-msxwt 624db019-54b1-4059-80fa-eb55a9f34171 49120 0 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8ab10 0xc004d8ab11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:,StartTime:2020-04-21 07:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.114: INFO: Pod "webserver-deployment-c7997dcc8-p8sfr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p8sfr webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-p8sfr 6db33224-5d97-42e4-8914-15f366339c4a 49232 0 2020-04-21 07:05:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8ac97 0xc004d8ac98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.114: INFO: Pod "webserver-deployment-c7997dcc8-pjrjs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pjrjs webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-pjrjs 148f1924-6d33-45fa-bcab-e27ed08ac525 49199 0 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8add0 0xc004d8add1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.144,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.144,PodIP:172.30.121.9,StartTime:2020-04-21 07:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.121.9,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.115: INFO: Pod "webserver-deployment-c7997dcc8-qhg4n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qhg4n webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-qhg4n 0a91e68b-095a-4c3e-b46d-422d059cb273 49122 0 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8af87 0xc004d8af88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.186,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.186,PodIP:,StartTime:2020-04-21 07:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr 21 07:05:58.115: INFO: Pod "webserver-deployment-c7997dcc8-s9wws" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-s9wws webserver-deployment-c7997dcc8- deployment-7956 /api/v1/namespaces/deployment-7956/pods/webserver-deployment-c7997dcc8-s9wws 0295d151-5b0c-4e8b-b283-f5a4bc9c8b6d 49144 0 2020-04-21 07:05:55 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 0dcd1025-a7ab-41aa-a39e-b90385744d35 0xc004d8b107 0xc004d8b108}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pnwnh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pnwnh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pnwnh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.177.30.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-21 07:05:55 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.177.30.140,PodIP:,StartTime:2020-04-21 07:05:55 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr 21 07:05:58.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7956" for this suite.
Apr 21 07:06:14.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr 21 07:06:15.000: INFO: namespace deployment-7956 deletion completed in 16.850725801s

• [SLOW TEST:23.952 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.9-beta.0.49+25599b5adea930/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSApr 21 07:06:15.003: INFO: Running AfterSuite actions on all nodes
Apr 21 07:06:15.003: INFO: Running AfterSuite actions on node 1
Apr 21 07:06:15.003: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 8917.144 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 2h28m38.995705593s
Test Suite Passed
