I1120 17:13:50.004409      23 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-455954265
I1120 17:13:50.004596      23 e2e.go:92] Starting e2e run "6fa2af08-5320-4d69-9117-748496b56198" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1574270028 - Will randomize all specs
Will run 276 of 4732 specs

Nov 20 17:13:50.018: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:13:50.021: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov 20 17:13:50.075: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov 20 17:13:50.164: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov 20 17:13:50.164: INFO: expected 11 pod replicas in namespace 'kube-system', 11 are Running and Ready.
Nov 20 17:13:50.164: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov 20 17:13:50.189: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Nov 20 17:13:50.189: INFO: e2e test version: v1.16.3
Nov 20 17:13:50.193: INFO: kube-apiserver version: v1.16.3+IKS
Nov 20 17:13:50.193: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:13:50.218: INFO: Cluster IP family: ipv4
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:13:50.218: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
Nov 20 17:13:50.323: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov 20 17:13:50.379: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7768
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov 20 17:13:50.576: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-7768'
Nov 20 17:13:51.274: INFO: stderr: ""
Nov 20 17:13:51.274: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 20 17:13:52.294: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:52.295: INFO: Found 0 / 1
Nov 20 17:13:53.305: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:53.305: INFO: Found 0 / 1
Nov 20 17:13:54.290: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:54.290: INFO: Found 0 / 1
Nov 20 17:13:55.290: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:55.290: INFO: Found 1 / 1
Nov 20 17:13:55.290: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov 20 17:13:55.303: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:55.303: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 20 17:13:55.303: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 patch pod redis-master-76xl5 --namespace=kubectl-7768 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov 20 17:13:55.474: INFO: stderr: ""
Nov 20 17:13:55.474: INFO: stdout: "pod/redis-master-76xl5 patched\n"
STEP: checking annotations
Nov 20 17:13:55.496: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:13:55.496: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:13:55.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7768" for this suite.
Nov 20 17:14:07.577: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:14:08.211: INFO: namespace kubectl-7768 deletion completed in 12.697886274s

• [SLOW TEST:17.993 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:14:08.211: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1486
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov 20 17:14:08.553: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1486 /api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-watch-closed 17ec30ec-5c52-4dcb-86ff-2143e34a3360 13068 0 2019-11-20 17:14:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 20 17:14:08.553: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1486 /api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-watch-closed 17ec30ec-5c52-4dcb-86ff-2143e34a3360 13069 0 2019-11-20 17:14:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov 20 17:14:08.588: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1486 /api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-watch-closed 17ec30ec-5c52-4dcb-86ff-2143e34a3360 13070 0 2019-11-20 17:14:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 20 17:14:08.589: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1486 /api/v1/namespaces/watch-1486/configmaps/e2e-watch-test-watch-closed 17ec30ec-5c52-4dcb-86ff-2143e34a3360 13071 0 2019-11-20 17:14:08 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:14:08.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1486" for this suite.
Nov 20 17:14:14.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:14:15.159: INFO: namespace watch-1486 deletion completed in 6.552865367s

• [SLOW TEST:6.948 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:14:15.160: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-7363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Nov 20 17:14:15.403: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Nov 20 17:14:16.234: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Nov 20 17:14:18.369: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 17:14:20.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 17:14:22.377: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 17:14:24.378: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866856, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 17:14:27.294: INFO: Waited 902.749254ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:14:27.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7363" for this suite.
Nov 20 17:14:36.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:14:36.428: INFO: namespace aggregator-7363 deletion completed in 8.499945523s

• [SLOW TEST:21.269 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:14:36.430: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-6385
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-6385
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-6385
STEP: Deleting pre-stop pod
Nov 20 17:14:51.895: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:14:51.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-6385" for this suite.
Nov 20 17:15:38.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:15:38.473: INFO: namespace prestop-6385 deletion completed in 46.493360531s

• [SLOW TEST:62.043 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:15:38.473: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-879
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:15:39.374: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov 20 17:15:41.403: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866939, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866939, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866939, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709866939, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:15:44.454: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:15:44.474: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:15:45.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-879" for this suite.
Nov 20 17:15:51.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:15:52.412: INFO: namespace crd-webhook-879 deletion completed in 6.536098174s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:14.019 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:15:52.492: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:15:52.758: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57" in namespace "projected-1835" to be "success or failure"
Nov 20 17:15:52.769: INFO: Pod "downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57": Phase="Pending", Reason="", readiness=false. Elapsed: 11.018862ms
Nov 20 17:15:54.784: INFO: Pod "downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026158569s
Nov 20 17:15:56.810: INFO: Pod "downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052717724s
STEP: Saw pod success
Nov 20 17:15:56.810: INFO: Pod "downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57" satisfied condition "success or failure"
Nov 20 17:15:56.848: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57 container client-container: <nil>
STEP: delete the pod
Nov 20 17:15:56.983: INFO: Waiting for pod downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57 to disappear
Nov 20 17:15:56.998: INFO: Pod downwardapi-volume-ef41a6ca-fc66-43fb-a529-868aacbd2f57 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:15:56.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1835" for this suite.
Nov 20 17:16:03.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:16:03.586: INFO: namespace projected-1835 deletion completed in 6.572790333s

• [SLOW TEST:11.095 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:16:03.586: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1120 17:16:14.034316      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 20 17:16:14.034: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:16:14.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-447" for this suite.
Nov 20 17:16:22.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:16:22.762: INFO: namespace gc-447 deletion completed in 8.712735088s

• [SLOW TEST:19.176 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:16:22.762: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Nov 20 17:16:23.058: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-455954265 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:16:23.176: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7933" for this suite.
Nov 20 17:16:29.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:16:29.800: INFO: namespace kubectl-7933 deletion completed in 6.579131s

• [SLOW TEST:7.037 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:16:29.800: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5862
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-1555e06a-b1f8-4b44-94ba-2bfbdb23d35b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-1555e06a-b1f8-4b44-94ba-2bfbdb23d35b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:16:34.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5862" for this suite.
Nov 20 17:17:04.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:17:05.165: INFO: namespace projected-5862 deletion completed in 30.844718182s

• [SLOW TEST:35.365 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:17:05.166: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7995
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:17:06.241: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:17:08.288: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867026, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867026, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867026, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867026, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:17:11.349: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
Nov 20 17:17:11.463: INFO: Waiting for webhook configuration to be ready...
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:17:11.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7995" for this suite.
Nov 20 17:17:19.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:17:20.730: INFO: namespace webhook-7995 deletion completed in 8.908587556s
STEP: Destroying namespace "webhook-7995-markers" for this suite.
Nov 20 17:17:26.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:17:27.336: INFO: namespace webhook-7995-markers deletion completed in 6.606212869s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.246 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:17:27.414: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-33017b47-457b-4ee1-87ea-cdb4e5d67c06
STEP: Creating a pod to test consume configMaps
Nov 20 17:17:27.731: INFO: Waiting up to 5m0s for pod "pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6" in namespace "configmap-9416" to be "success or failure"
Nov 20 17:17:27.744: INFO: Pod "pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.158343ms
Nov 20 17:17:29.758: INFO: Pod "pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027658955s
STEP: Saw pod success
Nov 20 17:17:29.758: INFO: Pod "pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6" satisfied condition "success or failure"
Nov 20 17:17:29.775: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 17:17:29.934: INFO: Waiting for pod pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6 to disappear
Nov 20 17:17:29.952: INFO: Pod pod-configmaps-2ed9e305-c4ab-4593-90cd-f4cd446535b6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:17:29.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9416" for this suite.
Nov 20 17:17:36.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:17:36.450: INFO: namespace configmap-9416 deletion completed in 6.474674689s

• [SLOW TEST:9.036 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:17:36.450: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4862
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-fd79ce1d-c4ba-45f0-8c67-49786d30f85a
STEP: Creating configMap with name cm-test-opt-upd-d6eec6ec-8d15-4a7f-a882-572fc7a11003
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fd79ce1d-c4ba-45f0-8c67-49786d30f85a
STEP: Updating configmap cm-test-opt-upd-d6eec6ec-8d15-4a7f-a882-572fc7a11003
STEP: Creating configMap with name cm-test-opt-create-51e73838-0aa9-435c-9007-2a14814e34b3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:19:04.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4862" for this suite.
Nov 20 17:19:16.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:19:16.728: INFO: namespace projected-4862 deletion completed in 12.53364711s

• [SLOW TEST:100.277 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:19:16.728: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:19:28.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5763" for this suite.
Nov 20 17:19:34.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:19:34.543: INFO: namespace resourcequota-5763 deletion completed in 6.441301922s

• [SLOW TEST:17.814 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:19:34.543: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Nov 20 17:19:34.810: INFO: Waiting up to 5m0s for pod "client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a" in namespace "containers-3410" to be "success or failure"
Nov 20 17:19:34.822: INFO: Pod "client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.310253ms
Nov 20 17:19:36.840: INFO: Pod "client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03001299s
STEP: Saw pod success
Nov 20 17:19:36.840: INFO: Pod "client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a" satisfied condition "success or failure"
Nov 20 17:19:36.870: INFO: Trying to get logs from node 10.184.110.176 pod client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a container test-container: <nil>
STEP: delete the pod
Nov 20 17:19:37.014: INFO: Waiting for pod client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a to disappear
Nov 20 17:19:37.027: INFO: Pod client-containers-e90a12de-3d40-4f85-95ab-c0b6e4460a3a no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:19:37.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3410" for this suite.
Nov 20 17:19:43.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:19:43.511: INFO: namespace containers-3410 deletion completed in 6.465382826s

• [SLOW TEST:8.968 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:19:43.511: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-24
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:19:43.943: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d" in namespace "projected-24" to be "success or failure"
Nov 20 17:19:43.956: INFO: Pod "downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d": Phase="Pending", Reason="", readiness=false. Elapsed: 13.00304ms
Nov 20 17:19:45.983: INFO: Pod "downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040429194s
STEP: Saw pod success
Nov 20 17:19:45.984: INFO: Pod "downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d" satisfied condition "success or failure"
Nov 20 17:19:46.000: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d container client-container: <nil>
STEP: delete the pod
Nov 20 17:19:46.131: INFO: Waiting for pod downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d to disappear
Nov 20 17:19:46.146: INFO: Pod downwardapi-volume-b992afa0-93df-4507-92a0-6bd8cee0433d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:19:46.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-24" for this suite.
Nov 20 17:19:52.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:19:52.715: INFO: namespace projected-24 deletion completed in 6.550539221s

• [SLOW TEST:9.204 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:19:52.715: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 17:19:52.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8504'
Nov 20 17:19:53.092: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 20 17:19:53.092: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Nov 20 17:19:55.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete deployment e2e-test-httpd-deployment --namespace=kubectl-8504'
Nov 20 17:19:55.300: INFO: stderr: ""
Nov 20 17:19:55.300: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:19:55.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8504" for this suite.
Nov 20 17:20:01.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:20:02.222: INFO: namespace kubectl-8504 deletion completed in 6.886104081s

• [SLOW TEST:9.507 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:20:02.224: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8860
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:20:02.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8860" for this suite.
Nov 20 17:20:32.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:20:33.119: INFO: namespace pods-8860 deletion completed in 30.55542231s

• [SLOW TEST:30.895 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:20:33.119: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-b4sd
STEP: Creating a pod to test atomic-volume-subpath
Nov 20 17:20:33.401: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-b4sd" in namespace "subpath-477" to be "success or failure"
Nov 20 17:20:33.415: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Pending", Reason="", readiness=false. Elapsed: 13.595519ms
Nov 20 17:20:35.440: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038682083s
Nov 20 17:20:37.453: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 4.051657659s
Nov 20 17:20:39.473: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 6.071739889s
Nov 20 17:20:41.491: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 8.089348425s
Nov 20 17:20:43.504: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 10.102528635s
Nov 20 17:20:45.519: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 12.117367222s
Nov 20 17:20:47.533: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 14.131851716s
Nov 20 17:20:49.548: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 16.147203866s
Nov 20 17:20:51.563: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 18.161502687s
Nov 20 17:20:53.575: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Running", Reason="", readiness=true. Elapsed: 20.173388543s
Nov 20 17:20:55.590: INFO: Pod "pod-subpath-test-secret-b4sd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.18838373s
STEP: Saw pod success
Nov 20 17:20:55.590: INFO: Pod "pod-subpath-test-secret-b4sd" satisfied condition "success or failure"
Nov 20 17:20:55.603: INFO: Trying to get logs from node 10.184.110.176 pod pod-subpath-test-secret-b4sd container test-container-subpath-secret-b4sd: <nil>
STEP: delete the pod
Nov 20 17:20:55.699: INFO: Waiting for pod pod-subpath-test-secret-b4sd to disappear
Nov 20 17:20:55.724: INFO: Pod pod-subpath-test-secret-b4sd no longer exists
STEP: Deleting pod pod-subpath-test-secret-b4sd
Nov 20 17:20:55.724: INFO: Deleting pod "pod-subpath-test-secret-b4sd" in namespace "subpath-477"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:20:55.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-477" for this suite.
Nov 20 17:21:01.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:21:02.516: INFO: namespace subpath-477 deletion completed in 6.736523981s

• [SLOW TEST:29.397 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:21:02.516: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2571
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:21:03.755: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:21:05.792: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867263, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867263, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867263, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867263, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:21:08.942: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:21:08.981: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5850-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:21:10.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2571" for this suite.
Nov 20 17:21:18.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:21:18.723: INFO: namespace webhook-2571 deletion completed in 8.512289802s
STEP: Destroying namespace "webhook-2571-markers" for this suite.
Nov 20 17:21:24.782: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:21:25.270: INFO: namespace webhook-2571-markers deletion completed in 6.547206906s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.830 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:21:25.347: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3147
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov 20 17:21:28.294: INFO: Successfully updated pod "annotationupdateb16c3970-57da-4443-8322-416666ac61a1"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:21:30.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3147" for this suite.
Nov 20 17:21:46.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:21:46.922: INFO: namespace projected-3147 deletion completed in 16.541642368s

• [SLOW TEST:21.575 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:21:46.922: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3018
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:21:47.150: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 20 17:21:50.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3018 create -f -'
Nov 20 17:21:51.100: INFO: stderr: ""
Nov 20 17:21:51.100: INFO: stdout: "e2e-test-crd-publish-openapi-4830-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 20 17:21:51.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3018 delete e2e-test-crd-publish-openapi-4830-crds test-cr'
Nov 20 17:21:51.345: INFO: stderr: ""
Nov 20 17:21:51.345: INFO: stdout: "e2e-test-crd-publish-openapi-4830-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov 20 17:21:51.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3018 apply -f -'
Nov 20 17:21:51.622: INFO: stderr: ""
Nov 20 17:21:51.622: INFO: stdout: "e2e-test-crd-publish-openapi-4830-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov 20 17:21:51.622: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3018 delete e2e-test-crd-publish-openapi-4830-crds test-cr'
Nov 20 17:21:51.889: INFO: stderr: ""
Nov 20 17:21:51.889: INFO: stdout: "e2e-test-crd-publish-openapi-4830-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov 20 17:21:51.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-4830-crds'
Nov 20 17:21:52.159: INFO: stderr: ""
Nov 20 17:21:52.159: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4830-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:21:56.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3018" for this suite.
Nov 20 17:22:02.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:22:02.763: INFO: namespace crd-publish-openapi-3018 deletion completed in 6.670281917s

• [SLOW TEST:15.841 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:22:02.763: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2316
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-87b845f1-460c-47e3-9bec-4f7906c48381
STEP: Creating a pod to test consume secrets
Nov 20 17:22:03.069: INFO: Waiting up to 5m0s for pod "pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b" in namespace "secrets-2316" to be "success or failure"
Nov 20 17:22:03.091: INFO: Pod "pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b": Phase="Pending", Reason="", readiness=false. Elapsed: 22.283363ms
Nov 20 17:22:05.151: INFO: Pod "pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082092926s
Nov 20 17:22:07.166: INFO: Pod "pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097191641s
STEP: Saw pod success
Nov 20 17:22:07.166: INFO: Pod "pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b" satisfied condition "success or failure"
Nov 20 17:22:07.183: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:22:07.278: INFO: Waiting for pod pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b to disappear
Nov 20 17:22:07.298: INFO: Pod pod-secrets-9e0c5030-1d4f-4f81-8937-027d6cc0705b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:22:07.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2316" for this suite.
Nov 20 17:22:13.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:22:14.271: INFO: namespace secrets-2316 deletion completed in 6.953787129s

• [SLOW TEST:11.508 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:22:14.272: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-z59t
STEP: Creating a pod to test atomic-volume-subpath
Nov 20 17:22:14.683: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-z59t" in namespace "subpath-203" to be "success or failure"
Nov 20 17:22:14.702: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Pending", Reason="", readiness=false. Elapsed: 19.595584ms
Nov 20 17:22:16.722: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 2.039023613s
Nov 20 17:22:18.741: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 4.058700047s
Nov 20 17:22:20.811: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 6.128362869s
Nov 20 17:22:22.850: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 8.167068884s
Nov 20 17:22:24.869: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 10.186176302s
Nov 20 17:22:26.885: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 12.202727373s
Nov 20 17:22:28.903: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 14.220549918s
Nov 20 17:22:30.926: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 16.243261231s
Nov 20 17:22:32.940: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 18.257237697s
Nov 20 17:22:34.955: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Running", Reason="", readiness=true. Elapsed: 20.271936522s
Nov 20 17:22:36.973: INFO: Pod "pod-subpath-test-configmap-z59t": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.289867037s
STEP: Saw pod success
Nov 20 17:22:36.973: INFO: Pod "pod-subpath-test-configmap-z59t" satisfied condition "success or failure"
Nov 20 17:22:36.986: INFO: Trying to get logs from node 10.184.110.176 pod pod-subpath-test-configmap-z59t container test-container-subpath-configmap-z59t: <nil>
STEP: delete the pod
Nov 20 17:22:37.071: INFO: Waiting for pod pod-subpath-test-configmap-z59t to disappear
Nov 20 17:22:37.082: INFO: Pod pod-subpath-test-configmap-z59t no longer exists
STEP: Deleting pod pod-subpath-test-configmap-z59t
Nov 20 17:22:37.082: INFO: Deleting pod "pod-subpath-test-configmap-z59t" in namespace "subpath-203"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:22:37.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-203" for this suite.
Nov 20 17:22:43.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:22:43.670: INFO: namespace subpath-203 deletion completed in 6.512316899s

• [SLOW TEST:29.398 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:22:43.670: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5269
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:22:43.925: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605" in namespace "downward-api-5269" to be "success or failure"
Nov 20 17:22:43.939: INFO: Pod "downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605": Phase="Pending", Reason="", readiness=false. Elapsed: 13.374148ms
Nov 20 17:22:45.956: INFO: Pod "downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030263822s
STEP: Saw pod success
Nov 20 17:22:45.956: INFO: Pod "downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605" satisfied condition "success or failure"
Nov 20 17:22:45.972: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605 container client-container: <nil>
STEP: delete the pod
Nov 20 17:22:46.087: INFO: Waiting for pod downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605 to disappear
Nov 20 17:22:46.101: INFO: Pod downwardapi-volume-5a8acff8-df66-4eb6-a936-78c33f48c605 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:22:46.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5269" for this suite.
Nov 20 17:22:52.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:22:52.559: INFO: namespace downward-api-5269 deletion completed in 6.434291541s

• [SLOW TEST:8.889 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:22:52.559: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5806
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:22:52.887: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov 20 17:22:52.934: INFO: Number of nodes with available pods: 0
Nov 20 17:22:52.935: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:53.976: INFO: Number of nodes with available pods: 0
Nov 20 17:22:53.976: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:54.962: INFO: Number of nodes with available pods: 1
Nov 20 17:22:54.962: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:55.965: INFO: Number of nodes with available pods: 1
Nov 20 17:22:55.965: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:56.968: INFO: Number of nodes with available pods: 1
Nov 20 17:22:56.968: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:57.969: INFO: Number of nodes with available pods: 1
Nov 20 17:22:57.969: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:22:58.985: INFO: Number of nodes with available pods: 1
Nov 20 17:22:58.985: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:23:00.012: INFO: Number of nodes with available pods: 3
Nov 20 17:23:00.012: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov 20 17:23:00.141: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:00.141: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:00.141: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:01.170: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:01.170: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:01.170: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:02.202: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:02.202: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:02.202: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:02.202: INFO: Pod daemon-set-xkmvm is not available
Nov 20 17:23:03.173: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:03.173: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:03.173: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:03.173: INFO: Pod daemon-set-xkmvm is not available
Nov 20 17:23:04.204: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:04.204: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:04.204: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:04.204: INFO: Pod daemon-set-xkmvm is not available
Nov 20 17:23:05.173: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:05.173: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:05.173: INFO: Wrong image for pod: daemon-set-xkmvm. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:05.173: INFO: Pod daemon-set-xkmvm is not available
Nov 20 17:23:06.178: INFO: Pod daemon-set-7hhhs is not available
Nov 20 17:23:06.179: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:06.179: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:07.183: INFO: Pod daemon-set-7hhhs is not available
Nov 20 17:23:07.183: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:07.183: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:08.199: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:08.200: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:09.171: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:09.171: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:09.171: INFO: Pod daemon-set-sp458 is not available
Nov 20 17:23:10.238: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:10.238: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:10.238: INFO: Pod daemon-set-sp458 is not available
Nov 20 17:23:11.270: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:11.271: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:11.271: INFO: Pod daemon-set-sp458 is not available
Nov 20 17:23:12.170: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:12.171: INFO: Wrong image for pod: daemon-set-sp458. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:12.171: INFO: Pod daemon-set-sp458 is not available
Nov 20 17:23:13.224: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:13.224: INFO: Pod daemon-set-ltfpc is not available
Nov 20 17:23:14.175: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:14.175: INFO: Pod daemon-set-ltfpc is not available
Nov 20 17:23:15.186: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:15.186: INFO: Pod daemon-set-ltfpc is not available
Nov 20 17:23:16.200: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:16.201: INFO: Pod daemon-set-ltfpc is not available
Nov 20 17:23:17.168: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:18.175: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:19.172: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:19.173: INFO: Pod daemon-set-7tbrh is not available
Nov 20 17:23:20.176: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:20.176: INFO: Pod daemon-set-7tbrh is not available
Nov 20 17:23:21.175: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:21.175: INFO: Pod daemon-set-7tbrh is not available
Nov 20 17:23:22.180: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:22.180: INFO: Pod daemon-set-7tbrh is not available
Nov 20 17:23:23.169: INFO: Wrong image for pod: daemon-set-7tbrh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov 20 17:23:23.169: INFO: Pod daemon-set-7tbrh is not available
Nov 20 17:23:25.168: INFO: Pod daemon-set-h5g4z is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov 20 17:23:25.226: INFO: Number of nodes with available pods: 2
Nov 20 17:23:25.226: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 17:23:26.304: INFO: Number of nodes with available pods: 2
Nov 20 17:23:26.304: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 17:23:27.274: INFO: Number of nodes with available pods: 2
Nov 20 17:23:27.274: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 17:23:28.275: INFO: Number of nodes with available pods: 2
Nov 20 17:23:28.275: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 17:23:29.266: INFO: Number of nodes with available pods: 3
Nov 20 17:23:29.266: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5806, will wait for the garbage collector to delete the pods
Nov 20 17:23:29.421: INFO: Deleting DaemonSet.extensions daemon-set took: 26.897002ms
Nov 20 17:23:29.621: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.339512ms
Nov 20 17:23:42.546: INFO: Number of nodes with available pods: 0
Nov 20 17:23:42.546: INFO: Number of running nodes: 0, number of available pods: 0
Nov 20 17:23:42.553: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5806/daemonsets","resourceVersion":"15104"},"items":null}

Nov 20 17:23:42.566: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5806/pods","resourceVersion":"15104"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:23:42.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5806" for this suite.
Nov 20 17:23:50.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:23:51.154: INFO: namespace daemonsets-5806 deletion completed in 8.491800517s

• [SLOW TEST:58.595 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:23:51.155: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7137
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov 20 17:23:51.382: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 20 17:23:51.438: INFO: Waiting for terminating namespaces to be deleted...
Nov 20 17:23:51.452: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.140 before test
Nov 20 17:23:51.546: INFO: ibm-master-proxy-static-10.184.110.140 from kube-system started at 2019-11-20 16:18:02 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:23:51.546: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:23:51.546: INFO: addon-catalog-source-67xr7 from ibm-system started at 2019-11-20 16:18:18 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container configmap-registry-server ready: true, restart count 1
Nov 20 17:23:51.546: INFO: calico-node-4dc2d from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:23:51.546: INFO: coredns-6db888bf8c-jr582 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:23:51.546: INFO: sonobuoy-e2e-job-b1a8acd3cb8d418c from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container e2e ready: true, restart count 0
Nov 20 17:23:51.546: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:23:51.546: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.546: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:23:51.546: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:23:51.547: INFO: ibm-keepalived-watcher-d59s8 from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.547: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:23:51.547: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.176 before test
Nov 20 17:23:51.580: INFO: ibm-master-proxy-static-10.184.110.176 from kube-system started at 2019-11-20 16:19:06 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:23:51.580: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:23:51.580: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:23:51.580: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:23:51.580: INFO: calico-node-lkmcb from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:23:51.580: INFO: coredns-6db888bf8c-pv2lc from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:23:51.580: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-20 16:20:03 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov 20 17:23:51.580: INFO: ibm-keepalived-watcher-qwxkl from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.580: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:23:51.580: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.184 before test
Nov 20 17:23:51.680: INFO: calico-kube-controllers-6f7dc6dfd4-7bt8x from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 20 17:23:51.680: INFO: metrics-server-6bb8bc7476-7x5bd from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container metrics-server ready: true, restart count 0
Nov 20 17:23:51.680: INFO: ibm-file-plugin-56c5959484-qv87m from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 20 17:23:51.680: INFO: olm-operator-58994486f9-zjnjt from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container olm-operator ready: true, restart count 0
Nov 20 17:23:51.680: INFO: catalog-operator-7885df777c-cvtfq from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container catalog-operator ready: true, restart count 0
Nov 20 17:23:51.680: INFO: coredns-6db888bf8c-nkkm5 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:23:51.680: INFO: ibm-master-proxy-static-10.184.110.184 from kube-system started at 2019-11-20 16:17:44 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:23:51.680: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:23:51.680: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:23:51.680: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:23:51.680: INFO: kubernetes-dashboard-6bb9bf847f-kvddq from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 20 17:23:51.680: INFO: ibm-keepalived-watcher-74vx6 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:23:51.680: INFO: dashboard-metrics-scraper-dff9cbb9c-fpcsc from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 20 17:23:51.680: INFO: sonobuoy from sonobuoy started at 2019-11-20 17:13:18 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 20 17:23:51.680: INFO: vpn-79845b6f9d-k9q7v from kube-system started at 2019-11-20 16:27:49 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container vpn ready: true, restart count 0
Nov 20 17:23:51.680: INFO: calico-node-7txr8 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.680: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:23:51.681: INFO: coredns-autoscaler-65c89858bf-x8hrv from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.681: INFO: 	Container autoscaler ready: true, restart count 0
Nov 20 17:23:51.681: INFO: ibm-storage-watcher-79dd7d8d79-88t7h from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:23:51.681: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d8eecc79ee75bb], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d8eecc7b6c3ba0], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:23:52.766: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7137" for this suite.
Nov 20 17:23:58.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:23:59.348: INFO: namespace sched-pred-7137 deletion completed in 6.561214009s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:8.193 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:23:59.349: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-244
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:24:07.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-244" for this suite.
Nov 20 17:24:15.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:24:16.176: INFO: namespace job-244 deletion completed in 8.554890511s

• [SLOW TEST:16.827 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:24:16.176: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2437
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 17:24:16.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-2437'
Nov 20 17:24:16.563: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 20 17:24:16.563: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Nov 20 17:24:18.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2437'
Nov 20 17:24:18.781: INFO: stderr: ""
Nov 20 17:24:18.781: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:24:18.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2437" for this suite.
Nov 20 17:26:30.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:26:31.254: INFO: namespace kubectl-2437 deletion completed in 2m12.45122858s

• [SLOW TEST:135.078 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:26:31.255: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 20 17:26:31.635: INFO: Number of nodes with available pods: 0
Nov 20 17:26:31.635: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:32.732: INFO: Number of nodes with available pods: 0
Nov 20 17:26:32.732: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:33.689: INFO: Number of nodes with available pods: 2
Nov 20 17:26:33.689: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 17:26:34.670: INFO: Number of nodes with available pods: 3
Nov 20 17:26:34.670: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov 20 17:26:34.747: INFO: Number of nodes with available pods: 2
Nov 20 17:26:34.747: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:35.775: INFO: Number of nodes with available pods: 2
Nov 20 17:26:35.775: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:36.809: INFO: Number of nodes with available pods: 2
Nov 20 17:26:36.809: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:37.776: INFO: Number of nodes with available pods: 2
Nov 20 17:26:37.776: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:38.780: INFO: Number of nodes with available pods: 2
Nov 20 17:26:38.780: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:39.776: INFO: Number of nodes with available pods: 2
Nov 20 17:26:39.776: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:40.784: INFO: Number of nodes with available pods: 2
Nov 20 17:26:40.785: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:41.784: INFO: Number of nodes with available pods: 2
Nov 20 17:26:41.785: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:42.781: INFO: Number of nodes with available pods: 2
Nov 20 17:26:42.781: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:43.779: INFO: Number of nodes with available pods: 2
Nov 20 17:26:43.779: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 17:26:44.789: INFO: Number of nodes with available pods: 3
Nov 20 17:26:44.789: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7793, will wait for the garbage collector to delete the pods
Nov 20 17:26:44.872: INFO: Deleting DaemonSet.extensions daemon-set took: 19.311948ms
Nov 20 17:26:45.072: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.339391ms
Nov 20 17:26:56.009: INFO: Number of nodes with available pods: 0
Nov 20 17:26:56.009: INFO: Number of running nodes: 0, number of available pods: 0
Nov 20 17:26:56.019: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7793/daemonsets","resourceVersion":"15756"},"items":null}

Nov 20 17:26:56.031: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7793/pods","resourceVersion":"15756"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:26:56.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7793" for this suite.
Nov 20 17:27:04.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:27:04.684: INFO: namespace daemonsets-7793 deletion completed in 8.575357371s

• [SLOW TEST:33.429 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:27:04.684: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9990
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Nov 20 17:27:04.936: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 20 17:28:04.978: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:28:05.007: INFO: Starting informer...
STEP: Starting pods...
Nov 20 17:28:05.323: INFO: Pod1 is running on 10.184.110.176. Tainting Node
Nov 20 17:28:07.733: INFO: Pod2 is running on 10.184.110.176. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov 20 17:28:25.877: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov 20 17:28:45.879: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:28:45.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9990" for this suite.
Nov 20 17:28:54.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:28:54.416: INFO: namespace taint-multiple-pods-9990 deletion completed in 8.467216656s

• [SLOW TEST:109.732 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:28:54.416: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:28:54.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb" in namespace "downward-api-8858" to be "success or failure"
Nov 20 17:28:54.695: INFO: Pod "downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb": Phase="Pending", Reason="", readiness=false. Elapsed: 13.763568ms
Nov 20 17:28:56.709: INFO: Pod "downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028616644s
STEP: Saw pod success
Nov 20 17:28:56.709: INFO: Pod "downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb" satisfied condition "success or failure"
Nov 20 17:28:56.722: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb container client-container: <nil>
STEP: delete the pod
Nov 20 17:28:56.859: INFO: Waiting for pod downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb to disappear
Nov 20 17:28:56.873: INFO: Pod downwardapi-volume-6d3aa32f-c18a-40ea-9536-bccf2e979ddb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:28:56.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8858" for this suite.
Nov 20 17:29:02.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:29:03.447: INFO: namespace downward-api-8858 deletion completed in 6.552809023s

• [SLOW TEST:9.031 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:29:03.447: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:29:03.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 version'
Nov 20 17:29:03.826: INFO: stderr: ""
Nov 20 17:29:03.826: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3+IKS\", GitCommit:\"6511e42c1f1568ac32d99ae33316985c43dbcca6\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T22:36:46Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:29:03.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2071" for this suite.
Nov 20 17:29:09.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:29:10.561: INFO: namespace kubectl-2071 deletion completed in 6.713220623s

• [SLOW TEST:7.114 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:29:10.561: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5235
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5235.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5235.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5235.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5235.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5235.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5235.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 17:29:21.279: INFO: DNS probes using dns-5235/dns-test-084327e8-24ff-4669-a024-1ad52f3609fd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:29:21.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5235" for this suite.
Nov 20 17:29:29.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:29:29.872: INFO: namespace dns-5235 deletion completed in 8.443012734s

• [SLOW TEST:19.311 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:29:29.872: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-6894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov 20 17:29:34.691: INFO: Successfully updated pod "adopt-release-gvvj5"
STEP: Checking that the Job readopts the Pod
Nov 20 17:29:34.691: INFO: Waiting up to 15m0s for pod "adopt-release-gvvj5" in namespace "job-6894" to be "adopted"
Nov 20 17:29:34.706: INFO: Pod "adopt-release-gvvj5": Phase="Running", Reason="", readiness=true. Elapsed: 15.438462ms
Nov 20 17:29:36.719: INFO: Pod "adopt-release-gvvj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.028637709s
Nov 20 17:29:36.719: INFO: Pod "adopt-release-gvvj5" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov 20 17:29:37.251: INFO: Successfully updated pod "adopt-release-gvvj5"
STEP: Checking that the Job releases the Pod
Nov 20 17:29:37.251: INFO: Waiting up to 15m0s for pod "adopt-release-gvvj5" in namespace "job-6894" to be "released"
Nov 20 17:29:37.265: INFO: Pod "adopt-release-gvvj5": Phase="Running", Reason="", readiness=true. Elapsed: 13.487293ms
Nov 20 17:29:39.279: INFO: Pod "adopt-release-gvvj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.027876382s
Nov 20 17:29:39.279: INFO: Pod "adopt-release-gvvj5" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:29:39.279: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6894" for this suite.
Nov 20 17:30:27.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:30:27.818: INFO: namespace job-6894 deletion completed in 48.494328405s

• [SLOW TEST:57.946 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:30:27.819: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:30:28.432: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:30:30.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867828, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867828, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867828, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709867828, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:30:33.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:30:33.972: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3167" for this suite.
Nov 20 17:30:42.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:30:42.497: INFO: namespace webhook-3167 deletion completed in 8.505994039s
STEP: Destroying namespace "webhook-3167-markers" for this suite.
Nov 20 17:30:48.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:30:48.946: INFO: namespace webhook-3167-markers deletion completed in 6.448492793s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.214 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:30:49.033: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1454
I1120 17:30:49.302104      23 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1454, replica count: 1
I1120 17:30:50.352532      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1120 17:30:51.352750      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 20 17:30:51.478: INFO: Created: latency-svc-jp4rx
Nov 20 17:30:51.488: INFO: Got endpoints: latency-svc-jp4rx [34.883575ms]
Nov 20 17:30:51.526: INFO: Created: latency-svc-gfhqg
Nov 20 17:30:51.528: INFO: Got endpoints: latency-svc-gfhqg [39.642522ms]
Nov 20 17:30:51.537: INFO: Created: latency-svc-8tcrt
Nov 20 17:30:51.541: INFO: Created: latency-svc-xxbkj
Nov 20 17:30:51.544: INFO: Got endpoints: latency-svc-8tcrt [56.34087ms]
Nov 20 17:30:51.554: INFO: Got endpoints: latency-svc-xxbkj [65.4593ms]
Nov 20 17:30:51.554: INFO: Created: latency-svc-jrdfq
Nov 20 17:30:51.565: INFO: Created: latency-svc-mhr6z
Nov 20 17:30:51.565: INFO: Got endpoints: latency-svc-jrdfq [76.394356ms]
Nov 20 17:30:51.574: INFO: Got endpoints: latency-svc-mhr6z [85.106508ms]
Nov 20 17:30:51.575: INFO: Created: latency-svc-vz8x4
Nov 20 17:30:51.585: INFO: Got endpoints: latency-svc-vz8x4 [96.348476ms]
Nov 20 17:30:51.589: INFO: Created: latency-svc-fprt2
Nov 20 17:30:51.602: INFO: Got endpoints: latency-svc-fprt2 [113.482912ms]
Nov 20 17:30:51.603: INFO: Created: latency-svc-9pltf
Nov 20 17:30:51.608: INFO: Got endpoints: latency-svc-9pltf [119.054177ms]
Nov 20 17:30:51.612: INFO: Created: latency-svc-qbjjk
Nov 20 17:30:51.624: INFO: Created: latency-svc-dxwc7
Nov 20 17:30:51.625: INFO: Got endpoints: latency-svc-qbjjk [136.197954ms]
Nov 20 17:30:51.632: INFO: Created: latency-svc-7m7w4
Nov 20 17:30:51.634: INFO: Got endpoints: latency-svc-dxwc7 [145.572581ms]
Nov 20 17:30:51.645: INFO: Got endpoints: latency-svc-7m7w4 [156.096501ms]
Nov 20 17:30:51.646: INFO: Created: latency-svc-qgxfx
Nov 20 17:30:51.654: INFO: Got endpoints: latency-svc-qgxfx [165.575364ms]
Nov 20 17:30:51.655: INFO: Created: latency-svc-22kbl
Nov 20 17:30:51.663: INFO: Got endpoints: latency-svc-22kbl [174.648348ms]
Nov 20 17:30:51.669: INFO: Created: latency-svc-jmdvm
Nov 20 17:30:51.678: INFO: Got endpoints: latency-svc-jmdvm [189.510271ms]
Nov 20 17:30:51.689: INFO: Created: latency-svc-24jxm
Nov 20 17:30:51.700: INFO: Created: latency-svc-ncrbg
Nov 20 17:30:51.718: INFO: Created: latency-svc-28plv
Nov 20 17:30:51.728: INFO: Created: latency-svc-wvf22
Nov 20 17:30:51.742: INFO: Created: latency-svc-pd4lg
Nov 20 17:30:51.756: INFO: Created: latency-svc-jdgzm
Nov 20 17:30:51.756: INFO: Got endpoints: latency-svc-24jxm [266.784637ms]
Nov 20 17:30:51.756: INFO: Got endpoints: latency-svc-ncrbg [228.629259ms]
Nov 20 17:30:51.758: INFO: Got endpoints: latency-svc-wvf22 [203.590726ms]
Nov 20 17:30:51.758: INFO: Got endpoints: latency-svc-28plv [213.323208ms]
Nov 20 17:30:51.758: INFO: Got endpoints: latency-svc-pd4lg [192.993912ms]
Nov 20 17:30:51.768: INFO: Created: latency-svc-ngzvd
Nov 20 17:30:51.772: INFO: Got endpoints: latency-svc-jdgzm [198.24576ms]
Nov 20 17:30:51.781: INFO: Got endpoints: latency-svc-ngzvd [196.324476ms]
Nov 20 17:30:51.783: INFO: Created: latency-svc-g5zzs
Nov 20 17:30:51.797: INFO: Created: latency-svc-989kk
Nov 20 17:30:51.808: INFO: Created: latency-svc-v6p2c
Nov 20 17:30:51.825: INFO: Created: latency-svc-x7nb8
Nov 20 17:30:51.835: INFO: Created: latency-svc-vnlbq
Nov 20 17:30:51.856: INFO: Created: latency-svc-nb59h
Nov 20 17:30:51.860: INFO: Got endpoints: latency-svc-v6p2c [234.632816ms]
Nov 20 17:30:51.860: INFO: Got endpoints: latency-svc-989kk [251.917744ms]
Nov 20 17:30:51.860: INFO: Got endpoints: latency-svc-g5zzs [257.595591ms]
Nov 20 17:30:51.860: INFO: Got endpoints: latency-svc-vnlbq [215.308166ms]
Nov 20 17:30:51.860: INFO: Got endpoints: latency-svc-x7nb8 [226.070636ms]
Nov 20 17:30:51.868: INFO: Created: latency-svc-lfsp6
Nov 20 17:30:51.870: INFO: Got endpoints: latency-svc-nb59h [215.866602ms]
Nov 20 17:30:51.874: INFO: Created: latency-svc-wwk9s
Nov 20 17:30:51.883: INFO: Created: latency-svc-2kbj7
Nov 20 17:30:51.886: INFO: Got endpoints: latency-svc-wwk9s [207.132954ms]
Nov 20 17:30:51.886: INFO: Got endpoints: latency-svc-lfsp6 [222.189241ms]
Nov 20 17:30:51.894: INFO: Got endpoints: latency-svc-2kbj7 [138.57649ms]
Nov 20 17:30:51.896: INFO: Created: latency-svc-7pk77
Nov 20 17:30:51.903: INFO: Got endpoints: latency-svc-7pk77 [146.18596ms]
Nov 20 17:30:51.910: INFO: Created: latency-svc-zfptz
Nov 20 17:30:51.920: INFO: Got endpoints: latency-svc-zfptz [162.127439ms]
Nov 20 17:30:51.921: INFO: Created: latency-svc-hst9r
Nov 20 17:30:51.929: INFO: Got endpoints: latency-svc-hst9r [34.840521ms]
Nov 20 17:30:51.931: INFO: Created: latency-svc-q5l7c
Nov 20 17:30:51.941: INFO: Got endpoints: latency-svc-q5l7c [182.997863ms]
Nov 20 17:30:51.945: INFO: Created: latency-svc-97mtv
Nov 20 17:30:51.957: INFO: Got endpoints: latency-svc-97mtv [199.256404ms]
Nov 20 17:30:51.958: INFO: Created: latency-svc-gcpvm
Nov 20 17:30:51.966: INFO: Got endpoints: latency-svc-gcpvm [193.508564ms]
Nov 20 17:30:51.972: INFO: Created: latency-svc-zq4xc
Nov 20 17:30:51.985: INFO: Got endpoints: latency-svc-zq4xc [203.680069ms]
Nov 20 17:30:51.986: INFO: Created: latency-svc-dvgsj
Nov 20 17:30:51.995: INFO: Got endpoints: latency-svc-dvgsj [134.684208ms]
Nov 20 17:30:51.998: INFO: Created: latency-svc-zdb64
Nov 20 17:30:52.006: INFO: Created: latency-svc-bqx2q
Nov 20 17:30:52.007: INFO: Got endpoints: latency-svc-zdb64 [147.434009ms]
Nov 20 17:30:52.014: INFO: Got endpoints: latency-svc-bqx2q [154.254952ms]
Nov 20 17:30:52.018: INFO: Created: latency-svc-5spcs
Nov 20 17:30:52.025: INFO: Created: latency-svc-mg28x
Nov 20 17:30:52.028: INFO: Got endpoints: latency-svc-5spcs [167.637645ms]
Nov 20 17:30:52.036: INFO: Got endpoints: latency-svc-mg28x [175.888958ms]
Nov 20 17:30:52.039: INFO: Created: latency-svc-k28b2
Nov 20 17:30:52.048: INFO: Created: latency-svc-jcw5t
Nov 20 17:30:52.051: INFO: Got endpoints: latency-svc-k28b2 [180.396471ms]
Nov 20 17:30:52.055: INFO: Got endpoints: latency-svc-jcw5t [169.319525ms]
Nov 20 17:30:52.059: INFO: Created: latency-svc-cnw2k
Nov 20 17:30:52.066: INFO: Got endpoints: latency-svc-cnw2k [180.706619ms]
Nov 20 17:30:52.071: INFO: Created: latency-svc-2swc8
Nov 20 17:30:52.082: INFO: Got endpoints: latency-svc-2swc8 [178.672304ms]
Nov 20 17:30:52.082: INFO: Created: latency-svc-fcggh
Nov 20 17:30:52.095: INFO: Created: latency-svc-vnslt
Nov 20 17:30:52.096: INFO: Got endpoints: latency-svc-fcggh [176.048298ms]
Nov 20 17:30:52.103: INFO: Got endpoints: latency-svc-vnslt [174.317956ms]
Nov 20 17:30:52.104: INFO: Created: latency-svc-dp9tw
Nov 20 17:30:52.115: INFO: Got endpoints: latency-svc-dp9tw [173.935729ms]
Nov 20 17:30:52.115: INFO: Created: latency-svc-8x29c
Nov 20 17:30:52.123: INFO: Got endpoints: latency-svc-8x29c [165.685698ms]
Nov 20 17:30:52.131: INFO: Created: latency-svc-sdl78
Nov 20 17:30:52.138: INFO: Got endpoints: latency-svc-sdl78 [172.509174ms]
Nov 20 17:30:52.143: INFO: Created: latency-svc-pzbhs
Nov 20 17:30:52.153: INFO: Created: latency-svc-vcqhw
Nov 20 17:30:52.153: INFO: Got endpoints: latency-svc-pzbhs [167.642699ms]
Nov 20 17:30:52.160: INFO: Got endpoints: latency-svc-vcqhw [165.361138ms]
Nov 20 17:30:52.162: INFO: Created: latency-svc-ds8nf
Nov 20 17:30:52.172: INFO: Got endpoints: latency-svc-ds8nf [164.992377ms]
Nov 20 17:30:52.177: INFO: Created: latency-svc-88btz
Nov 20 17:30:52.186: INFO: Got endpoints: latency-svc-88btz [171.98647ms]
Nov 20 17:30:52.189: INFO: Created: latency-svc-dhcd6
Nov 20 17:30:52.197: INFO: Got endpoints: latency-svc-dhcd6 [168.653893ms]
Nov 20 17:30:52.202: INFO: Created: latency-svc-qdbpg
Nov 20 17:30:52.209: INFO: Got endpoints: latency-svc-qdbpg [172.297544ms]
Nov 20 17:30:52.214: INFO: Created: latency-svc-blgjn
Nov 20 17:30:52.223: INFO: Created: latency-svc-hnbdc
Nov 20 17:30:52.225: INFO: Got endpoints: latency-svc-blgjn [174.09442ms]
Nov 20 17:30:52.232: INFO: Got endpoints: latency-svc-hnbdc [176.400032ms]
Nov 20 17:30:52.233: INFO: Created: latency-svc-z8ll2
Nov 20 17:30:52.248: INFO: Got endpoints: latency-svc-z8ll2 [182.057049ms]
Nov 20 17:30:52.253: INFO: Created: latency-svc-k2chq
Nov 20 17:30:52.259: INFO: Created: latency-svc-2p558
Nov 20 17:30:52.260: INFO: Got endpoints: latency-svc-k2chq [178.363369ms]
Nov 20 17:30:52.267: INFO: Got endpoints: latency-svc-2p558 [171.467038ms]
Nov 20 17:30:52.268: INFO: Created: latency-svc-hjzvs
Nov 20 17:30:52.277: INFO: Created: latency-svc-td9d7
Nov 20 17:30:52.278: INFO: Got endpoints: latency-svc-hjzvs [173.988803ms]
Nov 20 17:30:52.285: INFO: Got endpoints: latency-svc-td9d7 [170.347613ms]
Nov 20 17:30:52.292: INFO: Created: latency-svc-sbmch
Nov 20 17:30:52.301: INFO: Got endpoints: latency-svc-sbmch [177.530538ms]
Nov 20 17:30:52.301: INFO: Created: latency-svc-ngkqr
Nov 20 17:30:52.307: INFO: Got endpoints: latency-svc-ngkqr [168.540695ms]
Nov 20 17:30:52.314: INFO: Created: latency-svc-9gcz2
Nov 20 17:30:52.324: INFO: Got endpoints: latency-svc-9gcz2 [171.133979ms]
Nov 20 17:30:52.325: INFO: Created: latency-svc-6ksq8
Nov 20 17:30:52.335: INFO: Got endpoints: latency-svc-6ksq8 [174.527677ms]
Nov 20 17:30:52.340: INFO: Created: latency-svc-nnrgk
Nov 20 17:30:52.348: INFO: Got endpoints: latency-svc-nnrgk [175.919876ms]
Nov 20 17:30:52.349: INFO: Created: latency-svc-4zzz5
Nov 20 17:30:52.358: INFO: Got endpoints: latency-svc-4zzz5 [171.648131ms]
Nov 20 17:30:52.363: INFO: Created: latency-svc-4qxsj
Nov 20 17:30:52.370: INFO: Got endpoints: latency-svc-4qxsj [172.996592ms]
Nov 20 17:30:52.371: INFO: Created: latency-svc-gpzck
Nov 20 17:30:52.378: INFO: Got endpoints: latency-svc-gpzck [169.444649ms]
Nov 20 17:30:52.382: INFO: Created: latency-svc-59tw9
Nov 20 17:30:52.391: INFO: Got endpoints: latency-svc-59tw9 [165.734029ms]
Nov 20 17:30:52.395: INFO: Created: latency-svc-2pglq
Nov 20 17:30:52.404: INFO: Got endpoints: latency-svc-2pglq [172.331351ms]
Nov 20 17:30:52.412: INFO: Created: latency-svc-bvmsb
Nov 20 17:30:52.419: INFO: Created: latency-svc-r7gz8
Nov 20 17:30:52.420: INFO: Got endpoints: latency-svc-bvmsb [171.569233ms]
Nov 20 17:30:52.429: INFO: Got endpoints: latency-svc-r7gz8 [169.093389ms]
Nov 20 17:30:52.432: INFO: Created: latency-svc-b6qt6
Nov 20 17:30:52.439: INFO: Created: latency-svc-679gv
Nov 20 17:30:52.443: INFO: Got endpoints: latency-svc-b6qt6 [175.141653ms]
Nov 20 17:30:52.448: INFO: Got endpoints: latency-svc-679gv [170.613892ms]
Nov 20 17:30:52.456: INFO: Created: latency-svc-nvpkf
Nov 20 17:30:52.464: INFO: Got endpoints: latency-svc-nvpkf [179.205266ms]
Nov 20 17:30:52.469: INFO: Created: latency-svc-xmkxl
Nov 20 17:30:52.475: INFO: Got endpoints: latency-svc-xmkxl [174.611861ms]
Nov 20 17:30:52.493: INFO: Created: latency-svc-vqcz9
Nov 20 17:30:52.494: INFO: Created: latency-svc-rvjlf
Nov 20 17:30:52.503: INFO: Got endpoints: latency-svc-vqcz9 [195.959451ms]
Nov 20 17:30:52.504: INFO: Created: latency-svc-xmnvg
Nov 20 17:30:52.504: INFO: Got endpoints: latency-svc-rvjlf [180.144643ms]
Nov 20 17:30:52.514: INFO: Got endpoints: latency-svc-xmnvg [179.034386ms]
Nov 20 17:30:52.515: INFO: Created: latency-svc-w22vs
Nov 20 17:30:52.526: INFO: Got endpoints: latency-svc-w22vs [177.32807ms]
Nov 20 17:30:52.527: INFO: Created: latency-svc-bzjgh
Nov 20 17:30:52.536: INFO: Got endpoints: latency-svc-bzjgh [177.769012ms]
Nov 20 17:30:52.539: INFO: Created: latency-svc-pvtgx
Nov 20 17:30:52.550: INFO: Got endpoints: latency-svc-pvtgx [180.098466ms]
Nov 20 17:30:52.560: INFO: Created: latency-svc-q286g
Nov 20 17:30:52.565: INFO: Created: latency-svc-nrhk5
Nov 20 17:30:52.566: INFO: Got endpoints: latency-svc-q286g [188.187263ms]
Nov 20 17:30:52.574: INFO: Got endpoints: latency-svc-nrhk5 [182.85898ms]
Nov 20 17:30:52.579: INFO: Created: latency-svc-kz49z
Nov 20 17:30:52.585: INFO: Got endpoints: latency-svc-kz49z [180.759728ms]
Nov 20 17:30:52.588: INFO: Created: latency-svc-prxnd
Nov 20 17:30:52.603: INFO: Created: latency-svc-bzgzc
Nov 20 17:30:52.615: INFO: Created: latency-svc-pl9wv
Nov 20 17:30:52.630: INFO: Created: latency-svc-lb4qg
Nov 20 17:30:52.640: INFO: Got endpoints: latency-svc-lb4qg [191.391405ms]
Nov 20 17:30:52.640: INFO: Got endpoints: latency-svc-bzgzc [210.266251ms]
Nov 20 17:30:52.640: INFO: Got endpoints: latency-svc-prxnd [219.771689ms]
Nov 20 17:30:52.640: INFO: Got endpoints: latency-svc-pl9wv [197.423597ms]
Nov 20 17:30:52.643: INFO: Created: latency-svc-kkgb7
Nov 20 17:30:52.652: INFO: Got endpoints: latency-svc-kkgb7 [188.047679ms]
Nov 20 17:30:52.654: INFO: Created: latency-svc-kd6m9
Nov 20 17:30:52.664: INFO: Got endpoints: latency-svc-kd6m9 [188.834651ms]
Nov 20 17:30:52.665: INFO: Created: latency-svc-8nlfw
Nov 20 17:30:52.674: INFO: Got endpoints: latency-svc-8nlfw [170.753115ms]
Nov 20 17:30:52.676: INFO: Created: latency-svc-ccrh6
Nov 20 17:30:52.688: INFO: Got endpoints: latency-svc-ccrh6 [183.352666ms]
Nov 20 17:30:52.689: INFO: Created: latency-svc-x8m94
Nov 20 17:30:52.697: INFO: Got endpoints: latency-svc-x8m94 [183.553295ms]
Nov 20 17:30:52.700: INFO: Created: latency-svc-2fdnv
Nov 20 17:30:52.710: INFO: Got endpoints: latency-svc-2fdnv [184.275292ms]
Nov 20 17:30:52.712: INFO: Created: latency-svc-txmhr
Nov 20 17:30:52.720: INFO: Got endpoints: latency-svc-txmhr [184.122766ms]
Nov 20 17:30:52.726: INFO: Created: latency-svc-hkgkv
Nov 20 17:30:52.737: INFO: Got endpoints: latency-svc-hkgkv [186.873204ms]
Nov 20 17:30:52.738: INFO: Created: latency-svc-5ddr8
Nov 20 17:30:52.747: INFO: Got endpoints: latency-svc-5ddr8 [180.255199ms]
Nov 20 17:30:52.748: INFO: Created: latency-svc-5zkqk
Nov 20 17:30:52.758: INFO: Got endpoints: latency-svc-5zkqk [184.145507ms]
Nov 20 17:30:52.759: INFO: Created: latency-svc-d8ms5
Nov 20 17:30:52.771: INFO: Created: latency-svc-8j9x2
Nov 20 17:30:52.771: INFO: Got endpoints: latency-svc-d8ms5 [186.539116ms]
Nov 20 17:30:52.783: INFO: Created: latency-svc-pp6mz
Nov 20 17:30:52.783: INFO: Got endpoints: latency-svc-8j9x2 [142.550112ms]
Nov 20 17:30:52.797: INFO: Got endpoints: latency-svc-pp6mz [157.571755ms]
Nov 20 17:30:52.801: INFO: Created: latency-svc-lsf6w
Nov 20 17:30:52.809: INFO: Got endpoints: latency-svc-lsf6w [168.934268ms]
Nov 20 17:30:52.815: INFO: Created: latency-svc-sfs5p
Nov 20 17:30:52.823: INFO: Created: latency-svc-rrt2g
Nov 20 17:30:52.823: INFO: Got endpoints: latency-svc-sfs5p [183.592184ms]
Nov 20 17:30:52.837: INFO: Created: latency-svc-7fcfb
Nov 20 17:30:52.837: INFO: Got endpoints: latency-svc-rrt2g [184.97122ms]
Nov 20 17:30:52.848: INFO: Got endpoints: latency-svc-7fcfb [183.646772ms]
Nov 20 17:30:52.870: INFO: Created: latency-svc-8dsnz
Nov 20 17:30:52.870: INFO: Created: latency-svc-txwps
Nov 20 17:30:52.872: INFO: Created: latency-svc-kdmr4
Nov 20 17:30:52.882: INFO: Got endpoints: latency-svc-kdmr4 [184.417144ms]
Nov 20 17:30:52.882: INFO: Got endpoints: latency-svc-8dsnz [208.35549ms]
Nov 20 17:30:52.882: INFO: Created: latency-svc-bc9cg
Nov 20 17:30:52.883: INFO: Got endpoints: latency-svc-txwps [194.903617ms]
Nov 20 17:30:52.895: INFO: Got endpoints: latency-svc-bc9cg [184.827199ms]
Nov 20 17:30:52.896: INFO: Created: latency-svc-7k2ph
Nov 20 17:30:52.903: INFO: Got endpoints: latency-svc-7k2ph [182.615661ms]
Nov 20 17:30:52.907: INFO: Created: latency-svc-8kslr
Nov 20 17:30:52.922: INFO: Created: latency-svc-7ccpw
Nov 20 17:30:52.935: INFO: Created: latency-svc-llddr
Nov 20 17:30:52.935: INFO: Got endpoints: latency-svc-7ccpw [188.32492ms]
Nov 20 17:30:52.935: INFO: Got endpoints: latency-svc-8kslr [198.201371ms]
Nov 20 17:30:52.944: INFO: Got endpoints: latency-svc-llddr [186.137663ms]
Nov 20 17:30:52.966: INFO: Created: latency-svc-xxwcs
Nov 20 17:30:52.966: INFO: Created: latency-svc-rgfqf
Nov 20 17:30:52.973: INFO: Created: latency-svc-ls544
Nov 20 17:30:52.975: INFO: Got endpoints: latency-svc-rgfqf [191.385352ms]
Nov 20 17:30:52.975: INFO: Got endpoints: latency-svc-xxwcs [203.544679ms]
Nov 20 17:30:52.983: INFO: Got endpoints: latency-svc-ls544 [185.962204ms]
Nov 20 17:30:52.986: INFO: Created: latency-svc-j4ms7
Nov 20 17:30:52.994: INFO: Got endpoints: latency-svc-j4ms7 [184.49469ms]
Nov 20 17:30:52.999: INFO: Created: latency-svc-vlx29
Nov 20 17:30:53.008: INFO: Got endpoints: latency-svc-vlx29 [184.305035ms]
Nov 20 17:30:53.009: INFO: Created: latency-svc-rh275
Nov 20 17:30:53.021: INFO: Got endpoints: latency-svc-rh275 [183.245042ms]
Nov 20 17:30:53.022: INFO: Created: latency-svc-48vfz
Nov 20 17:30:53.030: INFO: Created: latency-svc-d68mg
Nov 20 17:30:53.031: INFO: Got endpoints: latency-svc-48vfz [183.138985ms]
Nov 20 17:30:53.040: INFO: Created: latency-svc-28hbq
Nov 20 17:30:53.040: INFO: Got endpoints: latency-svc-d68mg [158.422893ms]
Nov 20 17:30:53.052: INFO: Got endpoints: latency-svc-28hbq [170.284443ms]
Nov 20 17:30:53.055: INFO: Created: latency-svc-pnqzz
Nov 20 17:30:53.061: INFO: Created: latency-svc-mvrkf
Nov 20 17:30:53.062: INFO: Got endpoints: latency-svc-pnqzz [179.790783ms]
Nov 20 17:30:53.071: INFO: Got endpoints: latency-svc-mvrkf [175.832697ms]
Nov 20 17:30:53.072: INFO: Created: latency-svc-ctv9j
Nov 20 17:30:53.083: INFO: Got endpoints: latency-svc-ctv9j [180.508042ms]
Nov 20 17:30:53.084: INFO: Created: latency-svc-vhjxj
Nov 20 17:30:53.091: INFO: Got endpoints: latency-svc-vhjxj [156.108213ms]
Nov 20 17:30:53.098: INFO: Created: latency-svc-fzpnw
Nov 20 17:30:53.109: INFO: Got endpoints: latency-svc-fzpnw [173.716314ms]
Nov 20 17:30:53.109: INFO: Created: latency-svc-4kkmn
Nov 20 17:30:53.116: INFO: Got endpoints: latency-svc-4kkmn [171.821669ms]
Nov 20 17:30:53.116: INFO: Created: latency-svc-krbpt
Nov 20 17:30:53.125: INFO: Got endpoints: latency-svc-krbpt [149.724989ms]
Nov 20 17:30:53.135: INFO: Created: latency-svc-xk7nx
Nov 20 17:30:53.144: INFO: Created: latency-svc-g4tcf
Nov 20 17:30:53.149: INFO: Got endpoints: latency-svc-xk7nx [174.50425ms]
Nov 20 17:30:53.153: INFO: Got endpoints: latency-svc-g4tcf [169.901313ms]
Nov 20 17:30:53.155: INFO: Created: latency-svc-q6qwn
Nov 20 17:30:53.165: INFO: Got endpoints: latency-svc-q6qwn [171.574418ms]
Nov 20 17:30:53.165: INFO: Created: latency-svc-4cbk7
Nov 20 17:30:53.175: INFO: Got endpoints: latency-svc-4cbk7 [167.463574ms]
Nov 20 17:30:53.177: INFO: Created: latency-svc-gt4mb
Nov 20 17:30:53.189: INFO: Got endpoints: latency-svc-gt4mb [168.27581ms]
Nov 20 17:30:53.191: INFO: Created: latency-svc-vmmx8
Nov 20 17:30:53.203: INFO: Got endpoints: latency-svc-vmmx8 [171.968488ms]
Nov 20 17:30:53.205: INFO: Created: latency-svc-42x75
Nov 20 17:30:53.212: INFO: Got endpoints: latency-svc-42x75 [171.501525ms]
Nov 20 17:30:53.217: INFO: Created: latency-svc-c5fdn
Nov 20 17:30:53.223: INFO: Got endpoints: latency-svc-c5fdn [170.488303ms]
Nov 20 17:30:53.223: INFO: Created: latency-svc-66svv
Nov 20 17:30:53.234: INFO: Got endpoints: latency-svc-66svv [172.06371ms]
Nov 20 17:30:53.237: INFO: Created: latency-svc-t7hbj
Nov 20 17:30:53.245: INFO: Got endpoints: latency-svc-t7hbj [174.837046ms]
Nov 20 17:30:53.253: INFO: Created: latency-svc-9ctjr
Nov 20 17:30:53.261: INFO: Got endpoints: latency-svc-9ctjr [177.382876ms]
Nov 20 17:30:53.267: INFO: Created: latency-svc-dzkrz
Nov 20 17:30:53.275: INFO: Created: latency-svc-lzq7h
Nov 20 17:30:53.277: INFO: Got endpoints: latency-svc-dzkrz [185.430706ms]
Nov 20 17:30:53.292: INFO: Created: latency-svc-zvpkl
Nov 20 17:30:53.292: INFO: Got endpoints: latency-svc-lzq7h [182.909263ms]
Nov 20 17:30:53.298: INFO: Got endpoints: latency-svc-zvpkl [182.602293ms]
Nov 20 17:30:53.305: INFO: Created: latency-svc-xftfd
Nov 20 17:30:53.311: INFO: Created: latency-svc-fn45k
Nov 20 17:30:53.313: INFO: Got endpoints: latency-svc-xftfd [188.742126ms]
Nov 20 17:30:53.318: INFO: Got endpoints: latency-svc-fn45k [168.614166ms]
Nov 20 17:30:53.320: INFO: Created: latency-svc-t8z5b
Nov 20 17:30:53.330: INFO: Got endpoints: latency-svc-t8z5b [176.42597ms]
Nov 20 17:30:53.336: INFO: Created: latency-svc-v8g6v
Nov 20 17:30:53.341: INFO: Created: latency-svc-bpdzw
Nov 20 17:30:53.344: INFO: Got endpoints: latency-svc-v8g6v [178.596949ms]
Nov 20 17:30:53.352: INFO: Created: latency-svc-r486x
Nov 20 17:30:53.352: INFO: Got endpoints: latency-svc-bpdzw [176.577269ms]
Nov 20 17:30:53.363: INFO: Created: latency-svc-7pwct
Nov 20 17:30:53.363: INFO: Got endpoints: latency-svc-r486x [173.735665ms]
Nov 20 17:30:53.371: INFO: Got endpoints: latency-svc-7pwct [167.710407ms]
Nov 20 17:30:53.372: INFO: Created: latency-svc-79xtw
Nov 20 17:30:53.384: INFO: Created: latency-svc-qxh5x
Nov 20 17:30:53.384: INFO: Got endpoints: latency-svc-79xtw [172.03317ms]
Nov 20 17:30:53.389: INFO: Got endpoints: latency-svc-qxh5x [165.750316ms]
Nov 20 17:30:53.395: INFO: Created: latency-svc-w2b5s
Nov 20 17:30:53.404: INFO: Got endpoints: latency-svc-w2b5s [169.708943ms]
Nov 20 17:30:53.408: INFO: Created: latency-svc-2x5c7
Nov 20 17:30:53.415: INFO: Got endpoints: latency-svc-2x5c7 [169.729083ms]
Nov 20 17:30:53.419: INFO: Created: latency-svc-984t9
Nov 20 17:30:53.427: INFO: Got endpoints: latency-svc-984t9 [166.565144ms]
Nov 20 17:30:53.431: INFO: Created: latency-svc-bqjbl
Nov 20 17:30:53.437: INFO: Got endpoints: latency-svc-bqjbl [160.525351ms]
Nov 20 17:30:53.444: INFO: Created: latency-svc-dlq6h
Nov 20 17:30:53.454: INFO: Got endpoints: latency-svc-dlq6h [161.619556ms]
Nov 20 17:30:53.460: INFO: Created: latency-svc-c58bf
Nov 20 17:30:53.468: INFO: Created: latency-svc-q49j2
Nov 20 17:30:53.469: INFO: Got endpoints: latency-svc-c58bf [170.678509ms]
Nov 20 17:30:53.478: INFO: Got endpoints: latency-svc-q49j2 [164.445075ms]
Nov 20 17:30:53.481: INFO: Created: latency-svc-65fml
Nov 20 17:30:53.490: INFO: Got endpoints: latency-svc-65fml [172.110435ms]
Nov 20 17:30:53.493: INFO: Created: latency-svc-q6db6
Nov 20 17:30:53.502: INFO: Got endpoints: latency-svc-q6db6 [172.328231ms]
Nov 20 17:30:53.505: INFO: Created: latency-svc-r26z7
Nov 20 17:30:53.515: INFO: Got endpoints: latency-svc-r26z7 [171.324569ms]
Nov 20 17:30:53.517: INFO: Created: latency-svc-jfr22
Nov 20 17:30:53.526: INFO: Created: latency-svc-cpppr
Nov 20 17:30:53.528: INFO: Got endpoints: latency-svc-jfr22 [175.270242ms]
Nov 20 17:30:53.534: INFO: Got endpoints: latency-svc-cpppr [170.986993ms]
Nov 20 17:30:53.542: INFO: Created: latency-svc-8s42l
Nov 20 17:30:53.554: INFO: Got endpoints: latency-svc-8s42l [182.305783ms]
Nov 20 17:30:53.554: INFO: Created: latency-svc-5fj62
Nov 20 17:30:53.562: INFO: Got endpoints: latency-svc-5fj62 [177.899314ms]
Nov 20 17:30:53.563: INFO: Created: latency-svc-bnt2m
Nov 20 17:30:53.570: INFO: Got endpoints: latency-svc-bnt2m [181.492626ms]
Nov 20 17:30:53.577: INFO: Created: latency-svc-nhwsz
Nov 20 17:30:53.587: INFO: Got endpoints: latency-svc-nhwsz [182.513133ms]
Nov 20 17:30:53.589: INFO: Created: latency-svc-hlg6k
Nov 20 17:30:53.599: INFO: Got endpoints: latency-svc-hlg6k [183.447033ms]
Nov 20 17:30:53.602: INFO: Created: latency-svc-mv5lg
Nov 20 17:30:53.610: INFO: Got endpoints: latency-svc-mv5lg [182.400506ms]
Nov 20 17:30:53.612: INFO: Created: latency-svc-z6xht
Nov 20 17:30:53.621: INFO: Got endpoints: latency-svc-z6xht [183.582653ms]
Nov 20 17:30:53.628: INFO: Created: latency-svc-7ltl2
Nov 20 17:30:53.636: INFO: Got endpoints: latency-svc-7ltl2 [182.025024ms]
Nov 20 17:30:53.642: INFO: Created: latency-svc-xlhfg
Nov 20 17:30:53.650: INFO: Created: latency-svc-f8nnt
Nov 20 17:30:53.652: INFO: Got endpoints: latency-svc-xlhfg [182.50736ms]
Nov 20 17:30:53.662: INFO: Got endpoints: latency-svc-f8nnt [184.057716ms]
Nov 20 17:30:53.664: INFO: Created: latency-svc-qgvjh
Nov 20 17:30:53.674: INFO: Got endpoints: latency-svc-qgvjh [183.69569ms]
Nov 20 17:30:53.679: INFO: Created: latency-svc-hx8h6
Nov 20 17:30:53.691: INFO: Got endpoints: latency-svc-hx8h6 [188.612191ms]
Nov 20 17:30:53.697: INFO: Created: latency-svc-5tw7v
Nov 20 17:30:53.705: INFO: Got endpoints: latency-svc-5tw7v [190.141371ms]
Nov 20 17:30:53.734: INFO: Created: latency-svc-9zj2t
Nov 20 17:30:53.739: INFO: Created: latency-svc-8tbfx
Nov 20 17:30:53.739: INFO: Created: latency-svc-6cptq
Nov 20 17:30:53.739: INFO: Created: latency-svc-ns5fj
Nov 20 17:30:53.751: INFO: Got endpoints: latency-svc-6cptq [217.379692ms]
Nov 20 17:30:53.751: INFO: Got endpoints: latency-svc-9zj2t [223.845168ms]
Nov 20 17:30:53.752: INFO: Created: latency-svc-xgtfm
Nov 20 17:30:53.753: INFO: Got endpoints: latency-svc-ns5fj [190.358014ms]
Nov 20 17:30:53.753: INFO: Got endpoints: latency-svc-8tbfx [199.211668ms]
Nov 20 17:30:53.761: INFO: Got endpoints: latency-svc-xgtfm [191.105941ms]
Nov 20 17:30:53.787: INFO: Created: latency-svc-5dbr6
Nov 20 17:30:53.787: INFO: Created: latency-svc-7khxn
Nov 20 17:30:53.787: INFO: Created: latency-svc-p2f7r
Nov 20 17:30:53.798: INFO: Created: latency-svc-sj8dg
Nov 20 17:30:53.801: INFO: Got endpoints: latency-svc-5dbr6 [213.823432ms]
Nov 20 17:30:53.801: INFO: Got endpoints: latency-svc-p2f7r [191.064519ms]
Nov 20 17:30:53.801: INFO: Got endpoints: latency-svc-7khxn [202.214181ms]
Nov 20 17:30:53.832: INFO: Created: latency-svc-gnkcz
Nov 20 17:30:53.832: INFO: Created: latency-svc-m8w8g
Nov 20 17:30:53.833: INFO: Got endpoints: latency-svc-gnkcz [196.815445ms]
Nov 20 17:30:53.833: INFO: Got endpoints: latency-svc-sj8dg [211.630326ms]
Nov 20 17:30:53.840: INFO: Got endpoints: latency-svc-m8w8g [188.497524ms]
Nov 20 17:30:53.847: INFO: Created: latency-svc-mx2j5
Nov 20 17:30:53.856: INFO: Got endpoints: latency-svc-mx2j5 [193.801212ms]
Nov 20 17:30:53.873: INFO: Created: latency-svc-zwh6c
Nov 20 17:30:53.879: INFO: Got endpoints: latency-svc-zwh6c [204.650934ms]
Nov 20 17:30:53.882: INFO: Created: latency-svc-ckdh6
Nov 20 17:30:53.891: INFO: Got endpoints: latency-svc-ckdh6 [200.317103ms]
Nov 20 17:30:53.892: INFO: Created: latency-svc-6sng9
Nov 20 17:30:53.901: INFO: Got endpoints: latency-svc-6sng9 [195.215494ms]
Nov 20 17:30:53.908: INFO: Created: latency-svc-82x6b
Nov 20 17:30:53.913: INFO: Got endpoints: latency-svc-82x6b [161.889798ms]
Nov 20 17:30:53.914: INFO: Created: latency-svc-xmvpm
Nov 20 17:30:53.923: INFO: Got endpoints: latency-svc-xmvpm [171.47626ms]
Nov 20 17:30:53.928: INFO: Created: latency-svc-df92l
Nov 20 17:30:53.938: INFO: Got endpoints: latency-svc-df92l [185.422998ms]
Nov 20 17:30:53.938: INFO: Latencies: [34.840521ms 39.642522ms 56.34087ms 65.4593ms 76.394356ms 85.106508ms 96.348476ms 113.482912ms 119.054177ms 134.684208ms 136.197954ms 138.57649ms 142.550112ms 145.572581ms 146.18596ms 147.434009ms 149.724989ms 154.254952ms 156.096501ms 156.108213ms 157.571755ms 158.422893ms 160.525351ms 161.619556ms 161.889798ms 162.127439ms 164.445075ms 164.992377ms 165.361138ms 165.575364ms 165.685698ms 165.734029ms 165.750316ms 166.565144ms 167.463574ms 167.637645ms 167.642699ms 167.710407ms 168.27581ms 168.540695ms 168.614166ms 168.653893ms 168.934268ms 169.093389ms 169.319525ms 169.444649ms 169.708943ms 169.729083ms 169.901313ms 170.284443ms 170.347613ms 170.488303ms 170.613892ms 170.678509ms 170.753115ms 170.986993ms 171.133979ms 171.324569ms 171.467038ms 171.47626ms 171.501525ms 171.569233ms 171.574418ms 171.648131ms 171.821669ms 171.968488ms 171.98647ms 172.03317ms 172.06371ms 172.110435ms 172.297544ms 172.328231ms 172.331351ms 172.509174ms 172.996592ms 173.716314ms 173.735665ms 173.935729ms 173.988803ms 174.09442ms 174.317956ms 174.50425ms 174.527677ms 174.611861ms 174.648348ms 174.837046ms 175.141653ms 175.270242ms 175.832697ms 175.888958ms 175.919876ms 176.048298ms 176.400032ms 176.42597ms 176.577269ms 177.32807ms 177.382876ms 177.530538ms 177.769012ms 177.899314ms 178.363369ms 178.596949ms 178.672304ms 179.034386ms 179.205266ms 179.790783ms 180.098466ms 180.144643ms 180.255199ms 180.396471ms 180.508042ms 180.706619ms 180.759728ms 181.492626ms 182.025024ms 182.057049ms 182.305783ms 182.400506ms 182.50736ms 182.513133ms 182.602293ms 182.615661ms 182.85898ms 182.909263ms 182.997863ms 183.138985ms 183.245042ms 183.352666ms 183.447033ms 183.553295ms 183.582653ms 183.592184ms 183.646772ms 183.69569ms 184.057716ms 184.122766ms 184.145507ms 184.275292ms 184.305035ms 184.417144ms 184.49469ms 184.827199ms 184.97122ms 185.422998ms 185.430706ms 185.962204ms 186.137663ms 186.539116ms 186.873204ms 188.047679ms 188.187263ms 188.32492ms 188.497524ms 188.612191ms 188.742126ms 188.834651ms 189.510271ms 190.141371ms 190.358014ms 191.064519ms 191.105941ms 191.385352ms 191.391405ms 192.993912ms 193.508564ms 193.801212ms 194.903617ms 195.215494ms 195.959451ms 196.324476ms 196.815445ms 197.423597ms 198.201371ms 198.24576ms 199.211668ms 199.256404ms 200.317103ms 202.214181ms 203.544679ms 203.590726ms 203.680069ms 204.650934ms 207.132954ms 208.35549ms 210.266251ms 211.630326ms 213.323208ms 213.823432ms 215.308166ms 215.866602ms 217.379692ms 219.771689ms 222.189241ms 223.845168ms 226.070636ms 228.629259ms 234.632816ms 251.917744ms 257.595591ms 266.784637ms]
Nov 20 17:30:53.938: INFO: 50 %ile: 178.363369ms
Nov 20 17:30:53.938: INFO: 90 %ile: 203.680069ms
Nov 20 17:30:53.938: INFO: 99 %ile: 257.595591ms
Nov 20 17:30:53.938: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:30:53.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1454" for this suite.
Nov 20 17:31:16.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:31:16.691: INFO: namespace svc-latency-1454 deletion completed in 22.733391737s

• [SLOW TEST:27.658 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:31:16.691: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8007
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Nov 20 17:31:16.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 api-versions'
Nov 20 17:31:17.050: INFO: stderr: ""
Nov 20 17:31:17.050: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\noperators.coreos.com/v1alpha2\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:31:17.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8007" for this suite.
Nov 20 17:31:23.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:31:23.721: INFO: namespace kubectl-8007 deletion completed in 6.649356726s

• [SLOW TEST:7.030 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:31:23.721: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8214
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-e12d172f-f719-4f89-9d95-7a8caf74742d
STEP: Creating a pod to test consume secrets
Nov 20 17:31:24.038: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76" in namespace "projected-8214" to be "success or failure"
Nov 20 17:31:24.057: INFO: Pod "pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76": Phase="Pending", Reason="", readiness=false. Elapsed: 17.93052ms
Nov 20 17:31:26.078: INFO: Pod "pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039209889s
STEP: Saw pod success
Nov 20 17:31:26.078: INFO: Pod "pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76" satisfied condition "success or failure"
Nov 20 17:31:26.097: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:31:26.303: INFO: Waiting for pod pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76 to disappear
Nov 20 17:31:26.346: INFO: Pod pod-projected-secrets-b17af14f-71ec-4035-b81d-2f7a2a261a76 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:31:26.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8214" for this suite.
Nov 20 17:31:32.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:31:32.926: INFO: namespace projected-8214 deletion completed in 6.518110036s

• [SLOW TEST:9.205 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:31:32.926: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov 20 17:31:33.150: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:31:37.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9488" for this suite.
Nov 20 17:32:07.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:32:08.325: INFO: namespace init-container-9488 deletion completed in 30.532760251s

• [SLOW TEST:35.399 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:32:08.326: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-005ce417-2356-426f-84dd-684c4da6a4dc
STEP: Creating a pod to test consume configMaps
Nov 20 17:32:08.606: INFO: Waiting up to 5m0s for pod "pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f" in namespace "configmap-5897" to be "success or failure"
Nov 20 17:32:08.621: INFO: Pod "pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.311057ms
Nov 20 17:32:10.650: INFO: Pod "pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043777743s
Nov 20 17:32:12.666: INFO: Pod "pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05957255s
STEP: Saw pod success
Nov 20 17:32:12.666: INFO: Pod "pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f" satisfied condition "success or failure"
Nov 20 17:32:12.678: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 17:32:12.783: INFO: Waiting for pod pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f to disappear
Nov 20 17:32:12.807: INFO: Pod pod-configmaps-03b485fc-b6b8-4dd3-9ab0-056625dc0c0f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:32:12.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5897" for this suite.
Nov 20 17:32:21.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:32:21.482: INFO: namespace configmap-5897 deletion completed in 8.549825695s

• [SLOW TEST:13.156 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:32:21.482: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1444
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:32:21.725: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:32:26.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1444" for this suite.
Nov 20 17:32:32.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:32:32.633: INFO: namespace custom-resource-definition-1444 deletion completed in 6.446166065s

• [SLOW TEST:11.151 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:32:32.634: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:32:39.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2609" for this suite.
Nov 20 17:32:45.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:32:46.377: INFO: namespace resourcequota-2609 deletion completed in 6.470041824s

• [SLOW TEST:13.743 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:32:46.380: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-136
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Nov 20 17:32:46.639: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-136" to be "success or failure"
Nov 20 17:32:46.656: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 16.670819ms
Nov 20 17:32:48.668: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028683436s
Nov 20 17:32:50.681: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041645927s
STEP: Saw pod success
Nov 20 17:32:50.681: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov 20 17:32:50.692: INFO: Trying to get logs from node 10.184.110.176 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov 20 17:32:50.779: INFO: Waiting for pod pod-host-path-test to disappear
Nov 20 17:32:50.791: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:32:50.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-136" for this suite.
Nov 20 17:32:56.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:32:57.295: INFO: namespace hostpath-136 deletion completed in 6.484502343s

• [SLOW TEST:10.916 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:32:57.296: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:32:57.522: INFO: Creating ReplicaSet my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632
Nov 20 17:32:57.561: INFO: Pod name my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632: Found 0 pods out of 1
Nov 20 17:33:02.578: INFO: Pod name my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632: Found 1 pods out of 1
Nov 20 17:33:02.578: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632" is running
Nov 20 17:33:02.593: INFO: Pod "my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632-lrgz8" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-20 17:32:57 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-20 17:32:58 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-20 17:32:58 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-20 17:32:57 +0000 UTC Reason: Message:}])
Nov 20 17:33:02.593: INFO: Trying to dial the pod
Nov 20 17:33:07.760: INFO: Controller my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632: Got expected result from replica 1 [my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632-lrgz8]: "my-hostname-basic-9a6e1c14-98dc-4c06-974e-d8e2c5c7e632-lrgz8", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:33:07.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3833" for this suite.
Nov 20 17:33:13.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:33:14.336: INFO: namespace replicaset-3833 deletion completed in 6.524090042s

• [SLOW TEST:17.039 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:33:14.336: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9981
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov 20 17:33:14.582: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 20 17:33:14.781: INFO: Waiting for terminating namespaces to be deleted...
Nov 20 17:33:14.809: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.140 before test
Nov 20 17:33:14.974: INFO: calico-node-4dc2d from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:33:14.974: INFO: coredns-6db888bf8c-jr582 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:33:14.974: INFO: sonobuoy-e2e-job-b1a8acd3cb8d418c from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container e2e ready: true, restart count 0
Nov 20 17:33:14.974: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:33:14.974: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:33:14.974: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:33:14.974: INFO: ibm-master-proxy-static-10.184.110.140 from kube-system started at 2019-11-20 16:18:02 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:33:14.974: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:33:14.974: INFO: addon-catalog-source-67xr7 from ibm-system started at 2019-11-20 16:18:18 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container configmap-registry-server ready: true, restart count 1
Nov 20 17:33:14.974: INFO: ibm-keepalived-watcher-d59s8 from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:33:14.974: INFO: coredns-6db888bf8c-7xqjq from kube-system started at 2019-11-20 17:28:07 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:14.974: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:33:14.974: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.176 before test
Nov 20 17:33:15.031: INFO: ibm-master-proxy-static-10.184.110.176 from kube-system started at 2019-11-20 16:19:06 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:15.031: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:33:15.031: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:33:15.031: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:15.031: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:33:15.031: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:33:15.031: INFO: ibm-keepalived-watcher-qwxkl from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.031: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:33:15.031: INFO: calico-node-lkmcb from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.031: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:33:15.031: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.184 before test
Nov 20 17:33:15.199: INFO: calico-node-7txr8 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 17:33:15.199: INFO: coredns-autoscaler-65c89858bf-x8hrv from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container autoscaler ready: true, restart count 0
Nov 20 17:33:15.199: INFO: ibm-storage-watcher-79dd7d8d79-88t7h from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 20 17:33:15.199: INFO: sonobuoy from sonobuoy started at 2019-11-20 17:13:18 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 20 17:33:15.199: INFO: vpn-79845b6f9d-k9q7v from kube-system started at 2019-11-20 16:27:49 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container vpn ready: true, restart count 0
Nov 20 17:33:15.199: INFO: metrics-server-6bb8bc7476-7x5bd from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container metrics-server ready: true, restart count 0
Nov 20 17:33:15.199: INFO: ibm-file-plugin-56c5959484-qv87m from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 20 17:33:15.199: INFO: calico-kube-controllers-6f7dc6dfd4-7bt8x from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 20 17:33:15.199: INFO: ibm-master-proxy-static-10.184.110.184 from kube-system started at 2019-11-20 16:17:44 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 17:33:15.199: INFO: 	Container pause ready: true, restart count 0
Nov 20 17:33:15.199: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 17:33:15.199: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 17:33:15.199: INFO: kubernetes-dashboard-6bb9bf847f-kvddq from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 20 17:33:15.199: INFO: olm-operator-58994486f9-zjnjt from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container olm-operator ready: true, restart count 0
Nov 20 17:33:15.199: INFO: catalog-operator-7885df777c-cvtfq from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container catalog-operator ready: true, restart count 0
Nov 20 17:33:15.199: INFO: coredns-6db888bf8c-nkkm5 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container coredns ready: true, restart count 0
Nov 20 17:33:15.199: INFO: ibm-keepalived-watcher-74vx6 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 17:33:15.199: INFO: dashboard-metrics-scraper-dff9cbb9c-fpcsc from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 17:33:15.199: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.184.110.140
STEP: verifying the node has the label node 10.184.110.176
STEP: verifying the node has the label node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod addon-catalog-source-67xr7 requesting resource cpu=10m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod catalog-operator-7885df777c-cvtfq requesting resource cpu=10m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod olm-operator-58994486f9-zjnjt requesting resource cpu=10m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod calico-kube-controllers-6f7dc6dfd4-7bt8x requesting resource cpu=10m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod calico-node-4dc2d requesting resource cpu=250m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod calico-node-7txr8 requesting resource cpu=250m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod calico-node-lkmcb requesting resource cpu=250m on Node 10.184.110.176
Nov 20 17:33:15.658: INFO: Pod coredns-6db888bf8c-7xqjq requesting resource cpu=100m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod coredns-6db888bf8c-jr582 requesting resource cpu=100m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod coredns-6db888bf8c-nkkm5 requesting resource cpu=100m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod coredns-autoscaler-65c89858bf-x8hrv requesting resource cpu=20m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod dashboard-metrics-scraper-dff9cbb9c-fpcsc requesting resource cpu=1m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod ibm-file-plugin-56c5959484-qv87m requesting resource cpu=50m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod ibm-keepalived-watcher-74vx6 requesting resource cpu=5m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod ibm-keepalived-watcher-d59s8 requesting resource cpu=5m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod ibm-keepalived-watcher-qwxkl requesting resource cpu=5m on Node 10.184.110.176
Nov 20 17:33:15.658: INFO: Pod ibm-master-proxy-static-10.184.110.140 requesting resource cpu=25m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod ibm-master-proxy-static-10.184.110.176 requesting resource cpu=25m on Node 10.184.110.176
Nov 20 17:33:15.658: INFO: Pod ibm-master-proxy-static-10.184.110.184 requesting resource cpu=25m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod ibm-storage-watcher-79dd7d8d79-88t7h requesting resource cpu=50m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod kubernetes-dashboard-6bb9bf847f-kvddq requesting resource cpu=50m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod metrics-server-6bb8bc7476-7x5bd requesting resource cpu=48m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod vpn-79845b6f9d-k9q7v requesting resource cpu=5m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod sonobuoy-e2e-job-b1a8acd3cb8d418c requesting resource cpu=0m on Node 10.184.110.140
Nov 20 17:33:15.658: INFO: Pod sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc requesting resource cpu=0m on Node 10.184.110.176
Nov 20 17:33:15.658: INFO: Pod sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc requesting resource cpu=0m on Node 10.184.110.184
Nov 20 17:33:15.658: INFO: Pod sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 requesting resource cpu=0m on Node 10.184.110.140
STEP: Starting Pods to consume most of the cluster CPU.
Nov 20 17:33:15.658: INFO: Creating a pod which consumes cpu=2394m on Node 10.184.110.140
Nov 20 17:33:15.692: INFO: Creating a pod which consumes cpu=2541m on Node 10.184.110.176
Nov 20 17:33:15.730: INFO: Creating a pod which consumes cpu=2293m on Node 10.184.110.184
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349.15d8ef4fca9f6c56], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9981/filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349 to 10.184.110.176]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349.15d8ef500d627fa1], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349.15d8ef50116374e0], Reason = [Created], Message = [Created container filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349.15d8ef501b0d94fd], Reason = [Started], Message = [Started container filler-pod-48e1762e-de64-4c21-8579-0e7ce1119349]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202.15d8ef4fcd463590], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9981/filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202 to 10.184.110.184]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202.15d8ef500b063378], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202.15d8ef500eb2b5ab], Reason = [Created], Message = [Created container filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202.15d8ef5018abaae8], Reason = [Started], Message = [Started container filler-pod-7a79b50f-0fc4-4143-b258-d61e98732202]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb.15d8ef4fc85de0c4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9981/filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb to 10.184.110.140]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb.15d8ef500f11ca99], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb.15d8ef50138882c8], Reason = [Created], Message = [Created container filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb.15d8ef501ce5dd81], Reason = [Started], Message = [Started container filler-pod-b789dda5-d269-49f0-8f10-87f03ccbecfb]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d8ef50c2212359], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d8ef50c3c59413], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.184.110.184
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.184.110.140
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.184.110.176
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:33:21.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9981" for this suite.
Nov 20 17:33:29.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:33:29.893: INFO: namespace sched-pred-9981 deletion completed in 8.570591089s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:15.557 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:33:29.894: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-7706
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-7706
I1120 17:33:30.231454      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-7706, replica count: 2
I1120 17:33:33.282584      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1120 17:33:36.283031      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 20 17:33:36.283: INFO: Creating new exec pod
Nov 20 17:33:39.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 20 17:33:39.897: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 20 17:33:39.897: INFO: stdout: ""
Nov 20 17:33:39.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 172.21.123.35 80'
Nov 20 17:33:40.391: INFO: stderr: "+ nc -zv -t -w 2 172.21.123.35 80\nConnection to 172.21.123.35 80 port [tcp/http] succeeded!\n"
Nov 20 17:33:40.392: INFO: stdout: ""
Nov 20 17:33:40.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 10.184.110.140 30169'
Nov 20 17:33:40.724: INFO: stderr: "+ nc -zv -t -w 2 10.184.110.140 30169\nConnection to 10.184.110.140 30169 port [tcp/30169] succeeded!\n"
Nov 20 17:33:40.725: INFO: stdout: ""
Nov 20 17:33:40.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 10.184.110.176 30169'
Nov 20 17:33:41.081: INFO: stderr: "+ nc -zv -t -w 2 10.184.110.176 30169\nConnection to 10.184.110.176 30169 port [tcp/30169] succeeded!\n"
Nov 20 17:33:41.081: INFO: stdout: ""
Nov 20 17:33:41.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 169.63.53.2 30169'
Nov 20 17:33:41.432: INFO: stderr: "+ nc -zv -t -w 2 169.63.53.2 30169\nConnection to 169.63.53.2 30169 port [tcp/30169] succeeded!\n"
Nov 20 17:33:41.432: INFO: stdout: ""
Nov 20 17:33:41.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-7706 execpodqwk7s -- /bin/sh -x -c nc -zv -t -w 2 169.63.53.3 30169'
Nov 20 17:33:41.837: INFO: stderr: "+ nc -zv -t -w 2 169.63.53.3 30169\nConnection to 169.63.53.3 30169 port [tcp/30169] succeeded!\n"
Nov 20 17:33:41.837: INFO: stdout: ""
Nov 20 17:33:41.837: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:33:41.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7706" for this suite.
Nov 20 17:33:50.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:33:50.425: INFO: namespace services-7706 deletion completed in 8.457855246s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.532 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:33:50.426: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 20 17:33:58.851: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 20 17:33:58.864: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 20 17:34:00.865: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 20 17:34:00.880: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 20 17:34:02.865: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 20 17:34:02.881: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 20 17:34:04.864: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 20 17:34:04.993: INFO: Pod pod-with-prestop-exec-hook still exists
Nov 20 17:34:06.865: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov 20 17:34:06.894: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:34:06.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1252" for this suite.
Nov 20 17:34:37.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:34:37.572: INFO: namespace container-lifecycle-hook-1252 deletion completed in 30.582880994s

• [SLOW TEST:47.147 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:34:37.573: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6644
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6644
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 20 17:34:37.828: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 20 17:35:00.170: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.181.126 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6644 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:35:00.170: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:35:01.427: INFO: Found all expected endpoints: [netserver-0]
Nov 20 17:35:01.456: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.70.104 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6644 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:35:01.456: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:35:02.706: INFO: Found all expected endpoints: [netserver-1]
Nov 20 17:35:02.736: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.206.153 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6644 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:35:02.736: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:35:04.025: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:35:04.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6644" for this suite.
Nov 20 17:35:18.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:35:18.706: INFO: namespace pod-network-test-6644 deletion completed in 14.653159638s

• [SLOW TEST:41.133 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:35:18.707: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9492
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 20 17:35:19.087: INFO: Waiting up to 5m0s for pod "pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd" in namespace "emptydir-9492" to be "success or failure"
Nov 20 17:35:19.143: INFO: Pod "pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd": Phase="Pending", Reason="", readiness=false. Elapsed: 55.354851ms
Nov 20 17:35:21.156: INFO: Pod "pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068732831s
Nov 20 17:35:23.180: INFO: Pod "pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.092366265s
STEP: Saw pod success
Nov 20 17:35:23.180: INFO: Pod "pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd" satisfied condition "success or failure"
Nov 20 17:35:23.198: INFO: Trying to get logs from node 10.184.110.176 pod pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd container test-container: <nil>
STEP: delete the pod
Nov 20 17:35:23.303: INFO: Waiting for pod pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd to disappear
Nov 20 17:35:23.318: INFO: Pod pod-16fe6705-4f8a-4e9e-8b6e-5ac93bc9fffd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:35:23.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9492" for this suite.
Nov 20 17:35:29.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:35:29.810: INFO: namespace emptydir-9492 deletion completed in 6.472520547s

• [SLOW TEST:11.103 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:35:29.811: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5038
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:35:31.074: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:35:33.110: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868131, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868131, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868131, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868131, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:35:36.154: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:35:36.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5038" for this suite.
Nov 20 17:35:44.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:35:44.758: INFO: namespace webhook-5038 deletion completed in 8.427360112s
STEP: Destroying namespace "webhook-5038-markers" for this suite.
Nov 20 17:35:50.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:35:51.200: INFO: namespace webhook-5038-markers deletion completed in 6.441999879s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.469 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:35:51.280: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-4093
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-4093
I1120 17:35:51.593653      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-4093, replica count: 2
Nov 20 17:35:54.644: INFO: Creating new exec pod
I1120 17:35:54.644459      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 20 17:35:57.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-4093 execpodvn9lw -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov 20 17:35:58.056: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov 20 17:35:58.056: INFO: stdout: ""
Nov 20 17:35:58.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-4093 execpodvn9lw -- /bin/sh -x -c nc -zv -t -w 2 172.21.118.87 80'
Nov 20 17:35:58.421: INFO: stderr: "+ nc -zv -t -w 2 172.21.118.87 80\nConnection to 172.21.118.87 80 port [tcp/http] succeeded!\n"
Nov 20 17:35:58.421: INFO: stdout: ""
Nov 20 17:35:58.421: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:35:58.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4093" for this suite.
Nov 20 17:36:06.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:36:07.181: INFO: namespace services-4093 deletion completed in 8.649163683s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.901 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:36:07.182: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2776
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2776
STEP: creating replication controller externalsvc in namespace services-2776
I1120 17:36:07.511629      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2776, replica count: 2
I1120 17:36:10.562349      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov 20 17:36:10.884: INFO: Creating new exec pod
Nov 20 17:36:15.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-2776 execpodgxbt8 -- /bin/sh -x -c nslookup nodeport-service'
Nov 20 17:36:15.507: INFO: stderr: "+ nslookup nodeport-service\n"
Nov 20 17:36:15.507: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-2776.svc.cluster.local\tcanonical name = externalsvc.services-2776.svc.cluster.local.\nName:\texternalsvc.services-2776.svc.cluster.local\nAddress: 172.21.176.121\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2776, will wait for the garbage collector to delete the pods
Nov 20 17:36:15.654: INFO: Deleting ReplicationController externalsvc took: 40.105868ms
Nov 20 17:36:15.854: INFO: Terminating ReplicationController externalsvc pods took: 200.337301ms
Nov 20 17:36:26.066: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:36:26.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2776" for this suite.
Nov 20 17:36:34.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:36:34.781: INFO: namespace services-2776 deletion completed in 8.523968577s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:27.599 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:36:34.782: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7223
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:36:51.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7223" for this suite.
Nov 20 17:36:57.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:36:57.627: INFO: namespace resourcequota-7223 deletion completed in 6.500293372s

• [SLOW TEST:22.846 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:36:57.628: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5200
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-qxmd
STEP: Creating a pod to test atomic-volume-subpath
Nov 20 17:36:57.916: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-qxmd" in namespace "subpath-5200" to be "success or failure"
Nov 20 17:36:57.934: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.565493ms
Nov 20 17:36:59.948: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 2.032112762s
Nov 20 17:37:01.969: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 4.052593711s
Nov 20 17:37:03.990: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 6.073721525s
Nov 20 17:37:06.006: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 8.089576682s
Nov 20 17:37:08.102: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 10.18576769s
Nov 20 17:37:10.116: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 12.20027381s
Nov 20 17:37:12.132: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 14.215943504s
Nov 20 17:37:14.149: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 16.232629048s
Nov 20 17:37:16.168: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 18.251905503s
Nov 20 17:37:18.194: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Running", Reason="", readiness=true. Elapsed: 20.277831033s
Nov 20 17:37:20.208: INFO: Pod "pod-subpath-test-configmap-qxmd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.292076752s
STEP: Saw pod success
Nov 20 17:37:20.208: INFO: Pod "pod-subpath-test-configmap-qxmd" satisfied condition "success or failure"
Nov 20 17:37:20.264: INFO: Trying to get logs from node 10.184.110.176 pod pod-subpath-test-configmap-qxmd container test-container-subpath-configmap-qxmd: <nil>
STEP: delete the pod
Nov 20 17:37:20.473: INFO: Waiting for pod pod-subpath-test-configmap-qxmd to disappear
Nov 20 17:37:20.490: INFO: Pod pod-subpath-test-configmap-qxmd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-qxmd
Nov 20 17:37:20.490: INFO: Deleting pod "pod-subpath-test-configmap-qxmd" in namespace "subpath-5200"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:37:20.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5200" for this suite.
Nov 20 17:37:26.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:37:27.047: INFO: namespace subpath-5200 deletion completed in 6.493480721s

• [SLOW TEST:29.419 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:37:27.053: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6188.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-6188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6188.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 17:37:31.420: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.444: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.477: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.496: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.565: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.595: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.619: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.641: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:31.681: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:37:36.753: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:36.777: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:36.898: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:36.926: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:36.971: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:37:41.814: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:41.836: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:41.950: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:41.969: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:42.016: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:37:46.759: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:46.783: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:46.899: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:46.921: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:46.962: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:37:51.757: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:51.782: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:51.897: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:51.917: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:51.966: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:37:56.759: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:56.783: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:56.911: INFO: Unable to read jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:56.999: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local from pod dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691: the server could not find the requested resource (get pods dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691)
Nov 20 17:37:57.058: INFO: Lookups using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 failed for: [wheezy_udp@dns-test-service-2.dns-6188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-6188.svc.cluster.local jessie_udp@dns-test-service-2.dns-6188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-6188.svc.cluster.local]

Nov 20 17:38:02.142: INFO: DNS probes using dns-6188/dns-test-dccd4757-15aa-42c8-9fd8-2222a0e21691 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:38:02.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6188" for this suite.
Nov 20 17:38:10.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:38:10.990: INFO: namespace dns-6188 deletion completed in 8.539958061s

• [SLOW TEST:43.938 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:38:10.994: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-ea78f0f4-c27c-40f6-9b72-cdf115bef2d0
STEP: Creating a pod to test consume secrets
Nov 20 17:38:11.438: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850" in namespace "projected-2151" to be "success or failure"
Nov 20 17:38:11.478: INFO: Pod "pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850": Phase="Pending", Reason="", readiness=false. Elapsed: 40.712929ms
Nov 20 17:38:13.579: INFO: Pod "pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.141107366s
STEP: Saw pod success
Nov 20 17:38:13.579: INFO: Pod "pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850" satisfied condition "success or failure"
Nov 20 17:38:13.627: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:38:13.900: INFO: Waiting for pod pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850 to disappear
Nov 20 17:38:13.929: INFO: Pod pod-projected-secrets-f4b3d656-dab0-4561-bb59-6a85ea9ce850 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:38:13.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2151" for this suite.
Nov 20 17:38:20.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:38:20.533: INFO: namespace projected-2151 deletion completed in 6.551847876s

• [SLOW TEST:9.539 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:38:20.534: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:38:21.502: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:38:23.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868301, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868301, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868301, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868301, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:38:26.613: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Nov 20 17:38:26.677: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:38:37.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2616" for this suite.
Nov 20 17:38:45.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:38:45.596: INFO: namespace webhook-2616 deletion completed in 8.425079756s
STEP: Destroying namespace "webhook-2616-markers" for this suite.
Nov 20 17:38:51.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:38:52.099: INFO: namespace webhook-2616-markers deletion completed in 6.502210511s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.643 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:38:52.178: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9354
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:38:52.444: INFO: Waiting up to 5m0s for pod "downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467" in namespace "downward-api-9354" to be "success or failure"
Nov 20 17:38:52.455: INFO: Pod "downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670256ms
Nov 20 17:38:54.467: INFO: Pod "downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022460422s
Nov 20 17:38:56.482: INFO: Pod "downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037416811s
STEP: Saw pod success
Nov 20 17:38:56.482: INFO: Pod "downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467" satisfied condition "success or failure"
Nov 20 17:38:56.531: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467 container client-container: <nil>
STEP: delete the pod
Nov 20 17:38:56.608: INFO: Waiting for pod downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467 to disappear
Nov 20 17:38:56.623: INFO: Pod downwardapi-volume-de6e09f2-10f6-4cfa-b35f-467db585d467 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:38:56.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9354" for this suite.
Nov 20 17:39:02.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:39:03.367: INFO: namespace downward-api-9354 deletion completed in 6.719467327s

• [SLOW TEST:11.189 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:39:03.368: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6837
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 17:39:05.801: INFO: DNS probes using dns-test-3513b772-1240-42ed-aa0d-501ce6f36dd1 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 17:39:10.103: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:10.146: INFO: File jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:10.146: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:15.172: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:15.198: INFO: File jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:15.198: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:20.170: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:20.226: INFO: File jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:20.226: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:25.172: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:25.208: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:30.172: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:30.197: INFO: File jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:30.197: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:35.177: INFO: File wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:35.198: INFO: File jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local from pod  dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov 20 17:39:35.198: INFO: Lookups using dns-6837/dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e failed for: [wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local]

Nov 20 17:39:40.200: INFO: DNS probes using dns-test-dcad2922-b7db-41c9-8fd7-0828dedc355e succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6837.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6837.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 17:39:44.543: INFO: DNS probes using dns-test-f70f7551-3039-4832-adc4-8433e56500a3 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:39:44.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6837" for this suite.
Nov 20 17:39:52.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:39:53.165: INFO: namespace dns-6837 deletion completed in 8.447096057s

• [SLOW TEST:49.798 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:39:53.166: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:39:53.428: INFO: Waiting up to 5m0s for pod "downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f" in namespace "projected-2188" to be "success or failure"
Nov 20 17:39:53.469: INFO: Pod "downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f": Phase="Pending", Reason="", readiness=false. Elapsed: 40.815606ms
Nov 20 17:39:55.486: INFO: Pod "downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.057369212s
STEP: Saw pod success
Nov 20 17:39:55.486: INFO: Pod "downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f" satisfied condition "success or failure"
Nov 20 17:39:55.499: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f container client-container: <nil>
STEP: delete the pod
Nov 20 17:39:55.591: INFO: Waiting for pod downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f to disappear
Nov 20 17:39:55.605: INFO: Pod downwardapi-volume-023ce8e2-4057-40c1-9e05-f7424f52a36f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:39:55.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2188" for this suite.
Nov 20 17:40:01.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:40:02.289: INFO: namespace projected-2188 deletion completed in 6.669160225s

• [SLOW TEST:9.124 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:40:02.290: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-471ae0dd-54e5-4528-a7b2-917318f1b11a
STEP: Creating a pod to test consume configMaps
Nov 20 17:40:02.643: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2" in namespace "projected-3478" to be "success or failure"
Nov 20 17:40:02.665: INFO: Pod "pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2": Phase="Pending", Reason="", readiness=false. Elapsed: 22.387218ms
Nov 20 17:40:04.723: INFO: Pod "pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080410184s
Nov 20 17:40:06.738: INFO: Pod "pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.094921866s
STEP: Saw pod success
Nov 20 17:40:06.738: INFO: Pod "pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2" satisfied condition "success or failure"
Nov 20 17:40:06.752: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 17:40:06.859: INFO: Waiting for pod pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2 to disappear
Nov 20 17:40:06.890: INFO: Pod pod-projected-configmaps-b324c9e0-6815-422d-b0bf-aeb6b04692e2 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:40:06.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3478" for this suite.
Nov 20 17:40:13.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:40:13.903: INFO: namespace projected-3478 deletion completed in 6.809461311s

• [SLOW TEST:11.613 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:40:13.904: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5021
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-4b95a9e6-1ead-46e1-8092-01f0104fb50c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:40:14.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5021" for this suite.
Nov 20 17:40:20.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:40:21.297: INFO: namespace secrets-5021 deletion completed in 6.910758339s

• [SLOW TEST:7.393 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:40:21.299: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:40:21.586: INFO: Creating deployment "test-recreate-deployment"
Nov 20 17:40:21.596: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov 20 17:40:21.619: INFO: new replicaset for deployment "test-recreate-deployment" is yet to be created
Nov 20 17:40:23.657: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov 20 17:40:23.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868421, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868421, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868421, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868421, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 17:40:25.677: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov 20 17:40:25.743: INFO: Updating deployment test-recreate-deployment
Nov 20 17:40:25.743: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov 20 17:40:25.987: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-849 /apis/apps/v1/namespaces/deployment-849/deployments/test-recreate-deployment f0913462-02b6-4896-b76a-eb3d6d313e63 20761 2 2019-11-20 17:40:21 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0030d19f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-20 17:40:25 +0000 UTC,LastTransitionTime:2019-11-20 17:40:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-11-20 17:40:25 +0000 UTC,LastTransitionTime:2019-11-20 17:40:21 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov 20 17:40:26.007: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-849 /apis/apps/v1/namespaces/deployment-849/replicasets/test-recreate-deployment-5f94c574ff 3dcdc34e-1043-424e-bbb8-89e16b841433 20757 1 2019-11-20 17:40:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment f0913462-02b6-4896-b76a-eb3d6d313e63 0xc0035a0367 0xc0035a0368}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035a03c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 17:40:26.007: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov 20 17:40:26.007: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-849 /apis/apps/v1/namespaces/deployment-849/replicasets/test-recreate-deployment-68fc85c7bb 4d92a4df-a522-4180-85e5-ca3232d0cfb2 20748 2 2019-11-20 17:40:21 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment f0913462-02b6-4896-b76a-eb3d6d313e63 0xc0035a0487 0xc0035a0488}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035a0538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 17:40:26.022: INFO: Pod "test-recreate-deployment-5f94c574ff-bvmzn" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-bvmzn test-recreate-deployment-5f94c574ff- deployment-849 /api/v1/namespaces/deployment-849/pods/test-recreate-deployment-5f94c574ff-bvmzn 1bce39be-8ee5-40a4-9d6a-f002a522cdfc 20760 0 2019-11-20 17:40:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 3dcdc34e-1043-424e-bbb8-89e16b841433 0xc0035a09a7 0xc0035a09a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-n5zv7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-n5zv7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-n5zv7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 17:40:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 17:40:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 17:40:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 17:40:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:,StartTime:2019-11-20 17:40:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:40:26.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-849" for this suite.
Nov 20 17:40:34.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:40:34.560: INFO: namespace deployment-849 deletion completed in 8.511585077s

• [SLOW TEST:13.261 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:40:34.560: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-2494
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Nov 20 17:40:34.785: INFO: Waiting up to 1m0s for all nodes to be ready
Nov 20 17:41:34.816: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:41:34.830: INFO: Starting informer...
STEP: Starting pod...
Nov 20 17:41:35.071: INFO: Pod is running on 10.184.110.176. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov 20 17:41:35.113: INFO: Pod wasn't evicted. Proceeding
Nov 20 17:41:35.113: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov 20 17:42:50.154: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:42:50.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2494" for this suite.
Nov 20 17:43:02.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:43:02.829: INFO: namespace taint-single-pod-2494 deletion completed in 12.625824687s

• [SLOW TEST:148.269 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:43:02.829: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2303
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:43:03.377: INFO: (0) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 84.284709ms)
Nov 20 17:43:03.408: INFO: (1) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 30.746961ms)
Nov 20 17:43:03.448: INFO: (2) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 40.411179ms)
Nov 20 17:43:03.481: INFO: (3) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 32.767727ms)
Nov 20 17:43:03.507: INFO: (4) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 26.379583ms)
Nov 20 17:43:03.551: INFO: (5) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 43.922382ms)
Nov 20 17:43:03.586: INFO: (6) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 34.690534ms)
Nov 20 17:43:03.618: INFO: (7) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 32.516699ms)
Nov 20 17:43:03.650: INFO: (8) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 31.470273ms)
Nov 20 17:43:03.691: INFO: (9) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 40.673189ms)
Nov 20 17:43:03.805: INFO: (10) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 114.409045ms)
Nov 20 17:43:03.951: INFO: (11) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 146.02947ms)
Nov 20 17:43:04.109: INFO: (12) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 157.259418ms)
Nov 20 17:43:04.220: INFO: (13) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 111.461081ms)
Nov 20 17:43:04.268: INFO: (14) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 48.006872ms)
Nov 20 17:43:04.334: INFO: (15) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 66.199109ms)
Nov 20 17:43:04.424: INFO: (16) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 89.2296ms)
Nov 20 17:43:04.510: INFO: (17) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 85.916184ms)
Nov 20 17:43:04.548: INFO: (18) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 38.489924ms)
Nov 20 17:43:04.582: INFO: (19) /api/v1/nodes/10.184.110.140/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 33.551458ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:43:04.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2303" for this suite.
Nov 20 17:43:10.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:43:11.323: INFO: namespace proxy-2303 deletion completed in 6.711796379s

• [SLOW TEST:8.494 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:43:11.325: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9473
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-38375523-d2cf-4c45-9d26-82ad35255ff2 in namespace container-probe-9473
Nov 20 17:43:13.688: INFO: Started pod liveness-38375523-d2cf-4c45-9d26-82ad35255ff2 in namespace container-probe-9473
STEP: checking the pod's current state and verifying that restartCount is present
Nov 20 17:43:13.702: INFO: Initial restart count of pod liveness-38375523-d2cf-4c45-9d26-82ad35255ff2 is 0
Nov 20 17:43:29.970: INFO: Restart count of pod container-probe-9473/liveness-38375523-d2cf-4c45-9d26-82ad35255ff2 is now 1 (16.268220226s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:43:30.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9473" for this suite.
Nov 20 17:43:36.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:43:36.489: INFO: namespace container-probe-9473 deletion completed in 6.45748111s

• [SLOW TEST:25.165 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:43:36.490: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:43:38.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5151" for this suite.
Nov 20 17:43:44.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:43:45.408: INFO: namespace emptydir-wrapper-5151 deletion completed in 6.496164896s

• [SLOW TEST:8.919 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:43:45.409: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6266
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:43:45.733: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 20 17:43:49.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-6266 create -f -'
Nov 20 17:43:50.099: INFO: stderr: ""
Nov 20 17:43:50.099: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 20 17:43:50.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-6266 delete e2e-test-crd-publish-openapi-5742-crds test-cr'
Nov 20 17:43:50.269: INFO: stderr: ""
Nov 20 17:43:50.269: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov 20 17:43:50.269: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-6266 apply -f -'
Nov 20 17:43:50.752: INFO: stderr: ""
Nov 20 17:43:50.752: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov 20 17:43:50.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-6266 delete e2e-test-crd-publish-openapi-5742-crds test-cr'
Nov 20 17:43:50.922: INFO: stderr: ""
Nov 20 17:43:50.922: INFO: stdout: "e2e-test-crd-publish-openapi-5742-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 20 17:43:50.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-5742-crds'
Nov 20 17:43:51.160: INFO: stderr: ""
Nov 20 17:43:51.160: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5742-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:43:55.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6266" for this suite.
Nov 20 17:44:01.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:44:01.754: INFO: namespace crd-publish-openapi-6266 deletion completed in 6.677957439s

• [SLOW TEST:16.345 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:44:01.754: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov 20 17:44:06.858: INFO: Successfully updated pod "labelsupdate9d4d1ef6-9524-4751-a82c-3c43d0e7acba"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:44:08.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8515" for this suite.
Nov 20 17:44:21.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:44:21.698: INFO: namespace downward-api-8515 deletion completed in 12.70118243s

• [SLOW TEST:19.944 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:44:21.698: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2284
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-517df1ab-77e9-47b2-9ffc-bd7b42cf6ed0
STEP: Creating a pod to test consume secrets
Nov 20 17:44:22.028: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b" in namespace "projected-2284" to be "success or failure"
Nov 20 17:44:22.054: INFO: Pod "pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b": Phase="Pending", Reason="", readiness=false. Elapsed: 26.704429ms
Nov 20 17:44:24.069: INFO: Pod "pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b": Phase="Running", Reason="", readiness=true. Elapsed: 2.041183953s
Nov 20 17:44:26.084: INFO: Pod "pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056026475s
STEP: Saw pod success
Nov 20 17:44:26.084: INFO: Pod "pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b" satisfied condition "success or failure"
Nov 20 17:44:26.099: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:44:26.229: INFO: Waiting for pod pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b to disappear
Nov 20 17:44:26.250: INFO: Pod pod-projected-secrets-12509763-9cff-442d-a94e-b72a604b718b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:44:26.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2284" for this suite.
Nov 20 17:44:34.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:44:34.741: INFO: namespace projected-2284 deletion completed in 8.472495594s

• [SLOW TEST:13.043 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:44:34.742: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:44:34.991: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-a815dc8a-f4c2-422d-acb4-8195a20c8819" in namespace "security-context-test-9877" to be "success or failure"
Nov 20 17:44:35.007: INFO: Pod "busybox-readonly-false-a815dc8a-f4c2-422d-acb4-8195a20c8819": Phase="Pending", Reason="", readiness=false. Elapsed: 14.990951ms
Nov 20 17:44:37.022: INFO: Pod "busybox-readonly-false-a815dc8a-f4c2-422d-acb4-8195a20c8819": Phase="Running", Reason="", readiness=true. Elapsed: 2.030797501s
Nov 20 17:44:39.037: INFO: Pod "busybox-readonly-false-a815dc8a-f4c2-422d-acb4-8195a20c8819": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045295096s
Nov 20 17:44:39.037: INFO: Pod "busybox-readonly-false-a815dc8a-f4c2-422d-acb4-8195a20c8819" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:44:39.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9877" for this suite.
Nov 20 17:44:45.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:44:45.512: INFO: namespace security-context-test-9877 deletion completed in 6.456331482s

• [SLOW TEST:10.770 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:44:45.513: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov 20 17:44:49.903: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 20 17:44:49.918: INFO: Pod pod-with-prestop-http-hook still exists
Nov 20 17:44:51.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 20 17:44:51.934: INFO: Pod pod-with-prestop-http-hook still exists
Nov 20 17:44:53.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 20 17:44:53.933: INFO: Pod pod-with-prestop-http-hook still exists
Nov 20 17:44:55.918: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov 20 17:44:55.930: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:44:55.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-756" for this suite.
Nov 20 17:45:08.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:45:08.505: INFO: namespace container-lifecycle-hook-756 deletion completed in 12.513661381s

• [SLOW TEST:22.993 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:45:08.506: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-8ece2288-092a-40a3-827c-af9148501d7b
STEP: Creating a pod to test consume configMaps
Nov 20 17:45:08.811: INFO: Waiting up to 5m0s for pod "pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868" in namespace "configmap-5254" to be "success or failure"
Nov 20 17:45:08.829: INFO: Pod "pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868": Phase="Pending", Reason="", readiness=false. Elapsed: 17.968644ms
Nov 20 17:45:10.844: INFO: Pod "pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03354646s
Nov 20 17:45:12.862: INFO: Pod "pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051645656s
STEP: Saw pod success
Nov 20 17:45:12.862: INFO: Pod "pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868" satisfied condition "success or failure"
Nov 20 17:45:12.887: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 17:45:12.999: INFO: Waiting for pod pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868 to disappear
Nov 20 17:45:13.015: INFO: Pod pod-configmaps-9b6d7acb-7196-4a59-ab18-7b52874fe868 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:45:13.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5254" for this suite.
Nov 20 17:45:19.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:45:19.848: INFO: namespace configmap-5254 deletion completed in 6.810898525s

• [SLOW TEST:11.342 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:45:19.849: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7823
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov 20 17:45:20.170: INFO: Waiting up to 5m0s for pod "downward-api-2315baaa-bde4-47c2-a014-7b58873640e8" in namespace "downward-api-7823" to be "success or failure"
Nov 20 17:45:20.186: INFO: Pod "downward-api-2315baaa-bde4-47c2-a014-7b58873640e8": Phase="Pending", Reason="", readiness=false. Elapsed: 15.914861ms
Nov 20 17:45:22.207: INFO: Pod "downward-api-2315baaa-bde4-47c2-a014-7b58873640e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037114247s
Nov 20 17:45:24.236: INFO: Pod "downward-api-2315baaa-bde4-47c2-a014-7b58873640e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066283649s
STEP: Saw pod success
Nov 20 17:45:24.237: INFO: Pod "downward-api-2315baaa-bde4-47c2-a014-7b58873640e8" satisfied condition "success or failure"
Nov 20 17:45:24.254: INFO: Trying to get logs from node 10.184.110.176 pod downward-api-2315baaa-bde4-47c2-a014-7b58873640e8 container dapi-container: <nil>
STEP: delete the pod
Nov 20 17:45:24.372: INFO: Waiting for pod downward-api-2315baaa-bde4-47c2-a014-7b58873640e8 to disappear
Nov 20 17:45:24.388: INFO: Pod downward-api-2315baaa-bde4-47c2-a014-7b58873640e8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:45:24.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7823" for this suite.
Nov 20 17:45:30.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:45:30.891: INFO: namespace downward-api-7823 deletion completed in 6.481340976s

• [SLOW TEST:11.043 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:45:30.892: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 20 17:45:31.173: INFO: Waiting up to 5m0s for pod "pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56" in namespace "emptydir-810" to be "success or failure"
Nov 20 17:45:31.184: INFO: Pod "pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56": Phase="Pending", Reason="", readiness=false. Elapsed: 11.461985ms
Nov 20 17:45:33.255: INFO: Pod "pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.082502659s
Nov 20 17:45:35.306: INFO: Pod "pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.133456916s
STEP: Saw pod success
Nov 20 17:45:35.306: INFO: Pod "pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56" satisfied condition "success or failure"
Nov 20 17:45:35.323: INFO: Trying to get logs from node 10.184.110.176 pod pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56 container test-container: <nil>
STEP: delete the pod
Nov 20 17:45:35.411: INFO: Waiting for pod pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56 to disappear
Nov 20 17:45:35.421: INFO: Pod pod-6969634a-b5bb-4955-a498-d6b1c0cd2a56 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:45:35.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-810" for this suite.
Nov 20 17:45:41.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:45:41.891: INFO: namespace emptydir-810 deletion completed in 6.452156152s

• [SLOW TEST:10.999 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:45:41.891: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-4aebb120-0324-475c-9a88-92eda73a0566
STEP: Creating a pod to test consume secrets
Nov 20 17:45:42.152: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37" in namespace "projected-5012" to be "success or failure"
Nov 20 17:45:42.167: INFO: Pod "pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37": Phase="Pending", Reason="", readiness=false. Elapsed: 14.699766ms
Nov 20 17:45:44.180: INFO: Pod "pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027777056s
Nov 20 17:45:46.195: INFO: Pod "pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043113246s
STEP: Saw pod success
Nov 20 17:45:46.196: INFO: Pod "pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37" satisfied condition "success or failure"
Nov 20 17:45:46.241: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37 container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:45:46.324: INFO: Waiting for pod pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37 to disappear
Nov 20 17:45:46.338: INFO: Pod pod-projected-secrets-daf2fe1c-7ca3-4f41-80cb-a36e275c0c37 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:45:46.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5012" for this suite.
Nov 20 17:45:52.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:45:52.982: INFO: namespace projected-5012 deletion completed in 6.626548056s

• [SLOW TEST:11.091 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:45:52.982: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-7780
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov 20 17:45:59.348: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:45:59.348: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:45:59.572: INFO: Exec stderr: ""
Nov 20 17:45:59.572: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:45:59.572: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:45:59.826: INFO: Exec stderr: ""
Nov 20 17:45:59.826: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:45:59.826: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:00.070: INFO: Exec stderr: ""
Nov 20 17:46:00.070: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:00.070: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:00.323: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov 20 17:46:00.323: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:00.323: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:00.577: INFO: Exec stderr: ""
Nov 20 17:46:00.577: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:00.577: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:00.889: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov 20 17:46:00.889: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:00.889: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:01.186: INFO: Exec stderr: ""
Nov 20 17:46:01.186: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:01.186: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:01.431: INFO: Exec stderr: ""
Nov 20 17:46:01.431: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:01.431: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:01.729: INFO: Exec stderr: ""
Nov 20 17:46:01.729: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-7780 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 17:46:01.729: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:46:02.004: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:46:02.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-7780" for this suite.
Nov 20 17:46:48.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:46:48.622: INFO: namespace e2e-kubelet-etc-hosts-7780 deletion completed in 46.595721472s

• [SLOW TEST:55.640 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:46:48.623: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8411
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 17:46:48.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8411'
Nov 20 17:46:49.023: INFO: stderr: ""
Nov 20 17:46:49.023: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Nov 20 17:46:49.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete pods e2e-test-httpd-pod --namespace=kubectl-8411'
Nov 20 17:46:55.898: INFO: stderr: ""
Nov 20 17:46:55.898: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:46:55.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8411" for this suite.
Nov 20 17:47:01.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:47:02.501: INFO: namespace kubectl-8411 deletion completed in 6.575031468s

• [SLOW TEST:13.878 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:47:02.501: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3024
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 17:47:02.754: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3024'
Nov 20 17:47:02.909: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 20 17:47:02.909: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov 20 17:47:02.997: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-6hfhn]
Nov 20 17:47:02.998: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-6hfhn" in namespace "kubectl-3024" to be "running and ready"
Nov 20 17:47:03.049: INFO: Pod "e2e-test-httpd-rc-6hfhn": Phase="Pending", Reason="", readiness=false. Elapsed: 51.32082ms
Nov 20 17:47:05.071: INFO: Pod "e2e-test-httpd-rc-6hfhn": Phase="Running", Reason="", readiness=true. Elapsed: 2.07340112s
Nov 20 17:47:05.071: INFO: Pod "e2e-test-httpd-rc-6hfhn" satisfied condition "running and ready"
Nov 20 17:47:05.071: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-6hfhn]
Nov 20 17:47:05.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs rc/e2e-test-httpd-rc --namespace=kubectl-3024'
Nov 20 17:47:05.380: INFO: stderr: ""
Nov 20 17:47:05.380: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.70.79. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.70.79. Set the 'ServerName' directive globally to suppress this message\n[Wed Nov 20 17:47:04.385822 2019] [mpm_event:notice] [pid 1:tid 140018891656040] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Wed Nov 20 17:47:04.385885 2019] [core:notice] [pid 1:tid 140018891656040] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Nov 20 17:47:05.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete rc e2e-test-httpd-rc --namespace=kubectl-3024'
Nov 20 17:47:05.561: INFO: stderr: ""
Nov 20 17:47:05.561: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:47:05.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3024" for this suite.
Nov 20 17:47:17.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:47:18.133: INFO: namespace kubectl-3024 deletion completed in 12.523695247s

• [SLOW TEST:15.632 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:47:18.133: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:47:18.391: INFO: Waiting up to 5m0s for pod "downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de" in namespace "projected-206" to be "success or failure"
Nov 20 17:47:18.403: INFO: Pod "downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de": Phase="Pending", Reason="", readiness=false. Elapsed: 11.810486ms
Nov 20 17:47:20.422: INFO: Pod "downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031050161s
Nov 20 17:47:22.438: INFO: Pod "downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047103267s
STEP: Saw pod success
Nov 20 17:47:22.438: INFO: Pod "downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de" satisfied condition "success or failure"
Nov 20 17:47:22.452: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de container client-container: <nil>
STEP: delete the pod
Nov 20 17:47:22.603: INFO: Waiting for pod downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de to disappear
Nov 20 17:47:22.618: INFO: Pod downwardapi-volume-68c27fdb-2b61-46c5-809f-4febd1d671de no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:47:22.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-206" for this suite.
Nov 20 17:47:28.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:47:29.187: INFO: namespace projected-206 deletion completed in 6.540440674s

• [SLOW TEST:11.054 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:47:29.191: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4236
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-f7733508-d039-4ecc-952d-4906e5b8dbbc
STEP: Creating a pod to test consume secrets
Nov 20 17:47:29.452: INFO: Waiting up to 5m0s for pod "pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a" in namespace "secrets-4236" to be "success or failure"
Nov 20 17:47:29.468: INFO: Pod "pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.272294ms
Nov 20 17:47:31.483: INFO: Pod "pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03052474s
Nov 20 17:47:33.498: INFO: Pod "pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045594145s
STEP: Saw pod success
Nov 20 17:47:33.498: INFO: Pod "pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a" satisfied condition "success or failure"
Nov 20 17:47:33.511: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:47:33.618: INFO: Waiting for pod pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a to disappear
Nov 20 17:47:33.631: INFO: Pod pod-secrets-10986f74-2da3-4158-a604-abd452fcf20a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:47:33.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4236" for this suite.
Nov 20 17:47:39.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:47:40.125: INFO: namespace secrets-4236 deletion completed in 6.476612513s

• [SLOW TEST:10.934 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:47:40.125: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:47:40.997: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 20 17:47:43.027: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868861, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868861, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868861, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709868860, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:47:46.071: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov 20 17:47:48.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 attach --namespace=webhook-4607 to-be-attached-pod -i -c=container1'
Nov 20 17:47:48.403: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:47:48.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4607" for this suite.
Nov 20 17:48:02.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:48:03.035: INFO: namespace webhook-4607 deletion completed in 14.590942652s
STEP: Destroying namespace "webhook-4607-markers" for this suite.
Nov 20 17:48:09.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:48:09.819: INFO: namespace webhook-4607-markers deletion completed in 6.783667037s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.775 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:48:09.900: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:48:12.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3639" for this suite.
Nov 20 17:48:58.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:48:58.892: INFO: namespace kubelet-test-3639 deletion completed in 46.514771465s

• [SLOW TEST:48.992 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:48:58.892: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4670
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:49:01.283: INFO: Waiting up to 5m0s for pod "client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd" in namespace "pods-4670" to be "success or failure"
Nov 20 17:49:01.307: INFO: Pod "client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd": Phase="Pending", Reason="", readiness=false. Elapsed: 23.792219ms
Nov 20 17:49:03.322: INFO: Pod "client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039582979s
STEP: Saw pod success
Nov 20 17:49:03.322: INFO: Pod "client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd" satisfied condition "success or failure"
Nov 20 17:49:03.341: INFO: Trying to get logs from node 10.184.110.176 pod client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd container env3cont: <nil>
STEP: delete the pod
Nov 20 17:49:03.546: INFO: Waiting for pod client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd to disappear
Nov 20 17:49:03.601: INFO: Pod client-envvars-b154ce2a-18dd-4f0e-a943-6de1b295d1bd no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:49:03.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4670" for this suite.
Nov 20 17:49:33.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:49:34.320: INFO: namespace pods-4670 deletion completed in 30.675482261s

• [SLOW TEST:35.428 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:49:34.320: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7071
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:49:34.659: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827" in namespace "downward-api-7071" to be "success or failure"
Nov 20 17:49:34.676: INFO: Pod "downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827": Phase="Pending", Reason="", readiness=false. Elapsed: 16.456238ms
Nov 20 17:49:36.693: INFO: Pod "downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033826884s
Nov 20 17:49:38.709: INFO: Pod "downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050071407s
STEP: Saw pod success
Nov 20 17:49:38.709: INFO: Pod "downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827" satisfied condition "success or failure"
Nov 20 17:49:38.741: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827 container client-container: <nil>
STEP: delete the pod
Nov 20 17:49:38.838: INFO: Waiting for pod downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827 to disappear
Nov 20 17:49:38.851: INFO: Pod downwardapi-volume-2042808e-0bf3-4b67-bf64-80023c697827 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:49:38.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7071" for this suite.
Nov 20 17:49:44.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:49:45.386: INFO: namespace downward-api-7071 deletion completed in 6.512739785s

• [SLOW TEST:11.066 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:49:45.386: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:49:45.740: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"6380adf1-ff07-4ee9-80a6-c4ba5ffc1d41", Controller:(*bool)(0xc0010ba80a), BlockOwnerDeletion:(*bool)(0xc0010ba80b)}}
Nov 20 17:49:45.791: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"82fcc8da-963a-4ceb-b336-413751075a56", Controller:(*bool)(0xc0072a1146), BlockOwnerDeletion:(*bool)(0xc0072a1147)}}
Nov 20 17:49:45.811: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"0f34b019-d029-49da-9877-2498a0ebad94", Controller:(*bool)(0xc002c5dc96), BlockOwnerDeletion:(*bool)(0xc002c5dc97)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:49:50.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7022" for this suite.
Nov 20 17:49:58.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:49:59.582: INFO: namespace gc-7022 deletion completed in 8.707288113s

• [SLOW TEST:14.196 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:49:59.586: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7478
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov 20 17:49:59.828: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:50:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7478" for this suite.
Nov 20 17:50:26.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:50:27.266: INFO: namespace crd-publish-openapi-7478 deletion completed in 6.557624541s

• [SLOW TEST:27.680 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:50:27.266: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov 20 17:50:27.496: INFO: PodSpec: initContainers in spec.initContainers
Nov 20 17:51:12.127: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b785ec3e-6d26-47f1-9549-d7e06e2fc5ed", GenerateName:"", Namespace:"init-container-805", SelfLink:"/api/v1/namespaces/init-container-805/pods/pod-init-b785ec3e-6d26-47f1-9549-d7e06e2fc5ed", UID:"fb80cf99-33ac-4dba-8128-e5533fe294bc", ResourceVersion:"22742", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63709869027, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"496466393"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-w4qcj", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc00595f740), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-w4qcj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-w4qcj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-w4qcj", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc006c036e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.184.110.176", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001b83800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c03770)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc006c037d0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc006c037d8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc006c037dc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869027, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869027, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869027, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869027, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.184.110.176", PodIP:"172.30.70.72", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.70.72"}}, StartTime:(*v1.Time)(0xc0043f0c20), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f983f0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000f98460)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://76be643b629da71a9aae047b2e4039d8aeac596ae1b84f629312107ba15657f2", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0043f0c60), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0043f0c40), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc006c038bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:51:12.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-805" for this suite.
Nov 20 17:51:24.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:51:24.715: INFO: namespace init-container-805 deletion completed in 12.567614582s

• [SLOW TEST:57.449 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:51:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6272
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:51:38.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6272" for this suite.
Nov 20 17:51:44.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:51:44.762: INFO: namespace resourcequota-6272 deletion completed in 6.435230371s

• [SLOW TEST:20.048 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:51:44.765: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-7694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Nov 20 17:51:45.017: INFO: Waiting up to 5m0s for pod "var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44" in namespace "var-expansion-7694" to be "success or failure"
Nov 20 17:51:45.031: INFO: Pod "var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44": Phase="Pending", Reason="", readiness=false. Elapsed: 12.886415ms
Nov 20 17:51:47.048: INFO: Pod "var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030662049s
Nov 20 17:51:49.067: INFO: Pod "var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049326359s
STEP: Saw pod success
Nov 20 17:51:49.067: INFO: Pod "var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44" satisfied condition "success or failure"
Nov 20 17:51:49.081: INFO: Trying to get logs from node 10.184.110.176 pod var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44 container dapi-container: <nil>
STEP: delete the pod
Nov 20 17:51:49.282: INFO: Waiting for pod var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44 to disappear
Nov 20 17:51:49.298: INFO: Pod var-expansion-d6e7c63a-ead2-4e80-81d0-3ba34e0c9b44 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:51:49.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-7694" for this suite.
Nov 20 17:51:55.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:51:55.786: INFO: namespace var-expansion-7694 deletion completed in 6.47099152s

• [SLOW TEST:11.021 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:51:55.787: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5019
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-5019
Nov 20 17:51:56.066: INFO: Found 0 stateful pods, waiting for 1
Nov 20 17:52:06.119: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 17:52:06.278: INFO: Deleting all statefulset in ns statefulset-5019
Nov 20 17:52:06.309: INFO: Scaling statefulset ss to 0
Nov 20 17:52:16.433: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 17:52:16.491: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:52:16.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5019" for this suite.
Nov 20 17:52:24.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:52:25.264: INFO: namespace statefulset-5019 deletion completed in 8.660981423s

• [SLOW TEST:29.477 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:52:25.265: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1800
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:52:25.537: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685" in namespace "downward-api-1800" to be "success or failure"
Nov 20 17:52:25.551: INFO: Pod "downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685": Phase="Pending", Reason="", readiness=false. Elapsed: 13.477823ms
Nov 20 17:52:27.571: INFO: Pod "downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03347813s
STEP: Saw pod success
Nov 20 17:52:27.571: INFO: Pod "downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685" satisfied condition "success or failure"
Nov 20 17:52:27.589: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685 container client-container: <nil>
STEP: delete the pod
Nov 20 17:52:27.694: INFO: Waiting for pod downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685 to disappear
Nov 20 17:52:27.707: INFO: Pod downwardapi-volume-d9f57c1a-ffb2-48c3-a26b-cf73c8b56685 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:52:27.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1800" for this suite.
Nov 20 17:52:33.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:52:34.228: INFO: namespace downward-api-1800 deletion completed in 6.499249407s

• [SLOW TEST:8.963 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:52:34.229: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 20 17:52:34.483: INFO: Waiting up to 5m0s for pod "pod-497e25f9-83fb-49d8-b106-85e61146e09d" in namespace "emptydir-6455" to be "success or failure"
Nov 20 17:52:34.495: INFO: Pod "pod-497e25f9-83fb-49d8-b106-85e61146e09d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.355168ms
Nov 20 17:52:36.509: INFO: Pod "pod-497e25f9-83fb-49d8-b106-85e61146e09d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025736784s
STEP: Saw pod success
Nov 20 17:52:36.509: INFO: Pod "pod-497e25f9-83fb-49d8-b106-85e61146e09d" satisfied condition "success or failure"
Nov 20 17:52:36.523: INFO: Trying to get logs from node 10.184.110.176 pod pod-497e25f9-83fb-49d8-b106-85e61146e09d container test-container: <nil>
STEP: delete the pod
Nov 20 17:52:36.621: INFO: Waiting for pod pod-497e25f9-83fb-49d8-b106-85e61146e09d to disappear
Nov 20 17:52:36.632: INFO: Pod pod-497e25f9-83fb-49d8-b106-85e61146e09d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:52:36.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6455" for this suite.
Nov 20 17:52:42.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:52:43.139: INFO: namespace emptydir-6455 deletion completed in 6.491929185s

• [SLOW TEST:8.910 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:52:43.140: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7231
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 17:52:44.010: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 17:52:46.043: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869164, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869164, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869164, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869163, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 17:52:49.081: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:52:49.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7231" for this suite.
Nov 20 17:52:57.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:52:58.399: INFO: namespace webhook-7231 deletion completed in 8.47149649s
STEP: Destroying namespace "webhook-7231-markers" for this suite.
Nov 20 17:53:04.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:53:05.100: INFO: namespace webhook-7231-markers deletion completed in 6.700479472s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.047 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:53:05.187: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-752f1b7e-0f22-4846-a04b-fcce4a8af5f6
STEP: Creating a pod to test consume secrets
Nov 20 17:53:05.468: INFO: Waiting up to 5m0s for pod "pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed" in namespace "secrets-6205" to be "success or failure"
Nov 20 17:53:05.490: INFO: Pod "pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed": Phase="Pending", Reason="", readiness=false. Elapsed: 21.389831ms
Nov 20 17:53:07.508: INFO: Pod "pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039850679s
STEP: Saw pod success
Nov 20 17:53:07.508: INFO: Pod "pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed" satisfied condition "success or failure"
Nov 20 17:53:07.593: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 17:53:07.805: INFO: Waiting for pod pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed to disappear
Nov 20 17:53:07.844: INFO: Pod pod-secrets-243a27ac-c440-4181-b93a-aecab7110fed no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:53:07.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6205" for this suite.
Nov 20 17:53:13.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:53:14.416: INFO: namespace secrets-6205 deletion completed in 6.540636168s

• [SLOW TEST:9.229 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:53:14.418: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:53:14.706: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:53:17.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-689" for this suite.
Nov 20 17:54:07.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:54:07.675: INFO: namespace pods-689 deletion completed in 50.567879075s

• [SLOW TEST:53.258 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:54:07.676: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-79558878-e3da-41bf-bc92-c519a0fb3934 in namespace container-probe-2912
Nov 20 17:54:09.978: INFO: Started pod busybox-79558878-e3da-41bf-bc92-c519a0fb3934 in namespace container-probe-2912
STEP: checking the pod's current state and verifying that restartCount is present
Nov 20 17:54:09.990: INFO: Initial restart count of pod busybox-79558878-e3da-41bf-bc92-c519a0fb3934 is 0
Nov 20 17:55:04.613: INFO: Restart count of pod container-probe-2912/busybox-79558878-e3da-41bf-bc92-c519a0fb3934 is now 1 (54.622583745s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:55:04.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2912" for this suite.
Nov 20 17:55:10.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:55:11.586: INFO: namespace container-probe-2912 deletion completed in 6.814907181s

• [SLOW TEST:63.911 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:55:11.586: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3248
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:55:15.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3248" for this suite.
Nov 20 17:55:27.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:55:27.987: INFO: namespace replication-controller-3248 deletion completed in 12.580378617s

• [SLOW TEST:16.401 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:55:27.988: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 17:55:28.246: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b" in namespace "projected-5439" to be "success or failure"
Nov 20 17:55:28.262: INFO: Pod "downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.056425ms
Nov 20 17:55:30.276: INFO: Pod "downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030396614s
STEP: Saw pod success
Nov 20 17:55:30.276: INFO: Pod "downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b" satisfied condition "success or failure"
Nov 20 17:55:30.293: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b container client-container: <nil>
STEP: delete the pod
Nov 20 17:55:30.449: INFO: Waiting for pod downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b to disappear
Nov 20 17:55:30.461: INFO: Pod downwardapi-volume-58a93fa6-bbee-4fe4-9d08-8f4dabe1af8b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:55:30.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5439" for this suite.
Nov 20 17:55:36.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:55:36.999: INFO: namespace projected-5439 deletion completed in 6.518419621s

• [SLOW TEST:9.011 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:55:37.000: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-1449
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:55:37.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-1449" for this suite.
Nov 20 17:55:43.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:55:43.732: INFO: namespace tables-1449 deletion completed in 6.472913033s

• [SLOW TEST:6.732 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:55:43.732: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:55:43.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-9384'
Nov 20 17:55:44.365: INFO: stderr: ""
Nov 20 17:55:44.365: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov 20 17:55:44.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-9384'
Nov 20 17:55:44.768: INFO: stderr: ""
Nov 20 17:55:44.768: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 20 17:55:45.784: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:55:45.784: INFO: Found 0 / 1
Nov 20 17:55:46.781: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:55:46.782: INFO: Found 1 / 1
Nov 20 17:55:46.782: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 20 17:55:46.797: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 17:55:46.797: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 20 17:55:46.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 describe pod redis-master-l2xcz --namespace=kubectl-9384'
Nov 20 17:55:46.987: INFO: stderr: ""
Nov 20 17:55:46.987: INFO: stdout: "Name:         redis-master-l2xcz\nNamespace:    kubectl-9384\nPriority:     0\nNode:         10.184.110.176/10.184.110.176\nStart Time:   Wed, 20 Nov 2019 17:55:44 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.70.97\nIPs:\n  IP:           172.30.70.97\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://65f101d758f3d53573e01d0523e3901bcd058f7102da7092b312752c371b14bd\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Wed, 20 Nov 2019 17:55:45 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-m57ft (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-m57ft:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-m57ft\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age        From                     Message\n  ----    ------     ----       ----                     -------\n  Normal  Scheduled  <unknown>  default-scheduler        Successfully assigned kubectl-9384/redis-master-l2xcz to 10.184.110.176\n  Normal  Pulled     1s         kubelet, 10.184.110.176  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, 10.184.110.176  Created container redis-master\n  Normal  Started    1s         kubelet, 10.184.110.176  Started container redis-master\n"
Nov 20 17:55:46.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 describe rc redis-master --namespace=kubectl-9384'
Nov 20 17:55:47.170: INFO: stderr: ""
Nov 20 17:55:47.170: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9384\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-l2xcz\n"
Nov 20 17:55:47.170: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 describe service redis-master --namespace=kubectl-9384'
Nov 20 17:55:47.466: INFO: stderr: ""
Nov 20 17:55:47.466: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9384\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.12.228\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.70.97:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov 20 17:55:47.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 describe node 10.184.110.140'
Nov 20 17:55:47.730: INFO: stderr: ""
Nov 20 17:55:47.730: INFO: stdout: "Name:               10.184.110.140\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal12\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.63.53.2\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.184.110.140\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bnam3ubd0mmp4tre1o00-kubee2epvgh-default-00000223\n                    ibm-cloud.kubernetes.io/worker-pool-id=bnam3ubd0mmp4tre1o00-1f7d4db\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.2_1515\n                    ibm-cloud.kubernetes.io/zone=dal12\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.184.110.140\n                    kubernetes.io/os=linux\n                    privateVLAN=1764905\n                    publicVLAN=1764903\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Wed, 20 Nov 2019 16:18:03 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Wed, 20 Nov 2019 17:55:12 +0000   Wed, 20 Nov 2019 16:18:03 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Wed, 20 Nov 2019 17:55:12 +0000   Wed, 20 Nov 2019 16:18:03 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Wed, 20 Nov 2019 17:55:12 +0000   Wed, 20 Nov 2019 16:18:03 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Wed, 20 Nov 2019 17:55:12 +0000   Wed, 20 Nov 2019 16:18:14 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.184.110.140\n  ExternalIP:  169.63.53.2\n  Hostname:    10.184.110.140\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419956Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627508Ki\n pods:               110\nSystem Info:\n Machine ID:                 1ef72f1e655a421db8da14dcbcd40967\n System UUID:                320E1C85-6C26-0C26-6483-C72D3AD28F22\n Boot ID:                    488f03d2-149b-429c-9002-3c28eedf9589\n Kernel Version:             4.15.0-66-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.0\n Kubelet Version:            v1.16.2+IKS\n Kube-Proxy Version:         v1.16.2+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bnam3ubd0mmp4tre1o00/kube-bnam3ubd0mmp4tre1o00-kubee2epvgh-default-00000223\nNon-terminated Pods:         (8 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                 addon-catalog-source-67xr7                                 10m (0%)      0 (0%)      50Mi (0%)        0 (0%)         97m\n  kube-system                calico-node-4dc2d                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         97m\n  kube-system                coredns-6db888bf8c-7xqjq                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     27m\n  kube-system                coredns-6db888bf8c-jr582                                   100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     87m\n  kube-system                ibm-keepalived-watcher-d59s8                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         97m\n  kube-system                ibm-master-proxy-static-10.184.110.140                     25m (0%)      300m (7%)   32M (0%)         512M (3%)      97m\n  sonobuoy                   sonobuoy-e2e-job-b1a8acd3cb8d418c                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7    0 (0%)        0 (0%)      0 (0%)           0 (0%)         42m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                490m (12%)     300m (7%)\n  memory             317970Ki (2%)  1319200Ki (9%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Nov 20 17:55:47.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 describe namespace kubectl-9384'
Nov 20 17:55:47.918: INFO: stderr: ""
Nov 20 17:55:47.918: INFO: stdout: "Name:         kubectl-9384\nLabels:       e2e-framework=kubectl\n              e2e-run=6fa2af08-5320-4d69-9117-748496b56198\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:55:47.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9384" for this suite.
Nov 20 17:56:18.065: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:56:18.707: INFO: namespace kubectl-9384 deletion completed in 30.772382166s

• [SLOW TEST:34.976 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:56:18.709: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-pz4t7 in namespace proxy-4120
I1120 17:56:19.150515      23 runners.go:184] Created replication controller with name: proxy-service-pz4t7, namespace: proxy-4120, replica count: 1
I1120 17:56:20.200971      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1120 17:56:21.201266      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:22.215106      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:23.215422      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:24.215804      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:25.216088      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:26.216373      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:27.216604      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1120 17:56:28.216803      23 runners.go:184] proxy-service-pz4t7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 20 17:56:28.234: INFO: setup took 9.142044307s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov 20 17:56:28.274: INFO: (0) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 39.425054ms)
Nov 20 17:56:28.279: INFO: (0) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 44.790205ms)
Nov 20 17:56:28.280: INFO: (0) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 45.477333ms)
Nov 20 17:56:28.280: INFO: (0) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 45.455004ms)
Nov 20 17:56:28.280: INFO: (0) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 45.605401ms)
Nov 20 17:56:28.280: INFO: (0) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 46.204496ms)
Nov 20 17:56:28.287: INFO: (0) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 52.959131ms)
Nov 20 17:56:28.287: INFO: (0) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 52.67964ms)
Nov 20 17:56:28.288: INFO: (0) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 53.470923ms)
Nov 20 17:56:28.300: INFO: (0) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 65.132355ms)
Nov 20 17:56:28.300: INFO: (0) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 65.202032ms)
Nov 20 17:56:28.300: INFO: (0) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 65.805086ms)
Nov 20 17:56:28.308: INFO: (0) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 73.639631ms)
Nov 20 17:56:28.309: INFO: (0) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 74.633501ms)
Nov 20 17:56:28.493: INFO: (0) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 258.862125ms)
Nov 20 17:56:28.493: INFO: (0) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 259.129981ms)
Nov 20 17:56:28.519: INFO: (1) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 25.102335ms)
Nov 20 17:56:28.534: INFO: (1) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 40.545209ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 40.943567ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 41.023013ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 41.321493ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 41.208219ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 41.014725ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 41.605323ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 41.149214ms)
Nov 20 17:56:28.535: INFO: (1) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 41.184139ms)
Nov 20 17:56:28.550: INFO: (1) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 56.021233ms)
Nov 20 17:56:28.560: INFO: (1) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 65.719185ms)
Nov 20 17:56:28.560: INFO: (1) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 66.04305ms)
Nov 20 17:56:28.560: INFO: (1) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 66.470422ms)
Nov 20 17:56:28.560: INFO: (1) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 66.475247ms)
Nov 20 17:56:28.560: INFO: (1) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 66.284935ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 34.524759ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 34.725524ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 34.595618ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 34.735137ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 34.935209ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 34.835861ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 34.822033ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 34.834875ms)
Nov 20 17:56:28.595: INFO: (2) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 35.068927ms)
Nov 20 17:56:28.596: INFO: (2) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 35.197989ms)
Nov 20 17:56:28.599: INFO: (2) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 38.456818ms)
Nov 20 17:56:28.603: INFO: (2) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 42.253486ms)
Nov 20 17:56:28.603: INFO: (2) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 42.711934ms)
Nov 20 17:56:28.604: INFO: (2) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 43.020305ms)
Nov 20 17:56:28.612: INFO: (2) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 51.125391ms)
Nov 20 17:56:28.612: INFO: (2) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 51.153962ms)
Nov 20 17:56:28.634: INFO: (3) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 21.871349ms)
Nov 20 17:56:28.639: INFO: (3) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 27.008465ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 27.158187ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 27.438553ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 27.582818ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 27.650204ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 27.408696ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 28.081581ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 27.398315ms)
Nov 20 17:56:28.640: INFO: (3) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 28.009379ms)
Nov 20 17:56:28.650: INFO: (3) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 38.299929ms)
Nov 20 17:56:28.657: INFO: (3) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 44.150907ms)
Nov 20 17:56:28.657: INFO: (3) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 44.914813ms)
Nov 20 17:56:28.657: INFO: (3) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 44.882284ms)
Nov 20 17:56:28.657: INFO: (3) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 44.499028ms)
Nov 20 17:56:28.657: INFO: (3) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 45.060982ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 47.247854ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 46.900854ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 47.183597ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 47.109254ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 47.684958ms)
Nov 20 17:56:28.705: INFO: (4) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 47.429708ms)
Nov 20 17:56:28.706: INFO: (4) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 48.077059ms)
Nov 20 17:56:28.706: INFO: (4) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 47.940409ms)
Nov 20 17:56:28.706: INFO: (4) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 48.318695ms)
Nov 20 17:56:28.706: INFO: (4) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 48.054234ms)
Nov 20 17:56:28.706: INFO: (4) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 48.743055ms)
Nov 20 17:56:28.715: INFO: (4) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 57.392085ms)
Nov 20 17:56:28.715: INFO: (4) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 57.469832ms)
Nov 20 17:56:28.715: INFO: (4) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 57.317046ms)
Nov 20 17:56:28.715: INFO: (4) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 57.415145ms)
Nov 20 17:56:28.716: INFO: (4) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 58.186377ms)
Nov 20 17:56:28.746: INFO: (5) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 29.422025ms)
Nov 20 17:56:28.747: INFO: (5) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 29.648052ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 30.507968ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 31.537154ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 31.177133ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 30.849648ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 32.316747ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 31.250896ms)
Nov 20 17:56:28.748: INFO: (5) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 31.643083ms)
Nov 20 17:56:28.749: INFO: (5) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.084818ms)
Nov 20 17:56:28.757: INFO: (5) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 40.273088ms)
Nov 20 17:56:28.767: INFO: (5) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 50.039172ms)
Nov 20 17:56:28.773: INFO: (5) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 56.124623ms)
Nov 20 17:56:28.773: INFO: (5) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 56.11188ms)
Nov 20 17:56:28.782: INFO: (5) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 65.329695ms)
Nov 20 17:56:28.782: INFO: (5) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 64.951548ms)
Nov 20 17:56:28.812: INFO: (6) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 29.1028ms)
Nov 20 17:56:28.812: INFO: (6) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 29.222454ms)
Nov 20 17:56:28.812: INFO: (6) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 28.814755ms)
Nov 20 17:56:28.812: INFO: (6) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 29.697596ms)
Nov 20 17:56:28.813: INFO: (6) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 29.968344ms)
Nov 20 17:56:28.813: INFO: (6) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 30.786606ms)
Nov 20 17:56:28.813: INFO: (6) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 30.523562ms)
Nov 20 17:56:28.813: INFO: (6) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 30.776796ms)
Nov 20 17:56:28.814: INFO: (6) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 30.643406ms)
Nov 20 17:56:28.814: INFO: (6) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 30.977076ms)
Nov 20 17:56:28.818: INFO: (6) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 35.881953ms)
Nov 20 17:56:28.823: INFO: (6) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 40.502138ms)
Nov 20 17:56:28.823: INFO: (6) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 40.530206ms)
Nov 20 17:56:28.824: INFO: (6) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 40.713569ms)
Nov 20 17:56:28.824: INFO: (6) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 40.902278ms)
Nov 20 17:56:28.829: INFO: (6) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 46.604632ms)
Nov 20 17:56:28.859: INFO: (7) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 29.276464ms)
Nov 20 17:56:28.859: INFO: (7) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 29.985141ms)
Nov 20 17:56:28.863: INFO: (7) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 33.138493ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 33.692382ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 33.814806ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 34.26477ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 34.372567ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 34.098731ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 34.223483ms)
Nov 20 17:56:28.864: INFO: (7) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 34.149184ms)
Nov 20 17:56:28.872: INFO: (7) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 42.450307ms)
Nov 20 17:56:28.877: INFO: (7) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 46.354473ms)
Nov 20 17:56:28.877: INFO: (7) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 46.580152ms)
Nov 20 17:56:28.877: INFO: (7) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 47.225686ms)
Nov 20 17:56:28.877: INFO: (7) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 46.959742ms)
Nov 20 17:56:28.877: INFO: (7) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 46.680405ms)
Nov 20 17:56:28.897: INFO: (8) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 20.061382ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 27.418906ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 27.409731ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 27.423823ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 27.632387ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 27.257251ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 27.36923ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 27.561469ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 27.647831ms)
Nov 20 17:56:28.905: INFO: (8) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 27.574382ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 47.844178ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 47.882188ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 48.129631ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 47.961845ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 47.997968ms)
Nov 20 17:56:28.925: INFO: (8) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 48.139162ms)
Nov 20 17:56:28.956: INFO: (9) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 30.097893ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 32.449463ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 32.173271ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 32.280217ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 32.580045ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.296123ms)
Nov 20 17:56:28.958: INFO: (9) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.31022ms)
Nov 20 17:56:28.963: INFO: (9) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 37.846416ms)
Nov 20 17:56:28.963: INFO: (9) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 37.768304ms)
Nov 20 17:56:28.964: INFO: (9) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 37.870158ms)
Nov 20 17:56:28.969: INFO: (9) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 43.352306ms)
Nov 20 17:56:28.971: INFO: (9) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 45.4605ms)
Nov 20 17:56:28.972: INFO: (9) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 45.913565ms)
Nov 20 17:56:28.972: INFO: (9) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 46.107427ms)
Nov 20 17:56:28.972: INFO: (9) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 46.133727ms)
Nov 20 17:56:28.972: INFO: (9) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 46.129352ms)
Nov 20 17:56:28.995: INFO: (10) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 22.894625ms)
Nov 20 17:56:29.002: INFO: (10) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 28.991198ms)
Nov 20 17:56:29.003: INFO: (10) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 29.457559ms)
Nov 20 17:56:29.002: INFO: (10) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 29.012896ms)
Nov 20 17:56:29.003: INFO: (10) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 29.775088ms)
Nov 20 17:56:29.003: INFO: (10) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 30.077813ms)
Nov 20 17:56:29.007: INFO: (10) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 34.610746ms)
Nov 20 17:56:29.008: INFO: (10) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 34.854496ms)
Nov 20 17:56:29.008: INFO: (10) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 35.384094ms)
Nov 20 17:56:29.008: INFO: (10) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 35.494784ms)
Nov 20 17:56:29.015: INFO: (10) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 41.295551ms)
Nov 20 17:56:29.021: INFO: (10) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 47.938791ms)
Nov 20 17:56:29.022: INFO: (10) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 48.49965ms)
Nov 20 17:56:29.022: INFO: (10) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 49.128151ms)
Nov 20 17:56:29.022: INFO: (10) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 49.708549ms)
Nov 20 17:56:29.022: INFO: (10) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 49.843484ms)
Nov 20 17:56:29.056: INFO: (11) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.497026ms)
Nov 20 17:56:29.056: INFO: (11) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 32.643288ms)
Nov 20 17:56:29.056: INFO: (11) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 32.876579ms)
Nov 20 17:56:29.056: INFO: (11) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 33.557916ms)
Nov 20 17:56:29.056: INFO: (11) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 34.364491ms)
Nov 20 17:56:29.057: INFO: (11) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 33.571642ms)
Nov 20 17:56:29.057: INFO: (11) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 34.024192ms)
Nov 20 17:56:29.057: INFO: (11) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 33.610281ms)
Nov 20 17:56:29.057: INFO: (11) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 34.055368ms)
Nov 20 17:56:29.057: INFO: (11) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 34.4025ms)
Nov 20 17:56:29.076: INFO: (11) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 53.308917ms)
Nov 20 17:56:29.076: INFO: (11) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 53.710872ms)
Nov 20 17:56:29.076: INFO: (11) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 52.785246ms)
Nov 20 17:56:29.076: INFO: (11) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 52.945493ms)
Nov 20 17:56:29.081: INFO: (11) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 58.06589ms)
Nov 20 17:56:29.081: INFO: (11) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 57.265282ms)
Nov 20 17:56:29.127: INFO: (12) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 46.602582ms)
Nov 20 17:56:29.128: INFO: (12) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 46.989745ms)
Nov 20 17:56:29.128: INFO: (12) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 47.472307ms)
Nov 20 17:56:29.128: INFO: (12) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 47.609165ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 47.779327ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 47.698627ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 47.663178ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 47.970412ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 47.952733ms)
Nov 20 17:56:29.129: INFO: (12) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 48.079224ms)
Nov 20 17:56:29.136: INFO: (12) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 55.571591ms)
Nov 20 17:56:29.139: INFO: (12) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 57.755552ms)
Nov 20 17:56:29.139: INFO: (12) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 58.123879ms)
Nov 20 17:56:29.139: INFO: (12) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 58.192014ms)
Nov 20 17:56:29.139: INFO: (12) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 58.25949ms)
Nov 20 17:56:29.140: INFO: (12) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 59.752397ms)
Nov 20 17:56:29.171: INFO: (13) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 29.644475ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.531649ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 33.419867ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 33.413223ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 33.597245ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 33.479132ms)
Nov 20 17:56:29.174: INFO: (13) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 33.43273ms)
Nov 20 17:56:29.175: INFO: (13) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 33.963576ms)
Nov 20 17:56:29.183: INFO: (13) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 41.621488ms)
Nov 20 17:56:29.183: INFO: (13) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 41.973811ms)
Nov 20 17:56:29.190: INFO: (13) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 48.621516ms)
Nov 20 17:56:29.201: INFO: (13) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 60.034406ms)
Nov 20 17:56:29.201: INFO: (13) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 60.142029ms)
Nov 20 17:56:29.201: INFO: (13) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 60.431565ms)
Nov 20 17:56:29.201: INFO: (13) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 60.364355ms)
Nov 20 17:56:29.212: INFO: (13) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 71.121517ms)
Nov 20 17:56:29.246: INFO: (14) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 34.435108ms)
Nov 20 17:56:29.246: INFO: (14) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 34.171907ms)
Nov 20 17:56:29.247: INFO: (14) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 34.17716ms)
Nov 20 17:56:29.247: INFO: (14) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 35.035509ms)
Nov 20 17:56:29.247: INFO: (14) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 35.152902ms)
Nov 20 17:56:29.247: INFO: (14) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 35.201859ms)
Nov 20 17:56:29.248: INFO: (14) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 35.508237ms)
Nov 20 17:56:29.248: INFO: (14) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 35.696105ms)
Nov 20 17:56:29.248: INFO: (14) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 35.57958ms)
Nov 20 17:56:29.248: INFO: (14) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 35.582977ms)
Nov 20 17:56:29.259: INFO: (14) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 47.181398ms)
Nov 20 17:56:29.266: INFO: (14) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 54.128077ms)
Nov 20 17:56:29.275: INFO: (14) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 62.318816ms)
Nov 20 17:56:29.275: INFO: (14) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 62.488047ms)
Nov 20 17:56:29.275: INFO: (14) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 62.499845ms)
Nov 20 17:56:29.275: INFO: (14) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 62.526729ms)
Nov 20 17:56:29.300: INFO: (15) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 24.546243ms)
Nov 20 17:56:29.312: INFO: (15) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 35.895191ms)
Nov 20 17:56:29.312: INFO: (15) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 36.958727ms)
Nov 20 17:56:29.312: INFO: (15) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 36.834151ms)
Nov 20 17:56:29.312: INFO: (15) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 36.764358ms)
Nov 20 17:56:29.313: INFO: (15) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 37.265676ms)
Nov 20 17:56:29.313: INFO: (15) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 36.834878ms)
Nov 20 17:56:29.313: INFO: (15) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 36.19553ms)
Nov 20 17:56:29.313: INFO: (15) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 36.792522ms)
Nov 20 17:56:29.313: INFO: (15) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 36.943506ms)
Nov 20 17:56:29.326: INFO: (15) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 49.882673ms)
Nov 20 17:56:29.332: INFO: (15) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 56.402237ms)
Nov 20 17:56:29.332: INFO: (15) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 55.895351ms)
Nov 20 17:56:29.332: INFO: (15) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 56.41029ms)
Nov 20 17:56:29.332: INFO: (15) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 55.791606ms)
Nov 20 17:56:29.333: INFO: (15) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 56.346816ms)
Nov 20 17:56:29.356: INFO: (16) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 23.468209ms)
Nov 20 17:56:29.361: INFO: (16) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 27.671211ms)
Nov 20 17:56:29.361: INFO: (16) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 27.597499ms)
Nov 20 17:56:29.361: INFO: (16) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 27.89487ms)
Nov 20 17:56:29.361: INFO: (16) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 27.709931ms)
Nov 20 17:56:29.362: INFO: (16) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 28.484137ms)
Nov 20 17:56:29.362: INFO: (16) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 28.635795ms)
Nov 20 17:56:29.362: INFO: (16) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 28.242782ms)
Nov 20 17:56:29.362: INFO: (16) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 29.248725ms)
Nov 20 17:56:29.363: INFO: (16) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 30.359318ms)
Nov 20 17:56:29.367: INFO: (16) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 33.947319ms)
Nov 20 17:56:29.374: INFO: (16) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 40.55671ms)
Nov 20 17:56:29.374: INFO: (16) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 41.229597ms)
Nov 20 17:56:29.374: INFO: (16) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 41.223976ms)
Nov 20 17:56:29.374: INFO: (16) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 40.865663ms)
Nov 20 17:56:29.374: INFO: (16) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 40.755216ms)
Nov 20 17:56:29.410: INFO: (17) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 35.649345ms)
Nov 20 17:56:29.426: INFO: (17) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 50.832331ms)
Nov 20 17:56:29.426: INFO: (17) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 50.981819ms)
Nov 20 17:56:29.426: INFO: (17) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 51.154211ms)
Nov 20 17:56:29.426: INFO: (17) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 51.225694ms)
Nov 20 17:56:29.427: INFO: (17) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 51.940612ms)
Nov 20 17:56:29.427: INFO: (17) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 51.752212ms)
Nov 20 17:56:29.427: INFO: (17) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 52.11141ms)
Nov 20 17:56:29.427: INFO: (17) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 52.061283ms)
Nov 20 17:56:29.427: INFO: (17) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 52.236263ms)
Nov 20 17:56:29.438: INFO: (17) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 63.515965ms)
Nov 20 17:56:29.444: INFO: (17) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 69.601788ms)
Nov 20 17:56:29.445: INFO: (17) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 70.186798ms)
Nov 20 17:56:29.445: INFO: (17) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 70.533509ms)
Nov 20 17:56:29.445: INFO: (17) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 70.232815ms)
Nov 20 17:56:29.445: INFO: (17) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 70.384093ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 119.302018ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 119.253193ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 119.305602ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 119.587915ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 119.372717ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 119.582466ms)
Nov 20 17:56:29.565: INFO: (18) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 119.301028ms)
Nov 20 17:56:29.566: INFO: (18) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 120.267444ms)
Nov 20 17:56:29.566: INFO: (18) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 120.451417ms)
Nov 20 17:56:29.566: INFO: (18) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 120.36843ms)
Nov 20 17:56:29.566: INFO: (18) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 120.641539ms)
Nov 20 17:56:29.566: INFO: (18) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 120.921812ms)
Nov 20 17:56:29.579: INFO: (18) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 133.34166ms)
Nov 20 17:56:29.579: INFO: (18) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 133.296483ms)
Nov 20 17:56:29.579: INFO: (18) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 133.602568ms)
Nov 20 17:56:29.579: INFO: (18) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 133.235461ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 32.238078ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w/proxy/rewriteme">test</a> (200; 32.246622ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:160/proxy/: foo (200; 32.256817ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.227202ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">... (200; 32.531227ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/http:proxy-service-pz4t7-fwg5w:162/proxy/: bar (200; 32.826908ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:443/proxy/tlsrewritem... (200; 32.432111ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:460/proxy/: tls baz (200; 33.082831ms)
Nov 20 17:56:29.612: INFO: (19) /api/v1/namespaces/proxy-4120/pods/https:proxy-service-pz4t7-fwg5w:462/proxy/: tls qux (200; 32.425071ms)
Nov 20 17:56:29.617: INFO: (19) /api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/: <a href="/api/v1/namespaces/proxy-4120/pods/proxy-service-pz4t7-fwg5w:1080/proxy/rewriteme">test<... (200; 37.359066ms)
Nov 20 17:56:29.623: INFO: (19) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname1/proxy/: foo (200; 43.300281ms)
Nov 20 17:56:29.630: INFO: (19) /api/v1/namespaces/proxy-4120/services/proxy-service-pz4t7:portname2/proxy/: bar (200; 50.741546ms)
Nov 20 17:56:29.630: INFO: (19) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname2/proxy/: bar (200; 50.570617ms)
Nov 20 17:56:29.630: INFO: (19) /api/v1/namespaces/proxy-4120/services/http:proxy-service-pz4t7:portname1/proxy/: foo (200; 50.929363ms)
Nov 20 17:56:29.630: INFO: (19) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname2/proxy/: tls qux (200; 50.534627ms)
Nov 20 17:56:29.630: INFO: (19) /api/v1/namespaces/proxy-4120/services/https:proxy-service-pz4t7:tlsportname1/proxy/: tls baz (200; 50.266314ms)
STEP: deleting ReplicationController proxy-service-pz4t7 in namespace proxy-4120, will wait for the garbage collector to delete the pods
Nov 20 17:56:29.754: INFO: Deleting ReplicationController proxy-service-pz4t7 took: 52.18408ms
Nov 20 17:56:29.955: INFO: Terminating ReplicationController proxy-service-pz4t7 pods took: 200.326781ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:56:35.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4120" for this suite.
Nov 20 17:56:42.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:56:42.517: INFO: namespace proxy-4120 deletion completed in 6.542601716s

• [SLOW TEST:23.809 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:56:42.517: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7667
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov 20 17:56:42.766: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov 20 17:56:58.086: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 17:57:02.102: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:57:17.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7667" for this suite.
Nov 20 17:57:23.248: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:57:23.706: INFO: namespace crd-publish-openapi-7667 deletion completed in 6.522700844s

• [SLOW TEST:41.189 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:57:23.707: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8125
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:57:26.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8125" for this suite.
Nov 20 17:57:38.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:57:38.779: INFO: namespace containers-8125 deletion completed in 12.570894443s

• [SLOW TEST:15.073 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:57:38.780: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov 20 17:57:39.056: INFO: Waiting up to 5m0s for pod "downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082" in namespace "downward-api-2239" to be "success or failure"
Nov 20 17:57:39.074: INFO: Pod "downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082": Phase="Pending", Reason="", readiness=false. Elapsed: 17.949285ms
Nov 20 17:57:41.087: INFO: Pod "downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030987603s
STEP: Saw pod success
Nov 20 17:57:41.087: INFO: Pod "downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082" satisfied condition "success or failure"
Nov 20 17:57:41.102: INFO: Trying to get logs from node 10.184.110.176 pod downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082 container dapi-container: <nil>
STEP: delete the pod
Nov 20 17:57:41.186: INFO: Waiting for pod downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082 to disappear
Nov 20 17:57:41.201: INFO: Pod downward-api-44d0dcf0-2816-4622-991c-a18c7ad17082 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:57:41.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2239" for this suite.
Nov 20 17:57:47.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:57:47.678: INFO: namespace downward-api-2239 deletion completed in 6.455442692s

• [SLOW TEST:8.898 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:57:47.679: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2398
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-ae022fcd-3a06-4283-b551-96e5f103a9d9
STEP: Creating configMap with name cm-test-opt-upd-b1965af0-93fa-4b34-858f-acef8ceac494
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ae022fcd-3a06-4283-b551-96e5f103a9d9
STEP: Updating configmap cm-test-opt-upd-b1965af0-93fa-4b34-858f-acef8ceac494
STEP: Creating configMap with name cm-test-opt-create-6ce9516d-60a2-4cc0-955e-cbffc61c8568
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:57:52.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2398" for this suite.
Nov 20 17:58:04.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:58:05.122: INFO: namespace configmap-2398 deletion completed in 12.740950058s

• [SLOW TEST:17.443 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:58:05.122: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Nov 20 17:58:05.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-3678'
Nov 20 17:58:05.730: INFO: stderr: ""
Nov 20 17:58:05.730: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 17:58:05.730: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3678'
Nov 20 17:58:05.883: INFO: stderr: ""
Nov 20 17:58:05.883: INFO: stdout: "update-demo-nautilus-flv8r update-demo-nautilus-l8fkj "
Nov 20 17:58:05.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-flv8r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:06.028: INFO: stderr: ""
Nov 20 17:58:06.028: INFO: stdout: ""
Nov 20 17:58:06.028: INFO: update-demo-nautilus-flv8r is created but not running
Nov 20 17:58:11.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3678'
Nov 20 17:58:11.160: INFO: stderr: ""
Nov 20 17:58:11.160: INFO: stdout: "update-demo-nautilus-flv8r update-demo-nautilus-l8fkj "
Nov 20 17:58:11.160: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-flv8r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:11.294: INFO: stderr: ""
Nov 20 17:58:11.294: INFO: stdout: "true"
Nov 20 17:58:11.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-flv8r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:11.436: INFO: stderr: ""
Nov 20 17:58:11.436: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 17:58:11.436: INFO: validating pod update-demo-nautilus-flv8r
Nov 20 17:58:11.486: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 17:58:11.486: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 17:58:11.486: INFO: update-demo-nautilus-flv8r is verified up and running
Nov 20 17:58:11.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-l8fkj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:11.637: INFO: stderr: ""
Nov 20 17:58:11.637: INFO: stdout: "true"
Nov 20 17:58:11.637: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-l8fkj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:11.772: INFO: stderr: ""
Nov 20 17:58:11.772: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 17:58:11.772: INFO: validating pod update-demo-nautilus-l8fkj
Nov 20 17:58:11.808: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 17:58:11.808: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 17:58:11.808: INFO: update-demo-nautilus-l8fkj is verified up and running
STEP: rolling-update to new replication controller
Nov 20 17:58:11.811: INFO: scanned /root for discovery docs: <nil>
Nov 20 17:58:11.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-3678'
Nov 20 17:58:34.811: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 20 17:58:34.811: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 17:58:34.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3678'
Nov 20 17:58:34.954: INFO: stderr: ""
Nov 20 17:58:34.954: INFO: stdout: "update-demo-kitten-5lnqd update-demo-kitten-pp72b update-demo-nautilus-l8fkj "
STEP: Replicas for name=update-demo: expected=2 actual=3
Nov 20 17:58:39.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3678'
Nov 20 17:58:40.097: INFO: stderr: ""
Nov 20 17:58:40.097: INFO: stdout: "update-demo-kitten-5lnqd update-demo-kitten-pp72b "
Nov 20 17:58:40.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-kitten-5lnqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:40.216: INFO: stderr: ""
Nov 20 17:58:40.216: INFO: stdout: "true"
Nov 20 17:58:40.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-kitten-5lnqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:40.347: INFO: stderr: ""
Nov 20 17:58:40.347: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 20 17:58:40.347: INFO: validating pod update-demo-kitten-5lnqd
Nov 20 17:58:40.381: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 20 17:58:40.381: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 20 17:58:40.381: INFO: update-demo-kitten-5lnqd is verified up and running
Nov 20 17:58:40.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-kitten-pp72b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:40.507: INFO: stderr: ""
Nov 20 17:58:40.507: INFO: stdout: "true"
Nov 20 17:58:40.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-kitten-pp72b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3678'
Nov 20 17:58:40.646: INFO: stderr: ""
Nov 20 17:58:40.646: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov 20 17:58:40.646: INFO: validating pod update-demo-kitten-pp72b
Nov 20 17:58:40.676: INFO: got data: {
  "image": "kitten.jpg"
}

Nov 20 17:58:40.676: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov 20 17:58:40.676: INFO: update-demo-kitten-pp72b is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:58:40.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3678" for this suite.
Nov 20 17:59:10.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:59:11.628: INFO: namespace kubectl-3678 deletion completed in 30.928513445s

• [SLOW TEST:66.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:59:11.629: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2996
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:59:11.997: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2996" for this suite.
Nov 20 17:59:18.099: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:59:18.569: INFO: namespace resourcequota-2996 deletion completed in 6.535833669s

• [SLOW TEST:6.941 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:59:18.570: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:59:18.836: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8" in namespace "security-context-test-5712" to be "success or failure"
Nov 20 17:59:18.851: INFO: Pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8": Phase="Pending", Reason="", readiness=false. Elapsed: 14.989779ms
Nov 20 17:59:20.867: INFO: Pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031198775s
Nov 20 17:59:22.897: INFO: Pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.06123616s
Nov 20 17:59:22.897: INFO: Pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8" satisfied condition "success or failure"
Nov 20 17:59:23.005: INFO: Got logs for pod "busybox-privileged-false-8b656039-469f-44c8-a7c3-f1d5bed184b8": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:59:23.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5712" for this suite.
Nov 20 17:59:29.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:59:29.583: INFO: namespace security-context-test-5712 deletion completed in 6.527849614s

• [SLOW TEST:11.012 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:59:29.583: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6888
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 17:59:29.808: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:59:30.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6888" for this suite.
Nov 20 17:59:36.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:59:37.039: INFO: namespace custom-resource-definition-6888 deletion completed in 6.566512034s

• [SLOW TEST:7.456 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:59:37.040: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-3e107dee-48c3-4c50-aae8-f891e45bb6d1
STEP: Creating a pod to test consume configMaps
Nov 20 17:59:37.298: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb" in namespace "projected-547" to be "success or failure"
Nov 20 17:59:37.315: INFO: Pod "pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb": Phase="Pending", Reason="", readiness=false. Elapsed: 17.481181ms
Nov 20 17:59:39.331: INFO: Pod "pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032812245s
STEP: Saw pod success
Nov 20 17:59:39.331: INFO: Pod "pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb" satisfied condition "success or failure"
Nov 20 17:59:39.346: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 17:59:39.446: INFO: Waiting for pod pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb to disappear
Nov 20 17:59:39.464: INFO: Pod pod-projected-configmaps-1b58b76d-eedf-4d60-b0b0-29ac755d44bb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:59:39.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-547" for this suite.
Nov 20 17:59:45.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 17:59:46.013: INFO: namespace projected-547 deletion completed in 6.531594869s

• [SLOW TEST:8.974 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 17:59:46.015: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Nov 20 17:59:48.351: INFO: Pod pod-hostip-745f0810-a076-4219-9631-e27032d9c1c7 has hostIP: 10.184.110.176
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 17:59:48.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8480" for this suite.
Nov 20 18:00:00.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:00:01.195: INFO: namespace pods-8480 deletion completed in 12.819728516s

• [SLOW TEST:15.180 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:00:01.195: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:00:01.507: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e" in namespace "downward-api-4722" to be "success or failure"
Nov 20 18:00:01.540: INFO: Pod "downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e": Phase="Pending", Reason="", readiness=false. Elapsed: 33.308321ms
Nov 20 18:00:03.558: INFO: Pod "downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050991186s
STEP: Saw pod success
Nov 20 18:00:03.558: INFO: Pod "downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e" satisfied condition "success or failure"
Nov 20 18:00:03.590: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e container client-container: <nil>
STEP: delete the pod
Nov 20 18:00:03.735: INFO: Waiting for pod downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e to disappear
Nov 20 18:00:03.749: INFO: Pod downwardapi-volume-4d7f6fc1-a2f7-4bd6-9e44-267bb676e67e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:00:03.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4722" for this suite.
Nov 20 18:00:09.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:00:10.736: INFO: namespace downward-api-4722 deletion completed in 6.967246109s

• [SLOW TEST:9.540 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:00:10.736: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8620
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:00:11.002: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov 20 18:00:14.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 create -f -'
Nov 20 18:00:15.045: INFO: stderr: ""
Nov 20 18:00:15.045: INFO: stdout: "e2e-test-crd-publish-openapi-8257-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 20 18:00:15.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 delete e2e-test-crd-publish-openapi-8257-crds test-foo'
Nov 20 18:00:15.205: INFO: stderr: ""
Nov 20 18:00:15.205: INFO: stdout: "e2e-test-crd-publish-openapi-8257-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov 20 18:00:15.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 apply -f -'
Nov 20 18:00:15.698: INFO: stderr: ""
Nov 20 18:00:15.698: INFO: stdout: "e2e-test-crd-publish-openapi-8257-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov 20 18:00:15.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 delete e2e-test-crd-publish-openapi-8257-crds test-foo'
Nov 20 18:00:15.876: INFO: stderr: ""
Nov 20 18:00:15.876: INFO: stdout: "e2e-test-crd-publish-openapi-8257-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov 20 18:00:15.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 create -f -'
Nov 20 18:00:16.124: INFO: rc: 1
Nov 20 18:00:16.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 apply -f -'
Nov 20 18:00:16.439: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov 20 18:00:16.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 create -f -'
Nov 20 18:00:16.750: INFO: rc: 1
Nov 20 18:00:16.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-8620 apply -f -'
Nov 20 18:00:16.966: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov 20 18:00:16.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-8257-crds'
Nov 20 18:00:17.322: INFO: stderr: ""
Nov 20 18:00:17.322: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8257-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov 20 18:00:17.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-8257-crds.metadata'
Nov 20 18:00:17.554: INFO: stderr: ""
Nov 20 18:00:17.554: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8257-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov 20 18:00:17.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-8257-crds.spec'
Nov 20 18:00:17.797: INFO: stderr: ""
Nov 20 18:00:17.798: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8257-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov 20 18:00:17.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-8257-crds.spec.bars'
Nov 20 18:00:18.027: INFO: stderr: ""
Nov 20 18:00:18.027: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8257-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov 20 18:00:18.027: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-8257-crds.spec.bars2'
Nov 20 18:00:18.254: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:00:22.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8620" for this suite.
Nov 20 18:00:28.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:00:28.953: INFO: namespace crd-publish-openapi-8620 deletion completed in 6.76245663s

• [SLOW TEST:18.217 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:00:28.954: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-55a92901-b4f7-4fa5-a62e-3f37b8675fbb
STEP: Creating a pod to test consume configMaps
Nov 20 18:00:29.312: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10" in namespace "projected-3190" to be "success or failure"
Nov 20 18:00:29.335: INFO: Pod "pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10": Phase="Pending", Reason="", readiness=false. Elapsed: 22.570414ms
Nov 20 18:00:31.367: INFO: Pod "pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055039106s
STEP: Saw pod success
Nov 20 18:00:31.368: INFO: Pod "pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10" satisfied condition "success or failure"
Nov 20 18:00:31.382: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:00:31.505: INFO: Waiting for pod pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10 to disappear
Nov 20 18:00:31.519: INFO: Pod pod-projected-configmaps-15df8894-b700-4255-98fa-5f1aa6781f10 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:00:31.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3190" for this suite.
Nov 20 18:00:37.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:00:38.021: INFO: namespace projected-3190 deletion completed in 6.482320629s

• [SLOW TEST:9.067 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:00:38.023: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6863
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:00:40.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6863" for this suite.
Nov 20 18:01:28.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:01:28.941: INFO: namespace kubelet-test-6863 deletion completed in 48.513066978s

• [SLOW TEST:50.918 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:01:28.942: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1788
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:01:29.234: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66f98941-f086-43ad-a781-59036c978388" in namespace "projected-1788" to be "success or failure"
Nov 20 18:01:29.258: INFO: Pod "downwardapi-volume-66f98941-f086-43ad-a781-59036c978388": Phase="Pending", Reason="", readiness=false. Elapsed: 23.726885ms
Nov 20 18:01:31.276: INFO: Pod "downwardapi-volume-66f98941-f086-43ad-a781-59036c978388": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041530146s
Nov 20 18:01:33.297: INFO: Pod "downwardapi-volume-66f98941-f086-43ad-a781-59036c978388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063218197s
STEP: Saw pod success
Nov 20 18:01:33.297: INFO: Pod "downwardapi-volume-66f98941-f086-43ad-a781-59036c978388" satisfied condition "success or failure"
Nov 20 18:01:33.309: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-66f98941-f086-43ad-a781-59036c978388 container client-container: <nil>
STEP: delete the pod
Nov 20 18:01:33.391: INFO: Waiting for pod downwardapi-volume-66f98941-f086-43ad-a781-59036c978388 to disappear
Nov 20 18:01:33.401: INFO: Pod downwardapi-volume-66f98941-f086-43ad-a781-59036c978388 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:01:33.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1788" for this suite.
Nov 20 18:01:39.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:01:39.833: INFO: namespace projected-1788 deletion completed in 6.41621108s

• [SLOW TEST:10.891 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:01:39.834: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7976
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov 20 18:01:40.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-7976'
Nov 20 18:01:40.393: INFO: stderr: ""
Nov 20 18:01:40.393: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 18:01:40.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:01:40.532: INFO: stderr: ""
Nov 20 18:01:40.532: INFO: stdout: "update-demo-nautilus-89mp7 update-demo-nautilus-96mz5 "
Nov 20 18:01:40.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-89mp7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:40.663: INFO: stderr: ""
Nov 20 18:01:40.663: INFO: stdout: ""
Nov 20 18:01:40.663: INFO: update-demo-nautilus-89mp7 is created but not running
Nov 20 18:01:45.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:01:45.800: INFO: stderr: ""
Nov 20 18:01:45.800: INFO: stdout: "update-demo-nautilus-89mp7 update-demo-nautilus-96mz5 "
Nov 20 18:01:45.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-89mp7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:45.941: INFO: stderr: ""
Nov 20 18:01:45.941: INFO: stdout: "true"
Nov 20 18:01:45.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-89mp7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:46.077: INFO: stderr: ""
Nov 20 18:01:46.077: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:01:46.077: INFO: validating pod update-demo-nautilus-89mp7
Nov 20 18:01:46.108: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:01:46.108: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:01:46.108: INFO: update-demo-nautilus-89mp7 is verified up and running
Nov 20 18:01:46.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:46.244: INFO: stderr: ""
Nov 20 18:01:46.244: INFO: stdout: "true"
Nov 20 18:01:46.244: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:46.380: INFO: stderr: ""
Nov 20 18:01:46.380: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:01:46.380: INFO: validating pod update-demo-nautilus-96mz5
Nov 20 18:01:46.412: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:01:46.412: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:01:46.412: INFO: update-demo-nautilus-96mz5 is verified up and running
STEP: scaling down the replication controller
Nov 20 18:01:46.415: INFO: scanned /root for discovery docs: <nil>
Nov 20 18:01:46.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7976'
Nov 20 18:01:47.585: INFO: stderr: ""
Nov 20 18:01:47.585: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 18:01:47.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:01:47.883: INFO: stderr: ""
Nov 20 18:01:47.883: INFO: stdout: "update-demo-nautilus-89mp7 update-demo-nautilus-96mz5 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov 20 18:01:52.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:01:53.024: INFO: stderr: ""
Nov 20 18:01:53.024: INFO: stdout: "update-demo-nautilus-96mz5 "
Nov 20 18:01:53.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:53.162: INFO: stderr: ""
Nov 20 18:01:53.163: INFO: stdout: "true"
Nov 20 18:01:53.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:53.329: INFO: stderr: ""
Nov 20 18:01:53.329: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:01:53.329: INFO: validating pod update-demo-nautilus-96mz5
Nov 20 18:01:53.351: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:01:53.351: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:01:53.351: INFO: update-demo-nautilus-96mz5 is verified up and running
STEP: scaling up the replication controller
Nov 20 18:01:53.353: INFO: scanned /root for discovery docs: <nil>
Nov 20 18:01:53.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7976'
Nov 20 18:01:54.620: INFO: stderr: ""
Nov 20 18:01:54.620: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 18:01:54.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:01:54.757: INFO: stderr: ""
Nov 20 18:01:54.757: INFO: stdout: "update-demo-nautilus-96mz5 update-demo-nautilus-j6dvt "
Nov 20 18:01:54.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:54.899: INFO: stderr: ""
Nov 20 18:01:54.899: INFO: stdout: "true"
Nov 20 18:01:54.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:55.046: INFO: stderr: ""
Nov 20 18:01:55.046: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:01:55.046: INFO: validating pod update-demo-nautilus-96mz5
Nov 20 18:01:55.068: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:01:55.068: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:01:55.068: INFO: update-demo-nautilus-96mz5 is verified up and running
Nov 20 18:01:55.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-j6dvt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:01:55.204: INFO: stderr: ""
Nov 20 18:01:55.204: INFO: stdout: ""
Nov 20 18:01:55.204: INFO: update-demo-nautilus-j6dvt is created but not running
Nov 20 18:02:00.204: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7976'
Nov 20 18:02:00.349: INFO: stderr: ""
Nov 20 18:02:00.349: INFO: stdout: "update-demo-nautilus-96mz5 update-demo-nautilus-j6dvt "
Nov 20 18:02:00.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:02:00.482: INFO: stderr: ""
Nov 20 18:02:00.482: INFO: stdout: "true"
Nov 20 18:02:00.482: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-96mz5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:02:00.617: INFO: stderr: ""
Nov 20 18:02:00.617: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:02:00.617: INFO: validating pod update-demo-nautilus-96mz5
Nov 20 18:02:00.639: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:02:00.639: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:02:00.639: INFO: update-demo-nautilus-96mz5 is verified up and running
Nov 20 18:02:00.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-j6dvt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:02:00.781: INFO: stderr: ""
Nov 20 18:02:00.781: INFO: stdout: "true"
Nov 20 18:02:00.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-j6dvt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7976'
Nov 20 18:02:00.931: INFO: stderr: ""
Nov 20 18:02:00.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 18:02:00.931: INFO: validating pod update-demo-nautilus-j6dvt
Nov 20 18:02:00.966: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 18:02:00.966: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 18:02:00.966: INFO: update-demo-nautilus-j6dvt is verified up and running
STEP: using delete to clean up resources
Nov 20 18:02:00.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-7976'
Nov 20 18:02:01.165: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 18:02:01.165: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 20 18:02:01.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7976'
Nov 20 18:02:01.345: INFO: stderr: "No resources found in kubectl-7976 namespace.\n"
Nov 20 18:02:01.345: INFO: stdout: ""
Nov 20 18:02:01.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -l name=update-demo --namespace=kubectl-7976 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 20 18:02:01.517: INFO: stderr: ""
Nov 20 18:02:01.517: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:02:01.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7976" for this suite.
Nov 20 18:02:15.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:02:16.501: INFO: namespace kubectl-7976 deletion completed in 14.959640597s

• [SLOW TEST:36.668 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:02:16.502: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5733
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5733
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5733
STEP: Creating statefulset with conflicting port in namespace statefulset-5733
STEP: Waiting until pod test-pod will start running in namespace statefulset-5733
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5733
Nov 20 18:02:19.145: INFO: Observed stateful pod in namespace: statefulset-5733, name: ss-0, uid: ed5bbaae-2129-47e3-bcd3-b1b06ffad5a4, status phase: Pending. Waiting for statefulset controller to delete.
Nov 20 18:02:22.475: INFO: Observed stateful pod in namespace: statefulset-5733, name: ss-0, uid: ed5bbaae-2129-47e3-bcd3-b1b06ffad5a4, status phase: Failed. Waiting for statefulset controller to delete.
Nov 20 18:02:22.501: INFO: Observed stateful pod in namespace: statefulset-5733, name: ss-0, uid: ed5bbaae-2129-47e3-bcd3-b1b06ffad5a4, status phase: Failed. Waiting for statefulset controller to delete.
Nov 20 18:02:22.523: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5733
STEP: Removing pod with conflicting port in namespace statefulset-5733
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5733 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 18:02:42.800: INFO: Deleting all statefulset in ns statefulset-5733
Nov 20 18:02:42.810: INFO: Scaling statefulset ss to 0
Nov 20 18:02:52.869: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:02:52.877: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:02:52.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5733" for this suite.
Nov 20 18:03:00.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:03:01.465: INFO: namespace statefulset-5733 deletion completed in 8.533866377s

• [SLOW TEST:44.964 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:03:01.466: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3163
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov 20 18:03:31.842: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1120 18:03:31.842251      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:03:31.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3163" for this suite.
Nov 20 18:03:39.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:03:40.394: INFO: namespace gc-3163 deletion completed in 8.538657872s

• [SLOW TEST:38.928 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:03:40.394: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov 20 18:03:40.659: INFO: Waiting up to 5m0s for pod "downward-api-fffea634-59b7-4107-a0cf-849599680b3f" in namespace "downward-api-1159" to be "success or failure"
Nov 20 18:03:40.672: INFO: Pod "downward-api-fffea634-59b7-4107-a0cf-849599680b3f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.192377ms
Nov 20 18:03:42.707: INFO: Pod "downward-api-fffea634-59b7-4107-a0cf-849599680b3f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.047725329s
STEP: Saw pod success
Nov 20 18:03:42.707: INFO: Pod "downward-api-fffea634-59b7-4107-a0cf-849599680b3f" satisfied condition "success or failure"
Nov 20 18:03:42.733: INFO: Trying to get logs from node 10.184.110.176 pod downward-api-fffea634-59b7-4107-a0cf-849599680b3f container dapi-container: <nil>
STEP: delete the pod
Nov 20 18:03:42.870: INFO: Waiting for pod downward-api-fffea634-59b7-4107-a0cf-849599680b3f to disappear
Nov 20 18:03:42.886: INFO: Pod downward-api-fffea634-59b7-4107-a0cf-849599680b3f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:03:42.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1159" for this suite.
Nov 20 18:03:48.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:03:49.437: INFO: namespace downward-api-1159 deletion completed in 6.531670181s

• [SLOW TEST:9.043 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:03:49.443: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7043
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1120 18:03:50.808310      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 20 18:03:50.808: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:03:50.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7043" for this suite.
Nov 20 18:03:56.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:03:57.257: INFO: namespace gc-7043 deletion completed in 6.435385498s

• [SLOW TEST:7.815 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:03:57.258: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov 20 18:03:57.518: INFO: Waiting up to 5m0s for pod "pod-5cec5c78-b963-4c73-9605-11f83838aea1" in namespace "emptydir-4449" to be "success or failure"
Nov 20 18:03:57.530: INFO: Pod "pod-5cec5c78-b963-4c73-9605-11f83838aea1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.691612ms
Nov 20 18:03:59.547: INFO: Pod "pod-5cec5c78-b963-4c73-9605-11f83838aea1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029031692s
Nov 20 18:04:01.571: INFO: Pod "pod-5cec5c78-b963-4c73-9605-11f83838aea1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053090094s
STEP: Saw pod success
Nov 20 18:04:01.571: INFO: Pod "pod-5cec5c78-b963-4c73-9605-11f83838aea1" satisfied condition "success or failure"
Nov 20 18:04:01.625: INFO: Trying to get logs from node 10.184.110.176 pod pod-5cec5c78-b963-4c73-9605-11f83838aea1 container test-container: <nil>
STEP: delete the pod
Nov 20 18:04:01.787: INFO: Waiting for pod pod-5cec5c78-b963-4c73-9605-11f83838aea1 to disappear
Nov 20 18:04:01.809: INFO: Pod pod-5cec5c78-b963-4c73-9605-11f83838aea1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:04:01.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4449" for this suite.
Nov 20 18:04:07.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:04:08.511: INFO: namespace emptydir-4449 deletion completed in 6.672580268s

• [SLOW TEST:11.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:04:08.512: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9902
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:04:09.195: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:04:11.259: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869849, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869849, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869849, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869849, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:04:14.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:04:14.326: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:04:15.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9902" for this suite.
Nov 20 18:04:23.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:04:23.881: INFO: namespace webhook-9902 deletion completed in 8.499981665s
STEP: Destroying namespace "webhook-9902-markers" for this suite.
Nov 20 18:04:29.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:04:30.407: INFO: namespace webhook-9902-markers deletion completed in 6.525953839s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.013 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:04:30.525: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov 20 18:04:30.772: INFO: namespace kubectl-9292
Nov 20 18:04:30.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-9292'
Nov 20 18:04:31.128: INFO: stderr: ""
Nov 20 18:04:31.128: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov 20 18:04:32.150: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 18:04:32.150: INFO: Found 0 / 1
Nov 20 18:04:33.142: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 18:04:33.142: INFO: Found 1 / 1
Nov 20 18:04:33.142: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov 20 18:04:33.157: INFO: Selector matched 1 pods for map[app:redis]
Nov 20 18:04:33.157: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov 20 18:04:33.157: INFO: wait on redis-master startup in kubectl-9292 
Nov 20 18:04:33.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs redis-master-7x8kj redis-master --namespace=kubectl-9292'
Nov 20 18:04:33.342: INFO: stderr: ""
Nov 20 18:04:33.342: INFO: stdout: "1:C 20 Nov 2019 18:04:32.417 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Nov 2019 18:04:32.417 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Nov 2019 18:04:32.417 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 20 Nov 2019 18:04:32.419 * Running mode=standalone, port=6379.\n1:M 20 Nov 2019 18:04:32.419 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Nov 2019 18:04:32.419 # Server initialized\n1:M 20 Nov 2019 18:04:32.419 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Nov 2019 18:04:32.419 * Ready to accept connections\n"
STEP: exposing RC
Nov 20 18:04:33.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9292'
Nov 20 18:04:33.515: INFO: stderr: ""
Nov 20 18:04:33.515: INFO: stdout: "service/rm2 exposed\n"
Nov 20 18:04:33.527: INFO: Service rm2 in namespace kubectl-9292 found.
STEP: exposing service
Nov 20 18:04:35.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9292'
Nov 20 18:04:35.755: INFO: stderr: ""
Nov 20 18:04:35.755: INFO: stdout: "service/rm3 exposed\n"
Nov 20 18:04:35.771: INFO: Service rm3 in namespace kubectl-9292 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:04:37.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9292" for this suite.
Nov 20 18:05:07.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:05:08.524: INFO: namespace kubectl-9292 deletion completed in 30.704972024s

• [SLOW TEST:37.999 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:05:08.524: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7692
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov 20 18:05:08.883: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7692 /api/v1/namespaces/watch-7692/configmaps/e2e-watch-test-resource-version 8405c070-90ba-48a3-aab1-3dfa48b9bed3 25803 0 2019-11-20 18:05:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 20 18:05:08.883: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7692 /api/v1/namespaces/watch-7692/configmaps/e2e-watch-test-resource-version 8405c070-90ba-48a3-aab1-3dfa48b9bed3 25804 0 2019-11-20 18:05:08 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:05:08.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7692" for this suite.
Nov 20 18:05:15.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:05:15.532: INFO: namespace watch-7692 deletion completed in 6.619388611s

• [SLOW TEST:7.008 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:05:15.533: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:05:16.464: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:05:18.504: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869916, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869916, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869916, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869916, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:05:21.552: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
Nov 20 18:05:21.661: INFO: Waiting for webhook configuration to be ready...
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:05:22.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4395" for this suite.
Nov 20 18:05:30.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:05:30.927: INFO: namespace webhook-4395 deletion completed in 8.615797682s
STEP: Destroying namespace "webhook-4395-markers" for this suite.
Nov 20 18:05:37.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:05:37.516: INFO: namespace webhook-4395-markers deletion completed in 6.588318873s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.050 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:05:37.584: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-4149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:05:37.814: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov 20 18:05:39.917: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:05:39.932: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4149" for this suite.
Nov 20 18:05:48.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:05:48.424: INFO: namespace replication-controller-4149 deletion completed in 8.474151763s

• [SLOW TEST:10.840 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:05:48.425: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2103
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:06:04.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2103" for this suite.
Nov 20 18:06:13.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:06:13.903: INFO: namespace resourcequota-2103 deletion completed in 8.802449162s

• [SLOW TEST:25.478 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:06:13.903: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:06:14.811: INFO: new replicaset for deployment "sample-crd-conversion-webhook-deployment" is yet to be created
Nov 20 18:06:16.848: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869974, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869974, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869974, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709869974, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:06:19.896: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:06:19.918: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:06:21.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3275" for this suite.
Nov 20 18:06:29.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:06:29.610: INFO: namespace crd-webhook-3275 deletion completed in 8.444503074s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:15.780 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:06:29.688: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:06:30.051: INFO: Create a RollingUpdate DaemonSet
Nov 20 18:06:30.063: INFO: Check that daemon pods launch on every node of the cluster
Nov 20 18:06:30.092: INFO: Number of nodes with available pods: 0
Nov 20 18:06:30.092: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:06:31.132: INFO: Number of nodes with available pods: 0
Nov 20 18:06:31.132: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:06:32.159: INFO: Number of nodes with available pods: 2
Nov 20 18:06:32.159: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:06:33.139: INFO: Number of nodes with available pods: 3
Nov 20 18:06:33.140: INFO: Number of running nodes: 3, number of available pods: 3
Nov 20 18:06:33.140: INFO: Update the DaemonSet to trigger a rollout
Nov 20 18:06:33.157: INFO: Updating DaemonSet daemon-set
Nov 20 18:06:44.231: INFO: Roll back the DaemonSet before rollout is complete
Nov 20 18:06:44.249: INFO: Updating DaemonSet daemon-set
Nov 20 18:06:44.250: INFO: Make sure DaemonSet rollback is complete
Nov 20 18:06:44.275: INFO: Wrong image for pod: daemon-set-fmlx4. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 20 18:06:44.276: INFO: Pod daemon-set-fmlx4 is not available
Nov 20 18:06:45.309: INFO: Wrong image for pod: daemon-set-fmlx4. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 20 18:06:45.309: INFO: Pod daemon-set-fmlx4 is not available
Nov 20 18:06:46.308: INFO: Wrong image for pod: daemon-set-fmlx4. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 20 18:06:46.308: INFO: Pod daemon-set-fmlx4 is not available
Nov 20 18:06:47.347: INFO: Wrong image for pod: daemon-set-fmlx4. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 20 18:06:47.347: INFO: Pod daemon-set-fmlx4 is not available
Nov 20 18:06:48.339: INFO: Wrong image for pod: daemon-set-fmlx4. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov 20 18:06:48.339: INFO: Pod daemon-set-fmlx4 is not available
Nov 20 18:06:49.309: INFO: Pod daemon-set-8ttm4 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7107, will wait for the garbage collector to delete the pods
Nov 20 18:06:49.428: INFO: Deleting DaemonSet.extensions daemon-set took: 16.263923ms
Nov 20 18:06:49.628: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.454937ms
Nov 20 18:07:02.646: INFO: Number of nodes with available pods: 0
Nov 20 18:07:02.647: INFO: Number of running nodes: 0, number of available pods: 0
Nov 20 18:07:02.656: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7107/daemonsets","resourceVersion":"26417"},"items":null}

Nov 20 18:07:02.680: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7107/pods","resourceVersion":"26417"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:07:02.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7107" for this suite.
Nov 20 18:07:10.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:07:11.714: INFO: namespace daemonsets-7107 deletion completed in 8.931289809s

• [SLOW TEST:42.026 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:07:11.715: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4198
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:07:23.169: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4198" for this suite.
Nov 20 18:07:29.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:07:29.759: INFO: namespace resourcequota-4198 deletion completed in 6.568212018s

• [SLOW TEST:18.044 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:07:29.761: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5948
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:07:30.589: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:07:33.659: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:07:33.693: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5426-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:07:35.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5948" for this suite.
Nov 20 18:07:43.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:07:43.576: INFO: namespace webhook-5948 deletion completed in 8.524721953s
STEP: Destroying namespace "webhook-5948-markers" for this suite.
Nov 20 18:07:49.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:07:50.088: INFO: namespace webhook-5948-markers deletion completed in 6.512208884s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.459 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:07:50.222: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:07:50.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288" in namespace "projected-6063" to be "success or failure"
Nov 20 18:07:50.492: INFO: Pod "downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288": Phase="Pending", Reason="", readiness=false. Elapsed: 12.661403ms
Nov 20 18:07:52.510: INFO: Pod "downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030491973s
STEP: Saw pod success
Nov 20 18:07:52.510: INFO: Pod "downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288" satisfied condition "success or failure"
Nov 20 18:07:52.527: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288 container client-container: <nil>
STEP: delete the pod
Nov 20 18:07:52.649: INFO: Waiting for pod downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288 to disappear
Nov 20 18:07:52.662: INFO: Pod downwardapi-volume-ce7e16bc-7467-4ebc-9cde-723f72f93288 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:07:52.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6063" for this suite.
Nov 20 18:07:58.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:07:59.170: INFO: namespace projected-6063 deletion completed in 6.491240532s

• [SLOW TEST:8.948 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:07:59.170: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 20 18:08:02.560: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:08:02.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1884" for this suite.
Nov 20 18:08:08.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:08:09.142: INFO: namespace container-runtime-1884 deletion completed in 6.484754445s

• [SLOW TEST:9.971 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:08:09.142: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-149
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:08:09.435: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-bc9430fb-f6c2-496a-8c79-b08fe8bfb8e4" in namespace "security-context-test-149" to be "success or failure"
Nov 20 18:08:09.463: INFO: Pod "alpine-nnp-false-bc9430fb-f6c2-496a-8c79-b08fe8bfb8e4": Phase="Pending", Reason="", readiness=false. Elapsed: 27.52181ms
Nov 20 18:08:11.510: INFO: Pod "alpine-nnp-false-bc9430fb-f6c2-496a-8c79-b08fe8bfb8e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.074274262s
Nov 20 18:08:13.528: INFO: Pod "alpine-nnp-false-bc9430fb-f6c2-496a-8c79-b08fe8bfb8e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.093017235s
Nov 20 18:08:13.529: INFO: Pod "alpine-nnp-false-bc9430fb-f6c2-496a-8c79-b08fe8bfb8e4" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:08:13.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-149" for this suite.
Nov 20 18:08:21.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:08:22.387: INFO: namespace security-context-test-149 deletion completed in 8.796764587s

• [SLOW TEST:13.245 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:08:22.388: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:08:22.659: INFO: Waiting up to 5m0s for pod "busybox-user-65534-91665a45-378a-4c4d-951f-fe9f1feba41a" in namespace "security-context-test-893" to be "success or failure"
Nov 20 18:08:22.670: INFO: Pod "busybox-user-65534-91665a45-378a-4c4d-951f-fe9f1feba41a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.811501ms
Nov 20 18:08:24.687: INFO: Pod "busybox-user-65534-91665a45-378a-4c4d-951f-fe9f1feba41a": Phase="Running", Reason="", readiness=true. Elapsed: 2.028444454s
Nov 20 18:08:26.704: INFO: Pod "busybox-user-65534-91665a45-378a-4c4d-951f-fe9f1feba41a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045357439s
Nov 20 18:08:26.704: INFO: Pod "busybox-user-65534-91665a45-378a-4c4d-951f-fe9f1feba41a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:08:26.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-893" for this suite.
Nov 20 18:08:32.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:08:33.233: INFO: namespace security-context-test-893 deletion completed in 6.508466814s

• [SLOW TEST:10.845 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:08:33.233: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5449
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Nov 20 18:08:33.493: INFO: Waiting up to 5m0s for pod "client-containers-7ee06890-c080-41dd-8895-184e2ad83030" in namespace "containers-5449" to be "success or failure"
Nov 20 18:08:33.508: INFO: Pod "client-containers-7ee06890-c080-41dd-8895-184e2ad83030": Phase="Pending", Reason="", readiness=false. Elapsed: 14.435197ms
Nov 20 18:08:35.522: INFO: Pod "client-containers-7ee06890-c080-41dd-8895-184e2ad83030": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028789601s
STEP: Saw pod success
Nov 20 18:08:35.522: INFO: Pod "client-containers-7ee06890-c080-41dd-8895-184e2ad83030" satisfied condition "success or failure"
Nov 20 18:08:35.536: INFO: Trying to get logs from node 10.184.110.176 pod client-containers-7ee06890-c080-41dd-8895-184e2ad83030 container test-container: <nil>
STEP: delete the pod
Nov 20 18:08:35.622: INFO: Waiting for pod client-containers-7ee06890-c080-41dd-8895-184e2ad83030 to disappear
Nov 20 18:08:35.636: INFO: Pod client-containers-7ee06890-c080-41dd-8895-184e2ad83030 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:08:35.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5449" for this suite.
Nov 20 18:08:41.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:08:42.263: INFO: namespace containers-5449 deletion completed in 6.609866318s

• [SLOW TEST:9.029 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:08:42.263: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3388
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9876
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3308
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:08:49.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3388" for this suite.
Nov 20 18:08:55.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:08:55.731: INFO: namespace namespaces-3388 deletion completed in 6.553034341s
STEP: Destroying namespace "nsdeletetest-9876" for this suite.
Nov 20 18:08:55.746: INFO: Namespace nsdeletetest-9876 was already deleted
STEP: Destroying namespace "nsdeletetest-3308" for this suite.
Nov 20 18:09:01.833: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:09:02.531: INFO: namespace nsdeletetest-3308 deletion completed in 6.785621591s

• [SLOW TEST:20.268 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:09:02.531: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5429
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:09:04.208: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:09:06.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709870144, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709870144, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709870144, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709870144, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:09:09.316: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:09:09.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5429" for this suite.
Nov 20 18:09:17.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:09:18.265: INFO: namespace webhook-5429 deletion completed in 8.521481959s
STEP: Destroying namespace "webhook-5429-markers" for this suite.
Nov 20 18:09:24.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:09:24.923: INFO: namespace webhook-5429-markers deletion completed in 6.657077942s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.542 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:09:25.074: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6437
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov 20 18:09:25.334: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:09:29.292: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:09:44.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6437" for this suite.
Nov 20 18:09:50.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:09:51.317: INFO: namespace crd-publish-openapi-6437 deletion completed in 6.524563282s

• [SLOW TEST:26.243 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:09:51.318: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 20 18:09:55.995: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:09:56.010: INFO: Pod pod-with-poststart-http-hook still exists
Nov 20 18:09:58.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:09:58.030: INFO: Pod pod-with-poststart-http-hook still exists
Nov 20 18:10:00.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:10:00.024: INFO: Pod pod-with-poststart-http-hook still exists
Nov 20 18:10:02.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:10:02.037: INFO: Pod pod-with-poststart-http-hook still exists
Nov 20 18:10:04.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:10:04.042: INFO: Pod pod-with-poststart-http-hook still exists
Nov 20 18:10:06.010: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov 20 18:10:06.027: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:10:06.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-896" for this suite.
Nov 20 18:10:18.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:10:18.705: INFO: namespace container-lifecycle-hook-896 deletion completed in 12.661966564s

• [SLOW TEST:27.387 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:10:18.706: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 20 18:10:22.248: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:10:22.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6691" for this suite.
Nov 20 18:10:30.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:10:30.846: INFO: namespace container-runtime-6691 deletion completed in 8.488142946s

• [SLOW TEST:12.141 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:10:30.850: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1438
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-97769d27-a9d7-4ee9-a5fa-d8b6cb876eac in namespace container-probe-1438
Nov 20 18:10:35.161: INFO: Started pod busybox-97769d27-a9d7-4ee9-a5fa-d8b6cb876eac in namespace container-probe-1438
STEP: checking the pod's current state and verifying that restartCount is present
Nov 20 18:10:35.175: INFO: Initial restart count of pod busybox-97769d27-a9d7-4ee9-a5fa-d8b6cb876eac is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:14:35.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1438" for this suite.
Nov 20 18:14:41.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:14:42.158: INFO: namespace container-probe-1438 deletion completed in 6.468156457s

• [SLOW TEST:251.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:14:42.158: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:14:59.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9414" for this suite.
Nov 20 18:15:05.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:15:06.125: INFO: namespace resourcequota-9414 deletion completed in 6.637242369s

• [SLOW TEST:23.967 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:15:06.125: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov 20 18:15:06.638: INFO: Waiting up to 5m0s for pod "pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200" in namespace "emptydir-2064" to be "success or failure"
Nov 20 18:15:06.690: INFO: Pod "pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200": Phase="Pending", Reason="", readiness=false. Elapsed: 51.1057ms
Nov 20 18:15:08.709: INFO: Pod "pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200": Phase="Pending", Reason="", readiness=false. Elapsed: 2.07039671s
Nov 20 18:15:10.775: INFO: Pod "pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.136210591s
STEP: Saw pod success
Nov 20 18:15:10.775: INFO: Pod "pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200" satisfied condition "success or failure"
Nov 20 18:15:10.805: INFO: Trying to get logs from node 10.184.110.176 pod pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200 container test-container: <nil>
STEP: delete the pod
Nov 20 18:15:11.083: INFO: Waiting for pod pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200 to disappear
Nov 20 18:15:11.099: INFO: Pod pod-e48e23bd-ccbc-4cbe-80e9-50c3058de200 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:15:11.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2064" for this suite.
Nov 20 18:15:17.218: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:15:17.718: INFO: namespace emptydir-2064 deletion completed in 6.59925161s

• [SLOW TEST:11.593 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:15:17.719: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1623
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1623
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1623
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1623
Nov 20 18:15:17.996: INFO: Found 0 stateful pods, waiting for 1
Nov 20 18:15:28.017: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov 20 18:15:28.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:15:28.569: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:15:28.569: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:15:28.569: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:15:28.589: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 20 18:15:38.615: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:15:38.615: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:15:38.658: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999997985s
Nov 20 18:15:39.674: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.980594935s
Nov 20 18:15:40.688: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.965041754s
Nov 20 18:15:41.709: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.951300761s
Nov 20 18:15:42.729: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.929595138s
Nov 20 18:15:43.747: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.909739964s
Nov 20 18:15:44.762: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.891532575s
Nov 20 18:15:45.777: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.877209244s
Nov 20 18:15:46.796: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.862090027s
Nov 20 18:15:47.830: INFO: Verifying statefulset ss doesn't scale past 1 for another 842.39353ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1623
Nov 20 18:15:48.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:15:49.227: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:15:49.227: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:15:49.227: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:15:49.255: INFO: Found 1 stateful pods, waiting for 3
Nov 20 18:15:59.283: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:15:59.283: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:15:59.283: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov 20 18:15:59.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:15:59.677: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:15:59.677: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:15:59.677: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:15:59.677: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:16:00.070: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:16:00.070: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:16:00.070: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:16:00.070: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:16:00.484: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:16:00.484: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:16:00.484: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:16:00.484: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:16:00.493: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov 20 18:16:10.542: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:16:10.542: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:16:10.542: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:16:10.601: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999997808s
Nov 20 18:16:11.635: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.957598017s
Nov 20 18:16:12.660: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.924179375s
Nov 20 18:16:13.673: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.899027858s
Nov 20 18:16:14.694: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.885728341s
Nov 20 18:16:15.720: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.864423349s
Nov 20 18:16:16.734: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.838586529s
Nov 20 18:16:17.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.824617075s
Nov 20 18:16:18.779: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.79712696s
Nov 20 18:16:19.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 779.412196ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1623
Nov 20 18:16:20.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:16:21.168: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:16:21.168: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:16:21.168: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:16:21.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:16:21.554: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:16:21.554: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:16:21.554: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:16:21.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-1623 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:16:21.938: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:16:21.938: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:16:21.938: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:16:21.939: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 18:17:02.028: INFO: Deleting all statefulset in ns statefulset-1623
Nov 20 18:17:02.037: INFO: Scaling statefulset ss to 0
Nov 20 18:17:02.082: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:17:02.091: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:17:02.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1623" for this suite.
Nov 20 18:17:10.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:17:10.946: INFO: namespace statefulset-1623 deletion completed in 8.750976276s

• [SLOW TEST:113.228 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:17:10.948: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov 20 18:17:15.862: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5648 pod-service-account-a0493a34-a4a5-4a57-a3b3-3b11c16455ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov 20 18:17:16.264: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5648 pod-service-account-a0493a34-a4a5-4a57-a3b3-3b11c16455ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov 20 18:17:16.713: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5648 pod-service-account-a0493a34-a4a5-4a57-a3b3-3b11c16455ca -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:17:17.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5648" for this suite.
Nov 20 18:17:23.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:17:23.780: INFO: namespace svcaccounts-5648 deletion completed in 6.603784705s

• [SLOW TEST:12.833 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:17:23.780: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov 20 18:17:24.014: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:17:27.994: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4423" for this suite.
Nov 20 18:17:34.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:17:34.544: INFO: namespace init-container-4423 deletion completed in 6.52275898s

• [SLOW TEST:10.763 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:17:34.544: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-857550fc-2b04-463e-bb58-6e5f01673920
STEP: Creating a pod to test consume configMaps
Nov 20 18:17:34.804: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c" in namespace "projected-9502" to be "success or failure"
Nov 20 18:17:34.818: INFO: Pod "pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c": Phase="Pending", Reason="", readiness=false. Elapsed: 13.788718ms
Nov 20 18:17:36.831: INFO: Pod "pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02703172s
Nov 20 18:17:38.844: INFO: Pod "pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039725128s
STEP: Saw pod success
Nov 20 18:17:38.844: INFO: Pod "pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c" satisfied condition "success or failure"
Nov 20 18:17:38.858: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:17:38.983: INFO: Waiting for pod pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c to disappear
Nov 20 18:17:39.001: INFO: Pod pod-projected-configmaps-b05ec1b1-8098-4687-accc-80561249463c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:17:39.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9502" for this suite.
Nov 20 18:17:45.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:17:45.502: INFO: namespace projected-9502 deletion completed in 6.467246504s

• [SLOW TEST:10.958 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:17:45.502: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6414
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-b381f69d-d707-43d2-8e89-6d68bc9f6858
STEP: Creating a pod to test consume configMaps
Nov 20 18:17:45.752: INFO: Waiting up to 5m0s for pod "pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed" in namespace "configmap-6414" to be "success or failure"
Nov 20 18:17:45.768: INFO: Pod "pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed": Phase="Pending", Reason="", readiness=false. Elapsed: 15.233696ms
Nov 20 18:17:47.817: INFO: Pod "pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.064830453s
Nov 20 18:17:49.830: INFO: Pod "pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077189031s
STEP: Saw pod success
Nov 20 18:17:49.830: INFO: Pod "pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed" satisfied condition "success or failure"
Nov 20 18:17:49.841: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:17:49.927: INFO: Waiting for pod pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed to disappear
Nov 20 18:17:49.939: INFO: Pod pod-configmaps-1c12e4da-250f-4852-90ba-f743a2f1c6ed no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:17:49.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6414" for this suite.
Nov 20 18:17:56.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:17:56.439: INFO: namespace configmap-6414 deletion completed in 6.482948784s

• [SLOW TEST:10.937 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:17:56.439: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7827
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 20 18:17:56.656: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 20 18:18:15.031: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.70.80:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:18:15.031: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:18:15.254: INFO: Found all expected endpoints: [netserver-0]
Nov 20 18:18:15.274: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.206.161:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:18:15.274: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:18:15.513: INFO: Found all expected endpoints: [netserver-1]
Nov 20 18:18:15.530: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.181.83:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-7827 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:18:15.530: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:18:15.758: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:18:15.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7827" for this suite.
Nov 20 18:18:29.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:18:30.313: INFO: namespace pod-network-test-7827 deletion completed in 14.519947821s

• [SLOW TEST:33.874 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:18:30.315: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3203
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:18:30.563: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov 20 18:18:34.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3203 create -f -'
Nov 20 18:18:34.535: INFO: stderr: ""
Nov 20 18:18:34.536: INFO: stdout: "e2e-test-crd-publish-openapi-620-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 20 18:18:34.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3203 delete e2e-test-crd-publish-openapi-620-crds test-cr'
Nov 20 18:18:34.763: INFO: stderr: ""
Nov 20 18:18:34.763: INFO: stdout: "e2e-test-crd-publish-openapi-620-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov 20 18:18:34.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3203 apply -f -'
Nov 20 18:18:35.155: INFO: stderr: ""
Nov 20 18:18:35.155: INFO: stdout: "e2e-test-crd-publish-openapi-620-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov 20 18:18:35.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=crd-publish-openapi-3203 delete e2e-test-crd-publish-openapi-620-crds test-cr'
Nov 20 18:18:35.415: INFO: stderr: ""
Nov 20 18:18:35.415: INFO: stdout: "e2e-test-crd-publish-openapi-620-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov 20 18:18:35.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 explain e2e-test-crd-publish-openapi-620-crds'
Nov 20 18:18:35.791: INFO: stderr: ""
Nov 20 18:18:35.791: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-620-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:18:39.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3203" for this suite.
Nov 20 18:18:45.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:18:46.192: INFO: namespace crd-publish-openapi-3203 deletion completed in 6.510227845s

• [SLOW TEST:15.877 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:18:46.192: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5940
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov 20 18:18:46.506: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28605 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 20 18:18:46.506: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28606 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 20 18:18:46.506: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28607 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov 20 18:18:56.591: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28623 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 20 18:18:56.591: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28624 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov 20 18:18:56.591: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-5940 /api/v1/namespaces/watch-5940/configmaps/e2e-watch-test-label-changed 8a01c12c-b53f-40b2-8446-39637193cb3c 28625 0 2019-11-20 18:18:46 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:18:56.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5940" for this suite.
Nov 20 18:19:02.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:19:03.446: INFO: namespace watch-5940 deletion completed in 6.834400007s

• [SLOW TEST:17.254 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:19:03.446: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-707
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-d1f986b8-f83c-4e8e-96f8-954fc9eb586a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d1f986b8-f83c-4e8e-96f8-954fc9eb586a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:20:13.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-707" for this suite.
Nov 20 18:20:27.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:20:28.271: INFO: namespace configmap-707 deletion completed in 14.507939084s

• [SLOW TEST:84.825 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:20:28.271: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 20 18:20:28.516: INFO: Waiting up to 5m0s for pod "pod-c1a7520d-bd49-4152-8b5c-12314692486d" in namespace "emptydir-7586" to be "success or failure"
Nov 20 18:20:28.533: INFO: Pod "pod-c1a7520d-bd49-4152-8b5c-12314692486d": Phase="Pending", Reason="", readiness=false. Elapsed: 16.862783ms
Nov 20 18:20:30.549: INFO: Pod "pod-c1a7520d-bd49-4152-8b5c-12314692486d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032824919s
STEP: Saw pod success
Nov 20 18:20:30.549: INFO: Pod "pod-c1a7520d-bd49-4152-8b5c-12314692486d" satisfied condition "success or failure"
Nov 20 18:20:30.562: INFO: Trying to get logs from node 10.184.110.176 pod pod-c1a7520d-bd49-4152-8b5c-12314692486d container test-container: <nil>
STEP: delete the pod
Nov 20 18:20:30.737: INFO: Waiting for pod pod-c1a7520d-bd49-4152-8b5c-12314692486d to disappear
Nov 20 18:20:30.750: INFO: Pod pod-c1a7520d-bd49-4152-8b5c-12314692486d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:20:30.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7586" for this suite.
Nov 20 18:20:36.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:20:37.213: INFO: namespace emptydir-7586 deletion completed in 6.444802539s

• [SLOW TEST:8.942 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:20:37.213: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2580
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3993
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5341
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:21:09.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2580" for this suite.
Nov 20 18:21:15.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:21:15.987: INFO: namespace namespaces-2580 deletion completed in 6.805386889s
STEP: Destroying namespace "nsdeletetest-3993" for this suite.
Nov 20 18:21:16.014: INFO: Namespace nsdeletetest-3993 was already deleted
STEP: Destroying namespace "nsdeletetest-5341" for this suite.
Nov 20 18:21:22.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:21:22.565: INFO: namespace nsdeletetest-5341 deletion completed in 6.551543199s

• [SLOW TEST:45.352 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:21:22.566: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4246
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-38749a1b-d966-48c9-9d29-d5f023c9d35c
STEP: Creating a pod to test consume secrets
Nov 20 18:21:22.832: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245" in namespace "projected-4246" to be "success or failure"
Nov 20 18:21:22.852: INFO: Pod "pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245": Phase="Pending", Reason="", readiness=false. Elapsed: 19.617553ms
Nov 20 18:21:24.906: INFO: Pod "pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.073575065s
STEP: Saw pod success
Nov 20 18:21:24.906: INFO: Pod "pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245" satisfied condition "success or failure"
Nov 20 18:21:24.931: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 20 18:21:25.051: INFO: Waiting for pod pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245 to disappear
Nov 20 18:21:25.067: INFO: Pod pod-projected-secrets-c8ebdf76-59aa-4f94-8652-589744d31245 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:21:25.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4246" for this suite.
Nov 20 18:21:31.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:21:31.614: INFO: namespace projected-4246 deletion completed in 6.520508727s

• [SLOW TEST:9.048 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:21:31.614: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-605
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-c358b1e6-e9c5-40fa-bf2e-dc5063d49925
STEP: Creating secret with name s-test-opt-upd-60abf280-6805-4a5e-a6bc-51cfacd0f3f3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-c358b1e6-e9c5-40fa-bf2e-dc5063d49925
STEP: Updating secret s-test-opt-upd-60abf280-6805-4a5e-a6bc-51cfacd0f3f3
STEP: Creating secret with name s-test-opt-create-ae914d91-30c6-4dbd-b324-c62c486a970c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:22:56.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-605" for this suite.
Nov 20 18:23:08.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:23:09.025: INFO: namespace secrets-605 deletion completed in 12.597868762s

• [SLOW TEST:97.411 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:23:09.025: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8119
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8119
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov 20 18:23:09.319: INFO: Found 0 stateful pods, waiting for 3
Nov 20 18:23:19.374: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:23:19.374: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:23:19.374: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:23:19.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-8119 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:23:19.827: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:23:19.827: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:23:19.827: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 20 18:23:29.920: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov 20 18:23:39.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-8119 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:23:40.353: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:23:40.353: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:23:40.353: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:23:50.447: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:23:50.447: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 18:23:50.447: INFO: Waiting for Pod statefulset-8119/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 18:24:00.471: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:24:00.471: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 18:24:00.471: INFO: Waiting for Pod statefulset-8119/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 18:24:10.476: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:24:10.476: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 18:24:20.471: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
STEP: Rolling back to a previous revision
Nov 20 18:24:30.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-8119 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:24:30.836: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:24:30.836: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:24:30.836: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:24:40.913: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov 20 18:24:50.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-8119 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:24:51.357: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:24:51.357: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:24:51.357: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:25:01.522: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:25:01.522: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 20 18:25:01.522: INFO: Waiting for Pod statefulset-8119/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 20 18:25:01.522: INFO: Waiting for Pod statefulset-8119/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 20 18:25:11.546: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:25:11.546: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 20 18:25:11.546: INFO: Waiting for Pod statefulset-8119/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov 20 18:25:21.551: INFO: Waiting for StatefulSet statefulset-8119/ss2 to complete update
Nov 20 18:25:21.552: INFO: Waiting for Pod statefulset-8119/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 18:25:31.542: INFO: Deleting all statefulset in ns statefulset-8119
Nov 20 18:25:31.554: INFO: Scaling statefulset ss2 to 0
Nov 20 18:26:11.613: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:26:11.624: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:26:11.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8119" for this suite.
Nov 20 18:26:19.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:26:20.292: INFO: namespace statefulset-8119 deletion completed in 8.609237787s

• [SLOW TEST:191.267 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:26:20.292: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9342
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov 20 18:26:27.002: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:26:27.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1120 18:26:27.002700      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9342" for this suite.
Nov 20 18:26:35.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:26:35.561: INFO: namespace gc-9342 deletion completed in 8.533185335s

• [SLOW TEST:15.269 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:26:35.561: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:26:35.819: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5" in namespace "projected-1643" to be "success or failure"
Nov 20 18:26:35.831: INFO: Pod "downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.407929ms
Nov 20 18:26:37.843: INFO: Pod "downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024740566s
Nov 20 18:26:39.857: INFO: Pod "downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038719656s
STEP: Saw pod success
Nov 20 18:26:39.857: INFO: Pod "downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5" satisfied condition "success or failure"
Nov 20 18:26:39.873: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5 container client-container: <nil>
STEP: delete the pod
Nov 20 18:26:40.043: INFO: Waiting for pod downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5 to disappear
Nov 20 18:26:40.057: INFO: Pod downwardapi-volume-3dcb33ea-6ac5-432f-8740-1c86b1fa1eb5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:26:40.057: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1643" for this suite.
Nov 20 18:26:46.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:26:46.611: INFO: namespace projected-1643 deletion completed in 6.536350261s

• [SLOW TEST:11.050 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:26:46.612: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov 20 18:26:46.876: INFO: Waiting up to 5m0s for pod "pod-fa943469-7dd0-4320-97b3-6770cf12adf6" in namespace "emptydir-4437" to be "success or failure"
Nov 20 18:26:46.889: INFO: Pod "pod-fa943469-7dd0-4320-97b3-6770cf12adf6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.544403ms
Nov 20 18:26:48.903: INFO: Pod "pod-fa943469-7dd0-4320-97b3-6770cf12adf6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026789323s
Nov 20 18:26:50.915: INFO: Pod "pod-fa943469-7dd0-4320-97b3-6770cf12adf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038977154s
STEP: Saw pod success
Nov 20 18:26:50.915: INFO: Pod "pod-fa943469-7dd0-4320-97b3-6770cf12adf6" satisfied condition "success or failure"
Nov 20 18:26:50.930: INFO: Trying to get logs from node 10.184.110.176 pod pod-fa943469-7dd0-4320-97b3-6770cf12adf6 container test-container: <nil>
STEP: delete the pod
Nov 20 18:26:51.019: INFO: Waiting for pod pod-fa943469-7dd0-4320-97b3-6770cf12adf6 to disappear
Nov 20 18:26:51.038: INFO: Pod pod-fa943469-7dd0-4320-97b3-6770cf12adf6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:26:51.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4437" for this suite.
Nov 20 18:26:57.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:26:57.523: INFO: namespace emptydir-4437 deletion completed in 6.447080872s

• [SLOW TEST:10.911 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:26:57.523: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2926
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2926
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2926
Nov 20 18:26:57.796: INFO: Found 0 stateful pods, waiting for 1
Nov 20 18:27:07.845: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov 20 18:27:07.859: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:27:08.305: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:27:08.306: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:27:08.306: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:27:08.318: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov 20 18:27:18.342: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:27:18.342: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:27:18.386: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:18.386: INFO: ss-0  10.184.110.176  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:08 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:18.386: INFO: ss-1                  Pending         []
Nov 20 18:27:18.386: INFO: 
Nov 20 18:27:18.386: INFO: StatefulSet ss has not reached scale 3, at 2
Nov 20 18:27:19.402: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.984369393s
Nov 20 18:27:20.477: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.967931402s
Nov 20 18:27:21.494: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.893606535s
Nov 20 18:27:22.577: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.87649314s
Nov 20 18:27:23.646: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.79301407s
Nov 20 18:27:24.661: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.723984364s
Nov 20 18:27:25.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.709567703s
Nov 20 18:27:26.694: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.692005162s
Nov 20 18:27:27.715: INFO: Verifying statefulset ss doesn't scale past 3 for another 676.631969ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2926
Nov 20 18:27:28.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:27:29.127: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov 20 18:27:29.127: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:27:29.127: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:27:29.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:27:29.526: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 20 18:27:29.526: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:27:29.526: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:27:29.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:27:30.018: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov 20 18:27:30.018: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov 20 18:27:30.018: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov 20 18:27:30.037: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:27:30.037: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 18:27:30.037: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov 20 18:27:30.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:27:30.468: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:27:30.468: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:27:30.468: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:27:30.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:27:31.025: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:27:31.025: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:27:31.025: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:27:31.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov 20 18:27:31.408: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov 20 18:27:31.408: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov 20 18:27:31.408: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov 20 18:27:31.408: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:27:31.418: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Nov 20 18:27:41.451: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:27:41.451: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:27:41.451: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov 20 18:27:41.486: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:41.486: INFO: ss-0  10.184.110.176  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:41.486: INFO: ss-1  10.184.110.184  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:41.486: INFO: ss-2  10.184.110.140  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:41.486: INFO: 
Nov 20 18:27:41.486: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 20 18:27:42.506: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:42.506: INFO: ss-0  10.184.110.176  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:42.506: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:42.506: INFO: ss-2  10.184.110.140  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:42.506: INFO: 
Nov 20 18:27:42.506: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 20 18:27:43.524: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:43.524: INFO: ss-0  10.184.110.176  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:43.524: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:43.524: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:43.524: INFO: 
Nov 20 18:27:43.524: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 20 18:27:44.540: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:44.540: INFO: ss-0  10.184.110.176  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:44.540: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:44.540: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:44.540: INFO: 
Nov 20 18:27:44.540: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 20 18:27:45.558: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:45.558: INFO: ss-0  10.184.110.176  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:26:57 +0000 UTC  }]
Nov 20 18:27:45.558: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:45.558: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:45.558: INFO: 
Nov 20 18:27:45.558: INFO: StatefulSet ss has not reached scale 0, at 3
Nov 20 18:27:46.574: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:46.574: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:46.575: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:46.575: INFO: 
Nov 20 18:27:46.575: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 20 18:27:47.588: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:47.588: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:47.588: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:47.588: INFO: 
Nov 20 18:27:47.588: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 20 18:27:48.606: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:48.606: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:48.606: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:48.606: INFO: 
Nov 20 18:27:48.606: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 20 18:27:49.618: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:49.618: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:49.618: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:49.618: INFO: 
Nov 20 18:27:49.618: INFO: StatefulSet ss has not reached scale 0, at 2
Nov 20 18:27:50.637: INFO: POD   NODE            PHASE    GRACE  CONDITIONS
Nov 20 18:27:50.637: INFO: ss-1  10.184.110.184  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:50.637: INFO: ss-2  10.184.110.140  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:32 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-20 18:27:18 +0000 UTC  }]
Nov 20 18:27:50.637: INFO: 
Nov 20 18:27:50.637: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2926
Nov 20 18:27:51.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:27:51.943: INFO: rc: 1
Nov 20 18:27:51.943: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc0035abf20 exit status 1 <nil> <nil> true [0xc00339ceb0 0xc00339cf08 0xc00339cf50] [0xc00339ceb0 0xc00339cf08 0xc00339cf50] [0xc00339cef8 0xc00339cf38] [0x10efe30 0x10efe30] 0xc002329500 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Nov 20 18:28:01.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:02.114: INFO: rc: 1
Nov 20 18:28:02.114: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0037d02d0 exit status 1 <nil> <nil> true [0xc00339cf60 0xc00339cfa0 0xc00339cfd8] [0xc00339cf60 0xc00339cfa0 0xc00339cfd8] [0xc00339cf88 0xc00339cfc8] [0x10efe30 0x10efe30] 0xc001fdcf60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:28:12.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:12.266: INFO: rc: 1
Nov 20 18:28:12.266: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0037d0660 exit status 1 <nil> <nil> true [0xc00339cff0 0xc00339d028 0xc00339d060] [0xc00339cff0 0xc00339d028 0xc00339d060] [0xc00339d018 0xc00339d050] [0x10efe30 0x10efe30] 0xc00274a180 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:28:22.266: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:22.416: INFO: rc: 1
Nov 20 18:28:22.416: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0037d09c0 exit status 1 <nil> <nil> true [0xc00339d070 0xc00339d0a8 0xc00339d0f0] [0xc00339d070 0xc00339d0a8 0xc00339d0f0] [0xc00339d090 0xc00339d0c8] [0x10efe30 0x10efe30] 0xc002e6f920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:28:32.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:32.557: INFO: rc: 1
Nov 20 18:28:32.557: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0067c7f20 exit status 1 <nil> <nil> true [0xc002a40070 0xc002a40088 0xc002a400a0] [0xc002a40070 0xc002a40088 0xc002a400a0] [0xc002a40080 0xc002a40098] [0x10efe30 0x10efe30] 0xc0034d7c80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:28:42.558: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:42.815: INFO: rc: 1
Nov 20 18:28:42.815: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc00581af60 exit status 1 <nil> <nil> true [0xc00022dbb0 0xc00022dbf8 0xc00022dc30] [0xc00022dbb0 0xc00022dbf8 0xc00022dc30] [0xc00022dbe8 0xc00022dc18] [0x10efe30 0x10efe30] 0xc002fc5080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:28:52.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:28:52.965: INFO: rc: 1
Nov 20 18:28:52.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aa360 exit status 1 <nil> <nil> true [0xc00083a400 0xc00083adf8 0xc00083afc8] [0xc00083a400 0xc00083adf8 0xc00083afc8] [0xc00083aba8 0xc00083af28] [0x10efe30 0x10efe30] 0xc000ede060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:02.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:03.119: INFO: rc: 1
Nov 20 18:29:03.119: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aa6f0 exit status 1 <nil> <nil> true [0xc00083aff8 0xc00083b490 0xc00083b730] [0xc00083aff8 0xc00083b490 0xc00083b730] [0xc00083b380 0xc00083b5c8] [0x10efe30 0x10efe30] 0xc000ede6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:13.119: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:13.275: INFO: rc: 1
Nov 20 18:29:13.276: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aaa80 exit status 1 <nil> <nil> true [0xc00083b7c0 0xc00083b900 0xc00083ba90] [0xc00083b7c0 0xc00083b900 0xc00083ba90] [0xc00083b8c0 0xc00083b9f0] [0x10efe30 0x10efe30] 0xc000edeb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:23.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:23.465: INFO: rc: 1
Nov 20 18:29:23.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452330 exit status 1 <nil> <nil> true [0xc000010058 0xc0004f6a28 0xc0004f7060] [0xc000010058 0xc0004f6a28 0xc0004f7060] [0xc0004f6728 0xc0004f7000] [0x10efe30 0x10efe30] 0xc00185e360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:33.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:33.617: INFO: rc: 1
Nov 20 18:29:33.617: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0050d4390 exit status 1 <nil> <nil> true [0xc00267c040 0xc00267c368 0xc00267c670] [0xc00267c040 0xc00267c368 0xc00267c670] [0xc00267c290 0xc00267c4b0] [0x10efe30 0x10efe30] 0xc002712a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:43.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:43.749: INFO: rc: 1
Nov 20 18:29:43.749: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0084526c0 exit status 1 <nil> <nil> true [0xc0004f7088 0xc0004f7338 0xc0004f7620] [0xc0004f7088 0xc0004f7338 0xc0004f7620] [0xc0004f72b0 0xc0004f7568] [0x10efe30 0x10efe30] 0xc00185e780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:29:53.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:29:53.908: INFO: rc: 1
Nov 20 18:29:53.908: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452ae0 exit status 1 <nil> <nil> true [0xc0004f7698 0xc0004f78d0 0xc0004f7a80] [0xc0004f7698 0xc0004f78d0 0xc0004f7a80] [0xc0004f7810 0xc0004f7988] [0x10efe30 0x10efe30] 0xc00185eb40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:03.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:04.131: INFO: rc: 1
Nov 20 18:30:04.131: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452e70 exit status 1 <nil> <nil> true [0xc0004f7b28 0xc0004f7de8 0xc0015f8030] [0xc0004f7b28 0xc0004f7de8 0xc0015f8030] [0xc0004f7c90 0xc0004f7fe0] [0x10efe30 0x10efe30] 0xc00185eea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:14.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:14.269: INFO: rc: 1
Nov 20 18:30:14.270: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008453200 exit status 1 <nil> <nil> true [0xc0015f8140 0xc0015f8290 0xc0015f8380] [0xc0015f8140 0xc0015f8290 0xc0015f8380] [0xc0015f8260 0xc0015f8368] [0x10efe30 0x10efe30] 0xc00185f200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:24.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:24.447: INFO: rc: 1
Nov 20 18:30:24.447: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003516330 exit status 1 <nil> <nil> true [0xc00339c000 0xc00339c030 0xc00339c048] [0xc00339c000 0xc00339c030 0xc00339c048] [0xc00339c028 0xc00339c040] [0x10efe30 0x10efe30] 0xc0030e4120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:34.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:34.611: INFO: rc: 1
Nov 20 18:30:34.611: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0050d4720 exit status 1 <nil> <nil> true [0xc00267c700 0xc00267c870 0xc00267ca10] [0xc00267c700 0xc00267c870 0xc00267ca10] [0xc00267c830 0xc00267c998] [0x10efe30 0x10efe30] 0xc002713200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:44.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:44.763: INFO: rc: 1
Nov 20 18:30:44.764: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452360 exit status 1 <nil> <nil> true [0xc0004f6728 0xc0004f7000 0xc0004f71a8] [0xc0004f6728 0xc0004f7000 0xc0004f71a8] [0xc0004f6ec0 0xc0004f7088] [0x10efe30 0x10efe30] 0xc00185e060 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:30:54.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:30:54.918: INFO: rc: 1
Nov 20 18:30:54.918: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452750 exit status 1 <nil> <nil> true [0xc0004f72b0 0xc0004f7568 0xc0004f7708] [0xc0004f72b0 0xc0004f7568 0xc0004f7708] [0xc0004f74e8 0xc0004f7698] [0x10efe30 0x10efe30] 0xc00185e4e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:04.919: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:05.082: INFO: rc: 1
Nov 20 18:31:05.082: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003516360 exit status 1 <nil> <nil> true [0xc000010058 0xc0015f8200 0xc0015f82e8] [0xc000010058 0xc0015f8200 0xc0015f82e8] [0xc0015f8140 0xc0015f8290] [0x10efe30 0x10efe30] 0xc0030e4000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:15.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:15.448: INFO: rc: 1
Nov 20 18:31:15.448: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035166f0 exit status 1 <nil> <nil> true [0xc0015f8368 0xc0015f8438 0xc0015f8690] [0xc0015f8368 0xc0015f8438 0xc0015f8690] [0xc0015f8400 0xc0015f8568] [0x10efe30 0x10efe30] 0xc0030e47e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:25.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:25.577: INFO: rc: 1
Nov 20 18:31:25.577: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452b70 exit status 1 <nil> <nil> true [0xc0004f7810 0xc0004f7988 0xc0004f7bf0] [0xc0004f7810 0xc0004f7988 0xc0004f7bf0] [0xc0004f78f0 0xc0004f7b28] [0x10efe30 0x10efe30] 0xc00185e900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:35.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:35.716: INFO: rc: 1
Nov 20 18:31:35.716: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aa390 exit status 1 <nil> <nil> true [0xc00339c000 0xc00339c030 0xc00339c048] [0xc00339c000 0xc00339c030 0xc00339c048] [0xc00339c028 0xc00339c040] [0x10efe30 0x10efe30] 0xc000ede600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:45.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:45.854: INFO: rc: 1
Nov 20 18:31:45.854: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aa750 exit status 1 <nil> <nil> true [0xc00339c050 0xc00339c068 0xc00339c080] [0xc00339c050 0xc00339c068 0xc00339c080] [0xc00339c060 0xc00339c078] [0x10efe30 0x10efe30] 0xc000ede960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:31:55.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:31:56.011: INFO: rc: 1
Nov 20 18:31:56.011: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452f00 exit status 1 <nil> <nil> true [0xc0004f7c90 0xc0004f7fe0 0xc00083aba8] [0xc0004f7c90 0xc0004f7fe0 0xc00083aba8] [0xc0004f7f60 0xc00083aac0] [0x10efe30 0x10efe30] 0xc00185ec60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:06.011: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:06.197: INFO: rc: 1
Nov 20 18:32:06.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc003516d20 exit status 1 <nil> <nil> true [0xc0015f86a0 0xc0015f87b0 0xc0015f88f8] [0xc0015f86a0 0xc0015f87b0 0xc0015f88f8] [0xc0015f8780 0xc0015f8848] [0x10efe30 0x10efe30] 0xc0030e4fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:16.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:16.353: INFO: rc: 1
Nov 20 18:32:16.353: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0050d4330 exit status 1 <nil> <nil> true [0xc00267c040 0xc00267c368 0xc00267c670] [0xc00267c040 0xc00267c368 0xc00267c670] [0xc00267c290 0xc00267c4b0] [0x10efe30 0x10efe30] 0xc002712a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:26.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:26.583: INFO: rc: 1
Nov 20 18:32:26.583: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0050d46f0 exit status 1 <nil> <nil> true [0xc00267c700 0xc00267c870 0xc00267ca10] [0xc00267c700 0xc00267c870 0xc00267ca10] [0xc00267c830 0xc00267c998] [0x10efe30 0x10efe30] 0xc002713200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:36.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:36.724: INFO: rc: 1
Nov 20 18:32:36.724: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc0035aab40 exit status 1 <nil> <nil> true [0xc00339c090 0xc00339c100 0xc00339c128] [0xc00339c090 0xc00339c100 0xc00339c128] [0xc00339c0e0 0xc00339c120] [0x10efe30 0x10efe30] 0xc000edee40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:46.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:46.882: INFO: rc: 1
Nov 20 18:32:46.882: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-1" not found
 [] <nil> 0xc008452330 exit status 1 <nil> <nil> true [0xc0004f6200 0xc0004f6ec0 0xc0004f7088] [0xc0004f6200 0xc0004f6ec0 0xc0004f7088] [0xc0004f6a28 0xc0004f7060] [0x10efe30 0x10efe30] 0xc002a12120 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-1" not found

error:
exit status 1
Nov 20 18:32:56.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=statefulset-2926 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov 20 18:32:57.024: INFO: rc: 1
Nov 20 18:32:57.024: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: 
Nov 20 18:32:57.024: INFO: Scaling statefulset ss to 0
Nov 20 18:32:57.054: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 18:32:57.062: INFO: Deleting all statefulset in ns statefulset-2926
Nov 20 18:32:57.071: INFO: Scaling statefulset ss to 0
Nov 20 18:32:57.121: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 18:32:57.129: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:32:57.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2926" for this suite.
Nov 20 18:33:05.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:33:05.693: INFO: namespace statefulset-2926 deletion completed in 8.51200841s

• [SLOW TEST:368.170 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:33:05.693: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6031
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 20 18:33:06.086: INFO: Waiting up to 5m0s for pod "pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3" in namespace "emptydir-6031" to be "success or failure"
Nov 20 18:33:06.106: INFO: Pod "pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3": Phase="Pending", Reason="", readiness=false. Elapsed: 20.245153ms
Nov 20 18:33:08.127: INFO: Pod "pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040423877s
STEP: Saw pod success
Nov 20 18:33:08.127: INFO: Pod "pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3" satisfied condition "success or failure"
Nov 20 18:33:08.144: INFO: Trying to get logs from node 10.184.110.176 pod pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3 container test-container: <nil>
STEP: delete the pod
Nov 20 18:33:08.416: INFO: Waiting for pod pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3 to disappear
Nov 20 18:33:08.462: INFO: Pod pod-44a0b9b0-0e97-4b20-a43c-07c449602fd3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:33:08.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6031" for this suite.
Nov 20 18:33:14.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:33:15.297: INFO: namespace emptydir-6031 deletion completed in 6.803708305s

• [SLOW TEST:9.605 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:33:15.298: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Nov 20 18:33:15.612: INFO: Waiting up to 5m0s for pod "var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916" in namespace "var-expansion-8958" to be "success or failure"
Nov 20 18:33:15.629: INFO: Pod "var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916": Phase="Pending", Reason="", readiness=false. Elapsed: 17.012367ms
Nov 20 18:33:17.651: INFO: Pod "var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038271971s
Nov 20 18:33:19.670: INFO: Pod "var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057142878s
STEP: Saw pod success
Nov 20 18:33:19.670: INFO: Pod "var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916" satisfied condition "success or failure"
Nov 20 18:33:19.684: INFO: Trying to get logs from node 10.184.110.176 pod var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916 container dapi-container: <nil>
STEP: delete the pod
Nov 20 18:33:19.792: INFO: Waiting for pod var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916 to disappear
Nov 20 18:33:19.815: INFO: Pod var-expansion-dbc2a02b-1f9b-4a60-b685-ea845e972916 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:33:19.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8958" for this suite.
Nov 20 18:33:25.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:33:26.335: INFO: namespace var-expansion-8958 deletion completed in 6.498742529s

• [SLOW TEST:11.038 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:33:26.336: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov 20 18:33:31.223: INFO: Successfully updated pod "annotationupdate4eea8650-d812-4da5-8bb1-67245010d6e4"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:33:33.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-648" for this suite.
Nov 20 18:33:47.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:33:47.785: INFO: namespace downward-api-648 deletion completed in 14.469483249s

• [SLOW TEST:21.448 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:33:47.786: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov 20 18:33:48.146: INFO: Waiting up to 5m0s for pod "pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7" in namespace "emptydir-9409" to be "success or failure"
Nov 20 18:33:48.159: INFO: Pod "pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.822766ms
Nov 20 18:33:50.173: INFO: Pod "pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026488886s
STEP: Saw pod success
Nov 20 18:33:50.173: INFO: Pod "pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7" satisfied condition "success or failure"
Nov 20 18:33:50.186: INFO: Trying to get logs from node 10.184.110.176 pod pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7 container test-container: <nil>
STEP: delete the pod
Nov 20 18:33:50.275: INFO: Waiting for pod pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7 to disappear
Nov 20 18:33:50.289: INFO: Pod pod-66302d1b-99f9-46dd-a8fb-24f6118c6eb7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:33:50.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9409" for this suite.
Nov 20 18:33:56.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:33:56.791: INFO: namespace emptydir-9409 deletion completed in 6.47322933s

• [SLOW TEST:9.006 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:33:56.792: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-5777, will wait for the garbage collector to delete the pods
Nov 20 18:34:01.326: INFO: Deleting Job.batch foo took: 82.371929ms
Nov 20 18:34:01.526: INFO: Terminating Job.batch foo pods took: 200.293671ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:34:36.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5777" for this suite.
Nov 20 18:34:44.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:34:44.551: INFO: namespace job-5777 deletion completed in 8.486373474s

• [SLOW TEST:47.759 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:34:44.551: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:34:45.463: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov 20 18:34:47.496: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871685, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871685, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871685, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871685, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:34:50.535: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov 20 18:34:50.599: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:34:50.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5775" for this suite.
Nov 20 18:34:58.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:34:59.200: INFO: namespace webhook-5775 deletion completed in 8.546094665s
STEP: Destroying namespace "webhook-5775-markers" for this suite.
Nov 20 18:35:05.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:35:05.936: INFO: namespace webhook-5775-markers deletion completed in 6.735569366s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.577 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:35:06.128: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:35:06.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3064" for this suite.
Nov 20 18:35:12.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:35:13.287: INFO: namespace custom-resource-definition-3064 deletion completed in 6.800542941s

• [SLOW TEST:7.158 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:35:13.287: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7109
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18
Nov 20 18:35:13.654: INFO: Pod name my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18: Found 1 pods out of 1
Nov 20 18:35:13.655: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18" are running
Nov 20 18:35:17.691: INFO: Pod "my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18-6fm9q" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-20 18:35:13 +0000 UTC Reason: Message:}])
Nov 20 18:35:17.691: INFO: Trying to dial the pod
Nov 20 18:35:22.769: INFO: Controller my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18: Got expected result from replica 1 [my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18-6fm9q]: "my-hostname-basic-c08fe62a-90b6-4982-ae5f-bcae0b326a18-6fm9q", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:35:22.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7109" for this suite.
Nov 20 18:35:28.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:35:29.391: INFO: namespace replication-controller-7109 deletion completed in 6.598490675s

• [SLOW TEST:16.104 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:35:29.392: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov 20 18:35:29.674: INFO: Waiting up to 5m0s for pod "downward-api-5146ab33-54ad-484c-9787-aba26919df38" in namespace "downward-api-6541" to be "success or failure"
Nov 20 18:35:29.688: INFO: Pod "downward-api-5146ab33-54ad-484c-9787-aba26919df38": Phase="Pending", Reason="", readiness=false. Elapsed: 13.527832ms
Nov 20 18:35:31.722: INFO: Pod "downward-api-5146ab33-54ad-484c-9787-aba26919df38": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047792586s
Nov 20 18:35:33.736: INFO: Pod "downward-api-5146ab33-54ad-484c-9787-aba26919df38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061746318s
STEP: Saw pod success
Nov 20 18:35:33.736: INFO: Pod "downward-api-5146ab33-54ad-484c-9787-aba26919df38" satisfied condition "success or failure"
Nov 20 18:35:33.751: INFO: Trying to get logs from node 10.184.110.176 pod downward-api-5146ab33-54ad-484c-9787-aba26919df38 container dapi-container: <nil>
STEP: delete the pod
Nov 20 18:35:33.884: INFO: Waiting for pod downward-api-5146ab33-54ad-484c-9787-aba26919df38 to disappear
Nov 20 18:35:33.902: INFO: Pod downward-api-5146ab33-54ad-484c-9787-aba26919df38 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:35:33.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6541" for this suite.
Nov 20 18:35:39.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:35:40.418: INFO: namespace downward-api-6541 deletion completed in 6.495882055s

• [SLOW TEST:11.026 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:35:40.419: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5087
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5087/configmap-test-51e402fc-1546-46db-b7c2-83c46ae6b2f5
STEP: Creating a pod to test consume configMaps
Nov 20 18:35:40.691: INFO: Waiting up to 5m0s for pod "pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a" in namespace "configmap-5087" to be "success or failure"
Nov 20 18:35:40.708: INFO: Pod "pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a": Phase="Pending", Reason="", readiness=false. Elapsed: 16.99493ms
Nov 20 18:35:42.729: INFO: Pod "pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037266159s
Nov 20 18:35:44.744: INFO: Pod "pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052643802s
STEP: Saw pod success
Nov 20 18:35:44.744: INFO: Pod "pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a" satisfied condition "success or failure"
Nov 20 18:35:44.761: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a container env-test: <nil>
STEP: delete the pod
Nov 20 18:35:44.848: INFO: Waiting for pod pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a to disappear
Nov 20 18:35:44.863: INFO: Pod pod-configmaps-e05b06e9-5643-4505-b370-c9aa6fd6f33a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:35:44.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5087" for this suite.
Nov 20 18:35:50.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:35:51.423: INFO: namespace configmap-5087 deletion completed in 6.539478659s

• [SLOW TEST:11.004 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:35:51.423: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-6127
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov 20 18:35:55.738: INFO: &Pod{ObjectMeta:{send-events-b1d06b26-1467-49da-bf98-f13310fd20f9  events-6127 /api/v1/namespaces/events-6127/pods/send-events-b1d06b26-1467-49da-bf98-f13310fd20f9 7add3d43-ae83-4f3d-9035-822244ed1d45 31661 0 2019-11-20 18:35:51 +0000 UTC <nil> <nil> map[name:foo time:642066488] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ssm2f,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ssm2f,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ssm2f,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:35:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:35:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:35:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.106,StartTime:2019-11-20 18:35:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:35:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://24cff15918a48bf979827d00832c30488c2abb605b713811275b16701b8a83d2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov 20 18:35:57.747: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov 20 18:35:59.756: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:35:59.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-6127" for this suite.
Nov 20 18:36:45.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:36:46.347: INFO: namespace events-6127 deletion completed in 46.524798039s

• [SLOW TEST:54.924 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:36:46.348: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7010
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:37:08.687: INFO: Container started at 2019-11-20 18:36:47 +0000 UTC, pod became ready at 2019-11-20 18:37:07 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:37:08.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7010" for this suite.
Nov 20 18:37:38.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:37:39.223: INFO: namespace container-probe-7010 deletion completed in 30.503540244s

• [SLOW TEST:52.875 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:37:39.223: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5511
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:37:40.018: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:37:42.049: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871860, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871860, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871860, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709871860, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:37:45.112: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
Nov 20 18:37:52.507: INFO: Waiting for webhook configuration to be ready...
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:37:57.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5511" for this suite.
Nov 20 18:38:05.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:38:06.472: INFO: namespace webhook-5511 deletion completed in 8.770067069s
STEP: Destroying namespace "webhook-5511-markers" for this suite.
Nov 20 18:38:12.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:38:13.449: INFO: namespace webhook-5511-markers deletion completed in 6.97663788s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:34.334 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:38:13.558: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1483
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1483.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1483.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-1483.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1483.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 130.78.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.78.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.78.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.78.130_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-1483.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-1483.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-1483.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-1483.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-1483.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1483.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 130.78.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.78.130_udp@PTR;check="$$(dig +tcp +noall +answer +search 130.78.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.78.130_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 18:38:17.974: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.013: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.088: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.111: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.290: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.314: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.335: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.360: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:18.517: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:23.543: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.570: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.604: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.635: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.935: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.973: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:23.999: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:24.026: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:24.176: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:28.537: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.558: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.578: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.598: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.774: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.797: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.820: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:28.842: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:29.008: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:33.540: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.563: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.586: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.622: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.815: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.843: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.863: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:33.901: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:34.038: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:38.548: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.567: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.598: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.629: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.835: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.854: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.876: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:38.900: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:39.090: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:43.544: INFO: Unable to read wheezy_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.568: INFO: Unable to read wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.591: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.617: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.822: INFO: Unable to read jessie_udp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.845: INFO: Unable to read jessie_tcp@dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.880: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:43.899: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local from pod dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68: the server could not find the requested resource (get pods dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68)
Nov 20 18:38:44.038: INFO: Lookups using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 failed for: [wheezy_udp@dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@dns-test-service.dns-1483.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_udp@dns-test-service.dns-1483.svc.cluster.local jessie_tcp@dns-test-service.dns-1483.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-1483.svc.cluster.local]

Nov 20 18:38:49.021: INFO: DNS probes using dns-1483/dns-test-fcda54f0-dd6a-41ff-b5fd-40b27434de68 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:38:49.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1483" for this suite.
Nov 20 18:38:57.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:38:57.745: INFO: namespace dns-1483 deletion completed in 8.502965001s

• [SLOW TEST:44.187 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:38:57.746: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:38:57.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1" in namespace "projected-4247" to be "success or failure"
Nov 20 18:38:58.014: INFO: Pod "downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.69516ms
Nov 20 18:39:00.027: INFO: Pod "downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028818323s
STEP: Saw pod success
Nov 20 18:39:00.027: INFO: Pod "downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1" satisfied condition "success or failure"
Nov 20 18:39:00.040: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1 container client-container: <nil>
STEP: delete the pod
Nov 20 18:39:00.184: INFO: Waiting for pod downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1 to disappear
Nov 20 18:39:00.199: INFO: Pod downwardapi-volume-12d05e6b-1747-44e5-bb1b-a8c54de727f1 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:39:00.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4247" for this suite.
Nov 20 18:39:06.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:39:07.163: INFO: namespace projected-4247 deletion completed in 6.94290747s

• [SLOW TEST:9.417 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:39:07.163: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1977
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 20 18:39:07.522: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 20 18:39:30.092: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.110:8080/dial?request=hostName&protocol=udp&host=172.30.181.91&port=8081&tries=1'] Namespace:pod-network-test-1977 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:39:30.092: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:39:30.346: INFO: Waiting for endpoints: map[]
Nov 20 18:39:30.359: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.110:8080/dial?request=hostName&protocol=udp&host=172.30.206.167&port=8081&tries=1'] Namespace:pod-network-test-1977 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:39:30.359: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:39:30.608: INFO: Waiting for endpoints: map[]
Nov 20 18:39:30.623: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.110:8080/dial?request=hostName&protocol=udp&host=172.30.70.112&port=8081&tries=1'] Namespace:pod-network-test-1977 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 18:39:30.623: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:39:30.845: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:39:30.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1977" for this suite.
Nov 20 18:39:42.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:39:43.391: INFO: namespace pod-network-test-1977 deletion completed in 12.503569463s

• [SLOW TEST:36.228 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:39:43.393: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:39:43.650: INFO: Waiting up to 5m0s for pod "downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b" in namespace "downward-api-4565" to be "success or failure"
Nov 20 18:39:43.668: INFO: Pod "downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b": Phase="Pending", Reason="", readiness=false. Elapsed: 18.194588ms
Nov 20 18:39:45.686: INFO: Pod "downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036191178s
STEP: Saw pod success
Nov 20 18:39:45.686: INFO: Pod "downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b" satisfied condition "success or failure"
Nov 20 18:39:45.706: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b container client-container: <nil>
STEP: delete the pod
Nov 20 18:39:45.798: INFO: Waiting for pod downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b to disappear
Nov 20 18:39:45.819: INFO: Pod downwardapi-volume-612cbdd0-8505-4d36-ad70-7f40b9a8802b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:39:45.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4565" for this suite.
Nov 20 18:39:51.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:39:52.375: INFO: namespace downward-api-4565 deletion completed in 6.526127385s

• [SLOW TEST:8.983 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:39:52.376: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8584
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:39:52.592: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:39:53.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8584" for this suite.
Nov 20 18:39:59.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:40:00.182: INFO: namespace custom-resource-definition-8584 deletion completed in 6.480845301s

• [SLOW TEST:7.807 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:40:00.186: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov 20 18:40:00.595: INFO: Number of nodes with available pods: 0
Nov 20 18:40:00.595: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:40:01.639: INFO: Number of nodes with available pods: 0
Nov 20 18:40:01.639: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:40:02.631: INFO: Number of nodes with available pods: 2
Nov 20 18:40:02.631: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 18:40:03.685: INFO: Number of nodes with available pods: 3
Nov 20 18:40:03.686: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov 20 18:40:03.767: INFO: Number of nodes with available pods: 2
Nov 20 18:40:03.767: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 18:40:04.910: INFO: Number of nodes with available pods: 2
Nov 20 18:40:04.910: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 18:40:05.886: INFO: Number of nodes with available pods: 2
Nov 20 18:40:05.886: INFO: Node 10.184.110.184 is running more than one daemon pod
Nov 20 18:40:06.808: INFO: Number of nodes with available pods: 3
Nov 20 18:40:06.808: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5541, will wait for the garbage collector to delete the pods
Nov 20 18:40:06.907: INFO: Deleting DaemonSet.extensions daemon-set took: 18.967532ms
Nov 20 18:40:07.107: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.386151ms
Nov 20 18:40:15.946: INFO: Number of nodes with available pods: 0
Nov 20 18:40:15.946: INFO: Number of running nodes: 0, number of available pods: 0
Nov 20 18:40:15.954: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5541/daemonsets","resourceVersion":"32541"},"items":null}

Nov 20 18:40:15.967: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5541/pods","resourceVersion":"32541"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:40:16.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5541" for this suite.
Nov 20 18:40:24.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:40:25.082: INFO: namespace daemonsets-5541 deletion completed in 8.815881794s

• [SLOW TEST:24.897 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:40:25.083: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3740
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-1ff5af4f-2c95-4e4f-8e0c-9776c500efd7
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:40:29.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3740" for this suite.
Nov 20 18:40:47.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:40:48.030: INFO: namespace configmap-3740 deletion completed in 18.481715608s

• [SLOW TEST:22.948 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:40:48.031: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:40:48.890: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:40:50.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872048, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872048, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872048, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872048, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:40:53.961: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:40:53.975: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2553-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:40:55.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-433" for this suite.
Nov 20 18:41:03.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:41:03.903: INFO: namespace webhook-433 deletion completed in 8.604896208s
STEP: Destroying namespace "webhook-433-markers" for this suite.
Nov 20 18:41:10.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:41:10.873: INFO: namespace webhook-433-markers deletion completed in 6.969799689s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.109 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:41:11.140: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov 20 18:41:12.035: INFO: Pod name wrapped-volume-race-a13e734a-3eae-4f4b-9a2c-8b5ef0542cbb: Found 1 pods out of 5
Nov 20 18:41:17.066: INFO: Pod name wrapped-volume-race-a13e734a-3eae-4f4b-9a2c-8b5ef0542cbb: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a13e734a-3eae-4f4b-9a2c-8b5ef0542cbb in namespace emptydir-wrapper-1719, will wait for the garbage collector to delete the pods
Nov 20 18:41:17.503: INFO: Deleting ReplicationController wrapped-volume-race-a13e734a-3eae-4f4b-9a2c-8b5ef0542cbb took: 168.206797ms
Nov 20 18:41:17.703: INFO: Terminating ReplicationController wrapped-volume-race-a13e734a-3eae-4f4b-9a2c-8b5ef0542cbb pods took: 200.299321ms
STEP: Creating RC which spawns configmap-volume pods
Nov 20 18:41:52.965: INFO: Pod name wrapped-volume-race-f02d92e0-4d2a-4a26-8196-74164bb2e932: Found 0 pods out of 5
Nov 20 18:41:57.987: INFO: Pod name wrapped-volume-race-f02d92e0-4d2a-4a26-8196-74164bb2e932: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f02d92e0-4d2a-4a26-8196-74164bb2e932 in namespace emptydir-wrapper-1719, will wait for the garbage collector to delete the pods
Nov 20 18:41:58.181: INFO: Deleting ReplicationController wrapped-volume-race-f02d92e0-4d2a-4a26-8196-74164bb2e932 took: 37.521534ms
Nov 20 18:41:58.381: INFO: Terminating ReplicationController wrapped-volume-race-f02d92e0-4d2a-4a26-8196-74164bb2e932 pods took: 200.282431ms
STEP: Creating RC which spawns configmap-volume pods
Nov 20 18:42:42.841: INFO: Pod name wrapped-volume-race-88a21539-ce8c-4127-a6ee-cf8e89b20727: Found 0 pods out of 5
Nov 20 18:42:47.862: INFO: Pod name wrapped-volume-race-88a21539-ce8c-4127-a6ee-cf8e89b20727: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-88a21539-ce8c-4127-a6ee-cf8e89b20727 in namespace emptydir-wrapper-1719, will wait for the garbage collector to delete the pods
Nov 20 18:42:48.039: INFO: Deleting ReplicationController wrapped-volume-race-88a21539-ce8c-4127-a6ee-cf8e89b20727 took: 38.534957ms
Nov 20 18:42:48.240: INFO: Terminating ReplicationController wrapped-volume-race-88a21539-ce8c-4127-a6ee-cf8e89b20727 pods took: 200.304512ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:43:33.489: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1719" for this suite.
Nov 20 18:43:43.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:43:43.992: INFO: namespace emptydir-wrapper-1719 deletion completed in 10.483060168s

• [SLOW TEST:152.852 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:43:43.992: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9124
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov 20 18:43:44.214: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:44:06.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9124" for this suite.
Nov 20 18:44:12.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:44:13.034: INFO: namespace crd-publish-openapi-9124 deletion completed in 6.705700834s

• [SLOW TEST:29.042 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:44:13.034: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8242
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:44:17.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8242" for this suite.
Nov 20 18:44:25.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:44:25.966: INFO: namespace kubelet-test-8242 deletion completed in 8.519609191s

• [SLOW TEST:12.932 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:44:25.967: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:44:31.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3126" for this suite.
Nov 20 18:44:37.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:44:38.162: INFO: namespace watch-3126 deletion completed in 6.5062431s

• [SLOW TEST:12.196 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:44:38.162: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8504
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov 20 18:45:18.648: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1120 18:45:18.648785      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov 20 18:45:18.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8504" for this suite.
Nov 20 18:45:26.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:45:27.335: INFO: namespace gc-8504 deletion completed in 8.671929104s

• [SLOW TEST:49.173 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:45:27.337: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-jcjg
STEP: Creating a pod to test atomic-volume-subpath
Nov 20 18:45:27.625: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-jcjg" in namespace "subpath-2566" to be "success or failure"
Nov 20 18:45:27.651: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Pending", Reason="", readiness=false. Elapsed: 25.501965ms
Nov 20 18:45:29.675: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04978347s
Nov 20 18:45:31.720: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 4.094655947s
Nov 20 18:45:33.739: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 6.113226489s
Nov 20 18:45:35.752: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 8.126247097s
Nov 20 18:45:37.766: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 10.140831472s
Nov 20 18:45:39.783: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 12.157992816s
Nov 20 18:45:41.796: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 14.17112875s
Nov 20 18:45:43.814: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 16.188179711s
Nov 20 18:45:45.827: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 18.201661368s
Nov 20 18:45:47.842: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 20.216253248s
Nov 20 18:45:49.858: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Running", Reason="", readiness=true. Elapsed: 22.233073987s
Nov 20 18:45:51.874: INFO: Pod "pod-subpath-test-downwardapi-jcjg": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.24860685s
STEP: Saw pod success
Nov 20 18:45:51.874: INFO: Pod "pod-subpath-test-downwardapi-jcjg" satisfied condition "success or failure"
Nov 20 18:45:51.893: INFO: Trying to get logs from node 10.184.110.176 pod pod-subpath-test-downwardapi-jcjg container test-container-subpath-downwardapi-jcjg: <nil>
STEP: delete the pod
Nov 20 18:45:52.044: INFO: Waiting for pod pod-subpath-test-downwardapi-jcjg to disappear
Nov 20 18:45:52.058: INFO: Pod pod-subpath-test-downwardapi-jcjg no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-jcjg
Nov 20 18:45:52.058: INFO: Deleting pod "pod-subpath-test-downwardapi-jcjg" in namespace "subpath-2566"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:45:52.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2566" for this suite.
Nov 20 18:45:58.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:45:58.642: INFO: namespace subpath-2566 deletion completed in 6.551495257s

• [SLOW TEST:31.306 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:45:58.647: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-5518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov 20 18:46:07.185: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:07.223: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 20 18:46:09.223: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:09.239: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 20 18:46:11.223: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:11.284: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 20 18:46:13.223: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:13.263: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 20 18:46:15.223: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:15.263: INFO: Pod pod-with-poststart-exec-hook still exists
Nov 20 18:46:17.223: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov 20 18:46:17.257: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:46:17.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5518" for this suite.
Nov 20 18:46:47.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:46:47.852: INFO: namespace container-lifecycle-hook-5518 deletion completed in 30.576524863s

• [SLOW TEST:49.205 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:46:47.852: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8434
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov 20 18:46:48.099: INFO: Waiting up to 5m0s for pod "pod-e886357a-5f5a-44dc-ad50-f18965bb72a1" in namespace "emptydir-8434" to be "success or failure"
Nov 20 18:46:48.114: INFO: Pod "pod-e886357a-5f5a-44dc-ad50-f18965bb72a1": Phase="Pending", Reason="", readiness=false. Elapsed: 15.068684ms
Nov 20 18:46:50.130: INFO: Pod "pod-e886357a-5f5a-44dc-ad50-f18965bb72a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030529932s
Nov 20 18:46:52.144: INFO: Pod "pod-e886357a-5f5a-44dc-ad50-f18965bb72a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044957506s
STEP: Saw pod success
Nov 20 18:46:52.144: INFO: Pod "pod-e886357a-5f5a-44dc-ad50-f18965bb72a1" satisfied condition "success or failure"
Nov 20 18:46:52.159: INFO: Trying to get logs from node 10.184.110.176 pod pod-e886357a-5f5a-44dc-ad50-f18965bb72a1 container test-container: <nil>
STEP: delete the pod
Nov 20 18:46:52.251: INFO: Waiting for pod pod-e886357a-5f5a-44dc-ad50-f18965bb72a1 to disappear
Nov 20 18:46:52.264: INFO: Pod pod-e886357a-5f5a-44dc-ad50-f18965bb72a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:46:52.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8434" for this suite.
Nov 20 18:46:58.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:46:58.744: INFO: namespace emptydir-8434 deletion completed in 6.449166377s

• [SLOW TEST:10.892 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:46:58.744: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-3329
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:46:58.980: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Creating first CR 
Nov 20 18:46:59.174: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:46:59Z generation:1 name:name1 resourceVersion:34394 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9c6d483a-3fea-4ca8-a9e3-ed5bda80729f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov 20 18:47:09.220: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:47:09Z generation:1 name:name2 resourceVersion:34407 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d977d4a5-5c6a-41a1-9656-ac60a71b6990] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov 20 18:47:19.235: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:46:59Z generation:2 name:name1 resourceVersion:34422 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9c6d483a-3fea-4ca8-a9e3-ed5bda80729f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov 20 18:47:29.249: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:47:09Z generation:2 name:name2 resourceVersion:34436 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d977d4a5-5c6a-41a1-9656-ac60a71b6990] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov 20 18:47:39.286: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:46:59Z generation:2 name:name1 resourceVersion:34450 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:9c6d483a-3fea-4ca8-a9e3-ed5bda80729f] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov 20 18:47:49.359: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-20T18:47:09Z generation:2 name:name2 resourceVersion:34465 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:d977d4a5-5c6a-41a1-9656-ac60a71b6990] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:47:59.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-3329" for this suite.
Nov 20 18:48:06.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:48:06.750: INFO: namespace crd-watch-3329 deletion completed in 6.813408949s

• [SLOW TEST:68.006 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:48:06.751: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2298
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-56d07b4f-9118-494a-8ce3-59da92269a39
STEP: Creating secret with name secret-projected-all-test-volume-0ae63902-d79f-459d-ad65-21dfbf379ee2
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov 20 18:48:07.082: INFO: Waiting up to 5m0s for pod "projected-volume-37a179be-7e23-4bce-b59b-96243e045daf" in namespace "projected-2298" to be "success or failure"
Nov 20 18:48:07.096: INFO: Pod "projected-volume-37a179be-7e23-4bce-b59b-96243e045daf": Phase="Pending", Reason="", readiness=false. Elapsed: 13.914008ms
Nov 20 18:48:09.188: INFO: Pod "projected-volume-37a179be-7e23-4bce-b59b-96243e045daf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.105710908s
Nov 20 18:48:11.240: INFO: Pod "projected-volume-37a179be-7e23-4bce-b59b-96243e045daf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.158433319s
STEP: Saw pod success
Nov 20 18:48:11.240: INFO: Pod "projected-volume-37a179be-7e23-4bce-b59b-96243e045daf" satisfied condition "success or failure"
Nov 20 18:48:11.272: INFO: Trying to get logs from node 10.184.110.176 pod projected-volume-37a179be-7e23-4bce-b59b-96243e045daf container projected-all-volume-test: <nil>
STEP: delete the pod
Nov 20 18:48:11.434: INFO: Waiting for pod projected-volume-37a179be-7e23-4bce-b59b-96243e045daf to disappear
Nov 20 18:48:11.454: INFO: Pod projected-volume-37a179be-7e23-4bce-b59b-96243e045daf no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:48:11.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2298" for this suite.
Nov 20 18:48:17.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:48:18.192: INFO: namespace projected-2298 deletion completed in 6.716969979s

• [SLOW TEST:11.441 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:48:18.193: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2878
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Nov 20 18:48:18.582: INFO: Waiting up to 5m0s for pod "pod-e634ffa6-11fc-49eb-a30c-32845570a7dd" in namespace "emptydir-2878" to be "success or failure"
Nov 20 18:48:18.615: INFO: Pod "pod-e634ffa6-11fc-49eb-a30c-32845570a7dd": Phase="Pending", Reason="", readiness=false. Elapsed: 32.819366ms
Nov 20 18:48:20.628: INFO: Pod "pod-e634ffa6-11fc-49eb-a30c-32845570a7dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045596358s
STEP: Saw pod success
Nov 20 18:48:20.628: INFO: Pod "pod-e634ffa6-11fc-49eb-a30c-32845570a7dd" satisfied condition "success or failure"
Nov 20 18:48:20.643: INFO: Trying to get logs from node 10.184.110.176 pod pod-e634ffa6-11fc-49eb-a30c-32845570a7dd container test-container: <nil>
STEP: delete the pod
Nov 20 18:48:20.740: INFO: Waiting for pod pod-e634ffa6-11fc-49eb-a30c-32845570a7dd to disappear
Nov 20 18:48:20.760: INFO: Pod pod-e634ffa6-11fc-49eb-a30c-32845570a7dd no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:48:20.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2878" for this suite.
Nov 20 18:48:26.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:48:27.247: INFO: namespace emptydir-2878 deletion completed in 6.460395305s

• [SLOW TEST:9.054 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:48:27.247: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-lmj5
STEP: Creating a pod to test atomic-volume-subpath
Nov 20 18:48:27.511: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-lmj5" in namespace "subpath-7298" to be "success or failure"
Nov 20 18:48:27.527: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.227023ms
Nov 20 18:48:29.553: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 2.041879369s
Nov 20 18:48:31.568: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 4.057039169s
Nov 20 18:48:33.583: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 6.072170374s
Nov 20 18:48:35.598: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 8.086837532s
Nov 20 18:48:37.613: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 10.10182327s
Nov 20 18:48:39.626: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 12.115357052s
Nov 20 18:48:41.683: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 14.171841024s
Nov 20 18:48:43.699: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 16.187879554s
Nov 20 18:48:45.714: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 18.203112084s
Nov 20 18:48:47.732: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Running", Reason="", readiness=true. Elapsed: 20.221086422s
Nov 20 18:48:49.747: INFO: Pod "pod-subpath-test-projected-lmj5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.2363714s
STEP: Saw pod success
Nov 20 18:48:49.747: INFO: Pod "pod-subpath-test-projected-lmj5" satisfied condition "success or failure"
Nov 20 18:48:49.763: INFO: Trying to get logs from node 10.184.110.176 pod pod-subpath-test-projected-lmj5 container test-container-subpath-projected-lmj5: <nil>
STEP: delete the pod
Nov 20 18:48:49.856: INFO: Waiting for pod pod-subpath-test-projected-lmj5 to disappear
Nov 20 18:48:49.870: INFO: Pod pod-subpath-test-projected-lmj5 no longer exists
STEP: Deleting pod pod-subpath-test-projected-lmj5
Nov 20 18:48:49.870: INFO: Deleting pod "pod-subpath-test-projected-lmj5" in namespace "subpath-7298"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:48:49.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7298" for this suite.
Nov 20 18:48:55.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:48:56.350: INFO: namespace subpath-7298 deletion completed in 6.433103028s

• [SLOW TEST:29.103 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:48:56.350: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5844
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5844
STEP: creating replication controller externalsvc in namespace services-5844
I1120 18:48:56.653837      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5844, replica count: 2
I1120 18:48:59.704351      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov 20 18:48:59.771: INFO: Creating new exec pod
Nov 20 18:49:01.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5844 execpodz5rvq -- /bin/sh -x -c nslookup clusterip-service'
Nov 20 18:49:02.618: INFO: stderr: "+ nslookup clusterip-service\n"
Nov 20 18:49:02.618: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-5844.svc.cluster.local\tcanonical name = externalsvc.services-5844.svc.cluster.local.\nName:\texternalsvc.services-5844.svc.cluster.local\nAddress: 172.21.157.130\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5844, will wait for the garbage collector to delete the pods
Nov 20 18:49:03.062: INFO: Deleting ReplicationController externalsvc took: 264.870376ms
Nov 20 18:49:03.263: INFO: Terminating ReplicationController externalsvc pods took: 200.34831ms
Nov 20 18:49:16.093: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:49:16.241: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5844" for this suite.
Nov 20 18:49:24.331: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:49:24.745: INFO: namespace services-5844 deletion completed in 8.484125796s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.395 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:49:24.746: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-7ad6654c-fbd4-4def-8bb5-fbea2e10fd2c
STEP: Creating a pod to test consume configMaps
Nov 20 18:49:25.037: INFO: Waiting up to 5m0s for pod "pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808" in namespace "configmap-1481" to be "success or failure"
Nov 20 18:49:25.054: INFO: Pod "pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808": Phase="Pending", Reason="", readiness=false. Elapsed: 16.495036ms
Nov 20 18:49:27.087: INFO: Pod "pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050074758s
STEP: Saw pod success
Nov 20 18:49:27.087: INFO: Pod "pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808" satisfied condition "success or failure"
Nov 20 18:49:27.169: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:49:27.389: INFO: Waiting for pod pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808 to disappear
Nov 20 18:49:27.407: INFO: Pod pod-configmaps-5ec7094b-59eb-4f0a-839c-772adf514808 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:49:27.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1481" for this suite.
Nov 20 18:49:33.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:49:33.921: INFO: namespace configmap-1481 deletion completed in 6.484970486s

• [SLOW TEST:9.174 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:49:33.923: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Nov 20 18:49:34.167: INFO: Waiting up to 5m0s for pod "var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b" in namespace "var-expansion-1873" to be "success or failure"
Nov 20 18:49:34.181: INFO: Pod "var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.45538ms
Nov 20 18:49:36.198: INFO: Pod "var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030654617s
Nov 20 18:49:38.213: INFO: Pod "var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.045078804s
STEP: Saw pod success
Nov 20 18:49:38.213: INFO: Pod "var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b" satisfied condition "success or failure"
Nov 20 18:49:38.236: INFO: Trying to get logs from node 10.184.110.176 pod var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b container dapi-container: <nil>
STEP: delete the pod
Nov 20 18:49:38.326: INFO: Waiting for pod var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b to disappear
Nov 20 18:49:38.339: INFO: Pod var-expansion-7dfb1a87-9afe-41fc-b48e-26093d29583b no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:49:38.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1873" for this suite.
Nov 20 18:49:44.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:49:44.854: INFO: namespace var-expansion-1873 deletion completed in 6.495475389s

• [SLOW TEST:10.932 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:49:44.855: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8913
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov 20 18:49:49.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec pod-sharedvolume-5d8aca0c-66e4-4140-a720-b75d7d9cae11 -c busybox-main-container --namespace=emptydir-8913 -- cat /usr/share/volumeshare/shareddata.txt'
Nov 20 18:49:49.625: INFO: stderr: ""
Nov 20 18:49:49.625: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:49:49.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8913" for this suite.
Nov 20 18:49:55.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:49:56.152: INFO: namespace emptydir-8913 deletion completed in 6.501921983s

• [SLOW TEST:11.297 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:49:56.155: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:49:56.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8" in namespace "downward-api-2201" to be "success or failure"
Nov 20 18:49:56.482: INFO: Pod "downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8": Phase="Pending", Reason="", readiness=false. Elapsed: 13.10167ms
Nov 20 18:49:58.503: INFO: Pod "downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034899063s
Nov 20 18:50:00.517: INFO: Pod "downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048382644s
STEP: Saw pod success
Nov 20 18:50:00.517: INFO: Pod "downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8" satisfied condition "success or failure"
Nov 20 18:50:00.538: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8 container client-container: <nil>
STEP: delete the pod
Nov 20 18:50:00.642: INFO: Waiting for pod downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8 to disappear
Nov 20 18:50:00.679: INFO: Pod downwardapi-volume-c8f58de6-be35-488b-830d-249b64f93fc8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:00.679: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2201" for this suite.
Nov 20 18:50:06.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:07.322: INFO: namespace downward-api-2201 deletion completed in 6.606950714s

• [SLOW TEST:11.168 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:07.322: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 20 18:50:10.555: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8"
Nov 20 18:50:10.555: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8" in namespace "pods-618" to be "terminated due to deadline exceeded"
Nov 20 18:50:10.623: INFO: Pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8": Phase="Running", Reason="", readiness=true. Elapsed: 68.237448ms
Nov 20 18:50:12.647: INFO: Pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8": Phase="Running", Reason="", readiness=true. Elapsed: 2.091718846s
Nov 20 18:50:14.666: INFO: Pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.110333543s
Nov 20 18:50:14.666: INFO: Pod "pod-update-activedeadlineseconds-9026a896-66e0-426d-ae60-4ef1e3fa6ab8" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:14.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-618" for this suite.
Nov 20 18:50:20.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:21.432: INFO: namespace pods-618 deletion completed in 6.744586442s

• [SLOW TEST:14.110 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:21.433: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3482
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-3482/secret-test-4727e920-a130-4559-aef1-88c6f9b5e5e2
STEP: Creating a pod to test consume secrets
Nov 20 18:50:21.904: INFO: Waiting up to 5m0s for pod "pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b" in namespace "secrets-3482" to be "success or failure"
Nov 20 18:50:21.951: INFO: Pod "pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b": Phase="Pending", Reason="", readiness=false. Elapsed: 46.859347ms
Nov 20 18:50:23.973: INFO: Pod "pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.068800762s
STEP: Saw pod success
Nov 20 18:50:23.973: INFO: Pod "pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b" satisfied condition "success or failure"
Nov 20 18:50:23.995: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b container env-test: <nil>
STEP: delete the pod
Nov 20 18:50:24.107: INFO: Waiting for pod pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b to disappear
Nov 20 18:50:24.128: INFO: Pod pod-configmaps-b32d2d18-1629-4b89-b6dc-fcf8a7220c9b no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:24.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3482" for this suite.
Nov 20 18:50:30.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:30.674: INFO: namespace secrets-3482 deletion completed in 6.523835972s

• [SLOW TEST:9.241 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:30.674: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5813
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:30.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5813" for this suite.
Nov 20 18:50:37.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:37.444: INFO: namespace kubelet-test-5813 deletion completed in 6.466644641s

• [SLOW TEST:6.769 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:37.444: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7226
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 20 18:50:39.791: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:39.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7226" for this suite.
Nov 20 18:50:45.930: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:46.302: INFO: namespace container-runtime-7226 deletion completed in 6.434510964s

• [SLOW TEST:8.857 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:46.302: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1592
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Nov 20 18:50:46.528: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-455954265 proxy --unix-socket=/tmp/kubectl-proxy-unix970998680/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:46.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1592" for this suite.
Nov 20 18:50:52.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:50:53.139: INFO: namespace kubectl-1592 deletion completed in 6.480110073s

• [SLOW TEST:6.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:50:53.143: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:50:53.369: INFO: Creating deployment "webserver-deployment"
Nov 20 18:50:53.381: INFO: Waiting for observed generation 1
Nov 20 18:50:55.397: INFO: Waiting for all required pods to come up
Nov 20 18:50:55.415: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov 20 18:50:57.452: INFO: Waiting for deployment "webserver-deployment" to complete
Nov 20 18:50:57.474: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov 20 18:50:57.492: INFO: Updating deployment webserver-deployment
Nov 20 18:50:57.492: INFO: Waiting for observed generation 2
Nov 20 18:50:59.512: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov 20 18:50:59.524: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov 20 18:50:59.538: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 20 18:50:59.599: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov 20 18:50:59.599: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov 20 18:50:59.625: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov 20 18:50:59.657: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov 20 18:50:59.657: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov 20 18:50:59.671: INFO: Updating deployment webserver-deployment
Nov 20 18:50:59.671: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov 20 18:50:59.702: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov 20 18:50:59.716: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov 20 18:50:59.748: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5912 /apis/apps/v1/namespaces/deployment-5912/deployments/webserver-deployment 911df137-a777-41d6-bc2f-79f328f6ddb8 35537 3 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000052958 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-11-20 18:50:57 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-20 18:50:59 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Nov 20 18:50:59.779: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-5912 /apis/apps/v1/namespaces/deployment-5912/replicasets/webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 35524 3 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 911df137-a777-41d6-bc2f-79f328f6ddb8 0xc0005d1bf7 0xc0005d1bf8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0005d1cd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:50:59.779: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov 20 18:50:59.779: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-5912 /apis/apps/v1/namespaces/deployment-5912/replicasets/webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 35521 3 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 911df137-a777-41d6-bc2f-79f328f6ddb8 0xc0005d1b17 0xc0005d1b18}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0005d1b98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:50:59.813: INFO: Pod "webserver-deployment-595b5b9587-4crgx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4crgx webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-4crgx 6701a129-31ac-4b2b-b1cc-c1cb04016f39 35598 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388497 0xc003388498}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.184,PodIP:,StartTime:2019-11-20 18:50:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.814: INFO: Pod "webserver-deployment-595b5b9587-5hms9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5hms9 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-5hms9 14f42885-78aa-4714-aac0-5aac78c5cfa9 35412 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc0033885f7 0xc0033885f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.74,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://2eb046a63aade725f205439698ace1022a2d61bafe32053a2005d4bd3a13b8ac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.74,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.814: INFO: Pod "webserver-deployment-595b5b9587-6c4jr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6c4jr webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-6c4jr 5239743c-9ad6-43e3-ae28-87ea04800a20 35406 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388777 0xc003388778}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.77,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://b822e7ebd5ffd470d89f3b24513d8604cddf5963b8f0b5f7d0360a479a6a67e1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.814: INFO: Pod "webserver-deployment-595b5b9587-7njll" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7njll webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-7njll f11c3c6c-d114-43c9-8f8f-3b29df857387 35387 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc0033888f7 0xc0033888f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.184,PodIP:172.30.181.100,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://cb6e47488eccf6bfd76925f4ffe418dd68a7a9e06a608f83c797ae1989658b16,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.181.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.814: INFO: Pod "webserver-deployment-595b5b9587-89m2f" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-89m2f webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-89m2f a0f9f1d9-7b5e-40d2-90bd-085a0c6a61af 35582 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388a87 0xc003388a88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:,StartTime:2019-11-20 18:50:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.815: INFO: Pod "webserver-deployment-595b5b9587-8g92z" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8g92z webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-8g92z 58a9560f-bddd-4822-afdb-cc0d3c8729e4 35409 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388bf7 0xc003388bf8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.75,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://918e0aa059aaf7c42a81bb0557ab1cdea51d2500cde3dcc3fbd8275c503b62af,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.75,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.815: INFO: Pod "webserver-deployment-595b5b9587-8rb6h" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8rb6h webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-8rb6h 79bb71d8-7371-4577-8bf7-a71f408705ec 35583 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388d87 0xc003388d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.140,PodIP:,StartTime:2019-11-20 18:50:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.815: INFO: Pod "webserver-deployment-595b5b9587-9ddft" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9ddft webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-9ddft 0b2bf5bf-82ab-4408-bd64-d4291ef9281b 35577 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003388ee7 0xc003388ee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.815: INFO: Pod "webserver-deployment-595b5b9587-9tcg9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9tcg9 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-9tcg9 8290370c-c458-4b97-ba29-0915d4e76514 35566 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389010 0xc003389011}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.816: INFO: Pod "webserver-deployment-595b5b9587-bd4dz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bd4dz webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-bd4dz 75370d3c-fbe6-429a-95f7-55135f8a8d20 35545 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389130 0xc003389131}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.816: INFO: Pod "webserver-deployment-595b5b9587-bttw6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bttw6 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-bttw6 e85cb045-46d5-45ae-a12d-abf6d77c0dfa 35568 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389250 0xc003389251}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.816: INFO: Pod "webserver-deployment-595b5b9587-bwwc4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bwwc4 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-bwwc4 82347d1f-2d3a-4d1e-a9ac-62b50b5d5bf5 35579 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389360 0xc003389361}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.816: INFO: Pod "webserver-deployment-595b5b9587-krk4x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-krk4x webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-krk4x 9865b3b4-474b-4974-8447-187f473e2b52 35397 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389480 0xc003389481}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.140,PodIP:172.30.206.189,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://baa297a92d4c094270ce5bbdfd554aefe033f7d1f656c97da6c06b90e0bb545e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.206.189,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.816: INFO: Pod "webserver-deployment-595b5b9587-mr8zv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mr8zv webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-mr8zv 312ad916-8459-4437-87bf-a8ea2afcdad4 35551 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc0033895f7 0xc0033895f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.817: INFO: Pod "webserver-deployment-595b5b9587-pq79x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pq79x webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-pq79x 6275124f-b518-4248-8907-ad20dc11f06e 35393 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389710 0xc003389711}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.184,PodIP:172.30.181.101,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a7026414409cba99dd93728d69adc819b68223947e26ef82a1d4a30c8080bfe8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.181.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.817: INFO: Pod "webserver-deployment-595b5b9587-r9pdp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r9pdp webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-r9pdp 57367795-5eb0-495d-9ea9-bddf25ceb4c0 35581 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389897 0xc003389898}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.817: INFO: Pod "webserver-deployment-595b5b9587-tccn2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tccn2 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-tccn2 e2fa2d70-c04a-40f1-aa1e-ed91b86a77e2 35390 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc0033899d0 0xc0033899d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.184,PodIP:172.30.181.99,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://8a0ea7a14426c2268d723a2d3ed173c85ebb30de7bd6914b1374a3b63a180a79,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.181.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.818: INFO: Pod "webserver-deployment-595b5b9587-z254n" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-z254n webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-z254n fbfb0500-f789-4940-95c4-254623954b85 35578 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389b47 0xc003389b48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.818: INFO: Pod "webserver-deployment-595b5b9587-zbnfh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zbnfh webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-zbnfh e1def9bd-a56e-4d8e-ad1d-1c1754aa2bc5 35550 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389c60 0xc003389c61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.818: INFO: Pod "webserver-deployment-595b5b9587-zd7f9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zd7f9 webserver-deployment-595b5b9587- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-595b5b9587-zd7f9 dcd9118f-5ece-4797-8977-4cc250da0a42 35400 0 2019-11-20 18:50:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 9099a27e-f472-4412-98e7-7a80baa71698 0xc003389d70 0xc003389d71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.140,PodIP:172.30.206.190,StartTime:2019-11-20 18:50:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:50:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://833f8506653c109bf5474ac047569af1fb6df157e2178e538968a8e904baf0f2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.206.190,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.818: INFO: Pod "webserver-deployment-c7997dcc8-5qw4j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5qw4j webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-5qw4j 9fc7a20f-cd15-4793-a7f6-a4fee4ab4410 35567 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc003389f17 0xc003389f18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.819: INFO: Pod "webserver-deployment-c7997dcc8-75vsr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-75vsr webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-75vsr 2f74b1ff-ca1b-4420-9645-923ca48876ed 35526 0 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6060 0xc0034f6061}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.78,StartTime:2019-11-20 18:50:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.78,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.819: INFO: Pod "webserver-deployment-c7997dcc8-7dbg5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7dbg5 webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-7dbg5 ef5824fe-75f7-4253-92b0-ba5749eac487 35565 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6207 0xc0034f6208}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.819: INFO: Pod "webserver-deployment-c7997dcc8-7wnxp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7wnxp webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-7wnxp 017d1ffe-0417-4517-b8b1-e8b219c01a72 35570 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6330 0xc0034f6331}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.819: INFO: Pod "webserver-deployment-c7997dcc8-8phbb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8phbb webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-8phbb 6777f9dc-95ff-4249-8872-9c544064b0ec 35511 0 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6450 0xc0034f6451}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.184,PodIP:172.30.181.103,StartTime:2019-11-20 18:50:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.181.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.820: INFO: Pod "webserver-deployment-c7997dcc8-cfg5j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cfg5j webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-cfg5j d46d79b6-c6a9-498d-836b-b21be9f4acb0 35546 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f65f7 0xc0034f65f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.820: INFO: Pod "webserver-deployment-c7997dcc8-d4npn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-d4npn webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-d4npn 363b0319-ec2c-4b40-9917-494c94affb55 35547 0 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6720 0xc0034f6721}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.79,StartTime:2019-11-20 18:50:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.79,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.820: INFO: Pod "webserver-deployment-c7997dcc8-ghzfc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ghzfc webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-ghzfc 48e24391-40b7-47c3-8895-8fe3c9865259 35595 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f68c7 0xc0034f68c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.821: INFO: Pod "webserver-deployment-c7997dcc8-hgk5d" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hgk5d webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-hgk5d 7528ebad-04f6-43cc-8a62-ea7dcdb4d69d 35514 0 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f69f0 0xc0034f69f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.140,PodIP:172.30.206.131,StartTime:2019-11-20 18:50:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.206.131,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.821: INFO: Pod "webserver-deployment-c7997dcc8-nzfmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nzfmr webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-nzfmr 9420d6aa-6d14-4e7d-a31b-bbfaa77a4a1e 35518 0 2019-11-20 18:50:57 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6b97 0xc0034f6b98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.140,PodIP:172.30.206.130,StartTime:2019-11-20 18:50:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.206.130,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.821: INFO: Pod "webserver-deployment-c7997dcc8-pjvm4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pjvm4 webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-pjvm4 84a8c67f-057e-46ab-9aa2-cee74e007f55 35569 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6d47 0xc0034f6d48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.140,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.821: INFO: Pod "webserver-deployment-c7997dcc8-wh67r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wh67r webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-wh67r 5e072acf-83dc-4bcd-9d21-544aa0cdd118 35580 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6e70 0xc0034f6e71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov 20 18:50:59.822: INFO: Pod "webserver-deployment-c7997dcc8-xqtr2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xqtr2 webserver-deployment-c7997dcc8- deployment-5912 /api/v1/namespaces/deployment-5912/pods/webserver-deployment-c7997dcc8-xqtr2 ad0c255b-4ced-4518-b303-2e8ff87450db 35552 0 2019-11-20 18:50:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 3c97a1e1-8cec-4707-9691-e3302eafa632 0xc0034f6f90 0xc0034f6f91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gwqq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gwqq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gwqq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.184,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:50:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:50:59.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5912" for this suite.
Nov 20 18:51:11.972: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:51:12.491: INFO: namespace deployment-5912 deletion completed in 12.650413958s

• [SLOW TEST:19.348 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:51:12.491: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 18:51:13.508: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 18:51:15.552: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872673, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872673, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872673, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872673, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 18:51:18.628: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:51:18.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4518" for this suite.
Nov 20 18:51:30.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:51:31.312: INFO: namespace webhook-4518 deletion completed in 12.47143927s
STEP: Destroying namespace "webhook-4518-markers" for this suite.
Nov 20 18:51:37.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:51:37.745: INFO: namespace webhook-4518-markers deletion completed in 6.433372047s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:25.318 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:51:37.810: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7420
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-1451d351-9bd0-4f1e-b49f-260780d76e3e
STEP: Creating a pod to test consume configMaps
Nov 20 18:51:38.079: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec" in namespace "projected-7420" to be "success or failure"
Nov 20 18:51:38.095: INFO: Pod "pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec": Phase="Pending", Reason="", readiness=false. Elapsed: 15.911032ms
Nov 20 18:51:40.110: INFO: Pod "pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030837274s
STEP: Saw pod success
Nov 20 18:51:40.110: INFO: Pod "pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec" satisfied condition "success or failure"
Nov 20 18:51:40.124: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:51:40.232: INFO: Waiting for pod pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec to disappear
Nov 20 18:51:40.246: INFO: Pod pod-projected-configmaps-07078258-bfff-4eae-a0c8-ef7c90ec64ec no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:51:40.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7420" for this suite.
Nov 20 18:51:46.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:51:46.802: INFO: namespace projected-7420 deletion completed in 6.530358991s

• [SLOW TEST:8.992 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:51:46.804: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov 20 18:51:47.068: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:51:55.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8651" for this suite.
Nov 20 18:52:01.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:52:02.466: INFO: namespace pods-8651 deletion completed in 6.520493796s

• [SLOW TEST:15.663 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:52:02.467: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2268
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:52:02.792: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov 20 18:52:07.834: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 20 18:52:07.834: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov 20 18:52:09.848: INFO: Creating deployment "test-rollover-deployment"
Nov 20 18:52:09.895: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov 20 18:52:11.915: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov 20 18:52:11.939: INFO: Ensure that both replica sets have 1 created replica
Nov 20 18:52:11.977: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov 20 18:52:11.992: INFO: Updating deployment test-rollover-deployment
Nov 20 18:52:11.992: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov 20 18:52:14.016: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov 20 18:52:14.038: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov 20 18:52:14.057: INFO: all replica sets need to contain the pod-template-hash label
Nov 20 18:52:14.057: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:16.097: INFO: all replica sets need to contain the pod-template-hash label
Nov 20 18:52:16.097: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:18.098: INFO: all replica sets need to contain the pod-template-hash label
Nov 20 18:52:18.098: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:20.118: INFO: all replica sets need to contain the pod-template-hash label
Nov 20 18:52:20.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:22.084: INFO: all replica sets need to contain the pod-template-hash label
Nov 20 18:52:22.084: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:24.107: INFO: 
Nov 20 18:52:24.107: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872730, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872733, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709872729, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov 20 18:52:26.087: INFO: 
Nov 20 18:52:26.087: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov 20 18:52:26.125: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-2268 /apis/apps/v1/namespaces/deployment-2268/deployments/test-rollover-deployment c10eb276-3ddc-4014-9222-b2196ac88e00 36405 2 2019-11-20 18:52:09 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002a3ca78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-20 18:52:10 +0000 UTC,LastTransitionTime:2019-11-20 18:52:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-11-20 18:52:24 +0000 UTC,LastTransitionTime:2019-11-20 18:52:09 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 20 18:52:26.138: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-2268 /apis/apps/v1/namespaces/deployment-2268/replicasets/test-rollover-deployment-7d7dc6548c d50c99d9-48e4-4026-931b-990a38418349 36393 2 2019-11-20 18:52:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment c10eb276-3ddc-4014-9222-b2196ac88e00 0xc002a3cf77 0xc002a3cf78}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002a3cfd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:52:26.139: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov 20 18:52:26.139: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-2268 /apis/apps/v1/namespaces/deployment-2268/replicasets/test-rollover-controller b1ebcc00-23a0-4b5e-8c86-f7ea312ab9d9 36404 2 2019-11-20 18:52:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment c10eb276-3ddc-4014-9222-b2196ac88e00 0xc002a3cea7 0xc002a3cea8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002a3cf08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:52:26.139: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-2268 /apis/apps/v1/namespaces/deployment-2268/replicasets/test-rollover-deployment-f6c94f66c 872710c2-12a6-4dd4-a040-08386e548b5f 36359 2 2019-11-20 18:52:09 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment c10eb276-3ddc-4014-9222-b2196ac88e00 0xc002a3d040 0xc002a3d041}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002a3d0b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:52:26.156: INFO: Pod "test-rollover-deployment-7d7dc6548c-d8fdx" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-d8fdx test-rollover-deployment-7d7dc6548c- deployment-2268 /api/v1/namespaces/deployment-2268/pods/test-rollover-deployment-7d7dc6548c-d8fdx d16d17b5-adf4-44ea-9fcb-39434b144197 36377 0 2019-11-20 18:52:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c d50c99d9-48e4-4026-931b-990a38418349 0xc002a3d617 0xc002a3d618}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-pg86d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-pg86d,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-pg86d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:52:12 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:52:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:52:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:52:12 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.93,StartTime:2019-11-20 18:52:12 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:52:13 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://74b9250606275e7f0911989f367db7830a81a994748bc4ddbfd7a9652bf4abd1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:52:26.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2268" for this suite.
Nov 20 18:52:34.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:52:34.724: INFO: namespace deployment-2268 deletion completed in 8.539264155s

• [SLOW TEST:32.258 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:52:34.725: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5926
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:53:02.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5926" for this suite.
Nov 20 18:53:10.265: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:53:11.034: INFO: namespace container-runtime-5926 deletion completed in 8.898159251s

• [SLOW TEST:36.309 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:53:11.035: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Nov 20 18:53:11.268: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8258 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov 20 18:53:11.415: INFO: stderr: ""
Nov 20 18:53:11.415: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Nov 20 18:53:11.415: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov 20 18:53:11.415: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8258" to be "running and ready, or succeeded"
Nov 20 18:53:11.431: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 15.8557ms
Nov 20 18:53:13.447: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.031551525s
Nov 20 18:53:13.447: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov 20 18:53:13.447: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov 20 18:53:13.447: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258'
Nov 20 18:53:13.654: INFO: stderr: ""
Nov 20 18:53:13.654: INFO: stdout: "I1120 18:53:12.798872       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/ddf 310\nI1120 18:53:12.999156       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5w2n 346\nI1120 18:53:13.199091       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/lxjg 389\nI1120 18:53:13.399181       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/gl4 543\nI1120 18:53:13.599135       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/75ts 280\n"
STEP: limiting log lines
Nov 20 18:53:13.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258 --tail=1'
Nov 20 18:53:13.876: INFO: stderr: ""
Nov 20 18:53:13.876: INFO: stdout: "I1120 18:53:13.799097       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/lwg 345\n"
STEP: limiting log bytes
Nov 20 18:53:13.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258 --limit-bytes=1'
Nov 20 18:53:14.143: INFO: stderr: ""
Nov 20 18:53:14.143: INFO: stdout: "I"
STEP: exposing timestamps
Nov 20 18:53:14.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258 --tail=1 --timestamps'
Nov 20 18:53:14.363: INFO: stderr: ""
Nov 20 18:53:14.363: INFO: stdout: "2019-11-20T18:53:14.199346437Z I1120 18:53:14.199119       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/f49 509\n"
STEP: restricting to a time range
Nov 20 18:53:16.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258 --since=1s'
Nov 20 18:53:17.045: INFO: stderr: ""
Nov 20 18:53:17.045: INFO: stdout: "I1120 18:53:16.199060       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/8xh 352\nI1120 18:53:16.399087       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lcv 407\nI1120 18:53:16.599064       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xw8 554\nI1120 18:53:16.799038       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/26kl 223\nI1120 18:53:16.999104       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/fsx 370\n"
Nov 20 18:53:17.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 logs logs-generator logs-generator --namespace=kubectl-8258 --since=24h'
Nov 20 18:53:17.224: INFO: stderr: ""
Nov 20 18:53:17.224: INFO: stdout: "I1120 18:53:12.798872       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/ddf 310\nI1120 18:53:12.999156       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/5w2n 346\nI1120 18:53:13.199091       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/lxjg 389\nI1120 18:53:13.399181       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/gl4 543\nI1120 18:53:13.599135       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/75ts 280\nI1120 18:53:13.799097       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/default/pods/lwg 345\nI1120 18:53:13.999059       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/g8z 395\nI1120 18:53:14.199119       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/f49 509\nI1120 18:53:14.399053       1 logs_generator.go:76] 8 GET /api/v1/namespaces/default/pods/5srz 312\nI1120 18:53:14.599106       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/g9z9 520\nI1120 18:53:14.799089       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/jgn 228\nI1120 18:53:14.999055       1 logs_generator.go:76] 11 POST /api/v1/namespaces/default/pods/zrz 322\nI1120 18:53:15.199081       1 logs_generator.go:76] 12 GET /api/v1/namespaces/kube-system/pods/hz5 275\nI1120 18:53:15.399068       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/wjmk 477\nI1120 18:53:15.599048       1 logs_generator.go:76] 14 POST /api/v1/namespaces/default/pods/hmp 472\nI1120 18:53:15.799068       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/4sq 402\nI1120 18:53:15.999070       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/t8ch 341\nI1120 18:53:16.199060       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/kube-system/pods/8xh 352\nI1120 18:53:16.399087       1 logs_generator.go:76] 18 GET /api/v1/namespaces/default/pods/lcv 407\nI1120 18:53:16.599064       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/xw8 554\nI1120 18:53:16.799038       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/26kl 223\nI1120 18:53:16.999104       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/fsx 370\nI1120 18:53:17.199098       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/tl7c 217\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Nov 20 18:53:17.224: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete pod logs-generator --namespace=kubectl-8258'
Nov 20 18:53:25.882: INFO: stderr: ""
Nov 20 18:53:25.882: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:53:25.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8258" for this suite.
Nov 20 18:53:32.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:53:32.468: INFO: namespace kubectl-8258 deletion completed in 6.556794371s

• [SLOW TEST:21.433 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:53:32.471: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2424b62c-e105-46e1-a2d8-fdd21dc51194
STEP: Creating a pod to test consume secrets
Nov 20 18:53:32.753: INFO: Waiting up to 5m0s for pod "pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c" in namespace "secrets-9104" to be "success or failure"
Nov 20 18:53:32.765: INFO: Pod "pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c": Phase="Pending", Reason="", readiness=false. Elapsed: 12.254732ms
Nov 20 18:53:34.779: INFO: Pod "pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025734201s
STEP: Saw pod success
Nov 20 18:53:34.779: INFO: Pod "pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c" satisfied condition "success or failure"
Nov 20 18:53:34.803: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c container secret-env-test: <nil>
STEP: delete the pod
Nov 20 18:53:34.885: INFO: Waiting for pod pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c to disappear
Nov 20 18:53:34.896: INFO: Pod pod-secrets-22a1aeb5-508d-4f8d-a8d3-6d99e038109c no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:53:34.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9104" for this suite.
Nov 20 18:53:41.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:53:41.457: INFO: namespace secrets-9104 deletion completed in 6.540817339s

• [SLOW TEST:8.986 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:53:41.458: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2222
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov 20 18:53:41.715: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36732 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 20 18:53:41.716: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36732 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov 20 18:53:51.738: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36746 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov 20 18:53:51.738: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36746 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov 20 18:54:01.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36759 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 20 18:54:01.758: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36759 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov 20 18:54:11.777: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36773 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov 20 18:54:11.777: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-a c1f4461e-795c-453f-80f4-030b90cce752 36773 0 2019-11-20 18:53:41 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov 20 18:54:21.796: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-b c1f81f62-d2ed-4d07-b295-fcf53a2f5cc2 36787 0 2019-11-20 18:54:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 20 18:54:21.796: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-b c1f81f62-d2ed-4d07-b295-fcf53a2f5cc2 36787 0 2019-11-20 18:54:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov 20 18:54:31.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-b c1f81f62-d2ed-4d07-b295-fcf53a2f5cc2 36801 0 2019-11-20 18:54:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov 20 18:54:31.819: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2222 /api/v1/namespaces/watch-2222/configmaps/e2e-watch-test-configmap-b c1f81f62-d2ed-4d07-b295-fcf53a2f5cc2 36801 0 2019-11-20 18:54:21 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:54:41.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2222" for this suite.
Nov 20 18:54:47.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:54:48.299: INFO: namespace watch-2222 deletion completed in 6.458056588s

• [SLOW TEST:66.841 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:54:48.299: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9193
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Nov 20 18:54:48.556: INFO: Waiting up to 5m0s for pod "client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5" in namespace "containers-9193" to be "success or failure"
Nov 20 18:54:48.569: INFO: Pod "client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.389677ms
Nov 20 18:54:50.584: INFO: Pod "client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0281976s
STEP: Saw pod success
Nov 20 18:54:50.585: INFO: Pod "client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5" satisfied condition "success or failure"
Nov 20 18:54:50.597: INFO: Trying to get logs from node 10.184.110.176 pod client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5 container test-container: <nil>
STEP: delete the pod
Nov 20 18:54:50.706: INFO: Waiting for pod client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5 to disappear
Nov 20 18:54:50.737: INFO: Pod client-containers-2fabb52d-1eee-41bb-8b70-5e5b31807ad5 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:54:50.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9193" for this suite.
Nov 20 18:54:56.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:54:57.278: INFO: namespace containers-9193 deletion completed in 6.521314475s

• [SLOW TEST:8.979 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:54:57.278: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-225
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 20 18:54:57.561: INFO: Waiting up to 5m0s for pod "pod-df6a029a-977b-4178-a7fd-721cc7914a42" in namespace "emptydir-225" to be "success or failure"
Nov 20 18:54:57.575: INFO: Pod "pod-df6a029a-977b-4178-a7fd-721cc7914a42": Phase="Pending", Reason="", readiness=false. Elapsed: 14.074521ms
Nov 20 18:54:59.595: INFO: Pod "pod-df6a029a-977b-4178-a7fd-721cc7914a42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033651696s
STEP: Saw pod success
Nov 20 18:54:59.595: INFO: Pod "pod-df6a029a-977b-4178-a7fd-721cc7914a42" satisfied condition "success or failure"
Nov 20 18:54:59.610: INFO: Trying to get logs from node 10.184.110.176 pod pod-df6a029a-977b-4178-a7fd-721cc7914a42 container test-container: <nil>
STEP: delete the pod
Nov 20 18:54:59.716: INFO: Waiting for pod pod-df6a029a-977b-4178-a7fd-721cc7914a42 to disappear
Nov 20 18:54:59.730: INFO: Pod pod-df6a029a-977b-4178-a7fd-721cc7914a42 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:54:59.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-225" for this suite.
Nov 20 18:55:07.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:55:08.512: INFO: namespace emptydir-225 deletion completed in 8.762869066s

• [SLOW TEST:11.234 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:55:08.512: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8884
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-88ada0cb-d163-4f92-b9b3-956c3c92d6d6
STEP: Creating a pod to test consume configMaps
Nov 20 18:55:08.860: INFO: Waiting up to 5m0s for pod "pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68" in namespace "configmap-8884" to be "success or failure"
Nov 20 18:55:08.919: INFO: Pod "pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68": Phase="Pending", Reason="", readiness=false. Elapsed: 58.946604ms
Nov 20 18:55:10.981: INFO: Pod "pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.12083615s
STEP: Saw pod success
Nov 20 18:55:10.981: INFO: Pod "pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68" satisfied condition "success or failure"
Nov 20 18:55:11.007: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 18:55:11.215: INFO: Waiting for pod pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68 to disappear
Nov 20 18:55:11.250: INFO: Pod pod-configmaps-7b706699-2ae9-44c4-8888-2f95d3c8bb68 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:55:11.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8884" for this suite.
Nov 20 18:55:19.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:55:20.048: INFO: namespace configmap-8884 deletion completed in 8.753182842s

• [SLOW TEST:11.536 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:55:20.048: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5268
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov 20 18:55:22.414: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-455954265 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov 20 18:55:27.678: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:55:27.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5268" for this suite.
Nov 20 18:55:33.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:55:34.175: INFO: namespace pods-5268 deletion completed in 6.464177878s

• [SLOW TEST:14.127 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:55:34.176: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Nov 20 18:55:34.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 cluster-info'
Nov 20 18:55:34.546: INFO: stderr: ""
Nov 20 18:55:34.546: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:55:34.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9188" for this suite.
Nov 20 18:55:40.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:55:41.057: INFO: namespace kubectl-9188 deletion completed in 6.49431464s

• [SLOW TEST:6.881 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:55:41.057: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1957
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Nov 20 18:55:41.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-1957'
Nov 20 18:55:41.679: INFO: stderr: ""
Nov 20 18:55:41.679: INFO: stdout: "pod/pause created\n"
Nov 20 18:55:41.679: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov 20 18:55:41.679: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1957" to be "running and ready"
Nov 20 18:55:41.697: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.878896ms
Nov 20 18:55:43.713: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.034115078s
Nov 20 18:55:43.713: INFO: Pod "pause" satisfied condition "running and ready"
Nov 20 18:55:43.713: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Nov 20 18:55:43.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 label pods pause testing-label=testing-label-value --namespace=kubectl-1957'
Nov 20 18:55:43.869: INFO: stderr: ""
Nov 20 18:55:43.869: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov 20 18:55:43.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pod pause -L testing-label --namespace=kubectl-1957'
Nov 20 18:55:43.994: INFO: stderr: ""
Nov 20 18:55:43.994: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov 20 18:55:43.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 label pods pause testing-label- --namespace=kubectl-1957'
Nov 20 18:55:44.159: INFO: stderr: ""
Nov 20 18:55:44.159: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov 20 18:55:44.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pod pause -L testing-label --namespace=kubectl-1957'
Nov 20 18:55:44.288: INFO: stderr: ""
Nov 20 18:55:44.288: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Nov 20 18:55:44.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-1957'
Nov 20 18:55:44.473: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 18:55:44.473: INFO: stdout: "pod \"pause\" force deleted\n"
Nov 20 18:55:44.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get rc,svc -l name=pause --no-headers --namespace=kubectl-1957'
Nov 20 18:55:44.625: INFO: stderr: "No resources found in kubectl-1957 namespace.\n"
Nov 20 18:55:44.625: INFO: stdout: ""
Nov 20 18:55:44.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -l name=pause --namespace=kubectl-1957 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 20 18:55:44.785: INFO: stderr: ""
Nov 20 18:55:44.785: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:55:44.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1957" for this suite.
Nov 20 18:55:50.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:55:51.288: INFO: namespace kubectl-1957 deletion completed in 6.482417362s

• [SLOW TEST:10.230 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:55:51.288: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:55:51.630: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov 20 18:55:51.662: INFO: Number of nodes with available pods: 0
Nov 20 18:55:51.662: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov 20 18:55:51.735: INFO: Number of nodes with available pods: 0
Nov 20 18:55:51.735: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:52.749: INFO: Number of nodes with available pods: 0
Nov 20 18:55:52.749: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:53.747: INFO: Number of nodes with available pods: 1
Nov 20 18:55:53.747: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov 20 18:55:53.847: INFO: Number of nodes with available pods: 0
Nov 20 18:55:53.847: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov 20 18:55:53.874: INFO: Number of nodes with available pods: 0
Nov 20 18:55:53.874: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:54.886: INFO: Number of nodes with available pods: 0
Nov 20 18:55:54.887: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:55.895: INFO: Number of nodes with available pods: 0
Nov 20 18:55:55.895: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:56.887: INFO: Number of nodes with available pods: 0
Nov 20 18:55:56.887: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:57.913: INFO: Number of nodes with available pods: 0
Nov 20 18:55:57.913: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:58.888: INFO: Number of nodes with available pods: 0
Nov 20 18:55:58.888: INFO: Node 10.184.110.140 is running more than one daemon pod
Nov 20 18:55:59.891: INFO: Number of nodes with available pods: 1
Nov 20 18:55:59.892: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8978, will wait for the garbage collector to delete the pods
Nov 20 18:55:59.992: INFO: Deleting DaemonSet.extensions daemon-set took: 24.931135ms
Nov 20 18:56:00.193: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.529222ms
Nov 20 18:56:03.408: INFO: Number of nodes with available pods: 0
Nov 20 18:56:03.408: INFO: Number of running nodes: 0, number of available pods: 0
Nov 20 18:56:03.415: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8978/daemonsets","resourceVersion":"37210"},"items":null}

Nov 20 18:56:03.442: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8978/pods","resourceVersion":"37210"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:56:03.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8978" for this suite.
Nov 20 18:56:11.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:56:12.161: INFO: namespace daemonsets-8978 deletion completed in 8.578576073s

• [SLOW TEST:20.873 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:56:12.161: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:56:12.511: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov 20 18:56:17.570: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 20 18:56:17.570: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov 20 18:56:19.785: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-716 /apis/apps/v1/namespaces/deployment-716/deployments/test-cleanup-deployment d7ebb846-00cb-4370-b175-ef5e378ef9e2 37310 1 2019-11-20 18:56:17 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006aa8d98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-20 18:56:17 +0000 UTC,LastTransitionTime:2019-11-20 18:56:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-11-20 18:56:19 +0000 UTC,LastTransitionTime:2019-11-20 18:56:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 20 18:56:19.798: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-716 /apis/apps/v1/namespaces/deployment-716/replicasets/test-cleanup-deployment-65db99849b 1b2acb3e-5c20-4b0f-a1a7-02bccf1791f8 37299 1 2019-11-20 18:56:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment d7ebb846-00cb-4370-b175-ef5e378ef9e2 0xc006aa91c7 0xc006aa91c8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006aa9228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 20 18:56:19.819: INFO: Pod "test-cleanup-deployment-65db99849b-5vwmx" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-5vwmx test-cleanup-deployment-65db99849b- deployment-716 /api/v1/namespaces/deployment-716/pods/test-cleanup-deployment-65db99849b-5vwmx cc3ebad4-fdb7-4b56-b516-0f03d6e83479 37298 0 2019-11-20 18:56:17 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 1b2acb3e-5c20-4b0f-a1a7-02bccf1791f8 0xc006aa95c7 0xc006aa95c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5266j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5266j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5266j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:56:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:56:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 18:56:17 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.107,StartTime:2019-11-20 18:56:17 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 18:56:19 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://7405085f410d207748f539bcb2b646c8d93826072d0d8bfa79295bf5cc5b9498,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.107,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:56:19.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-716" for this suite.
Nov 20 18:56:27.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:56:28.306: INFO: namespace deployment-716 deletion completed in 8.462942315s

• [SLOW TEST:16.145 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:56:28.307: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3552
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov 20 18:56:28.537: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 18:56:32.515: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:56:47.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3552" for this suite.
Nov 20 18:56:53.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:56:54.037: INFO: namespace crd-publish-openapi-3552 deletion completed in 6.489886401s

• [SLOW TEST:25.730 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:56:54.037: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-581
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:57:54.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-581" for this suite.
Nov 20 18:58:24.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:58:25.182: INFO: namespace container-probe-581 deletion completed in 30.791387916s

• [SLOW TEST:91.145 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:58:25.182: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov 20 18:58:25.583: INFO: Waiting up to 5m0s for pod "pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d" in namespace "emptydir-9607" to be "success or failure"
Nov 20 18:58:25.603: INFO: Pod "pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 20.281068ms
Nov 20 18:58:27.620: INFO: Pod "pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036401363s
Nov 20 18:58:29.635: INFO: Pod "pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052016022s
STEP: Saw pod success
Nov 20 18:58:29.635: INFO: Pod "pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d" satisfied condition "success or failure"
Nov 20 18:58:29.651: INFO: Trying to get logs from node 10.184.110.176 pod pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d container test-container: <nil>
STEP: delete the pod
Nov 20 18:58:29.801: INFO: Waiting for pod pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d to disappear
Nov 20 18:58:29.816: INFO: Pod pod-0e36a901-78fb-4d81-a57f-2bfe532d7a7d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:58:29.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9607" for this suite.
Nov 20 18:58:35.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:58:36.329: INFO: namespace emptydir-9607 deletion completed in 6.485125526s

• [SLOW TEST:11.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:58:36.329: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 18:58:36.557: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:58:40.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3323" for this suite.
Nov 20 18:59:26.850: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:59:27.268: INFO: namespace pods-3323 deletion completed in 46.492093972s

• [SLOW TEST:50.939 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:59:27.269: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov 20 18:59:32.168: INFO: Successfully updated pod "pod-update-c128192b-020a-4426-a43c-54edf368064f"
STEP: verifying the updated pod is in kubernetes
Nov 20 18:59:32.195: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:59:32.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-307" for this suite.
Nov 20 18:59:44.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:59:44.656: INFO: namespace pods-307 deletion completed in 12.440983822s

• [SLOW TEST:17.388 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:59:44.657: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov 20 18:59:44.920: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381" in namespace "downward-api-8101" to be "success or failure"
Nov 20 18:59:44.935: INFO: Pod "downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381": Phase="Pending", Reason="", readiness=false. Elapsed: 14.890528ms
Nov 20 18:59:46.950: INFO: Pod "downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029648055s
STEP: Saw pod success
Nov 20 18:59:46.950: INFO: Pod "downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381" satisfied condition "success or failure"
Nov 20 18:59:46.963: INFO: Trying to get logs from node 10.184.110.176 pod downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381 container client-container: <nil>
STEP: delete the pod
Nov 20 18:59:47.044: INFO: Waiting for pod downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381 to disappear
Nov 20 18:59:47.056: INFO: Pod downwardapi-volume-ca4d87f6-0a8b-43bd-8eac-6240caddd381 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 18:59:47.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8101" for this suite.
Nov 20 18:59:53.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 18:59:53.530: INFO: namespace downward-api-8101 deletion completed in 6.454547131s

• [SLOW TEST:8.874 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 18:59:53.531: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6527
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc in namespace container-probe-6527
Nov 20 18:59:55.873: INFO: Started pod liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc in namespace container-probe-6527
STEP: checking the pod's current state and verifying that restartCount is present
Nov 20 18:59:55.887: INFO: Initial restart count of pod liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is 0
Nov 20 19:00:10.340: INFO: Restart count of pod container-probe-6527/liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is now 1 (14.453093524s elapsed)
Nov 20 19:00:30.654: INFO: Restart count of pod container-probe-6527/liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is now 2 (34.767006698s elapsed)
Nov 20 19:00:50.840: INFO: Restart count of pod container-probe-6527/liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is now 3 (54.953392806s elapsed)
Nov 20 19:01:10.404: INFO: Restart count of pod container-probe-6527/liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is now 4 (1m14.517162036s elapsed)
Nov 20 19:02:13.034: INFO: Restart count of pod container-probe-6527/liveness-bd9a2431-f116-4d1d-adc7-56d4b19dd4bc is now 5 (2m17.147263807s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:02:13.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6527" for this suite.
Nov 20 19:02:19.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:02:19.752: INFO: namespace container-probe-6527 deletion completed in 6.627155321s

• [SLOW TEST:146.221 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:02:19.753: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 19:02:20.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5683'
Nov 20 19:02:20.267: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 20 19:02:20.267: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Nov 20 19:02:20.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete jobs e2e-test-httpd-job --namespace=kubectl-5683'
Nov 20 19:02:20.468: INFO: stderr: ""
Nov 20 19:02:20.468: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:02:20.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5683" for this suite.
Nov 20 19:02:26.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:02:26.981: INFO: namespace kubectl-5683 deletion completed in 6.492848942s

• [SLOW TEST:7.229 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:02:26.982: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-ff205be7-603b-465a-a8ee-0d5b332de58b
STEP: Creating a pod to test consume configMaps
Nov 20 19:02:27.246: INFO: Waiting up to 5m0s for pod "pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293" in namespace "configmap-429" to be "success or failure"
Nov 20 19:02:27.258: INFO: Pod "pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293": Phase="Pending", Reason="", readiness=false. Elapsed: 11.731456ms
Nov 20 19:02:29.277: INFO: Pod "pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030925625s
STEP: Saw pod success
Nov 20 19:02:29.277: INFO: Pod "pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293" satisfied condition "success or failure"
Nov 20 19:02:29.290: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293 container configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 19:02:29.432: INFO: Waiting for pod pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293 to disappear
Nov 20 19:02:29.446: INFO: Pod pod-configmaps-d0dca881-08d7-4935-9c0b-5589dc3be293 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:02:29.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-429" for this suite.
Nov 20 19:02:35.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:02:35.888: INFO: namespace configmap-429 deletion completed in 6.423871184s

• [SLOW TEST:8.906 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:02:35.889: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7006
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:02:38.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7006" for this suite.
Nov 20 19:03:28.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:03:28.702: INFO: namespace kubelet-test-7006 deletion completed in 50.457381038s

• [SLOW TEST:52.814 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:03:28.703: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4249
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Nov 20 19:03:29.512: INFO: created pod pod-service-account-defaultsa
Nov 20 19:03:29.512: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov 20 19:03:29.530: INFO: created pod pod-service-account-mountsa
Nov 20 19:03:29.530: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov 20 19:03:29.548: INFO: created pod pod-service-account-nomountsa
Nov 20 19:03:29.548: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov 20 19:03:29.564: INFO: created pod pod-service-account-defaultsa-mountspec
Nov 20 19:03:29.564: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov 20 19:03:29.579: INFO: created pod pod-service-account-mountsa-mountspec
Nov 20 19:03:29.579: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov 20 19:03:29.593: INFO: created pod pod-service-account-nomountsa-mountspec
Nov 20 19:03:29.593: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov 20 19:03:29.609: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov 20 19:03:29.609: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov 20 19:03:29.627: INFO: created pod pod-service-account-mountsa-nomountspec
Nov 20 19:03:29.628: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov 20 19:03:29.652: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov 20 19:03:29.652: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:03:29.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4249" for this suite.
Nov 20 19:03:37.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:03:38.132: INFO: namespace svcaccounts-4249 deletion completed in 8.462463864s

• [SLOW TEST:9.429 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:03:38.132: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Nov 20 19:03:38.388: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov 20 19:03:38.388: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:38.774: INFO: stderr: ""
Nov 20 19:03:38.774: INFO: stdout: "service/redis-slave created\n"
Nov 20 19:03:38.774: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov 20 19:03:38.774: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:39.032: INFO: stderr: ""
Nov 20 19:03:39.032: INFO: stdout: "service/redis-master created\n"
Nov 20 19:03:39.032: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov 20 19:03:39.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:39.389: INFO: stderr: ""
Nov 20 19:03:39.389: INFO: stdout: "service/frontend created\n"
Nov 20 19:03:39.389: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov 20 19:03:39.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:39.727: INFO: stderr: ""
Nov 20 19:03:39.727: INFO: stdout: "deployment.apps/frontend created\n"
Nov 20 19:03:39.728: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov 20 19:03:39.728: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:40.052: INFO: stderr: ""
Nov 20 19:03:40.052: INFO: stdout: "deployment.apps/redis-master created\n"
Nov 20 19:03:40.052: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov 20 19:03:40.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-5804'
Nov 20 19:03:40.286: INFO: stderr: ""
Nov 20 19:03:40.286: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov 20 19:03:40.286: INFO: Waiting for all frontend pods to be Running.
Nov 20 19:03:55.337: INFO: Waiting for frontend to serve content.
Nov 20 19:03:55.387: INFO: Trying to add a new entry to the guestbook.
Nov 20 19:03:55.436: INFO: Verifying that added entry can be retrieved.
Nov 20 19:03:55.475: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:00.535: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:05.592: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:10.682: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:15.767: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:20.843: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:25.971: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:31.021: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:36.081: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov 20 19:04:41.125: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Nov 20 19:04:46.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:46.372: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:46.372: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov 20 19:04:46.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:46.583: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:46.583: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 20 19:04:46.584: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:46.806: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:46.806: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 20 19:04:46.806: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:46.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:46.970: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov 20 19:04:46.971: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:47.169: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:47.169: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov 20 19:04:47.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-5804'
Nov 20 19:04:47.343: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:04:47.343: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:04:47.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5804" for this suite.
Nov 20 19:05:01.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:05:01.973: INFO: namespace kubectl-5804 deletion completed in 14.606295961s

• [SLOW TEST:83.841 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:05:01.974: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a3864dfc-d55a-4616-96e9-283d692028f4
STEP: Creating a pod to test consume secrets
Nov 20 19:05:02.350: INFO: Waiting up to 5m0s for pod "pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f" in namespace "secrets-8478" to be "success or failure"
Nov 20 19:05:02.370: INFO: Pod "pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.869917ms
Nov 20 19:05:04.403: INFO: Pod "pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.052976198s
Nov 20 19:05:06.473: INFO: Pod "pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123164971s
STEP: Saw pod success
Nov 20 19:05:06.473: INFO: Pod "pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f" satisfied condition "success or failure"
Nov 20 19:05:06.546: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 19:05:06.748: INFO: Waiting for pod pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f to disappear
Nov 20 19:05:06.771: INFO: Pod pod-secrets-cbc21b1c-a236-479b-bd0e-2541b7e7135f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:05:06.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8478" for this suite.
Nov 20 19:05:13.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:05:13.656: INFO: namespace secrets-8478 deletion completed in 6.720754697s

• [SLOW TEST:11.682 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:05:13.656: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4785
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-bb986581-f862-48c3-bbde-2dbbe6153392 in namespace container-probe-4785
Nov 20 19:05:15.950: INFO: Started pod test-webserver-bb986581-f862-48c3-bbde-2dbbe6153392 in namespace container-probe-4785
STEP: checking the pod's current state and verifying that restartCount is present
Nov 20 19:05:15.969: INFO: Initial restart count of pod test-webserver-bb986581-f862-48c3-bbde-2dbbe6153392 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:09:16.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4785" for this suite.
Nov 20 19:09:24.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:09:25.253: INFO: namespace container-probe-4785 deletion completed in 8.575113794s

• [SLOW TEST:251.597 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:09:25.254: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-624
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov 20 19:09:25.584: INFO: Pod name pod-release: Found 0 pods out of 1
Nov 20 19:09:30.601: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:09:30.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-624" for this suite.
Nov 20 19:09:36.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:09:37.109: INFO: namespace replication-controller-624 deletion completed in 6.430853731s

• [SLOW TEST:11.854 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:09:37.110: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8758
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 19:09:37.804: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov 20 19:09:39.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709873777, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709873777, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63709873777, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63709873777, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 19:09:42.873: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:09:42.894: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8758" for this suite.
Nov 20 19:09:50.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:09:51.400: INFO: namespace webhook-8758 deletion completed in 8.488659454s
STEP: Destroying namespace "webhook-8758-markers" for this suite.
Nov 20 19:09:57.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:09:57.872: INFO: namespace webhook-8758-markers deletion completed in 6.472255247s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.830 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:09:57.939: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7719
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov 20 19:09:58.158: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov 20 19:10:16.528: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.66:8080/dial?request=hostName&protocol=http&host=172.30.206.146&port=8080&tries=1'] Namespace:pod-network-test-7719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 19:10:16.528: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 19:10:16.769: INFO: Waiting for endpoints: map[]
Nov 20 19:10:16.804: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.66:8080/dial?request=hostName&protocol=http&host=172.30.181.114&port=8080&tries=1'] Namespace:pod-network-test-7719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 19:10:16.804: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 19:10:17.038: INFO: Waiting for endpoints: map[]
Nov 20 19:10:17.059: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.70.66:8080/dial?request=hostName&protocol=http&host=172.30.70.127&port=8080&tries=1'] Namespace:pod-network-test-7719 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov 20 19:10:17.059: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
Nov 20 19:10:17.313: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:10:17.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7719" for this suite.
Nov 20 19:10:31.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:10:31.859: INFO: namespace pod-network-test-7719 deletion completed in 14.487464854s

• [SLOW TEST:33.919 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:10:31.859: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-7639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov 20 19:10:35.232: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:10:36.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-7639" for this suite.
Nov 20 19:10:48.396: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:10:48.974: INFO: namespace replicaset-7639 deletion completed in 12.631820236s

• [SLOW TEST:17.116 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:10:48.976: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:00.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1263" for this suite.
Nov 20 19:11:06.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:11:07.114: INFO: namespace resourcequota-1263 deletion completed in 6.652222796s

• [SLOW TEST:18.139 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:11:07.115: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-6848
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6848 to expose endpoints map[]
Nov 20 19:11:07.514: INFO: successfully validated that service endpoint-test2 in namespace services-6848 exposes endpoints map[] (60.072422ms elapsed)
STEP: Creating pod pod1 in namespace services-6848
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6848 to expose endpoints map[pod1:[80]]
Nov 20 19:11:10.764: INFO: successfully validated that service endpoint-test2 in namespace services-6848 exposes endpoints map[pod1:[80]] (3.197239386s elapsed)
STEP: Creating pod pod2 in namespace services-6848
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6848 to expose endpoints map[pod1:[80] pod2:[80]]
Nov 20 19:11:14.013: INFO: successfully validated that service endpoint-test2 in namespace services-6848 exposes endpoints map[pod1:[80] pod2:[80]] (3.230393033s elapsed)
STEP: Deleting pod pod1 in namespace services-6848
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6848 to expose endpoints map[pod2:[80]]
Nov 20 19:11:14.087: INFO: successfully validated that service endpoint-test2 in namespace services-6848 exposes endpoints map[pod2:[80]] (40.050595ms elapsed)
STEP: Deleting pod pod2 in namespace services-6848
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6848 to expose endpoints map[]
Nov 20 19:11:14.170: INFO: successfully validated that service endpoint-test2 in namespace services-6848 exposes endpoints map[] (42.197001ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:14.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6848" for this suite.
Nov 20 19:11:26.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:11:27.136: INFO: namespace services-6848 deletion completed in 12.70405556s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.021 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:11:27.136: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8777
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8777.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8777.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 19:11:31.675: INFO: DNS probes using dns-8777/dns-test-4c90c667-d1cf-417c-a713-92b76ecdd8a5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:31.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8777" for this suite.
Nov 20 19:11:39.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:11:40.270: INFO: namespace dns-8777 deletion completed in 8.512141584s

• [SLOW TEST:13.134 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:11:40.271: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-a9bbc759-8e65-4f20-88eb-08550516afb0
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:40.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5089" for this suite.
Nov 20 19:11:46.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:11:47.029: INFO: namespace configmap-5089 deletion completed in 6.50096941s

• [SLOW TEST:6.757 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:11:47.030: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:47.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2562" for this suite.
Nov 20 19:11:53.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:11:53.817: INFO: namespace services-2562 deletion completed in 6.516337792s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.788 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:11:53.818: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8244
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8244.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8244.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8244.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8244.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8244.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8244.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov 20 19:11:58.349: INFO: DNS probes using dns-8244/dns-test-9a69aa86-35bd-441d-b4f4-6310e0d2c3d4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:11:58.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8244" for this suite.
Nov 20 19:12:06.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:12:07.238: INFO: namespace dns-8244 deletion completed in 8.819865292s

• [SLOW TEST:13.420 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:12:07.240: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-873
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov 20 19:12:18.039: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:12:18.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1120 19:12:18.039366      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-873" for this suite.
Nov 20 19:12:26.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:12:26.553: INFO: namespace gc-873 deletion completed in 8.497139268s

• [SLOW TEST:19.314 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:12:26.554: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8705
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 19:12:26.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8705'
Nov 20 19:12:27.061: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov 20 19:12:27.061: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov 20 19:12:27.076: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov 20 19:12:27.087: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov 20 19:12:27.102: INFO: scanned /root for discovery docs: <nil>
Nov 20 19:12:27.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-8705'
Nov 20 19:12:43.099: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov 20 19:12:43.099: INFO: stdout: "Created e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629\nScaling up e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov 20 19:12:43.099: INFO: stdout: "Created e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629\nScaling up e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov 20 19:12:43.099: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-8705'
Nov 20 19:12:43.229: INFO: stderr: ""
Nov 20 19:12:43.229: INFO: stdout: "e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629-kgk2p "
Nov 20 19:12:43.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629-kgk2p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8705'
Nov 20 19:12:43.391: INFO: stderr: ""
Nov 20 19:12:43.391: INFO: stdout: "true"
Nov 20 19:12:43.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629-kgk2p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8705'
Nov 20 19:12:43.536: INFO: stderr: ""
Nov 20 19:12:43.536: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov 20 19:12:43.536: INFO: e2e-test-httpd-rc-fa01c43ed2ebfb4e7578fc29b3220629-kgk2p is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Nov 20 19:12:43.536: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete rc e2e-test-httpd-rc --namespace=kubectl-8705'
Nov 20 19:12:43.691: INFO: stderr: ""
Nov 20 19:12:43.691: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:12:43.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8705" for this suite.
Nov 20 19:13:13.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:13:14.168: INFO: namespace kubectl-8705 deletion completed in 30.45548341s

• [SLOW TEST:47.614 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:13:14.169: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov 20 19:13:16.540: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:13:16.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2854" for this suite.
Nov 20 19:13:22.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:13:23.326: INFO: namespace container-runtime-2854 deletion completed in 6.694221513s

• [SLOW TEST:9.158 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:13:23.326: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ebc30b75-e8eb-4747-a7f1-26886dfeba4a
STEP: Creating a pod to test consume configMaps
Nov 20 19:13:23.604: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0" in namespace "projected-3721" to be "success or failure"
Nov 20 19:13:23.625: INFO: Pod "pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0": Phase="Pending", Reason="", readiness=false. Elapsed: 20.646019ms
Nov 20 19:13:25.643: INFO: Pod "pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038497514s
STEP: Saw pod success
Nov 20 19:13:25.643: INFO: Pod "pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0" satisfied condition "success or failure"
Nov 20 19:13:25.691: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 19:13:25.891: INFO: Waiting for pod pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0 to disappear
Nov 20 19:13:25.907: INFO: Pod pod-projected-configmaps-79b3d451-5ce0-4e53-9ee6-298d13f2d5b0 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:13:25.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3721" for this suite.
Nov 20 19:13:31.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:13:32.368: INFO: namespace projected-3721 deletion completed in 6.441279704s

• [SLOW TEST:9.042 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:13:32.369: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1001
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1001/configmap-test-e3731859-c813-417a-bbc9-dbb11e6f5e13
STEP: Creating a pod to test consume configMaps
Nov 20 19:13:32.645: INFO: Waiting up to 5m0s for pod "pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f" in namespace "configmap-1001" to be "success or failure"
Nov 20 19:13:32.659: INFO: Pod "pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.709471ms
Nov 20 19:13:34.691: INFO: Pod "pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045865037s
STEP: Saw pod success
Nov 20 19:13:34.691: INFO: Pod "pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f" satisfied condition "success or failure"
Nov 20 19:13:34.710: INFO: Trying to get logs from node 10.184.110.176 pod pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f container env-test: <nil>
STEP: delete the pod
Nov 20 19:13:34.796: INFO: Waiting for pod pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f to disappear
Nov 20 19:13:34.807: INFO: Pod pod-configmaps-78b371c9-8f76-46d1-affe-bf2845bbee2f no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:13:34.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1001" for this suite.
Nov 20 19:13:40.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:13:41.234: INFO: namespace configmap-1001 deletion completed in 6.407926849s

• [SLOW TEST:8.865 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:13:41.234: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2818
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-3fbbe889-12c4-4c5f-b40a-2f969e4a7d74
STEP: Creating secret with name s-test-opt-upd-5c205dd5-8935-424f-b937-3c5120980c43
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-3fbbe889-12c4-4c5f-b40a-2f969e4a7d74
STEP: Updating secret s-test-opt-upd-5c205dd5-8935-424f-b937-3c5120980c43
STEP: Creating secret with name s-test-opt-create-a26877f4-43f0-4b1b-a61f-474c2252cc45
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:15:12.992: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2818" for this suite.
Nov 20 19:15:27.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:15:27.517: INFO: namespace projected-2818 deletion completed in 14.50659034s

• [SLOW TEST:106.283 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:15:27.518: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-340
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov 20 19:15:27.771: INFO: Waiting up to 5m0s for pod "downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0" in namespace "downward-api-340" to be "success or failure"
Nov 20 19:15:27.786: INFO: Pod "downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.139415ms
Nov 20 19:15:29.824: INFO: Pod "downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.053554096s
STEP: Saw pod success
Nov 20 19:15:29.825: INFO: Pod "downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0" satisfied condition "success or failure"
Nov 20 19:15:29.840: INFO: Trying to get logs from node 10.184.110.176 pod downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0 container dapi-container: <nil>
STEP: delete the pod
Nov 20 19:15:29.920: INFO: Waiting for pod downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0 to disappear
Nov 20 19:15:29.934: INFO: Pod downward-api-2c9250e6-fc42-47fc-b821-7761bfcad6c0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:15:29.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-340" for this suite.
Nov 20 19:15:36.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:15:36.424: INFO: namespace downward-api-340 deletion completed in 6.468469426s

• [SLOW TEST:8.905 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:15:36.425: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-bbb6df72-58c4-4d70-98f2-26daf9147987
STEP: Creating a pod to test consume secrets
Nov 20 19:15:36.690: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6" in namespace "projected-5768" to be "success or failure"
Nov 20 19:15:36.705: INFO: Pod "pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.840249ms
Nov 20 19:15:38.720: INFO: Pod "pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030097324s
Nov 20 19:15:40.745: INFO: Pod "pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055221261s
STEP: Saw pod success
Nov 20 19:15:40.746: INFO: Pod "pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6" satisfied condition "success or failure"
Nov 20 19:15:40.761: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov 20 19:15:40.858: INFO: Waiting for pod pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6 to disappear
Nov 20 19:15:40.874: INFO: Pod pod-projected-secrets-c9c034a5-57dd-4605-a5f6-a9725b2e55a6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:15:40.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5768" for this suite.
Nov 20 19:15:46.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:15:47.438: INFO: namespace projected-5768 deletion completed in 6.543455119s

• [SLOW TEST:11.013 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:15:47.438: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov 20 19:15:47.704: INFO: Waiting up to 5m0s for pod "pod-c01bf128-f972-4755-9d04-2b74df1b6dda" in namespace "emptydir-2378" to be "success or failure"
Nov 20 19:15:47.720: INFO: Pod "pod-c01bf128-f972-4755-9d04-2b74df1b6dda": Phase="Pending", Reason="", readiness=false. Elapsed: 15.19311ms
Nov 20 19:15:49.732: INFO: Pod "pod-c01bf128-f972-4755-9d04-2b74df1b6dda": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028017154s
Nov 20 19:15:51.747: INFO: Pod "pod-c01bf128-f972-4755-9d04-2b74df1b6dda": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042307545s
STEP: Saw pod success
Nov 20 19:15:51.747: INFO: Pod "pod-c01bf128-f972-4755-9d04-2b74df1b6dda" satisfied condition "success or failure"
Nov 20 19:15:51.762: INFO: Trying to get logs from node 10.184.110.176 pod pod-c01bf128-f972-4755-9d04-2b74df1b6dda container test-container: <nil>
STEP: delete the pod
Nov 20 19:15:51.896: INFO: Waiting for pod pod-c01bf128-f972-4755-9d04-2b74df1b6dda to disappear
Nov 20 19:15:51.928: INFO: Pod pod-c01bf128-f972-4755-9d04-2b74df1b6dda no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:15:51.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2378" for this suite.
Nov 20 19:15:58.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:15:58.423: INFO: namespace emptydir-2378 deletion completed in 6.476779859s

• [SLOW TEST:10.985 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:15:58.423: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5982
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-5982
STEP: creating replication controller nodeport-test in namespace services-5982
I1120 19:15:58.710697      23 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-5982, replica count: 2
Nov 20 19:16:01.761: INFO: Creating new exec pod
I1120 19:16:01.761130      23 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov 20 19:16:06.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov 20 19:16:07.261: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov 20 19:16:07.261: INFO: stdout: ""
Nov 20 19:16:07.262: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 172.21.7.230 80'
Nov 20 19:16:07.642: INFO: stderr: "+ nc -zv -t -w 2 172.21.7.230 80\nConnection to 172.21.7.230 80 port [tcp/http] succeeded!\n"
Nov 20 19:16:07.642: INFO: stdout: ""
Nov 20 19:16:07.643: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 10.184.110.140 30269'
Nov 20 19:16:08.032: INFO: stderr: "+ nc -zv -t -w 2 10.184.110.140 30269\nConnection to 10.184.110.140 30269 port [tcp/30269] succeeded!\n"
Nov 20 19:16:08.032: INFO: stdout: ""
Nov 20 19:16:08.032: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 10.184.110.176 30269'
Nov 20 19:16:08.499: INFO: stderr: "+ nc -zv -t -w 2 10.184.110.176 30269\nConnection to 10.184.110.176 30269 port [tcp/30269] succeeded!\n"
Nov 20 19:16:08.499: INFO: stdout: ""
Nov 20 19:16:08.499: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 169.63.53.2 30269'
Nov 20 19:16:08.890: INFO: stderr: "+ nc -zv -t -w 2 169.63.53.2 30269\nConnection to 169.63.53.2 30269 port [tcp/30269] succeeded!\n"
Nov 20 19:16:08.890: INFO: stdout: ""
Nov 20 19:16:08.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 exec --namespace=services-5982 execpodstfc8 -- /bin/sh -x -c nc -zv -t -w 2 169.63.53.3 30269'
Nov 20 19:16:09.257: INFO: stderr: "+ nc -zv -t -w 2 169.63.53.3 30269\nConnection to 169.63.53.3 30269 port [tcp/30269] succeeded!\n"
Nov 20 19:16:09.257: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:16:09.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5982" for this suite.
Nov 20 19:16:17.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:16:17.981: INFO: namespace services-5982 deletion completed in 8.695917545s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.559 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:16:17.984: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4459
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:16:34.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4459" for this suite.
Nov 20 19:16:40.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:16:41.001: INFO: namespace resourcequota-4459 deletion completed in 6.468653104s

• [SLOW TEST:23.017 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:16:41.001: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4369
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4369
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov 20 19:16:41.270: INFO: Found 0 stateful pods, waiting for 3
Nov 20 19:16:51.287: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 19:16:51.287: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 19:16:51.287: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov 20 19:16:51.354: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov 20 19:17:01.495: INFO: Updating stateful set ss2
Nov 20 19:17:01.533: INFO: Waiting for Pod statefulset-4369/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 19:17:11.572: INFO: Waiting for Pod statefulset-4369/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov 20 19:17:21.885: INFO: Found 2 stateful pods, waiting for 3
Nov 20 19:17:31.900: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 19:17:31.900: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov 20 19:17:31.900: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov 20 19:17:31.948: INFO: Updating stateful set ss2
Nov 20 19:17:31.971: INFO: Waiting for Pod statefulset-4369/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 19:17:42.002: INFO: Waiting for Pod statefulset-4369/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov 20 19:17:52.028: INFO: Updating stateful set ss2
Nov 20 19:17:52.049: INFO: Waiting for StatefulSet statefulset-4369/ss2 to complete update
Nov 20 19:17:52.049: INFO: Waiting for Pod statefulset-4369/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov 20 19:18:02.085: INFO: Deleting all statefulset in ns statefulset-4369
Nov 20 19:18:02.106: INFO: Scaling statefulset ss2 to 0
Nov 20 19:18:32.163: INFO: Waiting for statefulset status.replicas updated to 0
Nov 20 19:18:32.172: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:18:32.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4369" for this suite.
Nov 20 19:18:40.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:18:40.691: INFO: namespace statefulset-4369 deletion completed in 8.453932149s

• [SLOW TEST:119.689 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:18:40.691: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6203
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov 20 19:18:45.598: INFO: Successfully updated pod "labelsupdate91083fcc-2821-45d5-a8ef-029542cf474b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:18:47.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6203" for this suite.
Nov 20 19:19:07.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:19:08.683: INFO: namespace projected-6203 deletion completed in 20.984944336s

• [SLOW TEST:27.992 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:19:08.683: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8371
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov 20 19:19:08.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 create -f - --namespace=kubectl-8371'
Nov 20 19:19:09.302: INFO: stderr: ""
Nov 20 19:19:09.302: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov 20 19:19:09.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8371'
Nov 20 19:19:09.452: INFO: stderr: ""
Nov 20 19:19:09.452: INFO: stdout: "update-demo-nautilus-4q6hs update-demo-nautilus-gw6v4 "
Nov 20 19:19:09.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-4q6hs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8371'
Nov 20 19:19:09.592: INFO: stderr: ""
Nov 20 19:19:09.592: INFO: stdout: ""
Nov 20 19:19:09.593: INFO: update-demo-nautilus-4q6hs is created but not running
Nov 20 19:19:14.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8371'
Nov 20 19:19:14.739: INFO: stderr: ""
Nov 20 19:19:14.739: INFO: stdout: "update-demo-nautilus-4q6hs update-demo-nautilus-gw6v4 "
Nov 20 19:19:14.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-4q6hs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8371'
Nov 20 19:19:14.880: INFO: stderr: ""
Nov 20 19:19:14.880: INFO: stdout: "true"
Nov 20 19:19:14.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-4q6hs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8371'
Nov 20 19:19:15.041: INFO: stderr: ""
Nov 20 19:19:15.041: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 19:19:15.041: INFO: validating pod update-demo-nautilus-4q6hs
Nov 20 19:19:15.124: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 19:19:15.124: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 19:19:15.124: INFO: update-demo-nautilus-4q6hs is verified up and running
Nov 20 19:19:15.125: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-gw6v4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8371'
Nov 20 19:19:15.278: INFO: stderr: ""
Nov 20 19:19:15.278: INFO: stdout: "true"
Nov 20 19:19:15.279: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods update-demo-nautilus-gw6v4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8371'
Nov 20 19:19:15.420: INFO: stderr: ""
Nov 20 19:19:15.420: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov 20 19:19:15.420: INFO: validating pod update-demo-nautilus-gw6v4
Nov 20 19:19:15.464: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov 20 19:19:15.464: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov 20 19:19:15.464: INFO: update-demo-nautilus-gw6v4 is verified up and running
STEP: using delete to clean up resources
Nov 20 19:19:15.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete --grace-period=0 --force -f - --namespace=kubectl-8371'
Nov 20 19:19:15.616: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov 20 19:19:15.616: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov 20 19:19:15.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8371'
Nov 20 19:19:15.781: INFO: stderr: "No resources found in kubectl-8371 namespace.\n"
Nov 20 19:19:15.781: INFO: stdout: ""
Nov 20 19:19:15.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pods -l name=update-demo --namespace=kubectl-8371 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov 20 19:19:15.939: INFO: stderr: ""
Nov 20 19:19:15.939: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:19:15.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8371" for this suite.
Nov 20 19:19:28.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:19:28.434: INFO: namespace kubectl-8371 deletion completed in 12.46309631s

• [SLOW TEST:19.751 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:19:28.436: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2792
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov 20 19:19:28.693: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 20 19:19:28.753: INFO: Waiting for terminating namespaces to be deleted...
Nov 20 19:19:28.765: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.140 before test
Nov 20 19:19:28.856: INFO: addon-catalog-source-67xr7 from ibm-system started at 2019-11-20 16:18:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container configmap-registry-server ready: true, restart count 1
Nov 20 19:19:28.856: INFO: ibm-keepalived-watcher-d59s8 from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:19:28.856: INFO: coredns-6db888bf8c-7xqjq from kube-system started at 2019-11-20 17:28:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:19:28.856: INFO: ibm-master-proxy-static-10.184.110.140 from kube-system started at 2019-11-20 16:18:02 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:19:28.856: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:19:28.856: INFO: calico-node-4dc2d from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:19:28.856: INFO: coredns-6db888bf8c-jr582 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:19:28.856: INFO: sonobuoy-e2e-job-b1a8acd3cb8d418c from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container e2e ready: true, restart count 0
Nov 20 19:19:28.856: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 19:19:28.856: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:28.856: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:19:28.856: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:19:28.856: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.176 before test
Nov 20 19:19:28.913: INFO: ibm-master-proxy-static-10.184.110.176 from kube-system started at 2019-11-20 16:19:06 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:28.913: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:19:28.913: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:19:28.913: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:28.913: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:19:28.913: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:19:28.913: INFO: calico-node-lkmcb from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.913: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:19:28.914: INFO: ibm-keepalived-watcher-qwxkl from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:28.914: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:19:28.914: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.184 before test
Nov 20 19:19:29.070: INFO: ibm-file-plugin-56c5959484-qv87m from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 20 19:19:29.070: INFO: calico-kube-controllers-6f7dc6dfd4-7bt8x from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 20 19:19:29.070: INFO: metrics-server-6bb8bc7476-7x5bd from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container metrics-server ready: true, restart count 0
Nov 20 19:19:29.070: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:19:29.070: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:19:29.070: INFO: kubernetes-dashboard-6bb9bf847f-kvddq from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 20 19:19:29.070: INFO: olm-operator-58994486f9-zjnjt from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container olm-operator ready: true, restart count 0
Nov 20 19:19:29.070: INFO: catalog-operator-7885df777c-cvtfq from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container catalog-operator ready: true, restart count 0
Nov 20 19:19:29.070: INFO: coredns-6db888bf8c-nkkm5 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:19:29.070: INFO: ibm-master-proxy-static-10.184.110.184 from kube-system started at 2019-11-20 16:17:44 +0000 UTC (2 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:19:29.070: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:19:29.070: INFO: dashboard-metrics-scraper-dff9cbb9c-fpcsc from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 20 19:19:29.070: INFO: ibm-keepalived-watcher-74vx6 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:19:29.070: INFO: coredns-autoscaler-65c89858bf-x8hrv from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container autoscaler ready: true, restart count 0
Nov 20 19:19:29.070: INFO: ibm-storage-watcher-79dd7d8d79-88t7h from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 20 19:19:29.070: INFO: sonobuoy from sonobuoy started at 2019-11-20 17:13:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 20 19:19:29.070: INFO: vpn-79845b6f9d-k9q7v from kube-system started at 2019-11-20 16:27:49 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container vpn ready: true, restart count 0
Nov 20 19:19:29.070: INFO: calico-node-7txr8 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:19:29.070: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-18563bdf-c596-43f5-8768-0e7feda13d9e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-18563bdf-c596-43f5-8768-0e7feda13d9e off the node 10.184.110.176
STEP: verifying the node doesn't have the label kubernetes.io/e2e-18563bdf-c596-43f5-8768-0e7feda13d9e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:19:35.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2792" for this suite.
Nov 20 19:19:47.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:19:47.870: INFO: namespace sched-pred-2792 deletion completed in 12.497842046s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:19.435 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:19:47.871: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov 20 19:19:48.120: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:19:52.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7150" for this suite.
Nov 20 19:20:00.407: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:20:00.893: INFO: namespace init-container-7150 deletion completed in 8.548160642s

• [SLOW TEST:13.023 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:20:00.894: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Nov 20 19:20:01.149: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 --namespace=kubectl-6595 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov 20 19:20:03.647: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov 20 19:20:03.647: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:20:05.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6595" for this suite.
Nov 20 19:20:18.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:20:18.717: INFO: namespace kubectl-6595 deletion completed in 12.80547119s

• [SLOW TEST:17.823 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:20:18.717: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5595
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov 20 19:20:19.765: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov 20 19:20:22.881: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:20:23.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5595" for this suite.
Nov 20 19:20:31.345: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:20:31.721: INFO: namespace webhook-5595 deletion completed in 8.455387969s
STEP: Destroying namespace "webhook-5595-markers" for this suite.
Nov 20 19:20:37.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:20:38.329: INFO: namespace webhook-5595-markers deletion completed in 6.608734278s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.714 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:20:38.432: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-4f2a198a-cf25-4925-8a86-8f6c0d7b3475
STEP: Creating a pod to test consume secrets
Nov 20 19:20:38.707: INFO: Waiting up to 5m0s for pod "pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5" in namespace "secrets-180" to be "success or failure"
Nov 20 19:20:38.719: INFO: Pod "pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5": Phase="Pending", Reason="", readiness=false. Elapsed: 12.110259ms
Nov 20 19:20:40.739: INFO: Pod "pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031892917s
STEP: Saw pod success
Nov 20 19:20:40.739: INFO: Pod "pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5" satisfied condition "success or failure"
Nov 20 19:20:40.752: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5 container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 19:20:40.861: INFO: Waiting for pod pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5 to disappear
Nov 20 19:20:40.875: INFO: Pod pod-secrets-006eb07c-5d6c-4570-9e39-cd3ebb9bb3e5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:20:40.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-180" for this suite.
Nov 20 19:20:46.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:20:47.398: INFO: namespace secrets-180 deletion completed in 6.493318088s

• [SLOW TEST:8.967 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:20:47.398: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7659
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov 20 19:20:47.614: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 20 19:20:47.675: INFO: Waiting for terminating namespaces to be deleted...
Nov 20 19:20:47.688: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.140 before test
Nov 20 19:20:47.945: INFO: addon-catalog-source-67xr7 from ibm-system started at 2019-11-20 16:18:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container configmap-registry-server ready: true, restart count 1
Nov 20 19:20:47.945: INFO: ibm-keepalived-watcher-d59s8 from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:20:47.945: INFO: coredns-6db888bf8c-7xqjq from kube-system started at 2019-11-20 17:28:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:20:47.945: INFO: ibm-master-proxy-static-10.184.110.140 from kube-system started at 2019-11-20 16:18:02 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:20:47.945: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:20:47.945: INFO: calico-node-4dc2d from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:20:47.945: INFO: coredns-6db888bf8c-jr582 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:20:47.945: INFO: sonobuoy-e2e-job-b1a8acd3cb8d418c from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container e2e ready: true, restart count 0
Nov 20 19:20:47.945: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 19:20:47.945: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:47.945: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:20:47.945: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:20:47.945: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.176 before test
Nov 20 19:20:48.048: INFO: ibm-master-proxy-static-10.184.110.176 from kube-system started at 2019-11-20 16:19:06 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:48.048: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:20:48.048: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:20:48.048: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:48.048: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:20:48.048: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:20:48.048: INFO: calico-node-lkmcb from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.048: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:20:48.048: INFO: ibm-keepalived-watcher-qwxkl from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.048: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:20:48.048: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.184 before test
Nov 20 19:20:48.089: INFO: ibm-keepalived-watcher-74vx6 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:20:48.089: INFO: dashboard-metrics-scraper-dff9cbb9c-fpcsc from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 20 19:20:48.089: INFO: calico-node-7txr8 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:20:48.089: INFO: coredns-autoscaler-65c89858bf-x8hrv from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container autoscaler ready: true, restart count 0
Nov 20 19:20:48.089: INFO: ibm-storage-watcher-79dd7d8d79-88t7h from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 20 19:20:48.089: INFO: sonobuoy from sonobuoy started at 2019-11-20 17:13:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 20 19:20:48.089: INFO: vpn-79845b6f9d-k9q7v from kube-system started at 2019-11-20 16:27:49 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container vpn ready: true, restart count 0
Nov 20 19:20:48.089: INFO: metrics-server-6bb8bc7476-7x5bd from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container metrics-server ready: true, restart count 0
Nov 20 19:20:48.089: INFO: ibm-file-plugin-56c5959484-qv87m from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 20 19:20:48.089: INFO: calico-kube-controllers-6f7dc6dfd4-7bt8x from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 20 19:20:48.089: INFO: ibm-master-proxy-static-10.184.110.184 from kube-system started at 2019-11-20 16:17:44 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:20:48.089: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:20:48.089: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:20:48.089: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:20:48.089: INFO: kubernetes-dashboard-6bb9bf847f-kvddq from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov 20 19:20:48.089: INFO: olm-operator-58994486f9-zjnjt from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container olm-operator ready: true, restart count 0
Nov 20 19:20:48.089: INFO: catalog-operator-7885df777c-cvtfq from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container catalog-operator ready: true, restart count 0
Nov 20 19:20:48.089: INFO: coredns-6db888bf8c-nkkm5 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:20:48.089: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e9d11e7f-da33-4f17-9c57-579addd382c5 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-e9d11e7f-da33-4f17-9c57-579addd382c5 off the node 10.184.110.176
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e9d11e7f-da33-4f17-9c57-579addd382c5
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:25:56.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7659" for this suite.
Nov 20 19:26:06.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:26:07.023: INFO: namespace sched-pred-7659 deletion completed in 10.59193003s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:319.625 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:26:07.024: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-5882
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5882 to expose endpoints map[]
Nov 20 19:26:07.380: INFO: Get endpoints failed (25.197524ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Nov 20 19:26:08.394: INFO: successfully validated that service multi-endpoint-test in namespace services-5882 exposes endpoints map[] (1.038779244s elapsed)
STEP: Creating pod pod1 in namespace services-5882
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5882 to expose endpoints map[pod1:[100]]
Nov 20 19:26:10.853: INFO: successfully validated that service multi-endpoint-test in namespace services-5882 exposes endpoints map[pod1:[100]] (2.353667925s elapsed)
STEP: Creating pod pod2 in namespace services-5882
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5882 to expose endpoints map[pod1:[100] pod2:[101]]
Nov 20 19:26:13.194: INFO: successfully validated that service multi-endpoint-test in namespace services-5882 exposes endpoints map[pod1:[100] pod2:[101]] (2.295276007s elapsed)
STEP: Deleting pod pod1 in namespace services-5882
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5882 to expose endpoints map[pod2:[101]]
Nov 20 19:26:13.298: INFO: successfully validated that service multi-endpoint-test in namespace services-5882 exposes endpoints map[pod2:[101]] (45.406139ms elapsed)
STEP: Deleting pod pod2 in namespace services-5882
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5882 to expose endpoints map[]
Nov 20 19:26:13.348: INFO: successfully validated that service multi-endpoint-test in namespace services-5882 exposes endpoints map[] (9.668425ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:26:13.440: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5882" for this suite.
Nov 20 19:26:43.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:26:43.924: INFO: namespace services-5882 deletion completed in 30.472231233s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:36.900 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:26:43.924: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-3375
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 19:26:44.136: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov 20 19:26:44.164: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov 20 19:26:49.178: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov 20 19:26:49.178: INFO: Creating deployment "test-rolling-update-deployment"
Nov 20 19:26:49.209: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov 20 19:26:49.241: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Nov 20 19:26:51.262: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov 20 19:26:51.269: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov 20 19:26:51.304: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-3375 /apis/apps/v1/namespaces/deployment-3375/deployments/test-rolling-update-deployment 873d42d2-fda6-415c-b452-73e5328af462 43007 1 2019-11-20 19:26:49 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e32f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-20 19:26:49 +0000 UTC,LastTransitionTime:2019-11-20 19:26:49 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-11-20 19:26:51 +0000 UTC,LastTransitionTime:2019-11-20 19:26:49 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov 20 19:26:51.321: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-3375 /apis/apps/v1/namespaces/deployment-3375/replicasets/test-rolling-update-deployment-55d946486 2770c54c-5202-4f13-bd9a-0d6b0d796e85 42996 1 2019-11-20 19:26:49 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 873d42d2-fda6-415c-b452-73e5328af462 0xc002e33470 0xc002e33471}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e334d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov 20 19:26:51.321: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov 20 19:26:51.321: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-3375 /apis/apps/v1/namespaces/deployment-3375/replicasets/test-rolling-update-controller 3b392a87-2b31-4e96-a06a-f368372bd90d 43006 2 2019-11-20 19:26:44 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 873d42d2-fda6-415c-b452-73e5328af462 0xc002e333a7 0xc002e333a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002e33408 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov 20 19:26:51.337: INFO: Pod "test-rolling-update-deployment-55d946486-hqxmk" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-hqxmk test-rolling-update-deployment-55d946486- deployment-3375 /api/v1/namespaces/deployment-3375/pods/test-rolling-update-deployment-55d946486-hqxmk 9ed4414e-f355-4724-afb9-252b12a12a1b 42995 0 2019-11-20 19:26:49 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 2770c54c-5202-4f13-bd9a-0d6b0d796e85 0xc002e33950 0xc002e33951}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-t6c86,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-t6c86,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-t6c86,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.184.110.176,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 19:26:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 19:26:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 19:26:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-20 19:26:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.184.110.176,PodIP:172.30.70.103,StartTime:2019-11-20 19:26:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-20 19:26:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://ae6ed1dd2b346cce2ed5b9c1b77e7dad2207dd70c465ed901d784f8a9b5e75d7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.70.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:26:51.337: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3375" for this suite.
Nov 20 19:26:59.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:26:59.890: INFO: namespace deployment-3375 deletion completed in 8.539628746s

• [SLOW TEST:15.966 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:26:59.890: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-0e8dc011-0ea1-4763-8894-080478932a77
STEP: Creating a pod to test consume configMaps
Nov 20 19:27:00.156: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab" in namespace "projected-8404" to be "success or failure"
Nov 20 19:27:00.171: INFO: Pod "pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab": Phase="Pending", Reason="", readiness=false. Elapsed: 15.35972ms
Nov 20 19:27:02.188: INFO: Pod "pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032350222s
STEP: Saw pod success
Nov 20 19:27:02.188: INFO: Pod "pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab" satisfied condition "success or failure"
Nov 20 19:27:02.206: INFO: Trying to get logs from node 10.184.110.176 pod pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov 20 19:27:02.389: INFO: Waiting for pod pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab to disappear
Nov 20 19:27:02.406: INFO: Pod pod-projected-configmaps-6ad85b6e-da5b-456d-a9f9-35f2611898ab no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:27:02.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8404" for this suite.
Nov 20 19:27:08.520: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:27:08.963: INFO: namespace projected-8404 deletion completed in 6.544494322s

• [SLOW TEST:9.073 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:27:08.963: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov 20 19:27:09.286: INFO: (0) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 77.940861ms)
Nov 20 19:27:09.304: INFO: (1) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.17655ms)
Nov 20 19:27:09.323: INFO: (2) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.311863ms)
Nov 20 19:27:09.345: INFO: (3) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 21.389799ms)
Nov 20 19:27:09.363: INFO: (4) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.675616ms)
Nov 20 19:27:09.412: INFO: (5) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 49.44308ms)
Nov 20 19:27:09.437: INFO: (6) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 24.426215ms)
Nov 20 19:27:09.456: INFO: (7) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.991588ms)
Nov 20 19:27:09.474: INFO: (8) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 17.979905ms)
Nov 20 19:27:09.494: INFO: (9) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.363546ms)
Nov 20 19:27:09.513: INFO: (10) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.594396ms)
Nov 20 19:27:09.532: INFO: (11) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.158608ms)
Nov 20 19:27:09.554: INFO: (12) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 22.270595ms)
Nov 20 19:27:09.579: INFO: (13) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 23.851473ms)
Nov 20 19:27:09.597: INFO: (14) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 18.284004ms)
Nov 20 19:27:09.618: INFO: (15) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.968091ms)
Nov 20 19:27:09.638: INFO: (16) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.555092ms)
Nov 20 19:27:09.658: INFO: (17) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.735146ms)
Nov 20 19:27:09.679: INFO: (18) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.310618ms)
Nov 20 19:27:09.699: INFO: (19) /api/v1/nodes/10.184.110.140:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.73449ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:27:09.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1809" for this suite.
Nov 20 19:27:15.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:27:16.468: INFO: namespace proxy-1809 deletion completed in 6.758482197s

• [SLOW TEST:7.505 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:27:16.469: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5013
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov 20 19:27:16.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5013'
Nov 20 19:27:17.106: INFO: stderr: ""
Nov 20 19:27:17.106: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov 20 19:27:22.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 get pod e2e-test-httpd-pod --namespace=kubectl-5013 -o json'
Nov 20 19:27:22.289: INFO: stderr: ""
Nov 20 19:27:22.289: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-11-20T19:27:17Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5013\",\n        \"resourceVersion\": \"43148\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5013/pods/e2e-test-httpd-pod\",\n        \"uid\": \"0617d71f-47a0-417d-a4f1-eea8c98c0672\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-8hpxt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.184.110.176\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-8hpxt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-8hpxt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-20T19:27:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-20T19:27:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-20T19:27:19Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-20T19:27:17Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://817045dd859f18dd9326693a981e4de70b48e94b864b3a4dce6f2653c4aa2e27\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-20T19:27:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.184.110.176\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.70.107\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.70.107\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-20T19:27:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov 20 19:27:22.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 replace -f - --namespace=kubectl-5013'
Nov 20 19:27:22.543: INFO: stderr: ""
Nov 20 19:27:22.544: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Nov 20 19:27:22.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-455954265 delete pods e2e-test-httpd-pod --namespace=kubectl-5013'
Nov 20 19:27:24.157: INFO: stderr: ""
Nov 20 19:27:24.157: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:27:24.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5013" for this suite.
Nov 20 19:27:32.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:27:32.700: INFO: namespace kubectl-5013 deletion completed in 8.525563886s

• [SLOW TEST:16.232 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:27:32.701: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov 20 19:27:32.928: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov 20 19:27:32.956: INFO: Waiting for terminating namespaces to be deleted...
Nov 20 19:27:32.969: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.140 before test
Nov 20 19:27:33.017: INFO: addon-catalog-source-67xr7 from ibm-system started at 2019-11-20 16:18:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container configmap-registry-server ready: true, restart count 1
Nov 20 19:27:33.017: INFO: coredns-6db888bf8c-7xqjq from kube-system started at 2019-11-20 17:28:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:27:33.017: INFO: ibm-keepalived-watcher-d59s8 from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:27:33.017: INFO: calico-node-4dc2d from kube-system started at 2019-11-20 16:18:04 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:27:33.017: INFO: coredns-6db888bf8c-jr582 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:27:33.017: INFO: sonobuoy-e2e-job-b1a8acd3cb8d418c from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container e2e ready: true, restart count 0
Nov 20 19:27:33.017: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov 20 19:27:33.017: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-tvhx7 from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:27:33.017: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:27:33.017: INFO: ibm-master-proxy-static-10.184.110.140 from kube-system started at 2019-11-20 16:18:02 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.017: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:27:33.017: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:27:33.017: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.176 before test
Nov 20 19:27:33.044: INFO: ibm-keepalived-watcher-qwxkl from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.044: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:27:33.044: INFO: ibm-master-proxy-static-10.184.110.176 from kube-system started at 2019-11-20 16:19:06 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.045: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:27:33.045: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:27:33.045: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-5drcc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.045: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:27:33.045: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:27:33.045: INFO: calico-node-lkmcb from kube-system started at 2019-11-20 16:19:07 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.045: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:27:33.045: INFO: 
Logging pods the kubelet thinks is on node 10.184.110.184 before test
Nov 20 19:27:33.189: INFO: ibm-keepalived-watcher-74vx6 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.189: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov 20 19:27:33.189: INFO: dashboard-metrics-scraper-dff9cbb9c-fpcsc from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.189: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov 20 19:27:33.189: INFO: sonobuoy from sonobuoy started at 2019-11-20 17:13:18 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.189: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov 20 19:27:33.189: INFO: vpn-79845b6f9d-k9q7v from kube-system started at 2019-11-20 16:27:49 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.189: INFO: 	Container vpn ready: true, restart count 0
Nov 20 19:27:33.189: INFO: calico-node-7txr8 from kube-system started at 2019-11-20 16:17:45 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container calico-node ready: true, restart count 0
Nov 20 19:27:33.190: INFO: coredns-autoscaler-65c89858bf-x8hrv from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container autoscaler ready: true, restart count 0
Nov 20 19:27:33.190: INFO: ibm-storage-watcher-79dd7d8d79-88t7h from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov 20 19:27:33.190: INFO: calico-kube-controllers-6f7dc6dfd4-7bt8x from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov 20 19:27:33.190: INFO: metrics-server-6bb8bc7476-7x5bd from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container metrics-server ready: true, restart count 0
Nov 20 19:27:33.190: INFO: ibm-file-plugin-56c5959484-qv87m from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov 20 19:27:33.190: INFO: olm-operator-58994486f9-zjnjt from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container olm-operator ready: true, restart count 0
Nov 20 19:27:33.190: INFO: catalog-operator-7885df777c-cvtfq from ibm-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container catalog-operator ready: true, restart count 0
Nov 20 19:27:33.190: INFO: coredns-6db888bf8c-nkkm5 from kube-system started at 2019-11-20 16:28:06 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container coredns ready: true, restart count 0
Nov 20 19:27:33.190: INFO: ibm-master-proxy-static-10.184.110.184 from kube-system started at 2019-11-20 16:17:44 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov 20 19:27:33.190: INFO: 	Container pause ready: true, restart count 0
Nov 20 19:27:33.190: INFO: sonobuoy-systemd-logs-daemon-set-8c32bc4e699c4d13-k8ncc from sonobuoy started at 2019-11-20 17:13:24 +0000 UTC (2 container statuses recorded)
Nov 20 19:27:33.190: INFO: 	Container sonobuoy-worker ready: true, restart count 2
Nov 20 19:27:33.190: INFO: 	Container systemd-logs ready: true, restart count 0
Nov 20 19:27:33.191: INFO: kubernetes-dashboard-6bb9bf847f-kvddq from kube-system started at 2019-11-20 16:17:55 +0000 UTC (1 container statuses recorded)
Nov 20 19:27:33.191: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2fbe91ad-8405-4631-a6cb-e25a5ea54fc4 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-2fbe91ad-8405-4631-a6cb-e25a5ea54fc4 off the node 10.184.110.176
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2fbe91ad-8405-4631-a6cb-e25a5ea54fc4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:27:43.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7114" for this suite.
Nov 20 19:27:57.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:27:58.001: INFO: namespace sched-pred-7114 deletion completed in 14.464673432s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:25.301 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:27:58.002: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1615
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-3601
STEP: Creating secret with name secret-test-d7c79825-30ab-4141-860b-4bc23804b5ef
STEP: Creating a pod to test consume secrets
Nov 20 19:27:58.552: INFO: Waiting up to 5m0s for pod "pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20" in namespace "secrets-1615" to be "success or failure"
Nov 20 19:27:58.566: INFO: Pod "pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20": Phase="Pending", Reason="", readiness=false. Elapsed: 14.004028ms
Nov 20 19:28:00.587: INFO: Pod "pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03448315s
STEP: Saw pod success
Nov 20 19:28:00.587: INFO: Pod "pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20" satisfied condition "success or failure"
Nov 20 19:28:00.606: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20 container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 19:28:00.717: INFO: Waiting for pod pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20 to disappear
Nov 20 19:28:00.734: INFO: Pod pod-secrets-4e09a25c-4256-41e2-a2ca-1928a50faf20 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:28:00.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1615" for this suite.
Nov 20 19:28:08.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:28:09.513: INFO: namespace secrets-1615 deletion completed in 8.764840935s
STEP: Destroying namespace "secret-namespace-3601" for this suite.
Nov 20 19:28:15.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:28:16.522: INFO: namespace secret-namespace-3601 deletion completed in 7.008581075s

• [SLOW TEST:18.520 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov 20 19:28:16.523: INFO: >>> kubeConfig: /tmp/kubeconfig-455954265
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5228
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-9c6c031b-835b-4700-ac37-f3948a8a4a22
STEP: Creating a pod to test consume secrets
Nov 20 19:28:17.132: INFO: Waiting up to 5m0s for pod "pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9" in namespace "secrets-5228" to be "success or failure"
Nov 20 19:28:17.175: INFO: Pod "pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9": Phase="Pending", Reason="", readiness=false. Elapsed: 42.153559ms
Nov 20 19:28:19.223: INFO: Pod "pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090591817s
Nov 20 19:28:21.268: INFO: Pod "pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.135835059s
STEP: Saw pod success
Nov 20 19:28:21.268: INFO: Pod "pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9" satisfied condition "success or failure"
Nov 20 19:28:21.286: INFO: Trying to get logs from node 10.184.110.176 pod pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9 container secret-volume-test: <nil>
STEP: delete the pod
Nov 20 19:28:21.431: INFO: Waiting for pod pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9 to disappear
Nov 20 19:28:21.455: INFO: Pod pod-secrets-4f69f998-ce25-4921-9d27-97d7e9b857c9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov 20 19:28:21.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5228" for this suite.
Nov 20 19:28:27.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov 20 19:28:28.094: INFO: namespace secrets-5228 deletion completed in 6.624281804s

• [SLOW TEST:11.572 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSNov 20 19:28:28.095: INFO: Running AfterSuite actions on all nodes
Nov 20 19:28:28.095: INFO: Running AfterSuite actions on node 1
Nov 20 19:28:28.095: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 8078.083 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 2h14m39.841775908s
Test Suite Passed
