I1104 17:36:43.462727      25 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-229262933
I1104 17:36:43.462913      25 e2e.go:92] Starting e2e run "46823a00-03e7-4748-92ac-87ea7b15eaa7" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1572889001 - Will randomize all specs
Will run 276 of 4897 specs

Nov  4 17:36:43.478: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:36:43.481: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Nov  4 17:36:43.557: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Nov  4 17:36:43.644: INFO: 25 / 25 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Nov  4 17:36:43.645: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Nov  4 17:36:43.645: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Nov  4 17:36:43.672: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Nov  4 17:36:43.672: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Nov  4 17:36:43.672: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-kube-fluentd' (0 seconds elapsed)
Nov  4 17:36:43.672: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Nov  4 17:36:43.672: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Nov  4 17:36:43.673: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Nov  4 17:36:43.673: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Nov  4 17:36:43.673: INFO: e2e test version: v1.16.2
Nov  4 17:36:43.677: INFO: kube-apiserver version: v1.16.2+IKS
Nov  4 17:36:43.677: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:36:43.691: INFO: Cluster IP family: ipv4
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:36:43.691: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
Nov  4 17:36:43.821: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Nov  4 17:36:43.874: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9922
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-480434c6-69cc-4fd6-a769-1d69296d2df7
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-480434c6-69cc-4fd6-a769-1d69296d2df7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:37:55.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9922" for this suite.
Nov  4 17:38:07.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:38:08.179: INFO: namespace configmap-9922 deletion completed in 12.592998207s

• [SLOW TEST:84.489 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:38:08.185: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:38:15.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4543" for this suite.
Nov  4 17:38:23.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:38:24.050: INFO: namespace resourcequota-4543 deletion completed in 8.55642305s

• [SLOW TEST:15.865 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:38:24.050: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5001
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5001
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 17:38:24.303: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 17:38:48.584: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.75.202:8080/dial?request=hostName&protocol=udp&host=172.30.102.54&port=8081&tries=1'] Namespace:pod-network-test-5001 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:38:48.584: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:38:48.818: INFO: Waiting for endpoints: map[]
Nov  4 17:38:48.830: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.75.202:8080/dial?request=hostName&protocol=udp&host=172.30.168.98&port=8081&tries=1'] Namespace:pod-network-test-5001 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:38:48.830: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:38:49.045: INFO: Waiting for endpoints: map[]
Nov  4 17:38:49.057: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.75.202:8080/dial?request=hostName&protocol=udp&host=172.30.75.200&port=8081&tries=1'] Namespace:pod-network-test-5001 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 17:38:49.057: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:38:49.268: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:38:49.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5001" for this suite.
Nov  4 17:39:03.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:39:03.861: INFO: namespace pod-network-test-5001 deletion completed in 14.573538946s

• [SLOW TEST:39.811 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:39:03.861: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4885
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Nov  4 17:39:04.107: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 17:39:07.991: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:39:23.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4885" for this suite.
Nov  4 17:39:29.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:39:30.391: INFO: namespace crd-publish-openapi-4885 deletion completed in 6.91405465s

• [SLOW TEST:26.530 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:39:30.391: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1762
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:39:32.118: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov  4 17:39:34.177: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485972, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485972, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485972, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708485972, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:39:37.240: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Nov  4 17:39:37.309: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:39:37.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1762" for this suite.
Nov  4 17:39:45.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:39:46.077: INFO: namespace webhook-1762 deletion completed in 8.684958405s
STEP: Destroying namespace "webhook-1762-markers" for this suite.
Nov  4 17:39:52.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:39:52.865: INFO: namespace webhook-1762-markers deletion completed in 6.787630747s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.561 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:39:52.953: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4641
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 17:39:57.991: INFO: Successfully updated pod "labelsupdate98d1af88-08b1-40c6-9f93-32b0e45cdc92"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:40:00.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4641" for this suite.
Nov  4 17:40:30.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:40:32.302: INFO: namespace downward-api-4641 deletion completed in 32.054956244s

• [SLOW TEST:39.350 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:40:32.303: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6244
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  4 17:40:38.724: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:40:38.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1104 17:40:38.724064      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6244" for this suite.
Nov  4 17:40:46.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:40:47.376: INFO: namespace gc-6244 deletion completed in 8.632260507s

• [SLOW TEST:15.073 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:40:47.376: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 17:40:47.630: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:40:53.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-996" for this suite.
Nov  4 17:41:05.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:41:06.431: INFO: namespace init-container-996 deletion completed in 13.311132653s

• [SLOW TEST:19.055 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:41:06.433: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9514
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:41:06.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-9514'
Nov  4 17:41:07.007: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 17:41:07.007: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Nov  4 17:41:11.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9514'
Nov  4 17:41:11.243: INFO: stderr: ""
Nov  4 17:41:11.243: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:41:11.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9514" for this suite.
Nov  4 17:41:17.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:41:18.156: INFO: namespace kubectl-9514 deletion completed in 6.88879893s

• [SLOW TEST:11.722 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:41:18.157: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6142
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 17:41:18.450: INFO: Waiting up to 5m0s for pod "pod-12a5084f-a60e-4ffa-a975-f090ab56c41e" in namespace "emptydir-6142" to be "success or failure"
Nov  4 17:41:18.462: INFO: Pod "pod-12a5084f-a60e-4ffa-a975-f090ab56c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.976223ms
Nov  4 17:41:20.540: INFO: Pod "pod-12a5084f-a60e-4ffa-a975-f090ab56c41e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.090307609s
Nov  4 17:41:22.573: INFO: Pod "pod-12a5084f-a60e-4ffa-a975-f090ab56c41e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123051811s
STEP: Saw pod success
Nov  4 17:41:22.573: INFO: Pod "pod-12a5084f-a60e-4ffa-a975-f090ab56c41e" satisfied condition "success or failure"
Nov  4 17:41:22.585: INFO: Trying to get logs from node 10.93.34.21 pod pod-12a5084f-a60e-4ffa-a975-f090ab56c41e container test-container: <nil>
STEP: delete the pod
Nov  4 17:41:22.689: INFO: Waiting for pod pod-12a5084f-a60e-4ffa-a975-f090ab56c41e to disappear
Nov  4 17:41:22.702: INFO: Pod pod-12a5084f-a60e-4ffa-a975-f090ab56c41e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:41:22.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6142" for this suite.
Nov  4 17:41:28.846: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:41:29.414: INFO: namespace emptydir-6142 deletion completed in 6.668686683s

• [SLOW TEST:11.257 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:41:29.415: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9791
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:41:29.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9791'
Nov  4 17:41:29.911: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 17:41:29.911: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Nov  4 17:41:29.929: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete jobs e2e-test-httpd-job --namespace=kubectl-9791'
Nov  4 17:41:30.092: INFO: stderr: ""
Nov  4 17:41:30.092: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:41:30.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9791" for this suite.
Nov  4 17:41:38.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:41:38.778: INFO: namespace kubectl-9791 deletion completed in 8.666640029s

• [SLOW TEST:9.364 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:41:38.778: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:41:39.034: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Nov  4 17:41:39.082: INFO: Pod name sample-pod: Found 0 pods out of 1
Nov  4 17:41:44.097: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 17:41:44.097: INFO: Creating deployment "test-rolling-update-deployment"
Nov  4 17:41:44.121: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Nov  4 17:41:44.170: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Nov  4 17:41:46.207: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Nov  4 17:41:46.223: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:41:48.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486104, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:41:50.242: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:41:50.306: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4998 /apis/apps/v1/namespaces/deployment-4998/deployments/test-rolling-update-deployment 12fd9488-a8b1-40d7-8296-69dd74d4bb29 18711 1 2019-11-04 17:41:44 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0055088b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 17:41:44 +0000 UTC,LastTransitionTime:2019-11-04 17:41:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-11-04 17:41:49 +0000 UTC,LastTransitionTime:2019-11-04 17:41:44 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 17:41:50.323: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-4998 /apis/apps/v1/namespaces/deployment-4998/replicasets/test-rolling-update-deployment-55d946486 b0acbda2-40b0-4db1-bfe6-3ec5ce593758 18699 1 2019-11-04 17:41:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 12fd9488-a8b1-40d7-8296-69dd74d4bb29 0xc005508da0 0xc005508da1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005508e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:41:50.324: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Nov  4 17:41:50.324: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4998 /apis/apps/v1/namespaces/deployment-4998/replicasets/test-rolling-update-controller b86aad72-c037-4d10-b8ee-fd7d9767476c 18708 2 2019-11-04 17:41:39 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 12fd9488-a8b1-40d7-8296-69dd74d4bb29 0xc005508cd7 0xc005508cd8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005508d38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:41:50.338: INFO: Pod "test-rolling-update-deployment-55d946486-9xd94" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-9xd94 test-rolling-update-deployment-55d946486- deployment-4998 /api/v1/namespaces/deployment-4998/pods/test-rolling-update-deployment-55d946486-9xd94 43155145-fea3-48d7-91e8-13017637825c 18698 0 2019-11-04 17:41:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 b0acbda2-40b0-4db1-bfe6-3ec5ce593758 0xc005509270 0xc005509271}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j77qz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j77qz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j77qz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:41:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:41:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:41:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.206,StartTime:2019-11-04 17:41:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:41:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://3098f32519e710befb4c6c8dd065106387df848d9454b789b9b5b6cb29fe6e7e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.206,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:41:50.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4998" for this suite.
Nov  4 17:41:58.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:41:58.979: INFO: namespace deployment-4998 deletion completed in 8.616201351s

• [SLOW TEST:20.200 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:41:58.979: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9521
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:41:59.254: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39" in namespace "projected-9521" to be "success or failure"
Nov  4 17:41:59.265: INFO: Pod "downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39": Phase="Pending", Reason="", readiness=false. Elapsed: 11.142671ms
Nov  4 17:42:01.310: INFO: Pod "downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055977843s
Nov  4 17:42:03.323: INFO: Pod "downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068811803s
STEP: Saw pod success
Nov  4 17:42:03.323: INFO: Pod "downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39" satisfied condition "success or failure"
Nov  4 17:42:03.337: INFO: Trying to get logs from node 10.93.34.26 pod downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39 container client-container: <nil>
STEP: delete the pod
Nov  4 17:42:03.481: INFO: Waiting for pod downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39 to disappear
Nov  4 17:42:03.494: INFO: Pod downwardapi-volume-1db73e50-d03a-4ec7-817f-d03e4e4b7b39 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:42:03.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9521" for this suite.
Nov  4 17:42:11.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:42:12.373: INFO: namespace projected-9521 deletion completed in 8.854637211s

• [SLOW TEST:13.394 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:42:12.373: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2452
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 17:42:22.018: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:42:22.033: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:42:24.033: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:42:24.045: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:42:26.033: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:42:26.048: INFO: Pod pod-with-prestop-exec-hook still exists
Nov  4 17:42:28.033: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Nov  4 17:42:28.049: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:42:28.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2452" for this suite.
Nov  4 17:42:40.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:42:40.777: INFO: namespace container-lifecycle-hook-2452 deletion completed in 12.635647525s

• [SLOW TEST:28.404 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:42:40.779: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3955
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 17:42:41.242: INFO: Number of nodes with available pods: 0
Nov  4 17:42:41.242: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 17:42:42.286: INFO: Number of nodes with available pods: 0
Nov  4 17:42:42.286: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 17:42:43.279: INFO: Number of nodes with available pods: 1
Nov  4 17:42:43.279: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:44.296: INFO: Number of nodes with available pods: 2
Nov  4 17:42:44.296: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:45.277: INFO: Number of nodes with available pods: 2
Nov  4 17:42:45.277: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:46.277: INFO: Number of nodes with available pods: 2
Nov  4 17:42:46.277: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:47.279: INFO: Number of nodes with available pods: 2
Nov  4 17:42:47.279: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:48.282: INFO: Number of nodes with available pods: 2
Nov  4 17:42:48.282: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:49.279: INFO: Number of nodes with available pods: 3
Nov  4 17:42:49.279: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Nov  4 17:42:49.385: INFO: Number of nodes with available pods: 2
Nov  4 17:42:49.385: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:50.429: INFO: Number of nodes with available pods: 2
Nov  4 17:42:50.429: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:51.420: INFO: Number of nodes with available pods: 2
Nov  4 17:42:51.420: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 17:42:52.424: INFO: Number of nodes with available pods: 3
Nov  4 17:42:52.424: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3955, will wait for the garbage collector to delete the pods
Nov  4 17:42:52.565: INFO: Deleting DaemonSet.extensions daemon-set took: 40.073641ms
Nov  4 17:42:52.765: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.252378ms
Nov  4 17:43:03.389: INFO: Number of nodes with available pods: 0
Nov  4 17:43:03.389: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 17:43:03.407: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3955/daemonsets","resourceVersion":"19044"},"items":null}

Nov  4 17:43:03.429: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3955/pods","resourceVersion":"19044"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:03.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3955" for this suite.
Nov  4 17:43:11.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:12.482: INFO: namespace daemonsets-3955 deletion completed in 8.938758244s

• [SLOW TEST:31.703 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:12.482: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3621
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:43:12.767: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b" in namespace "projected-3621" to be "success or failure"
Nov  4 17:43:12.781: INFO: Pod "downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.426509ms
Nov  4 17:43:14.796: INFO: Pod "downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028833604s
STEP: Saw pod success
Nov  4 17:43:14.796: INFO: Pod "downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b" satisfied condition "success or failure"
Nov  4 17:43:14.809: INFO: Trying to get logs from node 10.93.34.26 pod downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b container client-container: <nil>
STEP: delete the pod
Nov  4 17:43:14.892: INFO: Waiting for pod downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b to disappear
Nov  4 17:43:14.905: INFO: Pod downwardapi-volume-bfc6c246-5aa7-4ccf-be98-3d9d0ef0b70b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:14.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3621" for this suite.
Nov  4 17:43:21.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:21.613: INFO: namespace projected-3621 deletion completed in 6.679948755s

• [SLOW TEST:9.131 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:21.613: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-208
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 17:43:21.920: INFO: Waiting up to 5m0s for pod "downward-api-02089977-1d45-466d-987a-14c0ec80a476" in namespace "downward-api-208" to be "success or failure"
Nov  4 17:43:21.937: INFO: Pod "downward-api-02089977-1d45-466d-987a-14c0ec80a476": Phase="Pending", Reason="", readiness=false. Elapsed: 17.278843ms
Nov  4 17:43:23.954: INFO: Pod "downward-api-02089977-1d45-466d-987a-14c0ec80a476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033845084s
Nov  4 17:43:25.967: INFO: Pod "downward-api-02089977-1d45-466d-987a-14c0ec80a476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046866792s
STEP: Saw pod success
Nov  4 17:43:25.967: INFO: Pod "downward-api-02089977-1d45-466d-987a-14c0ec80a476" satisfied condition "success or failure"
Nov  4 17:43:25.979: INFO: Trying to get logs from node 10.93.34.21 pod downward-api-02089977-1d45-466d-987a-14c0ec80a476 container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:43:26.074: INFO: Waiting for pod downward-api-02089977-1d45-466d-987a-14c0ec80a476 to disappear
Nov  4 17:43:26.085: INFO: Pod downward-api-02089977-1d45-466d-987a-14c0ec80a476 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:26.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-208" for this suite.
Nov  4 17:43:32.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:32.851: INFO: namespace downward-api-208 deletion completed in 6.744392604s

• [SLOW TEST:11.238 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:32.853: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:43:33.195: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76" in namespace "projected-5634" to be "success or failure"
Nov  4 17:43:33.207: INFO: Pod "downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76": Phase="Pending", Reason="", readiness=false. Elapsed: 11.848501ms
Nov  4 17:43:35.219: INFO: Pod "downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023414101s
Nov  4 17:43:37.231: INFO: Pod "downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036340177s
STEP: Saw pod success
Nov  4 17:43:37.232: INFO: Pod "downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76" satisfied condition "success or failure"
Nov  4 17:43:37.244: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76 container client-container: <nil>
STEP: delete the pod
Nov  4 17:43:37.301: INFO: Waiting for pod downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76 to disappear
Nov  4 17:43:37.318: INFO: Pod downwardapi-volume-4de91bcc-b345-443e-ae04-922fcad0be76 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:37.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5634" for this suite.
Nov  4 17:43:43.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:44.102: INFO: namespace projected-5634 deletion completed in 6.752115058s

• [SLOW TEST:11.249 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:44.102: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5989
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:43:44.417: INFO: (0) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 40.392359ms)
Nov  4 17:43:44.443: INFO: (1) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.578645ms)
Nov  4 17:43:44.465: INFO: (2) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.466561ms)
Nov  4 17:43:44.486: INFO: (3) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.422418ms)
Nov  4 17:43:44.507: INFO: (4) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.311319ms)
Nov  4 17:43:44.528: INFO: (5) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.77156ms)
Nov  4 17:43:44.548: INFO: (6) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.522621ms)
Nov  4 17:43:44.573: INFO: (7) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.952801ms)
Nov  4 17:43:44.594: INFO: (8) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.965585ms)
Nov  4 17:43:44.616: INFO: (9) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.549518ms)
Nov  4 17:43:44.635: INFO: (10) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 18.772598ms)
Nov  4 17:43:44.657: INFO: (11) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.897415ms)
Nov  4 17:43:44.677: INFO: (12) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.223948ms)
Nov  4 17:43:44.696: INFO: (13) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.012315ms)
Nov  4 17:43:44.717: INFO: (14) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.241925ms)
Nov  4 17:43:44.739: INFO: (15) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 22.068528ms)
Nov  4 17:43:44.761: INFO: (16) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.549004ms)
Nov  4 17:43:44.785: INFO: (17) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.226324ms)
Nov  4 17:43:44.805: INFO: (18) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 19.621773ms)
Nov  4 17:43:44.825: INFO: (19) /api/v1/nodes/10.93.34.21:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.073861ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:44.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5989" for this suite.
Nov  4 17:43:50.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:43:51.573: INFO: namespace proxy-5989 deletion completed in 6.729012041s

• [SLOW TEST:7.471 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:43:51.573: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2086
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Nov  4 17:43:51.877: INFO: Waiting up to 5m0s for pod "pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7" in namespace "emptydir-2086" to be "success or failure"
Nov  4 17:43:51.905: INFO: Pod "pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 27.769939ms
Nov  4 17:43:53.919: INFO: Pod "pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041566961s
Nov  4 17:43:55.931: INFO: Pod "pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054041635s
STEP: Saw pod success
Nov  4 17:43:55.931: INFO: Pod "pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7" satisfied condition "success or failure"
Nov  4 17:43:55.943: INFO: Trying to get logs from node 10.93.34.38 pod pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7 container test-container: <nil>
STEP: delete the pod
Nov  4 17:43:56.015: INFO: Waiting for pod pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7 to disappear
Nov  4 17:43:56.025: INFO: Pod pod-176a100c-fcb4-4c24-9956-0eeb10dbdbf7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:43:56.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2086" for this suite.
Nov  4 17:44:04.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:44:04.803: INFO: namespace emptydir-2086 deletion completed in 8.752428734s

• [SLOW TEST:13.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:44:04.803: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2796
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2796
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2796
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2796
Nov  4 17:44:05.135: INFO: Found 0 stateful pods, waiting for 1
Nov  4 17:44:15.163: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Nov  4 17:44:15.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:44:15.527: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:44:15.527: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:44:15.527: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:44:15.543: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  4 17:44:25.566: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:44:25.566: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:44:25.633: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:25.633: INFO: ss-0  10.93.34.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:16 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:25.633: INFO: 
Nov  4 17:44:25.633: INFO: StatefulSet ss has not reached scale 3, at 1
Nov  4 17:44:26.648: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.987865322s
Nov  4 17:44:27.664: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.973229364s
Nov  4 17:44:28.678: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.95671467s
Nov  4 17:44:29.691: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.943087217s
Nov  4 17:44:30.703: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.930606208s
Nov  4 17:44:31.716: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.918453727s
Nov  4 17:44:32.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.905263035s
Nov  4 17:44:33.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.891760231s
Nov  4 17:44:34.762: INFO: Verifying statefulset ss doesn't scale past 3 for another 872.426307ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2796
Nov  4 17:44:35.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:44:36.141: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 17:44:36.141: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:44:36.141: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:44:36.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:44:36.570: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 17:44:36.570: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:44:36.570: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:44:36.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 17:44:36.974: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Nov  4 17:44:36.974: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 17:44:36.974: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 17:44:36.986: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:44:36.986: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 17:44:36.986: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Nov  4 17:44:36.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:44:37.327: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:44:37.327: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:44:37.327: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:44:37.327: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:44:37.941: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:44:37.941: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:44:37.942: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:44:37.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-2796 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 17:44:38.364: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 17:44:38.364: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 17:44:38.364: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 17:44:38.364: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:44:38.382: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  4 17:44:48.413: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:44:48.413: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:44:48.413: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 17:44:48.471: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:48.471: INFO: ss-0  10.93.34.21  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:48.471: INFO: ss-1  10.93.34.38  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:48.471: INFO: ss-2  10.93.34.26  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:48.471: INFO: 
Nov  4 17:44:48.471: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:44:49.485: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:49.485: INFO: ss-0  10.93.34.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:49.485: INFO: ss-1  10.93.34.38  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:49.485: INFO: ss-2  10.93.34.26  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:49.485: INFO: 
Nov  4 17:44:49.485: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:44:50.500: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:50.500: INFO: ss-0  10.93.34.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:50.500: INFO: ss-1  10.93.34.38  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:50.500: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:50.500: INFO: 
Nov  4 17:44:50.500: INFO: StatefulSet ss has not reached scale 0, at 3
Nov  4 17:44:51.513: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:51.513: INFO: ss-0  10.93.34.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:51.513: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:51.513: INFO: 
Nov  4 17:44:51.513: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:44:52.536: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:52.536: INFO: ss-0  10.93.34.21  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:05 +0000 UTC  }]
Nov  4 17:44:52.536: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:52.536: INFO: 
Nov  4 17:44:52.536: INFO: StatefulSet ss has not reached scale 0, at 2
Nov  4 17:44:53.548: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:53.548: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:53.548: INFO: 
Nov  4 17:44:53.548: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  4 17:44:54.562: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:54.562: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:54.562: INFO: 
Nov  4 17:44:54.562: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  4 17:44:55.576: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:55.576: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:55.576: INFO: 
Nov  4 17:44:55.576: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  4 17:44:56.590: INFO: POD   NODE         PHASE    GRACE  CONDITIONS
Nov  4 17:44:56.590: INFO: ss-2  10.93.34.26  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-11-04 17:44:25 +0000 UTC  }]
Nov  4 17:44:56.590: INFO: 
Nov  4 17:44:56.590: INFO: StatefulSet ss has not reached scale 0, at 1
Nov  4 17:44:57.602: INFO: Verifying statefulset ss doesn't scale past 0 for another 856.298251ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2796
Nov  4 17:44:58.638: INFO: Scaling statefulset ss to 0
Nov  4 17:44:58.702: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 17:44:58.717: INFO: Deleting all statefulset in ns statefulset-2796
Nov  4 17:44:58.733: INFO: Scaling statefulset ss to 0
Nov  4 17:44:58.780: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 17:44:58.796: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:44:58.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2796" for this suite.
Nov  4 17:45:06.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:07.570: INFO: namespace statefulset-2796 deletion completed in 8.685795321s

• [SLOW TEST:62.767 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:07.571: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1559
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 17:45:07.828: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 17:45:07.899: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 17:45:07.916: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.21 before test
Nov  4 17:45:08.008: INFO: ibm-storage-watcher-77c86866cb-d9rwp from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov  4 17:45:08.008: INFO: coredns-autoscaler-65c89858bf-7kwgd from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container autoscaler ready: true, restart count 0
Nov  4 17:45:08.008: INFO: coredns-6db888bf8c-tx67z from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:45:08.008: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:45:08.008: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:45:08.008: INFO: calico-node-rqnj2 from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:45:08.008: INFO: ibm-file-plugin-7c6d445669-fzd47 from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov  4 17:45:08.008: INFO: metrics-server-d7b79fbb6-6ng9n from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container metrics-server ready: true, restart count 0
Nov  4 17:45:08.008: INFO: ibm-kube-fluentd-jskbg from kube-system started at 2019-11-04 16:09:19 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:45:08.008: INFO: ibm-master-proxy-static-10.93.34.21 from kube-system started at 2019-11-04 16:08:53 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:45:08.008: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:45:08.008: INFO: dashboard-metrics-scraper-dff9cbb9c-sc7q5 from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  4 17:45:08.008: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-k6cdg from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 17:45:08.008: INFO: ibm-keepalived-watcher-6p6hf from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 17:45:08.008: INFO: kubernetes-dashboard-5fc98b6f46-czxkn from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 17:45:08.008: INFO: calico-kube-controllers-77467ddb99-hm4pf from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  4 17:45:08.008: INFO: olm-operator-58994486f9-75rbg from ibm-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container olm-operator ready: true, restart count 0
Nov  4 17:45:08.008: INFO: catalog-operator-7885df777c-fbf7n from ibm-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container catalog-operator ready: true, restart count 0
Nov  4 17:45:08.008: INFO: vpn-79845b6f9d-lblq6 from kube-system started at 2019-11-04 16:32:40 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.008: INFO: 	Container vpn ready: true, restart count 0
Nov  4 17:45:08.008: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.26 before test
Nov  4 17:45:08.107: INFO: ibm-kube-fluentd-sjtjl from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:45:08.107: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 17:45:08.107: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:45:08.107: INFO: ibm-master-proxy-static-10.93.34.26 from kube-system started at 2019-11-04 16:12:06 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:45:08.107: INFO: ibm-keepalived-watcher-pnc97 from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 17:45:08.107: INFO: coredns-6db888bf8c-5vkjd from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:45:08.107: INFO: calico-node-dzhkq from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:45:08.107: INFO: sonobuoy-e2e-job-f11cbcc8e8e5452a from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.107: INFO: 	Container e2e ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:45:08.107: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.38 before test
Nov  4 17:45:08.177: INFO: ibm-kube-fluentd-zwc56 from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.177: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:45:08.177: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-04 16:17:52 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.177: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov  4 17:45:08.178: INFO: calico-node-k8p8l from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:45:08.178: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 17:45:08.178: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 17:45:08.178: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 17:45:08.178: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 17:45:08.178: INFO: sonobuoy from sonobuoy started at 2019-11-04 17:36:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 17:45:08.178: INFO: ibm-master-proxy-static-10.93.34.38 from kube-system started at 2019-11-04 16:16:27 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:45:08.178: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:45:08.178: INFO: ibm-keepalived-watcher-n9c7j from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 17:45:08.178: INFO: coredns-6db888bf8c-mgznm from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:45:08.178: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 17:45:08.178: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:45:08.178: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:45:08.178: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d406ac9c575d32], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15d406ac9d570f6f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:09.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1559" for this suite.
Nov  4 17:45:15.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:16.738: INFO: namespace sched-pred-1559 deletion completed in 7.368890235s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.167 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:16.738: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9772
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 17:45:17.006: INFO: namespace kubectl-9772
Nov  4 17:45:17.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-9772'
Nov  4 17:45:17.365: INFO: stderr: ""
Nov  4 17:45:17.365: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 17:45:18.378: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:45:18.378: INFO: Found 0 / 1
Nov  4 17:45:19.381: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:45:19.381: INFO: Found 0 / 1
Nov  4 17:45:20.377: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:45:20.377: INFO: Found 1 / 1
Nov  4 17:45:20.377: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 17:45:20.389: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 17:45:20.389: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 17:45:20.389: INFO: wait on redis-master startup in kubectl-9772 
Nov  4 17:45:20.389: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs redis-master-dssnl redis-master --namespace=kubectl-9772'
Nov  4 17:45:20.552: INFO: stderr: ""
Nov  4 17:45:20.552: INFO: stdout: "1:C 04 Nov 2019 17:45:18.740 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 04 Nov 2019 17:45:18.740 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 04 Nov 2019 17:45:18.740 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 04 Nov 2019 17:45:18.742 * Running mode=standalone, port=6379.\n1:M 04 Nov 2019 17:45:18.742 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 04 Nov 2019 17:45:18.742 # Server initialized\n1:M 04 Nov 2019 17:45:18.742 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 04 Nov 2019 17:45:18.742 * Ready to accept connections\n"
STEP: exposing RC
Nov  4 17:45:20.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9772'
Nov  4 17:45:20.725: INFO: stderr: ""
Nov  4 17:45:20.725: INFO: stdout: "service/rm2 exposed\n"
Nov  4 17:45:20.742: INFO: Service rm2 in namespace kubectl-9772 found.
STEP: exposing service
Nov  4 17:45:22.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9772'
Nov  4 17:45:22.958: INFO: stderr: ""
Nov  4 17:45:22.958: INFO: stdout: "service/rm3 exposed\n"
Nov  4 17:45:22.974: INFO: Service rm3 in namespace kubectl-9772 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:25.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9772" for this suite.
Nov  4 17:45:39.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:39.782: INFO: namespace kubectl-9772 deletion completed in 14.671060582s

• [SLOW TEST:23.044 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:39.782: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Nov  4 17:45:40.101: INFO: Waiting up to 5m0s for pod "var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f" in namespace "var-expansion-1156" to be "success or failure"
Nov  4 17:45:40.112: INFO: Pod "var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.79135ms
Nov  4 17:45:42.124: INFO: Pod "var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023279187s
STEP: Saw pod success
Nov  4 17:45:42.125: INFO: Pod "var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f" satisfied condition "success or failure"
Nov  4 17:45:42.136: INFO: Trying to get logs from node 10.93.34.21 pod var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:45:42.195: INFO: Waiting for pod var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f to disappear
Nov  4 17:45:42.205: INFO: Pod var-expansion-2f830db1-d668-4a35-bd60-88e889d3b00f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:42.205: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1156" for this suite.
Nov  4 17:45:48.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:48.855: INFO: namespace var-expansion-1156 deletion completed in 6.627925447s

• [SLOW TEST:9.073 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:48.856: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 17:45:49.133: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f" in namespace "projected-1736" to be "success or failure"
Nov  4 17:45:49.146: INFO: Pod "downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.986168ms
Nov  4 17:45:51.158: INFO: Pod "downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025250677s
STEP: Saw pod success
Nov  4 17:45:51.158: INFO: Pod "downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f" satisfied condition "success or failure"
Nov  4 17:45:51.169: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f container client-container: <nil>
STEP: delete the pod
Nov  4 17:45:51.227: INFO: Waiting for pod downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f to disappear
Nov  4 17:45:51.239: INFO: Pod downwardapi-volume-f8a4d8e8-2964-4b7d-8222-5a45c7510c7f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:45:51.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1736" for this suite.
Nov  4 17:45:57.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:45:58.098: INFO: namespace projected-1736 deletion completed in 6.825674437s

• [SLOW TEST:9.242 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:45:58.098: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7241
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 17:45:58.375: INFO: Waiting up to 5m0s for pod "pod-69f16116-0b53-4354-a682-a21f698c90be" in namespace "emptydir-7241" to be "success or failure"
Nov  4 17:45:58.386: INFO: Pod "pod-69f16116-0b53-4354-a682-a21f698c90be": Phase="Pending", Reason="", readiness=false. Elapsed: 11.171267ms
Nov  4 17:46:00.399: INFO: Pod "pod-69f16116-0b53-4354-a682-a21f698c90be": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024244736s
Nov  4 17:46:02.414: INFO: Pod "pod-69f16116-0b53-4354-a682-a21f698c90be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038707548s
STEP: Saw pod success
Nov  4 17:46:02.414: INFO: Pod "pod-69f16116-0b53-4354-a682-a21f698c90be" satisfied condition "success or failure"
Nov  4 17:46:02.437: INFO: Trying to get logs from node 10.93.34.38 pod pod-69f16116-0b53-4354-a682-a21f698c90be container test-container: <nil>
STEP: delete the pod
Nov  4 17:46:02.581: INFO: Waiting for pod pod-69f16116-0b53-4354-a682-a21f698c90be to disappear
Nov  4 17:46:02.597: INFO: Pod pod-69f16116-0b53-4354-a682-a21f698c90be no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:02.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7241" for this suite.
Nov  4 17:46:10.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:11.282: INFO: namespace emptydir-7241 deletion completed in 8.650825607s

• [SLOW TEST:13.185 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:11.283: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Nov  4 17:46:12.290: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1104 17:46:12.290644      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Nov  4 17:46:12.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9516" for this suite.
Nov  4 17:46:20.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:21.001: INFO: namespace gc-9516 deletion completed in 8.687906424s

• [SLOW TEST:9.718 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:21.002: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Nov  4 17:46:25.865: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5521 pod-service-account-6bdb321e-7a92-489b-a0bc-ad8229da32c8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Nov  4 17:46:26.246: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5521 pod-service-account-6bdb321e-7a92-489b-a0bc-ad8229da32c8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Nov  4 17:46:26.635: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-5521 pod-service-account-6bdb321e-7a92-489b-a0bc-ad8229da32c8 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:27.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5521" for this suite.
Nov  4 17:46:33.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:33.919: INFO: namespace svcaccounts-5521 deletion completed in 6.648343582s

• [SLOW TEST:12.918 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:33.921: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9264
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-e70de1b0-007d-4638-a622-c7b92c1ba97a
STEP: Creating a pod to test consume configMaps
Nov  4 17:46:34.241: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812" in namespace "projected-9264" to be "success or failure"
Nov  4 17:46:34.251: INFO: Pod "pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812": Phase="Pending", Reason="", readiness=false. Elapsed: 10.645973ms
Nov  4 17:46:36.266: INFO: Pod "pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025134326s
STEP: Saw pod success
Nov  4 17:46:36.266: INFO: Pod "pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812" satisfied condition "success or failure"
Nov  4 17:46:36.277: INFO: Trying to get logs from node 10.93.34.38 pod pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:46:36.334: INFO: Waiting for pod pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812 to disappear
Nov  4 17:46:36.344: INFO: Pod pod-projected-configmaps-4ad7f531-cba6-4f93-9412-fe3b606b7812 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:36.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9264" for this suite.
Nov  4 17:46:42.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:43.031: INFO: namespace projected-9264 deletion completed in 6.655762625s

• [SLOW TEST:9.111 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:43.031: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-3205/configmap-test-974db642-ffc1-498c-bb33-afb01f29fd71
STEP: Creating a pod to test consume configMaps
Nov  4 17:46:43.385: INFO: Waiting up to 5m0s for pod "pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba" in namespace "configmap-3205" to be "success or failure"
Nov  4 17:46:43.398: INFO: Pod "pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba": Phase="Pending", Reason="", readiness=false. Elapsed: 13.349259ms
Nov  4 17:46:45.410: INFO: Pod "pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02526505s
STEP: Saw pod success
Nov  4 17:46:45.410: INFO: Pod "pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba" satisfied condition "success or failure"
Nov  4 17:46:45.429: INFO: Trying to get logs from node 10.93.34.26 pod pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba container env-test: <nil>
STEP: delete the pod
Nov  4 17:46:45.557: INFO: Waiting for pod pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba to disappear
Nov  4 17:46:45.586: INFO: Pod pod-configmaps-6c35e9de-4ca8-4628-8657-54723345baba no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:45.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3205" for this suite.
Nov  4 17:46:51.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:46:52.228: INFO: namespace configmap-3205 deletion completed in 6.617708626s

• [SLOW TEST:9.197 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:46:52.231: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 17:46:52.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-2321'
Nov  4 17:46:52.875: INFO: stderr: ""
Nov  4 17:46:52.875: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 17:46:52.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2321'
Nov  4 17:46:53.033: INFO: stderr: ""
Nov  4 17:46:53.033: INFO: stdout: "update-demo-nautilus-4nvnd update-demo-nautilus-zpdrf "
Nov  4 17:46:53.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-4nvnd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2321'
Nov  4 17:46:53.188: INFO: stderr: ""
Nov  4 17:46:53.188: INFO: stdout: ""
Nov  4 17:46:53.188: INFO: update-demo-nautilus-4nvnd is created but not running
Nov  4 17:46:58.188: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2321'
Nov  4 17:46:58.325: INFO: stderr: ""
Nov  4 17:46:58.325: INFO: stdout: "update-demo-nautilus-4nvnd update-demo-nautilus-zpdrf "
Nov  4 17:46:58.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-4nvnd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2321'
Nov  4 17:46:58.464: INFO: stderr: ""
Nov  4 17:46:58.464: INFO: stdout: "true"
Nov  4 17:46:58.464: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-4nvnd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2321'
Nov  4 17:46:58.596: INFO: stderr: ""
Nov  4 17:46:58.596: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:46:58.596: INFO: validating pod update-demo-nautilus-4nvnd
Nov  4 17:46:58.625: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:46:58.625: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:46:58.625: INFO: update-demo-nautilus-4nvnd is verified up and running
Nov  4 17:46:58.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-zpdrf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2321'
Nov  4 17:46:58.759: INFO: stderr: ""
Nov  4 17:46:58.759: INFO: stdout: "true"
Nov  4 17:46:58.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-zpdrf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2321'
Nov  4 17:46:58.909: INFO: stderr: ""
Nov  4 17:46:58.909: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 17:46:58.909: INFO: validating pod update-demo-nautilus-zpdrf
Nov  4 17:46:58.927: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 17:46:58.927: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 17:46:58.927: INFO: update-demo-nautilus-zpdrf is verified up and running
STEP: using delete to clean up resources
Nov  4 17:46:58.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-2321'
Nov  4 17:46:59.091: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 17:46:59.091: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 17:46:59.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2321'
Nov  4 17:46:59.255: INFO: stderr: "No resources found in kubectl-2321 namespace.\n"
Nov  4 17:46:59.255: INFO: stdout: ""
Nov  4 17:46:59.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -l name=update-demo --namespace=kubectl-2321 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 17:46:59.382: INFO: stderr: ""
Nov  4 17:46:59.382: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:46:59.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2321" for this suite.
Nov  4 17:47:13.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:47:15.450: INFO: namespace kubectl-2321 deletion completed in 16.037294565s

• [SLOW TEST:23.219 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:47:15.450: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4172
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:47:15.830: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10" in namespace "security-context-test-4172" to be "success or failure"
Nov  4 17:47:15.848: INFO: Pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10": Phase="Pending", Reason="", readiness=false. Elapsed: 18.097234ms
Nov  4 17:47:17.860: INFO: Pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030296388s
Nov  4 17:47:19.872: INFO: Pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.042150377s
Nov  4 17:47:19.872: INFO: Pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10" satisfied condition "success or failure"
Nov  4 17:47:20.140: INFO: Got logs for pod "busybox-privileged-false-c908f659-2ef2-412d-90d3-e49f51310a10": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:47:20.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4172" for this suite.
Nov  4 17:47:28.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:47:28.781: INFO: namespace security-context-test-4172 deletion completed in 8.613733275s

• [SLOW TEST:13.331 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:47:28.782: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Nov  4 17:47:33.216: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:33.227: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:35.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:35.240: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:37.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:37.240: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:39.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:39.239: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:41.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:41.239: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:43.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:43.241: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:45.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:45.249: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:47.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:47.241: INFO: Pod pod-with-prestop-http-hook still exists
Nov  4 17:47:49.227: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Nov  4 17:47:49.241: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:47:49.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8839" for this suite.
Nov  4 17:48:19.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:48:20.147: INFO: namespace container-lifecycle-hook-8839 deletion completed in 30.806659442s

• [SLOW TEST:51.366 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:48:20.148: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-262
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-fc161d07-58bf-4708-8b61-d9785c94610a
STEP: Creating a pod to test consume configMaps
Nov  4 17:48:20.466: INFO: Waiting up to 5m0s for pod "pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45" in namespace "configmap-262" to be "success or failure"
Nov  4 17:48:20.480: INFO: Pod "pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45": Phase="Pending", Reason="", readiness=false. Elapsed: 13.789072ms
Nov  4 17:48:22.499: INFO: Pod "pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03244895s
STEP: Saw pod success
Nov  4 17:48:22.499: INFO: Pod "pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45" satisfied condition "success or failure"
Nov  4 17:48:22.511: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:48:22.591: INFO: Waiting for pod pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45 to disappear
Nov  4 17:48:22.605: INFO: Pod pod-configmaps-e723be7b-c4c4-477d-8c60-daa79c258e45 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:48:22.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-262" for this suite.
Nov  4 17:48:30.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:48:31.302: INFO: namespace configmap-262 deletion completed in 8.673948221s

• [SLOW TEST:11.154 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:48:31.303: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 17:48:34.269: INFO: Successfully updated pod "pod-update-f2e63172-d6d7-4864-bb75-db4489819d60"
STEP: verifying the updated pod is in kubernetes
Nov  4 17:48:34.296: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:48:34.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6140" for this suite.
Nov  4 17:49:04.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:49:05.018: INFO: namespace pods-6140 deletion completed in 30.697976427s

• [SLOW TEST:33.715 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:49:05.018: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:49:05.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6920'
Nov  4 17:49:05.452: INFO: stderr: ""
Nov  4 17:49:05.452: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Nov  4 17:49:05.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete pods e2e-test-httpd-pod --namespace=kubectl-6920'
Nov  4 17:49:07.905: INFO: stderr: ""
Nov  4 17:49:07.905: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:49:07.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6920" for this suite.
Nov  4 17:49:14.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:49:14.745: INFO: namespace kubectl-6920 deletion completed in 6.816368865s

• [SLOW TEST:9.727 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:49:14.745: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:49:31.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8484" for this suite.
Nov  4 17:49:39.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:49:40.099: INFO: namespace resourcequota-8484 deletion completed in 8.662203703s

• [SLOW TEST:25.354 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:49:40.100: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1648
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:49:40.383: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-a06a4264-9332-4174-99be-c44b23dedc88" in namespace "security-context-test-1648" to be "success or failure"
Nov  4 17:49:40.402: INFO: Pod "busybox-readonly-false-a06a4264-9332-4174-99be-c44b23dedc88": Phase="Pending", Reason="", readiness=false. Elapsed: 19.672456ms
Nov  4 17:49:42.416: INFO: Pod "busybox-readonly-false-a06a4264-9332-4174-99be-c44b23dedc88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033107247s
Nov  4 17:49:42.416: INFO: Pod "busybox-readonly-false-a06a4264-9332-4174-99be-c44b23dedc88" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:49:42.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1648" for this suite.
Nov  4 17:49:48.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:49:49.104: INFO: namespace security-context-test-1648 deletion completed in 6.661330079s

• [SLOW TEST:9.004 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:49:49.104: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1958
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Nov  4 17:49:51.461: INFO: &Pod{ObjectMeta:{send-events-4cdae8f8-5c2d-432b-8899-cafae3f8b77b  events-1958 /api/v1/namespaces/events-1958/pods/send-events-4cdae8f8-5c2d-432b-8899-cafae3f8b77b c02e7d60-3755-423e-ad04-23968f14df19 20744 0 2019-11-04 17:49:49 +0000 UTC <nil> <nil> map[name:foo time:375843016] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-9tdn6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-9tdn6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-9tdn6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:49:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:49:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:49:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:49:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.16,StartTime:2019-11-04 17:49:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:49:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://a32585ef64a1289e44027f55796b8565e2b8742e22b5f76b80f960b4a2479abe,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.16,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Nov  4 17:49:53.479: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Nov  4 17:49:55.500: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:49:55.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1958" for this suite.
Nov  4 17:50:41.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:50:42.211: INFO: namespace events-1958 deletion completed in 46.663780843s

• [SLOW TEST:53.107 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:50:42.211: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4011
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:50:43.205: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:50:45.257: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486643, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486643, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486643, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486643, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:50:48.948: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:50:49.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4011" for this suite.
Nov  4 17:51:19.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:20.844: INFO: namespace webhook-4011 deletion completed in 31.720036979s
STEP: Destroying namespace "webhook-4011-markers" for this suite.
Nov  4 17:51:26.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:28.953: INFO: namespace webhook-4011-markers deletion completed in 8.108912056s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:46.829 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:51:29.040: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7488
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Nov  4 17:51:29.352: INFO: Waiting up to 5m0s for pod "pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7" in namespace "emptydir-7488" to be "success or failure"
Nov  4 17:51:29.365: INFO: Pod "pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.911007ms
Nov  4 17:51:31.379: INFO: Pod "pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.027176811s
Nov  4 17:51:33.392: INFO: Pod "pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.039617006s
STEP: Saw pod success
Nov  4 17:51:33.392: INFO: Pod "pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7" satisfied condition "success or failure"
Nov  4 17:51:33.404: INFO: Trying to get logs from node 10.93.34.26 pod pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7 container test-container: <nil>
STEP: delete the pod
Nov  4 17:51:33.523: INFO: Waiting for pod pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7 to disappear
Nov  4 17:51:33.550: INFO: Pod pod-88eb4ecf-19ff-412d-9806-af5c4cb689b7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:51:33.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7488" for this suite.
Nov  4 17:51:39.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:40.268: INFO: namespace emptydir-7488 deletion completed in 6.692313484s

• [SLOW TEST:11.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:51:40.269: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1249
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:51:40.541: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 17:51:44.406: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1249 create -f -'
Nov  4 17:51:44.943: INFO: stderr: ""
Nov  4 17:51:44.943: INFO: stdout: "e2e-test-crd-publish-openapi-3520-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 17:51:44.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1249 delete e2e-test-crd-publish-openapi-3520-crds test-cr'
Nov  4 17:51:45.830: INFO: stderr: ""
Nov  4 17:51:45.830: INFO: stdout: "e2e-test-crd-publish-openapi-3520-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Nov  4 17:51:45.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1249 apply -f -'
Nov  4 17:51:46.099: INFO: stderr: ""
Nov  4 17:51:46.099: INFO: stdout: "e2e-test-crd-publish-openapi-3520-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Nov  4 17:51:46.100: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1249 delete e2e-test-crd-publish-openapi-3520-crds test-cr'
Nov  4 17:51:46.367: INFO: stderr: ""
Nov  4 17:51:46.367: INFO: stdout: "e2e-test-crd-publish-openapi-3520-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Nov  4 17:51:46.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-3520-crds'
Nov  4 17:51:46.706: INFO: stderr: ""
Nov  4 17:51:46.706: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3520-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:51:50.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1249" for this suite.
Nov  4 17:51:56.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:51:57.759: INFO: namespace crd-publish-openapi-1249 deletion completed in 7.201522577s

• [SLOW TEST:17.491 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:51:57.766: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6305
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:52:09.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6305" for this suite.
Nov  4 17:52:15.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:52:16.088: INFO: namespace resourcequota-6305 deletion completed in 6.651200428s

• [SLOW TEST:18.323 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:52:16.088: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8577
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:52:17.256: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 17:52:19.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486737, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486737, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486737, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708486737, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:52:22.370: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:52:22.386: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6218-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:52:23.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8577" for this suite.
Nov  4 17:52:32.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:52:32.649: INFO: namespace webhook-8577 deletion completed in 8.910478178s
STEP: Destroying namespace "webhook-8577-markers" for this suite.
Nov  4 17:52:38.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:52:39.190: INFO: namespace webhook-8577-markers deletion completed in 6.54123784s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.199 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:52:39.287: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3444
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-2f2120a8-a13a-4cf0-b6eb-c599aa836e71
STEP: Creating configMap with name cm-test-opt-upd-c18c2d95-669e-4798-ab13-a423ed60ad5d
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2f2120a8-a13a-4cf0-b6eb-c599aa836e71
STEP: Updating configmap cm-test-opt-upd-c18c2d95-669e-4798-ab13-a423ed60ad5d
STEP: Creating configMap with name cm-test-opt-create-89db1a07-8c36-46a4-8f52-0f9ffd844409
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:52:44.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3444" for this suite.
Nov  4 17:52:56.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:52:56.686: INFO: namespace configmap-3444 deletion completed in 12.545341339s

• [SLOW TEST:17.399 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:52:56.686: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Nov  4 17:52:57.520: INFO: created pod pod-service-account-defaultsa
Nov  4 17:52:57.520: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Nov  4 17:52:57.536: INFO: created pod pod-service-account-mountsa
Nov  4 17:52:57.536: INFO: pod pod-service-account-mountsa service account token volume mount: true
Nov  4 17:52:57.561: INFO: created pod pod-service-account-nomountsa
Nov  4 17:52:57.562: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Nov  4 17:52:57.575: INFO: created pod pod-service-account-defaultsa-mountspec
Nov  4 17:52:57.575: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Nov  4 17:52:57.591: INFO: created pod pod-service-account-mountsa-mountspec
Nov  4 17:52:57.591: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Nov  4 17:52:57.605: INFO: created pod pod-service-account-nomountsa-mountspec
Nov  4 17:52:57.605: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Nov  4 17:52:57.619: INFO: created pod pod-service-account-defaultsa-nomountspec
Nov  4 17:52:57.619: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Nov  4 17:52:57.631: INFO: created pod pod-service-account-mountsa-nomountspec
Nov  4 17:52:57.631: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Nov  4 17:52:57.643: INFO: created pod pod-service-account-nomountsa-nomountspec
Nov  4 17:52:57.643: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:52:57.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4620" for this suite.
Nov  4 17:53:05.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:06.404: INFO: namespace svcaccounts-4620 deletion completed in 8.738698006s

• [SLOW TEST:9.718 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:06.405: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2778
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 17:53:09.309: INFO: Successfully updated pod "annotationupdate97c23f9e-e3c8-409d-94a9-b845207780eb"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:12.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2778" for this suite.
Nov  4 17:53:30.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:31.089: INFO: namespace projected-2778 deletion completed in 18.612787338s

• [SLOW TEST:24.685 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:31.092: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-7239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 17:53:31.350: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 17:53:31.405: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 17:53:31.420: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.21 before test
Nov  4 17:53:31.824: INFO: ibm-master-proxy-static-10.93.34.21 from kube-system started at 2019-11-04 16:08:53 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.824: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:53:31.824: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:53:31.824: INFO: dashboard-metrics-scraper-dff9cbb9c-sc7q5 from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.824: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  4 17:53:31.824: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-k6cdg from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.824: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 17:53:31.824: INFO: ibm-keepalived-watcher-6p6hf from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.824: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 17:53:31.824: INFO: kubernetes-dashboard-5fc98b6f46-czxkn from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.824: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 17:53:31.825: INFO: calico-kube-controllers-77467ddb99-hm4pf from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  4 17:53:31.825: INFO: olm-operator-58994486f9-75rbg from ibm-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container olm-operator ready: true, restart count 0
Nov  4 17:53:31.825: INFO: catalog-operator-7885df777c-fbf7n from ibm-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container catalog-operator ready: true, restart count 0
Nov  4 17:53:31.825: INFO: vpn-79845b6f9d-lblq6 from kube-system started at 2019-11-04 16:32:40 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container vpn ready: true, restart count 0
Nov  4 17:53:31.825: INFO: ibm-storage-watcher-77c86866cb-d9rwp from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov  4 17:53:31.825: INFO: coredns-autoscaler-65c89858bf-7kwgd from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container autoscaler ready: true, restart count 0
Nov  4 17:53:31.825: INFO: coredns-6db888bf8c-tx67z from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:53:31.825: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:53:31.825: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:53:31.825: INFO: calico-node-rqnj2 from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:53:31.825: INFO: ibm-file-plugin-7c6d445669-fzd47 from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov  4 17:53:31.825: INFO: metrics-server-d7b79fbb6-6ng9n from kube-system started at 2019-11-04 16:09:04 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container metrics-server ready: true, restart count 0
Nov  4 17:53:31.825: INFO: ibm-kube-fluentd-jskbg from kube-system started at 2019-11-04 16:09:19 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.825: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:53:31.825: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.26 before test
Nov  4 17:53:31.903: INFO: ibm-kube-fluentd-sjtjl from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:53:31.903: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 17:53:31.903: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:53:31.903: INFO: ibm-master-proxy-static-10.93.34.26 from kube-system started at 2019-11-04 16:12:06 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:53:31.903: INFO: ibm-keepalived-watcher-pnc97 from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 17:53:31.903: INFO: coredns-6db888bf8c-5vkjd from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:53:31.903: INFO: calico-node-dzhkq from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:53:31.903: INFO: sonobuoy-e2e-job-f11cbcc8e8e5452a from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.903: INFO: 	Container e2e ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:53:31.903: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.38 before test
Nov  4 17:53:31.940: INFO: coredns-6db888bf8c-mgznm from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.940: INFO: 	Container coredns ready: true, restart count 0
Nov  4 17:53:31.940: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.940: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 17:53:31.940: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.940: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 17:53:31.940: INFO: 	Container systemd-logs ready: true, restart count 0
Nov  4 17:53:31.941: INFO: ibm-kube-fluentd-zwc56 from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.941: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 17:53:31.941: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-04 16:17:52 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.941: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov  4 17:53:31.941: INFO: calico-node-k8p8l from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.941: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 17:53:31.941: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 17:53:31.941: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 17:53:31.941: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 17:53:31.941: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 17:53:31.942: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 17:53:31.942: INFO: sonobuoy from sonobuoy started at 2019-11-04 17:36:13 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.942: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 17:53:31.942: INFO: ibm-master-proxy-static-10.93.34.38 from kube-system started at 2019-11-04 16:16:27 +0000 UTC (2 container statuses recorded)
Nov  4 17:53:31.942: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 17:53:31.942: INFO: 	Container pause ready: true, restart count 0
Nov  4 17:53:31.942: INFO: ibm-keepalived-watcher-n9c7j from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 17:53:31.942: INFO: 	Container keepalived-watcher ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.93.34.21
STEP: verifying the node has the label node 10.93.34.26
STEP: verifying the node has the label node 10.93.34.38
Nov  4 17:53:32.109: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.93.34.38
Nov  4 17:53:32.109: INFO: Pod catalog-operator-7885df777c-fbf7n requesting resource cpu=10m on Node 10.93.34.21
Nov  4 17:53:32.109: INFO: Pod ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-k6cdg requesting resource cpu=5m on Node 10.93.34.21
Nov  4 17:53:32.109: INFO: Pod ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 requesting resource cpu=5m on Node 10.93.34.38
Nov  4 17:53:32.109: INFO: Pod olm-operator-58994486f9-75rbg requesting resource cpu=10m on Node 10.93.34.21
Nov  4 17:53:32.109: INFO: Pod calico-kube-controllers-77467ddb99-hm4pf requesting resource cpu=10m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod calico-node-dzhkq requesting resource cpu=250m on Node 10.93.34.26
Nov  4 17:53:32.110: INFO: Pod calico-node-k8p8l requesting resource cpu=250m on Node 10.93.34.38
Nov  4 17:53:32.110: INFO: Pod calico-node-rqnj2 requesting resource cpu=250m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod coredns-6db888bf8c-5vkjd requesting resource cpu=100m on Node 10.93.34.26
Nov  4 17:53:32.110: INFO: Pod coredns-6db888bf8c-mgznm requesting resource cpu=100m on Node 10.93.34.38
Nov  4 17:53:32.110: INFO: Pod coredns-6db888bf8c-tx67z requesting resource cpu=100m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod coredns-autoscaler-65c89858bf-7kwgd requesting resource cpu=20m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod dashboard-metrics-scraper-dff9cbb9c-sc7q5 requesting resource cpu=1m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod ibm-file-plugin-7c6d445669-fzd47 requesting resource cpu=50m on Node 10.93.34.21
Nov  4 17:53:32.110: INFO: Pod ibm-keepalived-watcher-6p6hf requesting resource cpu=5m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod ibm-keepalived-watcher-n9c7j requesting resource cpu=5m on Node 10.93.34.38
Nov  4 17:53:32.111: INFO: Pod ibm-keepalived-watcher-pnc97 requesting resource cpu=5m on Node 10.93.34.26
Nov  4 17:53:32.111: INFO: Pod ibm-kube-fluentd-jskbg requesting resource cpu=25m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod ibm-kube-fluentd-sjtjl requesting resource cpu=25m on Node 10.93.34.26
Nov  4 17:53:32.111: INFO: Pod ibm-kube-fluentd-zwc56 requesting resource cpu=25m on Node 10.93.34.38
Nov  4 17:53:32.111: INFO: Pod ibm-master-proxy-static-10.93.34.21 requesting resource cpu=25m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod ibm-master-proxy-static-10.93.34.26 requesting resource cpu=25m on Node 10.93.34.26
Nov  4 17:53:32.111: INFO: Pod ibm-master-proxy-static-10.93.34.38 requesting resource cpu=25m on Node 10.93.34.38
Nov  4 17:53:32.111: INFO: Pod ibm-storage-watcher-77c86866cb-d9rwp requesting resource cpu=50m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod kubernetes-dashboard-5fc98b6f46-czxkn requesting resource cpu=50m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod metrics-server-d7b79fbb6-6ng9n requesting resource cpu=48m on Node 10.93.34.21
Nov  4 17:53:32.111: INFO: Pod public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 requesting resource cpu=0m on Node 10.93.34.26
Nov  4 17:53:32.112: INFO: Pod public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj requesting resource cpu=0m on Node 10.93.34.38
Nov  4 17:53:32.112: INFO: Pod vpn-79845b6f9d-lblq6 requesting resource cpu=5m on Node 10.93.34.21
Nov  4 17:53:32.112: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.93.34.38
Nov  4 17:53:32.112: INFO: Pod sonobuoy-e2e-job-f11cbcc8e8e5452a requesting resource cpu=0m on Node 10.93.34.26
Nov  4 17:53:32.112: INFO: Pod sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z requesting resource cpu=0m on Node 10.93.34.21
Nov  4 17:53:32.112: INFO: Pod sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f requesting resource cpu=0m on Node 10.93.34.26
Nov  4 17:53:32.112: INFO: Pod sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt requesting resource cpu=0m on Node 10.93.34.38
STEP: Starting Pods to consume most of the cluster CPU.
Nov  4 17:53:32.112: INFO: Creating a pod which consumes cpu=2272m on Node 10.93.34.21
Nov  4 17:53:32.138: INFO: Creating a pod which consumes cpu=2453m on Node 10.93.34.26
Nov  4 17:53:32.151: INFO: Creating a pod which consumes cpu=2450m on Node 10.93.34.38
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29.15d40721ee34b409], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7239/filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29 to 10.93.34.38]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29.15d407223263f47b], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29.15d40722362ada25], Reason = [Created], Message = [Created container filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29.15d4072240bd53ae], Reason = [Started], Message = [Started container filler-pod-24f92af3-89cd-4b6a-bf0c-29169356fa29]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3.15d40721ec8ec0cb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7239/filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3 to 10.93.34.21]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3.15d407222ec05440], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3.15d4072233170f76], Reason = [Created], Message = [Created container filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3.15d407223d4998a8], Reason = [Started], Message = [Started container filler-pod-43f0ac26-3405-4080-8647-913101ebe5e3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5.15d40721ed7f58d7], Reason = [Scheduled], Message = [Successfully assigned sched-pred-7239/filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5 to 10.93.34.26]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5.15d4072234a9d7ba], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5.15d4072238b744c7], Reason = [Created], Message = [Created container filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5.15d4072243c50776], Reason = [Started], Message = [Started container filler-pod-53b797e0-6011-4253-9bd0-6c22ca6193f5]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15d407226b1c9763], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.93.34.21
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.93.34.26
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.93.34.38
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:53:35.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7239" for this suite.
Nov  4 17:53:43.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:53:44.228: INFO: namespace sched-pred-7239 deletion completed in 8.751116463s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:13.137 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:53:44.229: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9328
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Nov  4 17:53:44.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-9328 -- logs-generator --log-lines-total 100 --run-duration 20s'
Nov  4 17:53:44.667: INFO: stderr: ""
Nov  4 17:53:44.667: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Nov  4 17:53:44.667: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Nov  4 17:53:44.667: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-9328" to be "running and ready, or succeeded"
Nov  4 17:53:44.677: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 9.26492ms
Nov  4 17:53:46.688: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020520729s
Nov  4 17:53:48.700: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.032796185s
Nov  4 17:53:48.700: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Nov  4 17:53:48.700: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Nov  4 17:53:48.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328'
Nov  4 17:53:48.918: INFO: stderr: ""
Nov  4 17:53:48.918: INFO: stdout: "I1104 17:53:46.037862       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/txf 252\nI1104 17:53:46.238131       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/8q7 519\nI1104 17:53:46.438046       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/9fgk 367\nI1104 17:53:46.638136       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/4xbb 289\nI1104 17:53:46.837995       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/sbb 269\nI1104 17:53:47.038020       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/s8j2 219\nI1104 17:53:47.238013       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/l6h 396\nI1104 17:53:47.437981       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/qkt2 599\nI1104 17:53:47.638021       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/tn8 217\nI1104 17:53:47.837989       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/8g58 302\nI1104 17:53:48.038015       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/rlj 541\nI1104 17:53:48.240340       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/gb4 218\nI1104 17:53:48.438000       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/fsnt 402\nI1104 17:53:48.638024       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/km2g 298\nI1104 17:53:48.838002       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h44 287\n"
STEP: limiting log lines
Nov  4 17:53:48.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328 --tail=1'
Nov  4 17:53:50.249: INFO: stderr: ""
Nov  4 17:53:50.249: INFO: stdout: "I1104 17:53:50.238177       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/ph6x 401\n"
STEP: limiting log bytes
Nov  4 17:53:50.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328 --limit-bytes=1'
Nov  4 17:53:50.421: INFO: stderr: ""
Nov  4 17:53:50.421: INFO: stdout: "I"
STEP: exposing timestamps
Nov  4 17:53:50.421: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328 --tail=1 --timestamps'
Nov  4 17:53:50.564: INFO: stderr: ""
Nov  4 17:53:50.564: INFO: stdout: "2019-11-04T17:53:50.438388961Z I1104 17:53:50.438203       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/6lkj 390\n"
STEP: restricting to a time range
Nov  4 17:53:53.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328 --since=1s'
Nov  4 17:53:53.264: INFO: stderr: ""
Nov  4 17:53:53.264: INFO: stdout: "I1104 17:53:52.438000       1 logs_generator.go:76] 32 POST /api/v1/namespaces/kube-system/pods/k5xv 288\nI1104 17:53:52.638015       1 logs_generator.go:76] 33 GET /api/v1/namespaces/default/pods/wbd 297\nI1104 17:53:52.838039       1 logs_generator.go:76] 34 GET /api/v1/namespaces/default/pods/8x5q 298\nI1104 17:53:53.038021       1 logs_generator.go:76] 35 GET /api/v1/namespaces/default/pods/wzdj 512\nI1104 17:53:53.238072       1 logs_generator.go:76] 36 POST /api/v1/namespaces/default/pods/p7v 390\n"
Nov  4 17:53:53.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs logs-generator logs-generator --namespace=kubectl-9328 --since=24h'
Nov  4 17:53:53.449: INFO: stderr: ""
Nov  4 17:53:53.449: INFO: stdout: "I1104 17:53:46.037862       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/txf 252\nI1104 17:53:46.238131       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/8q7 519\nI1104 17:53:46.438046       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/9fgk 367\nI1104 17:53:46.638136       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/4xbb 289\nI1104 17:53:46.837995       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/sbb 269\nI1104 17:53:47.038020       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/s8j2 219\nI1104 17:53:47.238013       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/l6h 396\nI1104 17:53:47.437981       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/qkt2 599\nI1104 17:53:47.638021       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/tn8 217\nI1104 17:53:47.837989       1 logs_generator.go:76] 9 GET /api/v1/namespaces/kube-system/pods/8g58 302\nI1104 17:53:48.038015       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/rlj 541\nI1104 17:53:48.240340       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/gb4 218\nI1104 17:53:48.438000       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/fsnt 402\nI1104 17:53:48.638024       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/km2g 298\nI1104 17:53:48.838002       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/h44 287\nI1104 17:53:49.038039       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/xx96 456\nI1104 17:53:49.238011       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/fhfx 382\nI1104 17:53:49.438013       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/65sc 440\nI1104 17:53:49.638015       1 logs_generator.go:76] 18 GET /api/v1/namespaces/ns/pods/l68v 510\nI1104 17:53:49.837986       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/qnk7 452\nI1104 17:53:50.037980       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/6x9 310\nI1104 17:53:50.238177       1 logs_generator.go:76] 21 POST /api/v1/namespaces/default/pods/ph6x 401\nI1104 17:53:50.438203       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/6lkj 390\nI1104 17:53:50.638013       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/ns/pods/wjf 477\nI1104 17:53:50.838030       1 logs_generator.go:76] 24 PUT /api/v1/namespaces/ns/pods/xbj 557\nI1104 17:53:51.038021       1 logs_generator.go:76] 25 GET /api/v1/namespaces/kube-system/pods/9zt5 596\nI1104 17:53:51.238008       1 logs_generator.go:76] 26 POST /api/v1/namespaces/ns/pods/smwm 240\nI1104 17:53:51.438007       1 logs_generator.go:76] 27 PUT /api/v1/namespaces/ns/pods/dlxh 257\nI1104 17:53:51.638020       1 logs_generator.go:76] 28 POST /api/v1/namespaces/kube-system/pods/wcf 442\nI1104 17:53:51.838014       1 logs_generator.go:76] 29 PUT /api/v1/namespaces/ns/pods/qq8g 562\nI1104 17:53:52.038013       1 logs_generator.go:76] 30 GET /api/v1/namespaces/kube-system/pods/lxk 279\nI1104 17:53:52.238023       1 logs_generator.go:76] 31 PUT /api/v1/namespaces/default/pods/8wgr 553\nI1104 17:53:52.438000       1 logs_generator.go:76] 32 POST /api/v1/namespaces/kube-system/pods/k5xv 288\nI1104 17:53:52.638015       1 logs_generator.go:76] 33 GET /api/v1/namespaces/default/pods/wbd 297\nI1104 17:53:52.838039       1 logs_generator.go:76] 34 GET /api/v1/namespaces/default/pods/8x5q 298\nI1104 17:53:53.038021       1 logs_generator.go:76] 35 GET /api/v1/namespaces/default/pods/wzdj 512\nI1104 17:53:53.238072       1 logs_generator.go:76] 36 POST /api/v1/namespaces/default/pods/p7v 390\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Nov  4 17:53:53.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete pod logs-generator --namespace=kubectl-9328'
Nov  4 17:54:06.911: INFO: stderr: ""
Nov  4 17:54:06.912: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:06.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9328" for this suite.
Nov  4 17:54:13.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:13.614: INFO: namespace kubectl-9328 deletion completed in 6.668827353s

• [SLOW TEST:29.385 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:13.614: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-b81e8461-86d5-49e4-b690-010f43047dfd
STEP: Creating a pod to test consume configMaps
Nov  4 17:54:13.945: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc" in namespace "projected-4312" to be "success or failure"
Nov  4 17:54:13.960: INFO: Pod "pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc": Phase="Pending", Reason="", readiness=false. Elapsed: 14.49055ms
Nov  4 17:54:15.977: INFO: Pod "pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031631852s
STEP: Saw pod success
Nov  4 17:54:15.977: INFO: Pod "pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc" satisfied condition "success or failure"
Nov  4 17:54:15.987: INFO: Trying to get logs from node 10.93.34.26 pod pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 17:54:16.050: INFO: Waiting for pod pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc to disappear
Nov  4 17:54:16.060: INFO: Pod pod-projected-configmaps-5cf3c485-7bfc-4a02-9b6d-679905ebe7dc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:16.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4312" for this suite.
Nov  4 17:54:22.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:22.660: INFO: namespace projected-4312 deletion completed in 6.579241225s

• [SLOW TEST:9.046 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:22.661: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2161
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Nov  4 17:54:22.917: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 cluster-info'
Nov  4 17:54:23.053: INFO: stderr: ""
Nov  4 17:54:23.053: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:23.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2161" for this suite.
Nov  4 17:54:31.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:31.654: INFO: namespace kubectl-2161 deletion completed in 8.57975021s

• [SLOW TEST:8.993 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:31.655: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4615
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-4e157c80-0788-48b2-a96f-8ad9a83dff01
STEP: Creating a pod to test consume secrets
Nov  4 17:54:31.963: INFO: Waiting up to 5m0s for pod "pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8" in namespace "secrets-4615" to be "success or failure"
Nov  4 17:54:31.976: INFO: Pod "pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.752005ms
Nov  4 17:54:33.991: INFO: Pod "pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028047274s
STEP: Saw pod success
Nov  4 17:54:33.991: INFO: Pod "pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8" satisfied condition "success or failure"
Nov  4 17:54:34.001: INFO: Trying to get logs from node 10.93.34.26 pod pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8 container secret-env-test: <nil>
STEP: delete the pod
Nov  4 17:54:34.064: INFO: Waiting for pod pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8 to disappear
Nov  4 17:54:34.075: INFO: Pod pod-secrets-dfec366c-8142-41cc-9ac9-73f9ec81fcf8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:54:34.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4615" for this suite.
Nov  4 17:54:40.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:54:40.667: INFO: namespace secrets-4615 deletion completed in 6.570766488s

• [SLOW TEST:9.012 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:54:40.667: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 17:54:40.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9934'
Nov  4 17:54:41.059: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 17:54:41.059: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Nov  4 17:54:41.082: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Nov  4 17:54:41.090: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Nov  4 17:54:41.105: INFO: scanned /root for discovery docs: <nil>
Nov  4 17:54:41.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9934'
Nov  4 17:54:57.242: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 17:54:57.242: INFO: stdout: "Created e2e-test-httpd-rc-7119167862f92ada908520645baf42ba\nScaling up e2e-test-httpd-rc-7119167862f92ada908520645baf42ba from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-7119167862f92ada908520645baf42ba up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-7119167862f92ada908520645baf42ba to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Nov  4 17:54:57.242: INFO: stdout: "Created e2e-test-httpd-rc-7119167862f92ada908520645baf42ba\nScaling up e2e-test-httpd-rc-7119167862f92ada908520645baf42ba from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-7119167862f92ada908520645baf42ba up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-7119167862f92ada908520645baf42ba to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Nov  4 17:54:57.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9934'
Nov  4 17:54:57.373: INFO: stderr: ""
Nov  4 17:54:57.373: INFO: stdout: "e2e-test-httpd-rc-7119167862f92ada908520645baf42ba-6n85r e2e-test-httpd-rc-hsqgx "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Nov  4 17:55:02.374: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9934'
Nov  4 17:55:02.554: INFO: stderr: ""
Nov  4 17:55:02.554: INFO: stdout: "e2e-test-httpd-rc-7119167862f92ada908520645baf42ba-6n85r "
Nov  4 17:55:02.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods e2e-test-httpd-rc-7119167862f92ada908520645baf42ba-6n85r -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9934'
Nov  4 17:55:02.699: INFO: stderr: ""
Nov  4 17:55:02.699: INFO: stdout: "true"
Nov  4 17:55:02.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods e2e-test-httpd-rc-7119167862f92ada908520645baf42ba-6n85r -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9934'
Nov  4 17:55:02.830: INFO: stderr: ""
Nov  4 17:55:02.830: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Nov  4 17:55:02.830: INFO: e2e-test-httpd-rc-7119167862f92ada908520645baf42ba-6n85r is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Nov  4 17:55:02.830: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete rc e2e-test-httpd-rc --namespace=kubectl-9934'
Nov  4 17:55:03.021: INFO: stderr: ""
Nov  4 17:55:03.021: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:03.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9934" for this suite.
Nov  4 17:55:15.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:15.679: INFO: namespace kubectl-9934 deletion completed in 12.631535124s

• [SLOW TEST:35.012 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:15.680: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9570
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-5a909dac-109d-4e55-88d9-32e54c7a773b
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:15.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9570" for this suite.
Nov  4 17:55:22.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:22.614: INFO: namespace secrets-9570 deletion completed in 6.632298529s

• [SLOW TEST:6.935 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:22.615: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Nov  4 17:55:22.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=kubectl-5798 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Nov  4 17:55:25.373: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Nov  4 17:55:25.373: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:27.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5798" for this suite.
Nov  4 17:55:35.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:36.145: INFO: namespace kubectl-5798 deletion completed in 8.699753031s

• [SLOW TEST:13.530 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:36.146: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:55:36.403: INFO: Creating deployment "webserver-deployment"
Nov  4 17:55:36.422: INFO: Waiting for observed generation 1
Nov  4 17:55:38.457: INFO: Waiting for all required pods to come up
Nov  4 17:55:38.471: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Nov  4 17:55:40.529: INFO: Waiting for deployment "webserver-deployment" to complete
Nov  4 17:55:40.567: INFO: Updating deployment "webserver-deployment" with a non-existent image
Nov  4 17:55:40.610: INFO: Updating deployment webserver-deployment
Nov  4 17:55:40.610: INFO: Waiting for observed generation 2
Nov  4 17:55:42.645: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Nov  4 17:55:42.670: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Nov  4 17:55:42.685: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 17:55:42.741: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Nov  4 17:55:42.741: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Nov  4 17:55:42.756: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Nov  4 17:55:42.790: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Nov  4 17:55:42.790: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Nov  4 17:55:42.823: INFO: Updating deployment webserver-deployment
Nov  4 17:55:42.823: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Nov  4 17:55:42.950: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Nov  4 17:55:44.986: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:55:45.029: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-7393 /apis/apps/v1/namespaces/deployment-7393/deployments/webserver-deployment 8e8c002b-e8b9-4be9-98a8-5becd169cc10 22610 3 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00671eb08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 17:55:43 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-11-04 17:55:45 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,},},ReadyReplicas:10,CollisionCount:nil,},}

Nov  4 17:55:45.046: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-7393 /apis/apps/v1/namespaces/deployment-7393/replicasets/webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 22506 3 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 8e8c002b-e8b9-4be9-98a8-5becd169cc10 0xc005703f07 0xc005703f08}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005703f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:55:45.046: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Nov  4 17:55:45.046: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-7393 /apis/apps/v1/namespaces/deployment-7393/replicasets/webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 22608 3 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 8e8c002b-e8b9-4be9-98a8-5becd169cc10 0xc005703e47 0xc005703e48}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005703ea8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:55:45.075: INFO: Pod "webserver-deployment-595b5b9587-65fwg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-65fwg webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-65fwg 6a53f03d-ae16-436f-8142-7d2786c00355 22315 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671ef17 0xc00671ef18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.31,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://fb9cdda902b53d71c31ab9a3364d4fc9a1abd867ab9f53788f3f2544990e919e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.31,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.075: INFO: Pod "webserver-deployment-595b5b9587-6gdr7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6gdr7 webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-6gdr7 7e55cc71-98e3-4ec2-a4d6-85f25a22bc0f 22301 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f097 0xc00671f098}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.33,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://87956ccda187b0b3651e003afbeff065d6acff68f8b933a7cd76f41e52e88b88,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.076: INFO: Pod "webserver-deployment-595b5b9587-6k4vb" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6k4vb webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-6k4vb ef045c64-da2d-4b1f-824e-a38186836aeb 22602 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f217 0xc00671f218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.230,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e6fc9ed4f742a64038e396b894687a5c44575f1afe96a02c2725b025812c4957,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.230,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.077: INFO: Pod "webserver-deployment-595b5b9587-fg5wj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fg5wj webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-fg5wj a76522e0-24eb-44e5-94c5-fa1f6cdf4a9b 22305 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f397 0xc00671f398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.29,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e4f1607a06f7ed483274591aa183ef0c5f60e83ec7fcaabfe1fc9ec3516ada31,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.077: INFO: Pod "webserver-deployment-595b5b9587-gnd2l" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gnd2l webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-gnd2l bccf05a7-4930-4013-8c7d-b43d105f65d9 22515 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f517 0xc00671f518}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.078: INFO: Pod "webserver-deployment-595b5b9587-j9hn2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j9hn2 webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-j9hn2 7c3a839d-3b73-4feb-8c4e-c3799cc89a83 22309 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f677 0xc00671f678}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.32,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://7e4ce0ccde580df46cddbafe404a022701d77b6fbaee1022f4e088c5835394a7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.078: INFO: Pod "webserver-deployment-595b5b9587-jmx8g" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jmx8g webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-jmx8g e790cb9b-7a7c-4c0c-ace5-c31122147645 22510 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f7f7 0xc00671f7f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.078: INFO: Pod "webserver-deployment-595b5b9587-k24dq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-k24dq webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-k24dq c60f7a1e-1887-4fb3-bd93-5fe44e4063bb 22282 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671f957 0xc00671f958}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:172.30.168.121,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://ff083b8690d6d11015492905fc95711ae42b5e1bfdbadb9ecd7d88699525b4a2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.168.121,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.078: INFO: Pod "webserver-deployment-595b5b9587-l29pq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l29pq webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-l29pq 7a5af0c5-d481-4a8d-85be-bb50ea51e835 22269 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671fad7 0xc00671fad8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.225,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://4c85a212dba8449de4a7e875fb3438e7a6f52a73dcda3df3c633ce58ecb25119,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.079: INFO: Pod "webserver-deployment-595b5b9587-mh5ld" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mh5ld webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-mh5ld a34b0f92-b775-40ec-92ff-0d95738dea18 22536 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671fc57 0xc00671fc58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.079: INFO: Pod "webserver-deployment-595b5b9587-mrmrn" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mrmrn webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-mrmrn a368fa8f-3060-4f33-acbd-430b3d5447fa 22300 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671fdb7 0xc00671fdb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.228,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://be9584cadd69369b92cdac8d2cb764ab4f4a44e87f2d4236123dbcb2294b8a5c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.228,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.079: INFO: Pod "webserver-deployment-595b5b9587-mswwz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mswwz webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-mswwz e42ab3ac-0aa1-4954-937d-f9f37cc6bbf4 22516 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc00671ff37 0xc00671ff38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.079: INFO: Pod "webserver-deployment-595b5b9587-pm67d" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pm67d webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-pm67d e5b76a35-c133-4336-bcb4-59fbd40fa1e8 22311 0 2019-11-04 17:55:36 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66097 0xc000b66098}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.27,StartTime:2019-11-04 17:55:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://8726868afae85338e97474bf343a2788fccba4cd4511fdfd71f295214fb59ca2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.27,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.080: INFO: Pod "webserver-deployment-595b5b9587-qzqf4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qzqf4 webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-qzqf4 f5c2f1a8-631a-4806-9914-4b391724e63e 22518 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66217 0xc000b66218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.080: INFO: Pod "webserver-deployment-595b5b9587-rdxn4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rdxn4 webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-rdxn4 7148ec93-7b46-4433-a194-d94100fa005e 22514 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66377 0xc000b66378}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.080: INFO: Pod "webserver-deployment-595b5b9587-tcsc8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tcsc8 webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-tcsc8 bed32ac7-5ee5-49db-86a7-a2caac658751 22529 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b664d7 0xc000b664d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.081: INFO: Pod "webserver-deployment-595b5b9587-trnhx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-trnhx webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-trnhx be750777-6e8f-45ec-afa4-2503ee017ac0 22606 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66637 0xc000b66638}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.36,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:55:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://f7dd2d485ab447af8f04524ece1eace08985ca94e3895361e0b6f318ced4cede,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.081: INFO: Pod "webserver-deployment-595b5b9587-wnj9k" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wnj9k webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-wnj9k 8dc7bd14-a22c-418c-8587-4c449eaa7440 22512 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b667b7 0xc000b667b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.081: INFO: Pod "webserver-deployment-595b5b9587-wrccb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wrccb webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-wrccb 576e8c4f-6d1a-4033-a5b5-dc94637b2ddf 22520 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66917 0xc000b66918}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.081: INFO: Pod "webserver-deployment-595b5b9587-zmflx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zmflx webserver-deployment-595b5b9587- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-595b5b9587-zmflx d1580139-d438-4c0d-9ac8-acb4652c4622 22539 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 39d24c8f-0f16-482b-9f91-b5a99101c252 0xc000b66a77 0xc000b66a78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.081: INFO: Pod "webserver-deployment-c7997dcc8-7q9q6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7q9q6 webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-7q9q6 d49bfbc9-111c-4344-ba8b-3bbd8f70d487 22524 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b66bd7 0xc000b66bd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.082: INFO: Pod "webserver-deployment-c7997dcc8-7wgdt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7wgdt webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-7wgdt c63a5ab7-60dd-4a6c-890e-4f59216c1856 22434 0 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b66d50 0xc000b66d51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:172.30.168.123,StartTime:2019-11-04 17:55:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.168.123,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.082: INFO: Pod "webserver-deployment-c7997dcc8-gbw5w" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gbw5w webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-gbw5w 41cd10a4-a539-416c-9d97-ac8442faeda2 22498 0 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b66ef0 0xc000b66ef1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:172.30.168.125,StartTime:2019-11-04 17:55:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.168.125,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.082: INFO: Pod "webserver-deployment-c7997dcc8-h5hzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-h5hzh webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-h5hzh 96f1b29d-e477-4fd5-96e0-343b845cda52 22533 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67090 0xc000b67091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.082: INFO: Pod "webserver-deployment-c7997dcc8-lcctc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lcctc webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-lcctc e5e0fd59-4e5a-4b95-a8f3-e11eed05c8c9 22422 0 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67200 0xc000b67201}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.35,StartTime:2019-11-04 17:55:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.083: INFO: Pod "webserver-deployment-c7997dcc8-lkdpl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lkdpl webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-lkdpl de83d550-f906-4e26-ba3f-6519e8592f9f 22527 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b673a0 0xc000b673a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.083: INFO: Pod "webserver-deployment-c7997dcc8-lpn4f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lpn4f webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-lpn4f f87a4be3-8bef-40b9-8440-463a761ed22a 22416 0 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67510 0xc000b67511}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.227,StartTime:2019-11-04 17:55:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.227,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.083: INFO: Pod "webserver-deployment-c7997dcc8-mvh9q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mvh9q webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-mvh9q c74e49cb-30e5-45f5-8598-32eef7dbdc00 22522 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b676b0 0xc000b676b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.083: INFO: Pod "webserver-deployment-c7997dcc8-qd7zb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qd7zb webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-qd7zb 060ff89b-1ef2-4a20-a7a4-448ad0d9bf00 22612 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67830 0xc000b67831}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.37,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.084: INFO: Pod "webserver-deployment-c7997dcc8-qm25r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qm25r webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-qm25r 6420e894-7651-4a72-a86a-c50833dcf869 22525 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b679d0 0xc000b679d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.26,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.26,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.084: INFO: Pod "webserver-deployment-c7997dcc8-rmgs5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rmgs5 webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-rmgs5 61e9e096-4d7b-40d2-b813-1e2dda9af48a 22519 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67b50 0xc000b67b51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.084: INFO: Pod "webserver-deployment-c7997dcc8-w9jh9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w9jh9 webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-w9jh9 aa76700f-30c3-429e-9768-16b45882b37f 22420 0 2019-11-04 17:55:40 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67cc0 0xc000b67cc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.34,StartTime:2019-11-04 17:55:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Nov  4 17:55:45.084: INFO: Pod "webserver-deployment-c7997dcc8-zzmd2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zzmd2 webserver-deployment-c7997dcc8- deployment-7393 /api/v1/namespaces/deployment-7393/pods/webserver-deployment-c7997dcc8-zzmd2 46e91811-b539-4426-abe1-ec331b4ff6a2 22502 0 2019-11-04 17:55:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 7f7e9db9-c727-4ead-9682-27f212073799 0xc000b67e60 0xc000b67e61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wljnm,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wljnm,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wljnm,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:55:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:,StartTime:2019-11-04 17:55:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:55:45.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7393" for this suite.
Nov  4 17:55:58.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:55:58.537: INFO: namespace deployment-7393 deletion completed in 12.569729147s

• [SLOW TEST:22.391 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:55:58.538: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 17:55:58.843: INFO: Waiting up to 5m0s for pod "pod-6cb321d4-f947-47af-b86c-da1d11940a4e" in namespace "emptydir-7966" to be "success or failure"
Nov  4 17:55:58.855: INFO: Pod "pod-6cb321d4-f947-47af-b86c-da1d11940a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 11.57885ms
Nov  4 17:56:00.866: INFO: Pod "pod-6cb321d4-f947-47af-b86c-da1d11940a4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022478405s
Nov  4 17:56:02.877: INFO: Pod "pod-6cb321d4-f947-47af-b86c-da1d11940a4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033787393s
STEP: Saw pod success
Nov  4 17:56:02.877: INFO: Pod "pod-6cb321d4-f947-47af-b86c-da1d11940a4e" satisfied condition "success or failure"
Nov  4 17:56:02.888: INFO: Trying to get logs from node 10.93.34.38 pod pod-6cb321d4-f947-47af-b86c-da1d11940a4e container test-container: <nil>
STEP: delete the pod
Nov  4 17:56:02.991: INFO: Waiting for pod pod-6cb321d4-f947-47af-b86c-da1d11940a4e to disappear
Nov  4 17:56:03.003: INFO: Pod pod-6cb321d4-f947-47af-b86c-da1d11940a4e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:56:03.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7966" for this suite.
Nov  4 17:56:09.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:56:09.680: INFO: namespace emptydir-7966 deletion completed in 6.652816875s

• [SLOW TEST:11.141 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:56:09.681: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9654
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:56:11.305: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:56:14.419: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:56:14.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9654" for this suite.
Nov  4 17:56:22.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:56:23.026: INFO: namespace webhook-9654 deletion completed in 8.554423298s
STEP: Destroying namespace "webhook-9654-markers" for this suite.
Nov  4 17:56:29.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:56:29.866: INFO: namespace webhook-9654-markers deletion completed in 6.839056367s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:20.265 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:56:29.946: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 17:56:30.246: INFO: Waiting up to 5m0s for pod "downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b" in namespace "downward-api-9841" to be "success or failure"
Nov  4 17:56:30.259: INFO: Pod "downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.241888ms
Nov  4 17:56:32.270: INFO: Pod "downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023446704s
STEP: Saw pod success
Nov  4 17:56:32.270: INFO: Pod "downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b" satisfied condition "success or failure"
Nov  4 17:56:32.280: INFO: Trying to get logs from node 10.93.34.21 pod downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b container dapi-container: <nil>
STEP: delete the pod
Nov  4 17:56:32.373: INFO: Waiting for pod downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b to disappear
Nov  4 17:56:32.383: INFO: Pod downward-api-e71385fb-8095-4b61-9cab-6fcb31bb225b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:56:32.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9841" for this suite.
Nov  4 17:56:38.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:56:39.007: INFO: namespace downward-api-9841 deletion completed in 6.582994264s

• [SLOW TEST:9.062 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:56:39.007: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2296
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-5df2d577-fb93-4f09-98d5-81ca68ce5938
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-5df2d577-fb93-4f09-98d5-81ca68ce5938
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:56:43.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2296" for this suite.
Nov  4 17:57:13.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:57:14.140: INFO: namespace projected-2296 deletion completed in 30.647688912s

• [SLOW TEST:35.133 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:57:14.141: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2788
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:57:30.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2788" for this suite.
Nov  4 17:57:38.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:57:39.241: INFO: namespace resourcequota-2788 deletion completed in 8.5273668s

• [SLOW TEST:25.101 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:57:39.242: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6254
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:57:42.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6254" for this suite.
Nov  4 17:57:54.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:57:55.348: INFO: namespace replication-controller-6254 deletion completed in 12.738492472s

• [SLOW TEST:16.107 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:57:55.348: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9439
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 17:57:55.631: INFO: Pod name rollover-pod: Found 0 pods out of 1
Nov  4 17:58:00.643: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 17:58:00.643: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Nov  4 17:58:02.692: INFO: Creating deployment "test-rollover-deployment"
Nov  4 17:58:02.752: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Nov  4 17:58:04.786: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Nov  4 17:58:04.834: INFO: Ensure that both replica sets have 1 created replica
Nov  4 17:58:04.867: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Nov  4 17:58:04.902: INFO: Updating deployment test-rollover-deployment
Nov  4 17:58:04.903: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Nov  4 17:58:06.935: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Nov  4 17:58:06.967: INFO: Make sure deployment "test-rollover-deployment" is complete
Nov  4 17:58:07.000: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:07.000: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487085, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:09.031: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:09.031: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487088, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:11.042: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:11.042: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487088, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:13.034: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:13.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487088, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:15.033: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:15.033: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487088, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:17.036: INFO: all replica sets need to contain the pod-template-hash label
Nov  4 17:58:17.036: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487088, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:19.314: INFO: 
Nov  4 17:58:19.314: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:2, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487098, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708487082, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 17:58:21.038: INFO: 
Nov  4 17:58:21.038: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 17:58:21.106: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-9439 /apis/apps/v1/namespaces/deployment-9439/deployments/test-rollover-deployment 1e484d39-7194-4bb7-8fe8-14ec7d4d3b75 23686 2 2019-11-04 17:58:02 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003749628 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 17:58:02 +0000 UTC,LastTransitionTime:2019-11-04 17:58:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-11-04 17:58:19 +0000 UTC,LastTransitionTime:2019-11-04 17:58:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 17:58:21.122: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-9439 /apis/apps/v1/namespaces/deployment-9439/replicasets/test-rollover-deployment-7d7dc6548c 85b508d3-a1d7-4aff-b2c6-d303b085a75a 23675 2 2019-11-04 17:58:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 1e484d39-7194-4bb7-8fe8-14ec7d4d3b75 0xc002b88867 0xc002b88868}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b88948 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:58:21.122: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Nov  4 17:58:21.122: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-9439 /apis/apps/v1/namespaces/deployment-9439/replicasets/test-rollover-controller c8540ea9-adec-4a47-b3d2-543a848f8313 23682 2 2019-11-04 17:57:55 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 1e484d39-7194-4bb7-8fe8-14ec7d4d3b75 0xc002b882b7 0xc002b882b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002b88638 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:58:21.122: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-9439 /apis/apps/v1/namespaces/deployment-9439/replicasets/test-rollover-deployment-f6c94f66c f46a8a85-5775-4438-8fce-6bf9ba506909 23642 2 2019-11-04 17:58:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 1e484d39-7194-4bb7-8fe8-14ec7d4d3b75 0xc002b88b50 0xc002b88b51}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002b88ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 17:58:21.134: INFO: Pod "test-rollover-deployment-7d7dc6548c-hh4dk" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-hh4dk test-rollover-deployment-7d7dc6548c- deployment-9439 /api/v1/namespaces/deployment-9439/pods/test-rollover-deployment-7d7dc6548c-hh4dk b06ecb68-b200-4b3d-ae51-b044ac417e53 23660 0 2019-11-04 17:58:04 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 85b508d3-a1d7-4aff-b2c6-d303b085a75a 0xc002b89f27 0xc002b89f28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7pglq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7pglq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7pglq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.38,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:58:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:58:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:58:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 17:58:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.38,PodIP:172.30.75.244,StartTime:2019-11-04 17:58:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 17:58:07 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://bf1ec915edce094bf76782a93cfa50d9ad3af91cfee45092b9b15ee737dc8875,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.75.244,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:21.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9439" for this suite.
Nov  4 17:58:29.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:29.948: INFO: namespace deployment-9439 deletion completed in 8.792717139s

• [SLOW TEST:34.599 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:29.948: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7305
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 17:58:30.904: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 17:58:33.997: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:58:44.457: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7305" for this suite.
Nov  4 17:58:52.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:53.043: INFO: namespace webhook-7305 deletion completed in 8.565766671s
STEP: Destroying namespace "webhook-7305-markers" for this suite.
Nov  4 17:58:59.108: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:58:59.671: INFO: namespace webhook-7305-markers deletion completed in 6.628308676s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:29.803 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:58:59.752: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4078
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-2d20354f-eb08-4e2a-8839-8a2ecb749087
STEP: Creating secret with name secret-projected-all-test-volume-4735123d-e959-4f94-94eb-01ac11c18fc2
STEP: Creating a pod to test Check all projections for projected volume plugin
Nov  4 17:59:00.089: INFO: Waiting up to 5m0s for pod "projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3" in namespace "projected-4078" to be "success or failure"
Nov  4 17:59:00.102: INFO: Pod "projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 12.821129ms
Nov  4 17:59:02.118: INFO: Pod "projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02841977s
Nov  4 17:59:04.129: INFO: Pod "projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03944199s
STEP: Saw pod success
Nov  4 17:59:04.129: INFO: Pod "projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3" satisfied condition "success or failure"
Nov  4 17:59:04.154: INFO: Trying to get logs from node 10.93.34.26 pod projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3 container projected-all-volume-test: <nil>
STEP: delete the pod
Nov  4 17:59:04.287: INFO: Waiting for pod projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3 to disappear
Nov  4 17:59:04.298: INFO: Pod projected-volume-fd674f72-7159-4e13-af5c-a652293fa0f3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:04.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4078" for this suite.
Nov  4 17:59:12.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:12.944: INFO: namespace projected-4078 deletion completed in 8.624553598s

• [SLOW TEST:13.191 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:12.945: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2417
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-l2ph
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 17:59:13.303: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-l2ph" in namespace "subpath-2417" to be "success or failure"
Nov  4 17:59:13.318: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Pending", Reason="", readiness=false. Elapsed: 14.662479ms
Nov  4 17:59:15.330: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026416348s
Nov  4 17:59:17.342: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 4.038696141s
Nov  4 17:59:19.354: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 6.050585304s
Nov  4 17:59:21.365: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 8.061189519s
Nov  4 17:59:23.387: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 10.083869009s
Nov  4 17:59:25.398: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 12.094497727s
Nov  4 17:59:27.409: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 14.105683221s
Nov  4 17:59:29.444: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 16.140157839s
Nov  4 17:59:31.454: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 18.150451261s
Nov  4 17:59:33.464: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 20.160996216s
Nov  4 17:59:35.476: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Running", Reason="", readiness=true. Elapsed: 22.173032891s
Nov  4 17:59:37.488: INFO: Pod "pod-subpath-test-configmap-l2ph": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.184195055s
STEP: Saw pod success
Nov  4 17:59:37.488: INFO: Pod "pod-subpath-test-configmap-l2ph" satisfied condition "success or failure"
Nov  4 17:59:37.498: INFO: Trying to get logs from node 10.93.34.38 pod pod-subpath-test-configmap-l2ph container test-container-subpath-configmap-l2ph: <nil>
STEP: delete the pod
Nov  4 17:59:37.597: INFO: Waiting for pod pod-subpath-test-configmap-l2ph to disappear
Nov  4 17:59:37.607: INFO: Pod pod-subpath-test-configmap-l2ph no longer exists
STEP: Deleting pod pod-subpath-test-configmap-l2ph
Nov  4 17:59:37.607: INFO: Deleting pod "pod-subpath-test-configmap-l2ph" in namespace "subpath-2417"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 17:59:37.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2417" for this suite.
Nov  4 17:59:43.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 17:59:44.315: INFO: namespace subpath-2417 deletion completed in 6.657567662s

• [SLOW TEST:31.370 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 17:59:44.316: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-049f63a1-770b-4039-ba64-8cae31df8760 in namespace container-probe-9956
Nov  4 17:59:46.644: INFO: Started pod liveness-049f63a1-770b-4039-ba64-8cae31df8760 in namespace container-probe-9956
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 17:59:46.655: INFO: Initial restart count of pod liveness-049f63a1-770b-4039-ba64-8cae31df8760 is 0
Nov  4 18:00:02.763: INFO: Restart count of pod container-probe-9956/liveness-049f63a1-770b-4039-ba64-8cae31df8760 is now 1 (16.108188328s elapsed)
Nov  4 18:00:22.892: INFO: Restart count of pod container-probe-9956/liveness-049f63a1-770b-4039-ba64-8cae31df8760 is now 2 (36.237267419s elapsed)
Nov  4 18:00:43.022: INFO: Restart count of pod container-probe-9956/liveness-049f63a1-770b-4039-ba64-8cae31df8760 is now 3 (56.367351721s elapsed)
Nov  4 18:01:03.146: INFO: Restart count of pod container-probe-9956/liveness-049f63a1-770b-4039-ba64-8cae31df8760 is now 4 (1m16.491197468s elapsed)
Nov  4 18:02:17.622: INFO: Restart count of pod container-probe-9956/liveness-049f63a1-770b-4039-ba64-8cae31df8760 is now 5 (2m30.966817193s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:17.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9956" for this suite.
Nov  4 18:02:25.738: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:26.307: INFO: namespace container-probe-9956 deletion completed in 8.629483392s

• [SLOW TEST:161.992 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:26.308: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2709
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1c807948-de71-48ec-8fec-a425f9d54382
STEP: Creating a pod to test consume configMaps
Nov  4 18:02:26.628: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027" in namespace "projected-2709" to be "success or failure"
Nov  4 18:02:26.641: INFO: Pod "pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027": Phase="Pending", Reason="", readiness=false. Elapsed: 12.864862ms
Nov  4 18:02:28.657: INFO: Pod "pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028991538s
Nov  4 18:02:30.669: INFO: Pod "pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040630045s
STEP: Saw pod success
Nov  4 18:02:30.669: INFO: Pod "pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027" satisfied condition "success or failure"
Nov  4 18:02:30.678: INFO: Trying to get logs from node 10.93.34.26 pod pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:02:30.772: INFO: Waiting for pod pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027 to disappear
Nov  4 18:02:30.782: INFO: Pod pod-projected-configmaps-9f99a85c-9cfe-446c-957b-92f3af021027 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:30.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2709" for this suite.
Nov  4 18:02:38.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:39.357: INFO: namespace projected-2709 deletion completed in 8.555362886s

• [SLOW TEST:13.050 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:39.358: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-5575cd14-df8f-4ec2-9ec8-a089d21b8c13
STEP: Creating a pod to test consume secrets
Nov  4 18:02:39.653: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d" in namespace "projected-4378" to be "success or failure"
Nov  4 18:02:39.665: INFO: Pod "pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.083922ms
Nov  4 18:02:41.677: INFO: Pod "pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023752392s
Nov  4 18:02:43.687: INFO: Pod "pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034555457s
STEP: Saw pod success
Nov  4 18:02:43.687: INFO: Pod "pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d" satisfied condition "success or failure"
Nov  4 18:02:43.697: INFO: Trying to get logs from node 10.93.34.38 pod pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:02:43.814: INFO: Waiting for pod pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d to disappear
Nov  4 18:02:43.830: INFO: Pod pod-projected-secrets-3459e759-fadd-4e28-8c23-a8f9600d819d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:43.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4378" for this suite.
Nov  4 18:02:51.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:02:52.536: INFO: namespace projected-4378 deletion completed in 8.682484025s

• [SLOW TEST:13.179 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:02:52.539: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:02:52.827: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2" in namespace "projected-9031" to be "success or failure"
Nov  4 18:02:52.838: INFO: Pod "downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.705808ms
Nov  4 18:02:54.849: INFO: Pod "downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022052817s
Nov  4 18:02:56.860: INFO: Pod "downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.03300001s
STEP: Saw pod success
Nov  4 18:02:56.860: INFO: Pod "downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2" satisfied condition "success or failure"
Nov  4 18:02:56.869: INFO: Trying to get logs from node 10.93.34.38 pod downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2 container client-container: <nil>
STEP: delete the pod
Nov  4 18:02:56.924: INFO: Waiting for pod downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2 to disappear
Nov  4 18:02:56.935: INFO: Pod downwardapi-volume-fae699d4-561c-4239-bf13-dc735fce61b2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:02:56.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9031" for this suite.
Nov  4 18:03:03.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:03.601: INFO: namespace projected-9031 deletion completed in 6.639978952s

• [SLOW TEST:11.062 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:03.601: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9326
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Nov  4 18:03:03.954: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24492 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:03:03.954: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24493 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 18:03:03.954: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24494 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Nov  4 18:03:14.128: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24510 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:03:14.128: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24511 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Nov  4 18:03:14.128: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-9326 /api/v1/namespaces/watch-9326/configmaps/e2e-watch-test-label-changed 4fc255c2-02ec-489a-a88f-c15e682127cd 24512 0 2019-11-04 18:03:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:03:14.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9326" for this suite.
Nov  4 18:03:22.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:03:22.746: INFO: namespace watch-9326 deletion completed in 8.590870897s

• [SLOW TEST:19.145 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:03:22.749: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6365
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5f9d2efb-9595-42d6-a6e8-29072006b196
STEP: Creating secret with name s-test-opt-upd-19397ca5-7d50-466f-af5c-bbaa804f6f29
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5f9d2efb-9595-42d6-a6e8-29072006b196
STEP: Updating secret s-test-opt-upd-19397ca5-7d50-466f-af5c-bbaa804f6f29
STEP: Creating secret with name s-test-opt-create-9f85e0dc-f1f0-4413-bf2a-00910de519a1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:31.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6365" for this suite.
Nov  4 18:04:45.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:04:45.621: INFO: namespace projected-6365 deletion completed in 14.580323765s

• [SLOW TEST:82.872 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:04:45.621: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-731
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-731
I1104 18:04:45.926189      25 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-731, replica count: 1
I1104 18:04:46.976727      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 18:04:47.976932      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 18:04:48.977178      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:04:49.121: INFO: Created: latency-svc-p7wss
Nov  4 18:04:49.137: INFO: Got endpoints: latency-svc-p7wss [60.256411ms]
Nov  4 18:04:49.179: INFO: Created: latency-svc-fw6z6
Nov  4 18:04:49.195: INFO: Got endpoints: latency-svc-fw6z6 [57.082824ms]
Nov  4 18:04:49.202: INFO: Created: latency-svc-8fgkx
Nov  4 18:04:49.216: INFO: Got endpoints: latency-svc-8fgkx [77.985156ms]
Nov  4 18:04:49.224: INFO: Created: latency-svc-87mth
Nov  4 18:04:49.236: INFO: Got endpoints: latency-svc-87mth [98.25101ms]
Nov  4 18:04:49.245: INFO: Created: latency-svc-fvppt
Nov  4 18:04:49.259: INFO: Got endpoints: latency-svc-fvppt [121.647656ms]
Nov  4 18:04:49.267: INFO: Created: latency-svc-9grl8
Nov  4 18:04:49.278: INFO: Got endpoints: latency-svc-9grl8 [140.914738ms]
Nov  4 18:04:49.292: INFO: Created: latency-svc-lbl8f
Nov  4 18:04:49.317: INFO: Got endpoints: latency-svc-lbl8f [179.457238ms]
Nov  4 18:04:49.318: INFO: Created: latency-svc-rbxkq
Nov  4 18:04:49.331: INFO: Got endpoints: latency-svc-rbxkq [193.595136ms]
Nov  4 18:04:49.349: INFO: Created: latency-svc-77sm4
Nov  4 18:04:49.360: INFO: Got endpoints: latency-svc-77sm4 [221.990096ms]
Nov  4 18:04:49.375: INFO: Created: latency-svc-vx9zm
Nov  4 18:04:49.392: INFO: Got endpoints: latency-svc-vx9zm [253.909145ms]
Nov  4 18:04:49.407: INFO: Created: latency-svc-d6mf7
Nov  4 18:04:49.414: INFO: Got endpoints: latency-svc-d6mf7 [276.702122ms]
Nov  4 18:04:49.430: INFO: Created: latency-svc-nrzt4
Nov  4 18:04:49.443: INFO: Got endpoints: latency-svc-nrzt4 [304.771437ms]
Nov  4 18:04:49.451: INFO: Created: latency-svc-s8pr8
Nov  4 18:04:49.465: INFO: Got endpoints: latency-svc-s8pr8 [327.142586ms]
Nov  4 18:04:49.482: INFO: Created: latency-svc-ltpsn
Nov  4 18:04:49.492: INFO: Got endpoints: latency-svc-ltpsn [354.048356ms]
Nov  4 18:04:49.500: INFO: Created: latency-svc-clqld
Nov  4 18:04:49.518: INFO: Got endpoints: latency-svc-clqld [379.781623ms]
Nov  4 18:04:49.526: INFO: Created: latency-svc-kfknc
Nov  4 18:04:49.538: INFO: Got endpoints: latency-svc-kfknc [401.009805ms]
Nov  4 18:04:49.557: INFO: Created: latency-svc-878sr
Nov  4 18:04:49.589: INFO: Created: latency-svc-9qpsf
Nov  4 18:04:49.589: INFO: Got endpoints: latency-svc-878sr [394.659257ms]
Nov  4 18:04:49.598: INFO: Got endpoints: latency-svc-9qpsf [382.235548ms]
Nov  4 18:04:49.607: INFO: Created: latency-svc-sk6r8
Nov  4 18:04:49.619: INFO: Got endpoints: latency-svc-sk6r8 [382.909332ms]
Nov  4 18:04:49.633: INFO: Created: latency-svc-95hg5
Nov  4 18:04:49.644: INFO: Got endpoints: latency-svc-95hg5 [384.119974ms]
Nov  4 18:04:49.662: INFO: Created: latency-svc-8jdk5
Nov  4 18:04:49.681: INFO: Got endpoints: latency-svc-8jdk5 [402.620295ms]
Nov  4 18:04:49.707: INFO: Created: latency-svc-cgr7d
Nov  4 18:04:49.710: INFO: Got endpoints: latency-svc-cgr7d [393.386273ms]
Nov  4 18:04:49.719: INFO: Created: latency-svc-s6rhc
Nov  4 18:04:49.730: INFO: Got endpoints: latency-svc-s6rhc [398.877952ms]
Nov  4 18:04:49.752: INFO: Created: latency-svc-psf26
Nov  4 18:04:49.768: INFO: Got endpoints: latency-svc-psf26 [408.173435ms]
Nov  4 18:04:49.786: INFO: Created: latency-svc-st2dj
Nov  4 18:04:49.797: INFO: Got endpoints: latency-svc-st2dj [405.850854ms]
Nov  4 18:04:49.808: INFO: Created: latency-svc-b88cw
Nov  4 18:04:49.829: INFO: Got endpoints: latency-svc-b88cw [414.793533ms]
Nov  4 18:04:49.843: INFO: Created: latency-svc-xv8v2
Nov  4 18:04:49.855: INFO: Got endpoints: latency-svc-xv8v2 [412.230428ms]
Nov  4 18:04:49.866: INFO: Created: latency-svc-jnxvs
Nov  4 18:04:49.887: INFO: Got endpoints: latency-svc-jnxvs [422.170599ms]
Nov  4 18:04:49.895: INFO: Created: latency-svc-5mxvv
Nov  4 18:04:49.912: INFO: Got endpoints: latency-svc-5mxvv [419.363012ms]
Nov  4 18:04:49.922: INFO: Created: latency-svc-pqv9r
Nov  4 18:04:49.935: INFO: Got endpoints: latency-svc-pqv9r [417.012171ms]
Nov  4 18:04:49.944: INFO: Created: latency-svc-cvk74
Nov  4 18:04:49.958: INFO: Got endpoints: latency-svc-cvk74 [419.793574ms]
Nov  4 18:04:49.971: INFO: Created: latency-svc-dfstp
Nov  4 18:04:49.982: INFO: Got endpoints: latency-svc-dfstp [393.075547ms]
Nov  4 18:04:49.996: INFO: Created: latency-svc-jrthr
Nov  4 18:04:50.012: INFO: Got endpoints: latency-svc-jrthr [413.424219ms]
Nov  4 18:04:50.038: INFO: Created: latency-svc-jw7qr
Nov  4 18:04:50.039: INFO: Got endpoints: latency-svc-jw7qr [420.14994ms]
Nov  4 18:04:50.050: INFO: Created: latency-svc-x7vrf
Nov  4 18:04:50.063: INFO: Got endpoints: latency-svc-x7vrf [419.072004ms]
Nov  4 18:04:50.074: INFO: Created: latency-svc-fxflq
Nov  4 18:04:50.088: INFO: Got endpoints: latency-svc-fxflq [406.746152ms]
Nov  4 18:04:50.099: INFO: Created: latency-svc-b9j9z
Nov  4 18:04:50.117: INFO: Got endpoints: latency-svc-b9j9z [406.432121ms]
Nov  4 18:04:50.126: INFO: Created: latency-svc-hlzsv
Nov  4 18:04:50.141: INFO: Got endpoints: latency-svc-hlzsv [411.005406ms]
Nov  4 18:04:50.154: INFO: Created: latency-svc-2bjc8
Nov  4 18:04:50.166: INFO: Got endpoints: latency-svc-2bjc8 [397.906692ms]
Nov  4 18:04:50.177: INFO: Created: latency-svc-m7l6b
Nov  4 18:04:50.190: INFO: Got endpoints: latency-svc-m7l6b [392.482695ms]
Nov  4 18:04:50.205: INFO: Created: latency-svc-nz22h
Nov  4 18:04:50.218: INFO: Got endpoints: latency-svc-nz22h [388.955997ms]
Nov  4 18:04:50.230: INFO: Created: latency-svc-pkcxm
Nov  4 18:04:50.239: INFO: Got endpoints: latency-svc-pkcxm [384.338299ms]
Nov  4 18:04:50.253: INFO: Created: latency-svc-f97rw
Nov  4 18:04:50.263: INFO: Got endpoints: latency-svc-f97rw [375.827406ms]
Nov  4 18:04:50.274: INFO: Created: latency-svc-jg6jq
Nov  4 18:04:50.288: INFO: Got endpoints: latency-svc-jg6jq [376.793685ms]
Nov  4 18:04:50.299: INFO: Created: latency-svc-hls7k
Nov  4 18:04:50.312: INFO: Got endpoints: latency-svc-hls7k [377.479749ms]
Nov  4 18:04:50.324: INFO: Created: latency-svc-2xmc8
Nov  4 18:04:50.338: INFO: Got endpoints: latency-svc-2xmc8 [379.35902ms]
Nov  4 18:04:50.347: INFO: Created: latency-svc-w8m8v
Nov  4 18:04:50.359: INFO: Got endpoints: latency-svc-w8m8v [376.003449ms]
Nov  4 18:04:50.368: INFO: Created: latency-svc-f49xj
Nov  4 18:04:50.378: INFO: Got endpoints: latency-svc-f49xj [365.957015ms]
Nov  4 18:04:50.403: INFO: Created: latency-svc-nm9qk
Nov  4 18:04:50.417: INFO: Created: latency-svc-49622
Nov  4 18:04:50.417: INFO: Got endpoints: latency-svc-nm9qk [378.15217ms]
Nov  4 18:04:50.423: INFO: Got endpoints: latency-svc-49622 [360.346105ms]
Nov  4 18:04:50.434: INFO: Created: latency-svc-42s2m
Nov  4 18:04:50.449: INFO: Got endpoints: latency-svc-42s2m [360.78026ms]
Nov  4 18:04:50.468: INFO: Created: latency-svc-4h2qs
Nov  4 18:04:50.487: INFO: Got endpoints: latency-svc-4h2qs [370.288269ms]
Nov  4 18:04:50.493: INFO: Created: latency-svc-2hpk4
Nov  4 18:04:50.509: INFO: Got endpoints: latency-svc-2hpk4 [367.183735ms]
Nov  4 18:04:50.534: INFO: Created: latency-svc-p4rlj
Nov  4 18:04:50.545: INFO: Got endpoints: latency-svc-p4rlj [378.950682ms]
Nov  4 18:04:50.566: INFO: Created: latency-svc-55ddm
Nov  4 18:04:50.568: INFO: Got endpoints: latency-svc-55ddm [378.097514ms]
Nov  4 18:04:50.592: INFO: Created: latency-svc-ssczn
Nov  4 18:04:50.600: INFO: Got endpoints: latency-svc-ssczn [381.930346ms]
Nov  4 18:04:50.611: INFO: Created: latency-svc-hlhlx
Nov  4 18:04:50.621: INFO: Got endpoints: latency-svc-hlhlx [381.774204ms]
Nov  4 18:04:50.633: INFO: Created: latency-svc-v8rd9
Nov  4 18:04:50.645: INFO: Got endpoints: latency-svc-v8rd9 [381.661629ms]
Nov  4 18:04:50.654: INFO: Created: latency-svc-24kxl
Nov  4 18:04:50.667: INFO: Got endpoints: latency-svc-24kxl [378.045821ms]
Nov  4 18:04:50.678: INFO: Created: latency-svc-qg2x4
Nov  4 18:04:50.694: INFO: Got endpoints: latency-svc-qg2x4 [380.958254ms]
Nov  4 18:04:50.702: INFO: Created: latency-svc-4tt29
Nov  4 18:04:50.714: INFO: Got endpoints: latency-svc-4tt29 [376.623919ms]
Nov  4 18:04:50.725: INFO: Created: latency-svc-d86xh
Nov  4 18:04:50.740: INFO: Got endpoints: latency-svc-d86xh [380.943139ms]
Nov  4 18:04:50.753: INFO: Created: latency-svc-mvs9j
Nov  4 18:04:50.764: INFO: Got endpoints: latency-svc-mvs9j [386.453632ms]
Nov  4 18:04:50.773: INFO: Created: latency-svc-lzqrq
Nov  4 18:04:50.785: INFO: Got endpoints: latency-svc-lzqrq [367.590959ms]
Nov  4 18:04:50.795: INFO: Created: latency-svc-xb95z
Nov  4 18:04:50.806: INFO: Got endpoints: latency-svc-xb95z [383.302347ms]
Nov  4 18:04:50.818: INFO: Created: latency-svc-hmkw7
Nov  4 18:04:50.828: INFO: Got endpoints: latency-svc-hmkw7 [379.527587ms]
Nov  4 18:04:50.839: INFO: Created: latency-svc-qlmz5
Nov  4 18:04:50.850: INFO: Got endpoints: latency-svc-qlmz5 [362.88347ms]
Nov  4 18:04:50.860: INFO: Created: latency-svc-l6j4s
Nov  4 18:04:50.877: INFO: Got endpoints: latency-svc-l6j4s [367.745588ms]
Nov  4 18:04:50.898: INFO: Created: latency-svc-rb5rt
Nov  4 18:04:50.899: INFO: Got endpoints: latency-svc-rb5rt [353.856379ms]
Nov  4 18:04:50.913: INFO: Created: latency-svc-95msr
Nov  4 18:04:50.923: INFO: Got endpoints: latency-svc-95msr [354.056763ms]
Nov  4 18:04:50.930: INFO: Created: latency-svc-dg8s9
Nov  4 18:04:50.942: INFO: Got endpoints: latency-svc-dg8s9 [342.097404ms]
Nov  4 18:04:50.951: INFO: Created: latency-svc-4jd2n
Nov  4 18:04:50.963: INFO: Got endpoints: latency-svc-4jd2n [341.653549ms]
Nov  4 18:04:50.975: INFO: Created: latency-svc-9qtln
Nov  4 18:04:50.982: INFO: Got endpoints: latency-svc-9qtln [337.195916ms]
Nov  4 18:04:50.996: INFO: Created: latency-svc-fcqwn
Nov  4 18:04:51.008: INFO: Got endpoints: latency-svc-fcqwn [340.932111ms]
Nov  4 18:04:51.032: INFO: Created: latency-svc-vt8lj
Nov  4 18:04:51.032: INFO: Got endpoints: latency-svc-vt8lj [338.815274ms]
Nov  4 18:04:51.041: INFO: Created: latency-svc-jwbcz
Nov  4 18:04:51.051: INFO: Got endpoints: latency-svc-jwbcz [337.172029ms]
Nov  4 18:04:51.061: INFO: Created: latency-svc-4hckv
Nov  4 18:04:51.073: INFO: Got endpoints: latency-svc-4hckv [332.977476ms]
Nov  4 18:04:51.083: INFO: Created: latency-svc-xgpvr
Nov  4 18:04:51.098: INFO: Got endpoints: latency-svc-xgpvr [334.02691ms]
Nov  4 18:04:51.108: INFO: Created: latency-svc-wjlm7
Nov  4 18:04:51.118: INFO: Got endpoints: latency-svc-wjlm7 [332.155726ms]
Nov  4 18:04:51.124: INFO: Created: latency-svc-x246w
Nov  4 18:04:51.135: INFO: Got endpoints: latency-svc-x246w [328.86687ms]
Nov  4 18:04:51.144: INFO: Created: latency-svc-dck5n
Nov  4 18:04:51.159: INFO: Got endpoints: latency-svc-dck5n [330.322967ms]
Nov  4 18:04:51.169: INFO: Created: latency-svc-ff7h4
Nov  4 18:04:51.181: INFO: Got endpoints: latency-svc-ff7h4 [330.575403ms]
Nov  4 18:04:51.190: INFO: Created: latency-svc-l25h6
Nov  4 18:04:51.208: INFO: Got endpoints: latency-svc-l25h6 [330.882968ms]
Nov  4 18:04:51.213: INFO: Created: latency-svc-s2f24
Nov  4 18:04:51.222: INFO: Got endpoints: latency-svc-s2f24 [322.928531ms]
Nov  4 18:04:51.236: INFO: Created: latency-svc-md794
Nov  4 18:04:51.248: INFO: Got endpoints: latency-svc-md794 [325.243741ms]
Nov  4 18:04:51.257: INFO: Created: latency-svc-lnpsp
Nov  4 18:04:51.277: INFO: Got endpoints: latency-svc-lnpsp [335.211373ms]
Nov  4 18:04:51.288: INFO: Created: latency-svc-x86s9
Nov  4 18:04:51.299: INFO: Got endpoints: latency-svc-x86s9 [336.039217ms]
Nov  4 18:04:51.315: INFO: Created: latency-svc-8m5p9
Nov  4 18:04:51.328: INFO: Got endpoints: latency-svc-8m5p9 [345.882678ms]
Nov  4 18:04:51.339: INFO: Created: latency-svc-4msl2
Nov  4 18:04:51.350: INFO: Got endpoints: latency-svc-4msl2 [50.949227ms]
Nov  4 18:04:51.364: INFO: Created: latency-svc-xx9xv
Nov  4 18:04:51.375: INFO: Got endpoints: latency-svc-xx9xv [367.152842ms]
Nov  4 18:04:51.391: INFO: Created: latency-svc-8l2qq
Nov  4 18:04:51.411: INFO: Got endpoints: latency-svc-8l2qq [378.423872ms]
Nov  4 18:04:51.420: INFO: Created: latency-svc-xxqkz
Nov  4 18:04:51.430: INFO: Got endpoints: latency-svc-xxqkz [378.811981ms]
Nov  4 18:04:51.444: INFO: Created: latency-svc-rtw4d
Nov  4 18:04:51.457: INFO: Got endpoints: latency-svc-rtw4d [383.727818ms]
Nov  4 18:04:51.481: INFO: Created: latency-svc-s49wq
Nov  4 18:04:51.494: INFO: Got endpoints: latency-svc-s49wq [395.175371ms]
Nov  4 18:04:51.509: INFO: Created: latency-svc-z4t4m
Nov  4 18:04:51.519: INFO: Got endpoints: latency-svc-z4t4m [401.38558ms]
Nov  4 18:04:51.528: INFO: Created: latency-svc-b9529
Nov  4 18:04:51.540: INFO: Got endpoints: latency-svc-b9529 [404.599811ms]
Nov  4 18:04:51.550: INFO: Created: latency-svc-9z4jf
Nov  4 18:04:51.563: INFO: Got endpoints: latency-svc-9z4jf [404.180073ms]
Nov  4 18:04:51.575: INFO: Created: latency-svc-th85s
Nov  4 18:04:51.587: INFO: Got endpoints: latency-svc-th85s [406.09413ms]
Nov  4 18:04:51.608: INFO: Created: latency-svc-49db9
Nov  4 18:04:51.618: INFO: Got endpoints: latency-svc-49db9 [410.403998ms]
Nov  4 18:04:51.653: INFO: Created: latency-svc-zj486
Nov  4 18:04:51.653: INFO: Created: latency-svc-chx4b
Nov  4 18:04:51.653: INFO: Got endpoints: latency-svc-chx4b [430.742112ms]
Nov  4 18:04:51.663: INFO: Got endpoints: latency-svc-zj486 [414.928243ms]
Nov  4 18:04:51.675: INFO: Created: latency-svc-npd4j
Nov  4 18:04:51.688: INFO: Got endpoints: latency-svc-npd4j [410.05241ms]
Nov  4 18:04:51.700: INFO: Created: latency-svc-dcq8g
Nov  4 18:04:51.713: INFO: Got endpoints: latency-svc-dcq8g [384.824903ms]
Nov  4 18:04:51.723: INFO: Created: latency-svc-2pngg
Nov  4 18:04:51.736: INFO: Got endpoints: latency-svc-2pngg [385.387692ms]
Nov  4 18:04:51.750: INFO: Created: latency-svc-hw7rd
Nov  4 18:04:51.767: INFO: Got endpoints: latency-svc-hw7rd [392.409336ms]
Nov  4 18:04:51.785: INFO: Created: latency-svc-8ct96
Nov  4 18:04:51.797: INFO: Got endpoints: latency-svc-8ct96 [386.409658ms]
Nov  4 18:04:51.808: INFO: Created: latency-svc-lfzt2
Nov  4 18:04:51.821: INFO: Got endpoints: latency-svc-lfzt2 [390.178217ms]
Nov  4 18:04:51.832: INFO: Created: latency-svc-zqkwj
Nov  4 18:04:51.843: INFO: Got endpoints: latency-svc-zqkwj [386.340184ms]
Nov  4 18:04:51.855: INFO: Created: latency-svc-rrjwr
Nov  4 18:04:51.874: INFO: Got endpoints: latency-svc-rrjwr [379.785851ms]
Nov  4 18:04:51.874: INFO: Created: latency-svc-sc6gc
Nov  4 18:04:51.886: INFO: Got endpoints: latency-svc-sc6gc [366.42617ms]
Nov  4 18:04:51.916: INFO: Created: latency-svc-74vfj
Nov  4 18:04:51.926: INFO: Got endpoints: latency-svc-74vfj [386.325462ms]
Nov  4 18:04:51.935: INFO: Created: latency-svc-xfmf8
Nov  4 18:04:51.947: INFO: Got endpoints: latency-svc-xfmf8 [383.447136ms]
Nov  4 18:04:51.959: INFO: Created: latency-svc-xgplc
Nov  4 18:04:51.974: INFO: Got endpoints: latency-svc-xgplc [386.536104ms]
Nov  4 18:04:51.977: INFO: Created: latency-svc-p6xtk
Nov  4 18:04:51.989: INFO: Got endpoints: latency-svc-p6xtk [370.307144ms]
Nov  4 18:04:52.001: INFO: Created: latency-svc-7sp4z
Nov  4 18:04:52.012: INFO: Got endpoints: latency-svc-7sp4z [359.26754ms]
Nov  4 18:04:52.027: INFO: Created: latency-svc-bg666
Nov  4 18:04:52.039: INFO: Got endpoints: latency-svc-bg666 [376.118268ms]
Nov  4 18:04:52.052: INFO: Created: latency-svc-cq7qh
Nov  4 18:04:52.067: INFO: Got endpoints: latency-svc-cq7qh [379.789863ms]
Nov  4 18:04:52.075: INFO: Created: latency-svc-bn4hd
Nov  4 18:04:52.089: INFO: Got endpoints: latency-svc-bn4hd [376.152439ms]
Nov  4 18:04:52.110: INFO: Created: latency-svc-8xn9c
Nov  4 18:04:52.122: INFO: Got endpoints: latency-svc-8xn9c [386.586767ms]
Nov  4 18:04:52.131: INFO: Created: latency-svc-2pzgn
Nov  4 18:04:52.139: INFO: Got endpoints: latency-svc-2pzgn [371.677913ms]
Nov  4 18:04:52.155: INFO: Created: latency-svc-jw6zd
Nov  4 18:04:52.167: INFO: Got endpoints: latency-svc-jw6zd [369.193206ms]
Nov  4 18:04:52.182: INFO: Created: latency-svc-n9djh
Nov  4 18:04:52.190: INFO: Got endpoints: latency-svc-n9djh [369.827762ms]
Nov  4 18:04:52.201: INFO: Created: latency-svc-wb9l5
Nov  4 18:04:52.211: INFO: Got endpoints: latency-svc-wb9l5 [367.667466ms]
Nov  4 18:04:52.223: INFO: Created: latency-svc-4zg6k
Nov  4 18:04:52.234: INFO: Got endpoints: latency-svc-4zg6k [359.889401ms]
Nov  4 18:04:52.258: INFO: Created: latency-svc-k6vc7
Nov  4 18:04:52.258: INFO: Got endpoints: latency-svc-k6vc7 [372.75965ms]
Nov  4 18:04:52.265: INFO: Created: latency-svc-hvvxq
Nov  4 18:04:52.277: INFO: Got endpoints: latency-svc-hvvxq [350.641417ms]
Nov  4 18:04:52.288: INFO: Created: latency-svc-6m8x8
Nov  4 18:04:52.299: INFO: Got endpoints: latency-svc-6m8x8 [352.582592ms]
Nov  4 18:04:52.309: INFO: Created: latency-svc-nvcpl
Nov  4 18:04:52.321: INFO: Got endpoints: latency-svc-nvcpl [347.087136ms]
Nov  4 18:04:52.333: INFO: Created: latency-svc-qs75x
Nov  4 18:04:52.347: INFO: Got endpoints: latency-svc-qs75x [357.602278ms]
Nov  4 18:04:52.359: INFO: Created: latency-svc-s9r8w
Nov  4 18:04:52.366: INFO: Got endpoints: latency-svc-s9r8w [353.744755ms]
Nov  4 18:04:52.381: INFO: Created: latency-svc-6bmhz
Nov  4 18:04:52.392: INFO: Got endpoints: latency-svc-6bmhz [353.264556ms]
Nov  4 18:04:52.409: INFO: Created: latency-svc-tp9qs
Nov  4 18:04:52.419: INFO: Got endpoints: latency-svc-tp9qs [351.951239ms]
Nov  4 18:04:52.432: INFO: Created: latency-svc-ctd9s
Nov  4 18:04:52.454: INFO: Got endpoints: latency-svc-ctd9s [364.471483ms]
Nov  4 18:04:52.460: INFO: Created: latency-svc-8cmtt
Nov  4 18:04:52.468: INFO: Got endpoints: latency-svc-8cmtt [345.396816ms]
Nov  4 18:04:52.477: INFO: Created: latency-svc-nq9v2
Nov  4 18:04:52.488: INFO: Got endpoints: latency-svc-nq9v2 [349.097811ms]
Nov  4 18:04:52.506: INFO: Created: latency-svc-ngtcv
Nov  4 18:04:52.512: INFO: Got endpoints: latency-svc-ngtcv [344.779506ms]
Nov  4 18:04:52.522: INFO: Created: latency-svc-85lbv
Nov  4 18:04:52.538: INFO: Got endpoints: latency-svc-85lbv [347.934844ms]
Nov  4 18:04:52.552: INFO: Created: latency-svc-cqcmb
Nov  4 18:04:52.563: INFO: Got endpoints: latency-svc-cqcmb [351.449407ms]
Nov  4 18:04:52.576: INFO: Created: latency-svc-4d8jg
Nov  4 18:04:52.588: INFO: Got endpoints: latency-svc-4d8jg [354.232918ms]
Nov  4 18:04:52.598: INFO: Created: latency-svc-t6ld7
Nov  4 18:04:52.611: INFO: Got endpoints: latency-svc-t6ld7 [352.782856ms]
Nov  4 18:04:52.623: INFO: Created: latency-svc-85dst
Nov  4 18:04:52.641: INFO: Got endpoints: latency-svc-85dst [363.526141ms]
Nov  4 18:04:52.646: INFO: Created: latency-svc-5mhc7
Nov  4 18:04:52.659: INFO: Got endpoints: latency-svc-5mhc7 [360.053327ms]
Nov  4 18:04:52.669: INFO: Created: latency-svc-k8j7m
Nov  4 18:04:52.680: INFO: Got endpoints: latency-svc-k8j7m [358.779481ms]
Nov  4 18:04:52.693: INFO: Created: latency-svc-9b4ft
Nov  4 18:04:52.706: INFO: Got endpoints: latency-svc-9b4ft [359.521512ms]
Nov  4 18:04:52.719: INFO: Created: latency-svc-4hnc9
Nov  4 18:04:52.732: INFO: Got endpoints: latency-svc-4hnc9 [365.71106ms]
Nov  4 18:04:52.745: INFO: Created: latency-svc-6rjb6
Nov  4 18:04:52.759: INFO: Got endpoints: latency-svc-6rjb6 [366.874126ms]
Nov  4 18:04:52.773: INFO: Created: latency-svc-fgmhf
Nov  4 18:04:52.783: INFO: Got endpoints: latency-svc-fgmhf [363.305267ms]
Nov  4 18:04:52.806: INFO: Created: latency-svc-mdpb9
Nov  4 18:04:52.819: INFO: Got endpoints: latency-svc-mdpb9 [365.346402ms]
Nov  4 18:04:52.830: INFO: Created: latency-svc-8p7lb
Nov  4 18:04:52.845: INFO: Got endpoints: latency-svc-8p7lb [376.758072ms]
Nov  4 18:04:52.854: INFO: Created: latency-svc-bfbmm
Nov  4 18:04:52.866: INFO: Got endpoints: latency-svc-bfbmm [377.367703ms]
Nov  4 18:04:52.886: INFO: Created: latency-svc-782jp
Nov  4 18:04:52.890: INFO: Got endpoints: latency-svc-782jp [378.158183ms]
Nov  4 18:04:52.900: INFO: Created: latency-svc-hh8cx
Nov  4 18:04:52.918: INFO: Got endpoints: latency-svc-hh8cx [379.364417ms]
Nov  4 18:04:52.925: INFO: Created: latency-svc-m98q4
Nov  4 18:04:52.941: INFO: Got endpoints: latency-svc-m98q4 [377.872518ms]
Nov  4 18:04:52.952: INFO: Created: latency-svc-j9kzp
Nov  4 18:04:52.964: INFO: Got endpoints: latency-svc-j9kzp [375.617406ms]
Nov  4 18:04:52.972: INFO: Created: latency-svc-zs89f
Nov  4 18:04:52.985: INFO: Got endpoints: latency-svc-zs89f [373.501652ms]
Nov  4 18:04:52.996: INFO: Created: latency-svc-bmslh
Nov  4 18:04:53.008: INFO: Got endpoints: latency-svc-bmslh [366.961454ms]
Nov  4 18:04:53.039: INFO: Created: latency-svc-bgf67
Nov  4 18:04:53.063: INFO: Got endpoints: latency-svc-bgf67 [404.050458ms]
Nov  4 18:04:53.074: INFO: Created: latency-svc-x5j7b
Nov  4 18:04:53.099: INFO: Got endpoints: latency-svc-x5j7b [418.022019ms]
Nov  4 18:04:53.099: INFO: Created: latency-svc-dw2mt
Nov  4 18:04:53.115: INFO: Got endpoints: latency-svc-dw2mt [408.486189ms]
Nov  4 18:04:53.134: INFO: Created: latency-svc-6snzn
Nov  4 18:04:53.136: INFO: Got endpoints: latency-svc-6snzn [403.456529ms]
Nov  4 18:04:53.148: INFO: Created: latency-svc-8kpr2
Nov  4 18:04:53.160: INFO: Got endpoints: latency-svc-8kpr2 [400.428032ms]
Nov  4 18:04:53.173: INFO: Created: latency-svc-j2p78
Nov  4 18:04:53.186: INFO: Got endpoints: latency-svc-j2p78 [402.752673ms]
Nov  4 18:04:53.195: INFO: Created: latency-svc-hg649
Nov  4 18:04:53.207: INFO: Got endpoints: latency-svc-hg649 [388.290672ms]
Nov  4 18:04:53.225: INFO: Created: latency-svc-4xnqs
Nov  4 18:04:53.237: INFO: Got endpoints: latency-svc-4xnqs [392.154884ms]
Nov  4 18:04:53.251: INFO: Created: latency-svc-xg8xj
Nov  4 18:04:53.266: INFO: Got endpoints: latency-svc-xg8xj [400.132002ms]
Nov  4 18:04:53.276: INFO: Created: latency-svc-h89tn
Nov  4 18:04:53.289: INFO: Got endpoints: latency-svc-h89tn [398.71857ms]
Nov  4 18:04:53.304: INFO: Created: latency-svc-n7tcb
Nov  4 18:04:53.313: INFO: Got endpoints: latency-svc-n7tcb [395.2258ms]
Nov  4 18:04:53.338: INFO: Created: latency-svc-rvxdz
Nov  4 18:04:53.439: INFO: Created: latency-svc-vgxpf
Nov  4 18:04:53.439: INFO: Created: latency-svc-7hdmm
Nov  4 18:04:53.440: INFO: Created: latency-svc-7nqbt
Nov  4 18:04:53.440: INFO: Got endpoints: latency-svc-rvxdz [498.444004ms]
Nov  4 18:04:53.440: INFO: Created: latency-svc-4bzzf
Nov  4 18:04:53.446: INFO: Got endpoints: latency-svc-vgxpf [437.48426ms]
Nov  4 18:04:53.446: INFO: Got endpoints: latency-svc-7hdmm [460.820106ms]
Nov  4 18:04:53.446: INFO: Got endpoints: latency-svc-7nqbt [482.687368ms]
Nov  4 18:04:53.446: INFO: Got endpoints: latency-svc-4bzzf [382.741728ms]
Nov  4 18:04:53.459: INFO: Created: latency-svc-h9rdd
Nov  4 18:04:53.476: INFO: Got endpoints: latency-svc-h9rdd [376.966111ms]
Nov  4 18:04:53.490: INFO: Created: latency-svc-4pmsr
Nov  4 18:04:53.505: INFO: Got endpoints: latency-svc-4pmsr [390.613782ms]
Nov  4 18:04:53.523: INFO: Created: latency-svc-w7qwl
Nov  4 18:04:53.544: INFO: Created: latency-svc-z2dtv
Nov  4 18:04:53.544: INFO: Got endpoints: latency-svc-w7qwl [408.143388ms]
Nov  4 18:04:53.556: INFO: Got endpoints: latency-svc-z2dtv [395.818613ms]
Nov  4 18:04:53.565: INFO: Created: latency-svc-skm77
Nov  4 18:04:53.576: INFO: Got endpoints: latency-svc-skm77 [389.420626ms]
Nov  4 18:04:53.590: INFO: Created: latency-svc-nd752
Nov  4 18:04:53.611: INFO: Got endpoints: latency-svc-nd752 [402.859119ms]
Nov  4 18:04:53.621: INFO: Created: latency-svc-ljlcn
Nov  4 18:04:53.643: INFO: Got endpoints: latency-svc-ljlcn [405.277107ms]
Nov  4 18:04:53.649: INFO: Created: latency-svc-mw28z
Nov  4 18:04:53.663: INFO: Got endpoints: latency-svc-mw28z [397.260818ms]
Nov  4 18:04:53.675: INFO: Created: latency-svc-785br
Nov  4 18:04:53.689: INFO: Got endpoints: latency-svc-785br [399.957905ms]
Nov  4 18:04:53.697: INFO: Created: latency-svc-58hpp
Nov  4 18:04:53.708: INFO: Got endpoints: latency-svc-58hpp [394.324799ms]
Nov  4 18:04:53.732: INFO: Created: latency-svc-s8x6c
Nov  4 18:04:53.744: INFO: Got endpoints: latency-svc-s8x6c [298.373398ms]
Nov  4 18:04:53.755: INFO: Created: latency-svc-9fhrm
Nov  4 18:04:53.777: INFO: Got endpoints: latency-svc-9fhrm [336.821925ms]
Nov  4 18:04:53.791: INFO: Created: latency-svc-khrp2
Nov  4 18:04:53.803: INFO: Got endpoints: latency-svc-khrp2 [356.338322ms]
Nov  4 18:04:53.818: INFO: Created: latency-svc-pdfww
Nov  4 18:04:53.834: INFO: Got endpoints: latency-svc-pdfww [387.550904ms]
Nov  4 18:04:53.845: INFO: Created: latency-svc-9n5bd
Nov  4 18:04:53.856: INFO: Got endpoints: latency-svc-9n5bd [409.238453ms]
Nov  4 18:04:53.879: INFO: Created: latency-svc-fzqdl
Nov  4 18:04:53.894: INFO: Got endpoints: latency-svc-fzqdl [418.251611ms]
Nov  4 18:04:53.907: INFO: Created: latency-svc-sp5js
Nov  4 18:04:53.924: INFO: Got endpoints: latency-svc-sp5js [419.0196ms]
Nov  4 18:04:53.936: INFO: Created: latency-svc-f4st9
Nov  4 18:04:53.948: INFO: Got endpoints: latency-svc-f4st9 [404.338095ms]
Nov  4 18:04:53.962: INFO: Created: latency-svc-dl8pk
Nov  4 18:04:53.976: INFO: Got endpoints: latency-svc-dl8pk [420.726979ms]
Nov  4 18:04:53.990: INFO: Created: latency-svc-7f4v7
Nov  4 18:04:54.003: INFO: Got endpoints: latency-svc-7f4v7 [427.171784ms]
Nov  4 18:04:54.019: INFO: Created: latency-svc-7px6p
Nov  4 18:04:54.046: INFO: Got endpoints: latency-svc-7px6p [435.348375ms]
Nov  4 18:04:54.053: INFO: Created: latency-svc-r94rm
Nov  4 18:04:54.067: INFO: Got endpoints: latency-svc-r94rm [424.369976ms]
Nov  4 18:04:54.087: INFO: Created: latency-svc-pgdt8
Nov  4 18:04:54.105: INFO: Got endpoints: latency-svc-pgdt8 [440.90665ms]
Nov  4 18:04:54.116: INFO: Created: latency-svc-r2lwj
Nov  4 18:04:54.127: INFO: Got endpoints: latency-svc-r2lwj [437.764049ms]
Nov  4 18:04:54.149: INFO: Created: latency-svc-xc4n5
Nov  4 18:04:54.160: INFO: Got endpoints: latency-svc-xc4n5 [451.971535ms]
Nov  4 18:04:54.172: INFO: Created: latency-svc-fqfcc
Nov  4 18:04:54.184: INFO: Got endpoints: latency-svc-fqfcc [439.301804ms]
Nov  4 18:04:54.196: INFO: Created: latency-svc-kk9k9
Nov  4 18:04:54.208: INFO: Got endpoints: latency-svc-kk9k9 [430.912653ms]
Nov  4 18:04:54.218: INFO: Created: latency-svc-g5hbn
Nov  4 18:04:54.231: INFO: Got endpoints: latency-svc-g5hbn [427.953515ms]
Nov  4 18:04:54.241: INFO: Created: latency-svc-xqr2g
Nov  4 18:04:54.252: INFO: Got endpoints: latency-svc-xqr2g [418.136034ms]
Nov  4 18:04:54.252: INFO: Latencies: [50.949227ms 57.082824ms 77.985156ms 98.25101ms 121.647656ms 140.914738ms 179.457238ms 193.595136ms 221.990096ms 253.909145ms 276.702122ms 298.373398ms 304.771437ms 322.928531ms 325.243741ms 327.142586ms 328.86687ms 330.322967ms 330.575403ms 330.882968ms 332.155726ms 332.977476ms 334.02691ms 335.211373ms 336.039217ms 336.821925ms 337.172029ms 337.195916ms 338.815274ms 340.932111ms 341.653549ms 342.097404ms 344.779506ms 345.396816ms 345.882678ms 347.087136ms 347.934844ms 349.097811ms 350.641417ms 351.449407ms 351.951239ms 352.582592ms 352.782856ms 353.264556ms 353.744755ms 353.856379ms 354.048356ms 354.056763ms 354.232918ms 356.338322ms 357.602278ms 358.779481ms 359.26754ms 359.521512ms 359.889401ms 360.053327ms 360.346105ms 360.78026ms 362.88347ms 363.305267ms 363.526141ms 364.471483ms 365.346402ms 365.71106ms 365.957015ms 366.42617ms 366.874126ms 366.961454ms 367.152842ms 367.183735ms 367.590959ms 367.667466ms 367.745588ms 369.193206ms 369.827762ms 370.288269ms 370.307144ms 371.677913ms 372.75965ms 373.501652ms 375.617406ms 375.827406ms 376.003449ms 376.118268ms 376.152439ms 376.623919ms 376.758072ms 376.793685ms 376.966111ms 377.367703ms 377.479749ms 377.872518ms 378.045821ms 378.097514ms 378.15217ms 378.158183ms 378.423872ms 378.811981ms 378.950682ms 379.35902ms 379.364417ms 379.527587ms 379.781623ms 379.785851ms 379.789863ms 380.943139ms 380.958254ms 381.661629ms 381.774204ms 381.930346ms 382.235548ms 382.741728ms 382.909332ms 383.302347ms 383.447136ms 383.727818ms 384.119974ms 384.338299ms 384.824903ms 385.387692ms 386.325462ms 386.340184ms 386.409658ms 386.453632ms 386.536104ms 386.586767ms 387.550904ms 388.290672ms 388.955997ms 389.420626ms 390.178217ms 390.613782ms 392.154884ms 392.409336ms 392.482695ms 393.075547ms 393.386273ms 394.324799ms 394.659257ms 395.175371ms 395.2258ms 395.818613ms 397.260818ms 397.906692ms 398.71857ms 398.877952ms 399.957905ms 400.132002ms 400.428032ms 401.009805ms 401.38558ms 402.620295ms 402.752673ms 402.859119ms 403.456529ms 404.050458ms 404.180073ms 404.338095ms 404.599811ms 405.277107ms 405.850854ms 406.09413ms 406.432121ms 406.746152ms 408.143388ms 408.173435ms 408.486189ms 409.238453ms 410.05241ms 410.403998ms 411.005406ms 412.230428ms 413.424219ms 414.793533ms 414.928243ms 417.012171ms 418.022019ms 418.136034ms 418.251611ms 419.0196ms 419.072004ms 419.363012ms 419.793574ms 420.14994ms 420.726979ms 422.170599ms 424.369976ms 427.171784ms 427.953515ms 430.742112ms 430.912653ms 435.348375ms 437.48426ms 437.764049ms 439.301804ms 440.90665ms 451.971535ms 460.820106ms 482.687368ms 498.444004ms]
Nov  4 18:04:54.252: INFO: 50 %ile: 379.364417ms
Nov  4 18:04:54.253: INFO: 90 %ile: 419.072004ms
Nov  4 18:04:54.253: INFO: 99 %ile: 482.687368ms
Nov  4 18:04:54.253: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:04:54.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-731" for this suite.
Nov  4 18:05:22.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:05:22.843: INFO: namespace svc-latency-731 deletion completed in 28.57122199s

• [SLOW TEST:37.223 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:05:22.844: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6419
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Nov  4 18:05:23.117: INFO: Waiting up to 5m0s for pod "client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab" in namespace "containers-6419" to be "success or failure"
Nov  4 18:05:23.128: INFO: Pod "client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.522318ms
Nov  4 18:05:25.138: INFO: Pod "client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021035195s
Nov  4 18:05:27.152: INFO: Pod "client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035366474s
STEP: Saw pod success
Nov  4 18:05:27.152: INFO: Pod "client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab" satisfied condition "success or failure"
Nov  4 18:05:27.165: INFO: Trying to get logs from node 10.93.34.26 pod client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab container test-container: <nil>
STEP: delete the pod
Nov  4 18:05:27.520: INFO: Waiting for pod client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab to disappear
Nov  4 18:05:27.530: INFO: Pod client-containers-49ea010c-d2e4-4a50-8f42-08804995a7ab no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:05:27.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6419" for this suite.
Nov  4 18:05:33.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:05:35.180: INFO: namespace containers-6419 deletion completed in 7.629647587s

• [SLOW TEST:12.336 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:05:35.180: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9732
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:05:35.464: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6" in namespace "downward-api-9732" to be "success or failure"
Nov  4 18:05:35.476: INFO: Pod "downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6": Phase="Pending", Reason="", readiness=false. Elapsed: 11.927693ms
Nov  4 18:05:37.486: INFO: Pod "downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022260981s
STEP: Saw pod success
Nov  4 18:05:37.486: INFO: Pod "downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6" satisfied condition "success or failure"
Nov  4 18:05:37.496: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6 container client-container: <nil>
STEP: delete the pod
Nov  4 18:05:37.563: INFO: Waiting for pod downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6 to disappear
Nov  4 18:05:37.576: INFO: Pod downwardapi-volume-ba59f9f1-9a18-45e6-be04-f4250adc43a6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:05:37.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9732" for this suite.
Nov  4 18:05:43.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:05:44.176: INFO: namespace downward-api-9732 deletion completed in 6.580248791s

• [SLOW TEST:8.996 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:05:44.177: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:05:47.662: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:05:47.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3628" for this suite.
Nov  4 18:05:53.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:05:54.344: INFO: namespace container-runtime-3628 deletion completed in 6.610520962s

• [SLOW TEST:10.167 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:05:54.344: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:05:56.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5117" for this suite.
Nov  4 18:06:08.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:06:09.269: INFO: namespace containers-5117 deletion completed in 12.580146475s

• [SLOW TEST:14.925 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:06:09.269: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-d2bdf104-af3d-4d7a-90a8-7641b6892791
STEP: Creating a pod to test consume secrets
Nov  4 18:06:09.595: INFO: Waiting up to 5m0s for pod "pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875" in namespace "secrets-8475" to be "success or failure"
Nov  4 18:06:09.607: INFO: Pod "pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875": Phase="Pending", Reason="", readiness=false. Elapsed: 12.100253ms
Nov  4 18:06:11.622: INFO: Pod "pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026738422s
STEP: Saw pod success
Nov  4 18:06:11.622: INFO: Pod "pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875" satisfied condition "success or failure"
Nov  4 18:06:11.643: INFO: Trying to get logs from node 10.93.34.26 pod pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:06:11.722: INFO: Waiting for pod pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875 to disappear
Nov  4 18:06:11.737: INFO: Pod pod-secrets-7c03f604-1edd-4046-bbf0-7bc94a2e1875 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:11.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8475" for this suite.
Nov  4 18:06:19.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:06:20.410: INFO: namespace secrets-8475 deletion completed in 8.646547555s

• [SLOW TEST:11.141 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:06:20.410: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8249
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 18:06:24.849: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:24.860: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:06:26.860: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:26.873: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:06:28.860: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:28.878: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:06:30.860: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:30.871: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:06:32.860: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:32.883: INFO: Pod pod-with-poststart-exec-hook still exists
Nov  4 18:06:34.860: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Nov  4 18:06:34.871: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:06:34.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8249" for this suite.
Nov  4 18:07:04.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:07:05.512: INFO: namespace container-lifecycle-hook-8249 deletion completed in 30.619067256s

• [SLOW TEST:45.102 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:07:05.513: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6479
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6479
STEP: Creating statefulset with conflicting port in namespace statefulset-6479
STEP: Waiting until pod test-pod will start running in namespace statefulset-6479
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6479
Nov  4 18:07:07.893: INFO: Observed stateful pod in namespace: statefulset-6479, name: ss-0, uid: a4084db5-d588-47bd-b434-2fe8265476d5, status phase: Pending. Waiting for statefulset controller to delete.
Nov  4 18:07:13.329: INFO: Observed stateful pod in namespace: statefulset-6479, name: ss-0, uid: a4084db5-d588-47bd-b434-2fe8265476d5, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 18:07:13.351: INFO: Observed stateful pod in namespace: statefulset-6479, name: ss-0, uid: a4084db5-d588-47bd-b434-2fe8265476d5, status phase: Failed. Waiting for statefulset controller to delete.
Nov  4 18:07:13.365: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6479
STEP: Removing pod with conflicting port in namespace statefulset-6479
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6479 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:07:17.434: INFO: Deleting all statefulset in ns statefulset-6479
Nov  4 18:07:17.841: INFO: Scaling statefulset ss to 0
Nov  4 18:07:27.898: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:07:27.913: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:07:27.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6479" for this suite.
Nov  4 18:07:36.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:07:36.562: INFO: namespace statefulset-6479 deletion completed in 8.565730391s

• [SLOW TEST:31.050 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:07:36.563: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6017
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6017
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 18:07:36.821: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 18:07:59.057: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.168.81:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6017 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:07:59.057: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:07:59.284: INFO: Found all expected endpoints: [netserver-0]
Nov  4 18:07:59.295: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.75.248:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6017 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:07:59.295: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:07:59.540: INFO: Found all expected endpoints: [netserver-1]
Nov  4 18:07:59.552: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.102.52:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6017 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:07:59.552: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:07:59.843: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:07:59.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6017" for this suite.
Nov  4 18:08:13.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:08:14.509: INFO: namespace pod-network-test-6017 deletion completed in 14.644416852s

• [SLOW TEST:37.947 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:08:14.510: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-4672
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Nov  4 18:08:14.772: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 18:09:14.856: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:09:14.879: INFO: Starting informer...
STEP: Starting pods...
Nov  4 18:09:15.153: INFO: Pod1 is running on 10.93.34.21. Tainting Node
Nov  4 18:09:17.420: INFO: Pod2 is running on 10.93.34.21. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Nov  4 18:09:33.420: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Nov  4 18:09:53.411: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:09:53.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4672" for this suite.
Nov  4 18:10:31.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:10:32.272: INFO: namespace taint-multiple-pods-4672 deletion completed in 38.792648562s

• [SLOW TEST:137.762 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:10:32.273: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5908
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 18:10:32.544: INFO: Waiting up to 5m0s for pod "pod-a567d7a4-1610-4091-b326-2fc250ae5ce7" in namespace "emptydir-5908" to be "success or failure"
Nov  4 18:10:32.557: INFO: Pod "pod-a567d7a4-1610-4091-b326-2fc250ae5ce7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.128174ms
Nov  4 18:10:34.570: INFO: Pod "pod-a567d7a4-1610-4091-b326-2fc250ae5ce7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025828732s
STEP: Saw pod success
Nov  4 18:10:34.570: INFO: Pod "pod-a567d7a4-1610-4091-b326-2fc250ae5ce7" satisfied condition "success or failure"
Nov  4 18:10:34.583: INFO: Trying to get logs from node 10.93.34.21 pod pod-a567d7a4-1610-4091-b326-2fc250ae5ce7 container test-container: <nil>
STEP: delete the pod
Nov  4 18:10:34.730: INFO: Waiting for pod pod-a567d7a4-1610-4091-b326-2fc250ae5ce7 to disappear
Nov  4 18:10:34.739: INFO: Pod pod-a567d7a4-1610-4091-b326-2fc250ae5ce7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:10:34.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5908" for this suite.
Nov  4 18:10:40.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:10:41.337: INFO: namespace emptydir-5908 deletion completed in 6.577494152s

• [SLOW TEST:9.064 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:10:41.337: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5207
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 18:10:46.197: INFO: Successfully updated pod "annotationupdate429ff53a-a25a-4489-bd7a-85d14dcdf6e7"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:10:48.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5207" for this suite.
Nov  4 18:11:18.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:11:20.438: INFO: namespace downward-api-5207 deletion completed in 32.160926331s

• [SLOW TEST:39.101 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:11:20.439: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-8839
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:11:20.702: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:11:21.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8839" for this suite.
Nov  4 18:11:27.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:11:27.985: INFO: namespace custom-resource-definition-8839 deletion completed in 6.638690196s

• [SLOW TEST:7.545 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:11:27.986: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6836
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-bed81dec-cb6b-40f8-9297-5712776736ea in namespace container-probe-6836
Nov  4 18:11:30.277: INFO: Started pod test-webserver-bed81dec-cb6b-40f8-9297-5712776736ea in namespace container-probe-6836
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 18:11:30.295: INFO: Initial restart count of pod test-webserver-bed81dec-cb6b-40f8-9297-5712776736ea is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6836" for this suite.
Nov  4 18:15:38.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:39.105: INFO: namespace container-probe-6836 deletion completed in 8.576740103s

• [SLOW TEST:251.119 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:39.106: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2821
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2821
I1104 18:15:39.485554      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2821, replica count: 2
Nov  4 18:15:42.536: INFO: Creating new exec pod
I1104 18:15:42.536210      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:15:47.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 18:15:48.077: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 18:15:48.077: INFO: stdout: ""
Nov  4 18:15:48.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 172.21.31.154 80'
Nov  4 18:15:48.461: INFO: stderr: "+ nc -zv -t -w 2 172.21.31.154 80\nConnection to 172.21.31.154 80 port [tcp/http] succeeded!\n"
Nov  4 18:15:48.461: INFO: stdout: ""
Nov  4 18:15:48.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 10.93.34.21 32514'
Nov  4 18:15:48.840: INFO: stderr: "+ nc -zv -t -w 2 10.93.34.21 32514\nConnection to 10.93.34.21 32514 port [tcp/32514] succeeded!\n"
Nov  4 18:15:48.840: INFO: stdout: ""
Nov  4 18:15:48.840: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 10.93.34.26 32514'
Nov  4 18:15:49.183: INFO: stderr: "+ nc -zv -t -w 2 10.93.34.26 32514\nConnection to 10.93.34.26 32514 port [tcp/32514] succeeded!\n"
Nov  4 18:15:49.183: INFO: stdout: ""
Nov  4 18:15:49.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 169.63.203.101 32514'
Nov  4 18:15:50.217: INFO: stderr: "+ nc -zv -t -w 2 169.63.203.101 32514\nConnection to 169.63.203.101 32514 port [tcp/32514] succeeded!\n"
Nov  4 18:15:50.217: INFO: stdout: ""
Nov  4 18:15:50.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-2821 execpod9ff6f -- /bin/sh -x -c nc -zv -t -w 2 169.63.203.126 32514'
Nov  4 18:15:50.645: INFO: stderr: "+ nc -zv -t -w 2 169.63.203.126 32514\nConnection to 169.63.203.126 32514 port [tcp/32514] succeeded!\n"
Nov  4 18:15:50.645: INFO: stdout: ""
Nov  4 18:15:50.645: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:15:50.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2821" for this suite.
Nov  4 18:15:58.842: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:15:59.350: INFO: namespace services-2821 deletion completed in 8.569027229s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.244 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:15:59.350: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9734
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:15:59.589: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 18:16:03.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9734 create -f -'
Nov  4 18:16:04.009: INFO: stderr: ""
Nov  4 18:16:04.009: INFO: stdout: "e2e-test-crd-publish-openapi-8245-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 18:16:04.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9734 delete e2e-test-crd-publish-openapi-8245-crds test-cr'
Nov  4 18:16:04.211: INFO: stderr: ""
Nov  4 18:16:04.211: INFO: stdout: "e2e-test-crd-publish-openapi-8245-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Nov  4 18:16:04.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9734 apply -f -'
Nov  4 18:16:04.621: INFO: stderr: ""
Nov  4 18:16:04.621: INFO: stdout: "e2e-test-crd-publish-openapi-8245-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Nov  4 18:16:04.621: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9734 delete e2e-test-crd-publish-openapi-8245-crds test-cr'
Nov  4 18:16:04.805: INFO: stderr: ""
Nov  4 18:16:04.805: INFO: stdout: "e2e-test-crd-publish-openapi-8245-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 18:16:04.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-8245-crds'
Nov  4 18:16:05.158: INFO: stderr: ""
Nov  4 18:16:05.158: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8245-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:08.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9734" for this suite.
Nov  4 18:16:15.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:15.608: INFO: namespace crd-publish-openapi-9734 deletion completed in 6.654955765s

• [SLOW TEST:16.259 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:15.609: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-80014cfc-5920-4481-8814-9753f9e7bc89
STEP: Creating a pod to test consume secrets
Nov  4 18:16:15.923: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792" in namespace "projected-1701" to be "success or failure"
Nov  4 18:16:15.942: INFO: Pod "pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792": Phase="Pending", Reason="", readiness=false. Elapsed: 18.985797ms
Nov  4 18:16:17.963: INFO: Pod "pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.040385312s
STEP: Saw pod success
Nov  4 18:16:17.963: INFO: Pod "pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792" satisfied condition "success or failure"
Nov  4 18:16:17.974: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:16:18.077: INFO: Waiting for pod pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792 to disappear
Nov  4 18:16:18.088: INFO: Pod pod-projected-secrets-2f63388d-d46e-4eb9-ab49-5a054c8c0792 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:18.088: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1701" for this suite.
Nov  4 18:16:24.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:24.699: INFO: namespace projected-1701 deletion completed in 6.588160585s

• [SLOW TEST:9.090 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:24.701: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Nov  4 18:16:24.946: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-229262933 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:25.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4518" for this suite.
Nov  4 18:16:31.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:31.610: INFO: namespace kubectl-4518 deletion completed in 6.537542936s

• [SLOW TEST:6.909 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:31.611: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3966
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-90aba612-b67f-44c4-8a4f-036b60f9ce70
STEP: Creating a pod to test consume secrets
Nov  4 18:16:31.924: INFO: Waiting up to 5m0s for pod "pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480" in namespace "secrets-3966" to be "success or failure"
Nov  4 18:16:31.938: INFO: Pod "pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480": Phase="Pending", Reason="", readiness=false. Elapsed: 13.17779ms
Nov  4 18:16:33.949: INFO: Pod "pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024831838s
STEP: Saw pod success
Nov  4 18:16:33.949: INFO: Pod "pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480" satisfied condition "success or failure"
Nov  4 18:16:33.960: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:16:34.028: INFO: Waiting for pod pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480 to disappear
Nov  4 18:16:34.038: INFO: Pod pod-secrets-38a8d39c-cd59-453b-84dd-ab8682542480 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:16:34.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3966" for this suite.
Nov  4 18:16:42.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:16:42.588: INFO: namespace secrets-3966 deletion completed in 8.528789145s

• [SLOW TEST:10.977 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:16:42.588: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6013
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6013
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 18:16:42.834: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 18:17:05.092: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.102.62 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6013 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:17:05.092: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:17:06.294: INFO: Found all expected endpoints: [netserver-0]
Nov  4 18:17:06.305: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.75.194 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6013 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:17:06.305: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:17:07.539: INFO: Found all expected endpoints: [netserver-1]
Nov  4 18:17:07.554: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.168.84 8081 | grep -v '^\s*$'] Namespace:pod-network-test-6013 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 18:17:07.554: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:17:08.792: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:17:08.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6013" for this suite.
Nov  4 18:17:22.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:17:23.432: INFO: namespace pod-network-test-6013 deletion completed in 14.615838048s

• [SLOW TEST:40.844 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:17:23.433: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-6074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Nov  4 18:17:23.848: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-6074" to be "success or failure"
Nov  4 18:17:23.860: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 11.51243ms
Nov  4 18:17:25.881: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032835157s
STEP: Saw pod success
Nov  4 18:17:25.881: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Nov  4 18:17:25.891: INFO: Trying to get logs from node 10.93.34.21 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Nov  4 18:17:25.961: INFO: Waiting for pod pod-host-path-test to disappear
Nov  4 18:17:25.971: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:17:25.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-6074" for this suite.
Nov  4 18:17:34.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:17:34.649: INFO: namespace hostpath-6074 deletion completed in 8.647834294s

• [SLOW TEST:11.217 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:17:34.650: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Nov  4 18:17:34.973: INFO: Pod name pod-release: Found 0 pods out of 1
Nov  4 18:17:39.987: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:17:40.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7318" for this suite.
Nov  4 18:17:48.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:17:48.740: INFO: namespace replication-controller-7318 deletion completed in 8.68967383s

• [SLOW TEST:14.089 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:17:48.740: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:17:49.052: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"523a5381-4c1f-42f4-abf6-d69869f641bc", Controller:(*bool)(0xc005a6bc6a), BlockOwnerDeletion:(*bool)(0xc005a6bc6b)}}
Nov  4 18:17:49.065: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"f170bf44-d2a0-4a0d-b567-0b5b235726cd", Controller:(*bool)(0xc0050932e6), BlockOwnerDeletion:(*bool)(0xc0050932e7)}}
Nov  4 18:17:49.078: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"eea36527-b745-4e18-bdf0-63976ef0b095", Controller:(*bool)(0xc004f66016), BlockOwnerDeletion:(*bool)(0xc004f66017)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:17:54.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9809" for this suite.
Nov  4 18:18:00.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:18:00.830: INFO: namespace gc-9809 deletion completed in 6.695366214s

• [SLOW TEST:12.090 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:18:00.830: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5228
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:18:01.157: INFO: (0) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 52.404646ms)
Nov  4 18:18:01.209: INFO: (1) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 51.46455ms)
Nov  4 18:18:01.231: INFO: (2) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.730828ms)
Nov  4 18:18:01.251: INFO: (3) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.011336ms)
Nov  4 18:18:01.272: INFO: (4) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 20.842125ms)
Nov  4 18:18:01.296: INFO: (5) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.628628ms)
Nov  4 18:18:01.322: INFO: (6) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 25.562094ms)
Nov  4 18:18:01.346: INFO: (7) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 24.304963ms)
Nov  4 18:18:01.375: INFO: (8) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 28.768306ms)
Nov  4 18:18:01.397: INFO: (9) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 21.888122ms)
Nov  4 18:18:01.428: INFO: (10) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 30.478654ms)
Nov  4 18:18:01.459: INFO: (11) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 31.038344ms)
Nov  4 18:18:01.486: INFO: (12) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 26.952966ms)
Nov  4 18:18:01.523: INFO: (13) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 36.880596ms)
Nov  4 18:18:01.556: INFO: (14) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 33.513416ms)
Nov  4 18:18:01.587: INFO: (15) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 31.008989ms)
Nov  4 18:18:01.638: INFO: (16) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 50.619878ms)
Nov  4 18:18:01.672: INFO: (17) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 33.714214ms)
Nov  4 18:18:01.702: INFO: (18) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 29.834216ms)
Nov  4 18:18:01.733: INFO: (19) /api/v1/nodes/10.93.34.21/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="at/">at/</... (200; 31.365065ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:18:01.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5228" for this suite.
Nov  4 18:18:07.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:18:08.379: INFO: namespace proxy-5228 deletion completed in 6.61093635s

• [SLOW TEST:7.549 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:18:08.379: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7000
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2r7zl in namespace proxy-7000
I1104 18:18:09.635761      25 runners.go:184] Created replication controller with name: proxy-service-2r7zl, namespace: proxy-7000, replica count: 1
I1104 18:18:10.686217      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 18:18:11.686421      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1104 18:18:12.686712      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 18:18:13.686951      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 18:18:14.687205      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 18:18:15.687437      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 18:18:16.687657      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1104 18:18:17.687931      25 runners.go:184] proxy-service-2r7zl Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:18:17.705: INFO: setup took 8.137139142s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Nov  4 18:18:17.744: INFO: (0) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 37.806184ms)
Nov  4 18:18:17.744: INFO: (0) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 38.289326ms)
Nov  4 18:18:17.745: INFO: (0) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 39.136878ms)
Nov  4 18:18:17.750: INFO: (0) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 44.149878ms)
Nov  4 18:18:17.750: INFO: (0) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 44.197154ms)
Nov  4 18:18:17.750: INFO: (0) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 44.261104ms)
Nov  4 18:18:17.753: INFO: (0) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 47.540823ms)
Nov  4 18:18:17.755: INFO: (0) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 49.32385ms)
Nov  4 18:18:17.760: INFO: (0) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 54.324289ms)
Nov  4 18:18:17.760: INFO: (0) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 54.54695ms)
Nov  4 18:18:17.762: INFO: (0) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 55.823009ms)
Nov  4 18:18:17.765: INFO: (0) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 59.369351ms)
Nov  4 18:18:17.775: INFO: (0) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 69.470664ms)
Nov  4 18:18:17.795: INFO: (0) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 88.616906ms)
Nov  4 18:18:17.963: INFO: (0) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 256.560065ms)
Nov  4 18:18:17.965: INFO: (0) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 258.721585ms)
Nov  4 18:18:17.979: INFO: (1) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 13.877442ms)
Nov  4 18:18:17.986: INFO: (1) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 21.010066ms)
Nov  4 18:18:17.986: INFO: (1) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 20.834239ms)
Nov  4 18:18:17.986: INFO: (1) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 21.532904ms)
Nov  4 18:18:17.987: INFO: (1) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 21.33858ms)
Nov  4 18:18:17.987: INFO: (1) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 21.562528ms)
Nov  4 18:18:17.987: INFO: (1) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 21.904386ms)
Nov  4 18:18:17.987: INFO: (1) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.654965ms)
Nov  4 18:18:17.987: INFO: (1) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 22.133034ms)
Nov  4 18:18:17.998: INFO: (1) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 32.492633ms)
Nov  4 18:18:18.000: INFO: (1) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 34.988256ms)
Nov  4 18:18:18.011: INFO: (1) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 45.324371ms)
Nov  4 18:18:18.014: INFO: (1) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 48.526054ms)
Nov  4 18:18:18.014: INFO: (1) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 48.964763ms)
Nov  4 18:18:18.014: INFO: (1) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 48.600001ms)
Nov  4 18:18:18.015: INFO: (1) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 49.737258ms)
Nov  4 18:18:18.033: INFO: (2) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 17.972493ms)
Nov  4 18:18:18.039: INFO: (2) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 24.253521ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 24.817777ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 25.198904ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 24.996287ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 24.97284ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 24.998308ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 25.371711ms)
Nov  4 18:18:18.040: INFO: (2) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 25.071033ms)
Nov  4 18:18:18.041: INFO: (2) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 25.54973ms)
Nov  4 18:18:18.046: INFO: (2) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 31.000906ms)
Nov  4 18:18:18.055: INFO: (2) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 40.007478ms)
Nov  4 18:18:18.057: INFO: (2) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 41.542371ms)
Nov  4 18:18:18.057: INFO: (2) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 41.37549ms)
Nov  4 18:18:18.075: INFO: (2) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 60.319429ms)
Nov  4 18:18:18.075: INFO: (2) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 60.514825ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 30.090507ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 29.234967ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 29.92541ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 29.21533ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 29.807799ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 30.057062ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 29.678712ms)
Nov  4 18:18:18.106: INFO: (3) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 29.926906ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 44.190517ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 43.983743ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 44.178008ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 44.407786ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 44.703792ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 44.367366ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 44.942077ms)
Nov  4 18:18:18.121: INFO: (3) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 44.806137ms)
Nov  4 18:18:18.138: INFO: (4) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 17.43172ms)
Nov  4 18:18:18.140: INFO: (4) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 19.498956ms)
Nov  4 18:18:18.141: INFO: (4) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.700133ms)
Nov  4 18:18:18.141: INFO: (4) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 19.686115ms)
Nov  4 18:18:18.141: INFO: (4) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 19.883988ms)
Nov  4 18:18:18.141: INFO: (4) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 19.873893ms)
Nov  4 18:18:18.141: INFO: (4) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 20.81937ms)
Nov  4 18:18:18.143: INFO: (4) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 22.331916ms)
Nov  4 18:18:18.143: INFO: (4) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 22.126887ms)
Nov  4 18:18:18.143: INFO: (4) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 22.482058ms)
Nov  4 18:18:18.151: INFO: (4) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 29.696922ms)
Nov  4 18:18:18.156: INFO: (4) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 35.043846ms)
Nov  4 18:18:18.158: INFO: (4) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 36.492691ms)
Nov  4 18:18:18.158: INFO: (4) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 37.183999ms)
Nov  4 18:18:18.162: INFO: (4) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 40.718033ms)
Nov  4 18:18:18.163: INFO: (4) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 42.728837ms)
Nov  4 18:18:18.182: INFO: (5) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 18.159206ms)
Nov  4 18:18:18.182: INFO: (5) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 18.324369ms)
Nov  4 18:18:18.182: INFO: (5) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 18.367873ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 19.802043ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 19.906508ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.822112ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.698147ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 19.926439ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.893988ms)
Nov  4 18:18:18.184: INFO: (5) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 19.768098ms)
Nov  4 18:18:18.194: INFO: (5) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 30.729726ms)
Nov  4 18:18:18.199: INFO: (5) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 35.288658ms)
Nov  4 18:18:18.203: INFO: (5) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 39.086771ms)
Nov  4 18:18:18.215: INFO: (5) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 51.077606ms)
Nov  4 18:18:18.215: INFO: (5) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 51.252967ms)
Nov  4 18:18:18.215: INFO: (5) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 50.958995ms)
Nov  4 18:18:18.231: INFO: (6) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 15.642317ms)
Nov  4 18:18:18.235: INFO: (6) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.671039ms)
Nov  4 18:18:18.235: INFO: (6) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 20.023054ms)
Nov  4 18:18:18.236: INFO: (6) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 20.034596ms)
Nov  4 18:18:18.236: INFO: (6) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 20.253581ms)
Nov  4 18:18:18.236: INFO: (6) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 20.177798ms)
Nov  4 18:18:18.237: INFO: (6) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 21.178621ms)
Nov  4 18:18:18.237: INFO: (6) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 21.716297ms)
Nov  4 18:18:18.237: INFO: (6) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.92578ms)
Nov  4 18:18:18.237: INFO: (6) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 21.834523ms)
Nov  4 18:18:18.239: INFO: (6) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 24.182718ms)
Nov  4 18:18:18.254: INFO: (6) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 38.01429ms)
Nov  4 18:18:18.255: INFO: (6) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 39.882197ms)
Nov  4 18:18:18.256: INFO: (6) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 40.495732ms)
Nov  4 18:18:18.260: INFO: (6) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 44.813307ms)
Nov  4 18:18:18.261: INFO: (6) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 45.129001ms)
Nov  4 18:18:18.279: INFO: (7) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 18.067135ms)
Nov  4 18:18:18.279: INFO: (7) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 18.562911ms)
Nov  4 18:18:18.280: INFO: (7) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 19.235634ms)
Nov  4 18:18:18.281: INFO: (7) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.547465ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 20.460478ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 21.039586ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.444256ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 21.068587ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 21.539912ms)
Nov  4 18:18:18.282: INFO: (7) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 21.293219ms)
Nov  4 18:18:18.287: INFO: (7) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 26.573502ms)
Nov  4 18:18:18.298: INFO: (7) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 36.736019ms)
Nov  4 18:18:18.300: INFO: (7) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 39.092845ms)
Nov  4 18:18:18.300: INFO: (7) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 39.46035ms)
Nov  4 18:18:18.310: INFO: (7) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 48.989916ms)
Nov  4 18:18:18.310: INFO: (7) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 49.242799ms)
Nov  4 18:18:18.326: INFO: (8) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 14.857853ms)
Nov  4 18:18:18.328: INFO: (8) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 16.898711ms)
Nov  4 18:18:18.329: INFO: (8) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 18.446679ms)
Nov  4 18:18:18.339: INFO: (8) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 28.102864ms)
Nov  4 18:18:18.339: INFO: (8) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 28.131269ms)
Nov  4 18:18:18.342: INFO: (8) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 30.519667ms)
Nov  4 18:18:18.344: INFO: (8) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 33.126692ms)
Nov  4 18:18:18.344: INFO: (8) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 33.066059ms)
Nov  4 18:18:18.344: INFO: (8) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 33.443892ms)
Nov  4 18:18:18.348: INFO: (8) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 37.25289ms)
Nov  4 18:18:18.358: INFO: (8) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 47.436255ms)
Nov  4 18:18:18.358: INFO: (8) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 47.521089ms)
Nov  4 18:18:18.358: INFO: (8) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 47.45748ms)
Nov  4 18:18:18.358: INFO: (8) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 47.379329ms)
Nov  4 18:18:18.360: INFO: (8) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 48.816565ms)
Nov  4 18:18:18.360: INFO: (8) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 48.649489ms)
Nov  4 18:18:18.385: INFO: (9) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 24.583555ms)
Nov  4 18:18:18.386: INFO: (9) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 25.675796ms)
Nov  4 18:18:18.386: INFO: (9) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 25.694584ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 33.667224ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 33.69573ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 33.714549ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 33.685349ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 34.139036ms)
Nov  4 18:18:18.394: INFO: (9) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 33.988404ms)
Nov  4 18:18:18.401: INFO: (9) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 40.518342ms)
Nov  4 18:18:18.402: INFO: (9) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 42.381047ms)
Nov  4 18:18:18.403: INFO: (9) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 42.547771ms)
Nov  4 18:18:18.403: INFO: (9) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 43.105951ms)
Nov  4 18:18:18.403: INFO: (9) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 43.266501ms)
Nov  4 18:18:18.403: INFO: (9) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 43.603383ms)
Nov  4 18:18:18.406: INFO: (9) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 45.771877ms)
Nov  4 18:18:18.426: INFO: (10) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 19.522412ms)
Nov  4 18:18:18.426: INFO: (10) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.852666ms)
Nov  4 18:18:18.426: INFO: (10) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.636008ms)
Nov  4 18:18:18.426: INFO: (10) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.910735ms)
Nov  4 18:18:18.426: INFO: (10) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.726169ms)
Nov  4 18:18:18.428: INFO: (10) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 21.409613ms)
Nov  4 18:18:18.428: INFO: (10) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 21.411751ms)
Nov  4 18:18:18.428: INFO: (10) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.478862ms)
Nov  4 18:18:18.429: INFO: (10) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 22.528654ms)
Nov  4 18:18:18.429: INFO: (10) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 22.523353ms)
Nov  4 18:18:18.445: INFO: (10) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 39.070136ms)
Nov  4 18:18:18.445: INFO: (10) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 39.19583ms)
Nov  4 18:18:18.445: INFO: (10) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 39.138901ms)
Nov  4 18:18:18.448: INFO: (10) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 42.139255ms)
Nov  4 18:18:18.448: INFO: (10) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 42.231018ms)
Nov  4 18:18:18.449: INFO: (10) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 42.243787ms)
Nov  4 18:18:18.466: INFO: (11) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 16.995368ms)
Nov  4 18:18:18.466: INFO: (11) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 17.094321ms)
Nov  4 18:18:18.467: INFO: (11) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 17.87307ms)
Nov  4 18:18:18.467: INFO: (11) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 18.113494ms)
Nov  4 18:18:18.467: INFO: (11) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 18.375729ms)
Nov  4 18:18:18.470: INFO: (11) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 21.350378ms)
Nov  4 18:18:18.472: INFO: (11) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 23.294837ms)
Nov  4 18:18:18.473: INFO: (11) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 23.764749ms)
Nov  4 18:18:18.473: INFO: (11) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 23.883696ms)
Nov  4 18:18:18.473: INFO: (11) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 24.261415ms)
Nov  4 18:18:18.485: INFO: (11) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 36.330785ms)
Nov  4 18:18:18.485: INFO: (11) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 36.254453ms)
Nov  4 18:18:18.495: INFO: (11) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 46.373746ms)
Nov  4 18:18:18.495: INFO: (11) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 46.362371ms)
Nov  4 18:18:18.514: INFO: (11) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 64.870487ms)
Nov  4 18:18:18.514: INFO: (11) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 65.14817ms)
Nov  4 18:18:18.533: INFO: (12) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 18.08501ms)
Nov  4 18:18:18.536: INFO: (12) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.775031ms)
Nov  4 18:18:18.536: INFO: (12) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 22.079455ms)
Nov  4 18:18:18.536: INFO: (12) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 21.945906ms)
Nov  4 18:18:18.536: INFO: (12) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 22.025323ms)
Nov  4 18:18:18.536: INFO: (12) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 22.021733ms)
Nov  4 18:18:18.537: INFO: (12) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 22.160152ms)
Nov  4 18:18:18.537: INFO: (12) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 22.107758ms)
Nov  4 18:18:18.543: INFO: (12) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 28.853644ms)
Nov  4 18:18:18.548: INFO: (12) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 34.018699ms)
Nov  4 18:18:18.548: INFO: (12) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 33.993048ms)
Nov  4 18:18:18.556: INFO: (12) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 41.464798ms)
Nov  4 18:18:18.556: INFO: (12) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 41.499543ms)
Nov  4 18:18:18.559: INFO: (12) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 45.13715ms)
Nov  4 18:18:18.565: INFO: (12) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 50.407715ms)
Nov  4 18:18:18.598: INFO: (12) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 83.370082ms)
Nov  4 18:18:18.748: INFO: (13) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 150.22611ms)
Nov  4 18:18:18.766: INFO: (13) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 167.926866ms)
Nov  4 18:18:18.766: INFO: (13) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 167.872884ms)
Nov  4 18:18:18.766: INFO: (13) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 167.830158ms)
Nov  4 18:18:18.766: INFO: (13) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 167.983956ms)
Nov  4 18:18:18.766: INFO: (13) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 167.787106ms)
Nov  4 18:18:18.767: INFO: (13) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 169.049195ms)
Nov  4 18:18:18.767: INFO: (13) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 169.062329ms)
Nov  4 18:18:18.768: INFO: (13) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 169.380818ms)
Nov  4 18:18:18.768: INFO: (13) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 169.861546ms)
Nov  4 18:18:18.768: INFO: (13) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 169.991403ms)
Nov  4 18:18:18.771: INFO: (13) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 172.85794ms)
Nov  4 18:18:18.786: INFO: (13) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 187.894416ms)
Nov  4 18:18:18.786: INFO: (13) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 187.679978ms)
Nov  4 18:18:18.786: INFO: (13) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 188.198691ms)
Nov  4 18:18:18.786: INFO: (13) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 188.145766ms)
Nov  4 18:18:18.803: INFO: (14) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 16.706319ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 22.102627ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 21.764996ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 21.97607ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 21.97702ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 21.882974ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 22.075724ms)
Nov  4 18:18:18.809: INFO: (14) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 22.399103ms)
Nov  4 18:18:18.812: INFO: (14) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 24.984433ms)
Nov  4 18:18:18.812: INFO: (14) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 25.016894ms)
Nov  4 18:18:18.813: INFO: (14) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 26.345075ms)
Nov  4 18:18:18.821: INFO: (14) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 33.867406ms)
Nov  4 18:18:18.824: INFO: (14) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 37.250798ms)
Nov  4 18:18:18.824: INFO: (14) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 37.768032ms)
Nov  4 18:18:18.824: INFO: (14) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 37.632613ms)
Nov  4 18:18:18.825: INFO: (14) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 37.709441ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 17.804134ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 17.809024ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 17.790626ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 17.903596ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 17.8705ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 17.835572ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 17.865306ms)
Nov  4 18:18:18.843: INFO: (15) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 18.24439ms)
Nov  4 18:18:18.847: INFO: (15) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 22.434663ms)
Nov  4 18:18:18.848: INFO: (15) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 22.52575ms)
Nov  4 18:18:18.851: INFO: (15) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 26.409832ms)
Nov  4 18:18:18.856: INFO: (15) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 30.937625ms)
Nov  4 18:18:18.860: INFO: (15) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 35.506572ms)
Nov  4 18:18:18.861: INFO: (15) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 36.187769ms)
Nov  4 18:18:18.861: INFO: (15) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 36.369634ms)
Nov  4 18:18:18.861: INFO: (15) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 36.224181ms)
Nov  4 18:18:18.877: INFO: (16) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 15.13778ms)
Nov  4 18:18:18.880: INFO: (16) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 17.789943ms)
Nov  4 18:18:18.880: INFO: (16) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 17.498603ms)
Nov  4 18:18:18.880: INFO: (16) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 17.696974ms)
Nov  4 18:18:18.881: INFO: (16) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 18.864877ms)
Nov  4 18:18:18.884: INFO: (16) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 21.920497ms)
Nov  4 18:18:18.884: INFO: (16) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 21.65631ms)
Nov  4 18:18:18.884: INFO: (16) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 21.925217ms)
Nov  4 18:18:18.884: INFO: (16) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 21.998714ms)
Nov  4 18:18:18.884: INFO: (16) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 21.872321ms)
Nov  4 18:18:18.887: INFO: (16) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 24.861508ms)
Nov  4 18:18:18.898: INFO: (16) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 35.481242ms)
Nov  4 18:18:18.902: INFO: (16) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 40.3782ms)
Nov  4 18:18:18.903: INFO: (16) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 40.769645ms)
Nov  4 18:18:18.902: INFO: (16) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 40.311025ms)
Nov  4 18:18:18.903: INFO: (16) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 40.596365ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 31.055146ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 31.474267ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 30.984897ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 31.336005ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 31.118627ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 31.26215ms)
Nov  4 18:18:18.934: INFO: (17) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 31.462318ms)
Nov  4 18:18:18.935: INFO: (17) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 31.972094ms)
Nov  4 18:18:18.935: INFO: (17) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 31.922383ms)
Nov  4 18:18:18.935: INFO: (17) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 31.793183ms)
Nov  4 18:18:18.935: INFO: (17) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 32.534126ms)
Nov  4 18:18:18.936: INFO: (17) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 33.511964ms)
Nov  4 18:18:18.938: INFO: (17) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 35.27377ms)
Nov  4 18:18:18.938: INFO: (17) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 35.649395ms)
Nov  4 18:18:18.939: INFO: (17) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 35.436668ms)
Nov  4 18:18:18.939: INFO: (17) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 36.061355ms)
Nov  4 18:18:18.953: INFO: (18) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 14.148863ms)
Nov  4 18:18:18.958: INFO: (18) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 19.173104ms)
Nov  4 18:18:18.958: INFO: (18) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 19.127853ms)
Nov  4 18:18:18.958: INFO: (18) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 19.467958ms)
Nov  4 18:18:18.958: INFO: (18) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.106369ms)
Nov  4 18:18:18.959: INFO: (18) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 19.271041ms)
Nov  4 18:18:18.959: INFO: (18) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 19.27106ms)
Nov  4 18:18:18.959: INFO: (18) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 19.425439ms)
Nov  4 18:18:18.970: INFO: (18) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 30.277315ms)
Nov  4 18:18:18.972: INFO: (18) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 32.591618ms)
Nov  4 18:18:18.972: INFO: (18) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 32.451367ms)
Nov  4 18:18:18.972: INFO: (18) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 33.266892ms)
Nov  4 18:18:18.976: INFO: (18) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 36.343404ms)
Nov  4 18:18:18.976: INFO: (18) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 37.140013ms)
Nov  4 18:18:18.976: INFO: (18) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 37.287285ms)
Nov  4 18:18:18.977: INFO: (18) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 37.516804ms)
Nov  4 18:18:19.002: INFO: (19) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 25.645566ms)
Nov  4 18:18:19.002: INFO: (19) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:460/proxy/: tls baz (200; 25.008547ms)
Nov  4 18:18:19.002: INFO: (19) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">... (200; 24.103613ms)
Nov  4 18:18:19.002: INFO: (19) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:1080/proxy/rewriteme">test<... (200; 25.358875ms)
Nov  4 18:18:19.002: INFO: (19) /api/v1/namespaces/proxy-7000/pods/http:proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 24.453132ms)
Nov  4 18:18:19.003: INFO: (19) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q/proxy/rewriteme">test</a> (200; 25.350602ms)
Nov  4 18:18:19.003: INFO: (19) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/: <a href="/api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:443/proxy/tlsrewritem... (200; 25.044508ms)
Nov  4 18:18:19.010: INFO: (19) /api/v1/namespaces/proxy-7000/pods/https:proxy-service-2r7zl-lkm4q:462/proxy/: tls qux (200; 32.318606ms)
Nov  4 18:18:19.010: INFO: (19) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname1/proxy/: tls baz (200; 32.961757ms)
Nov  4 18:18:19.012: INFO: (19) /api/v1/namespaces/proxy-7000/services/https:proxy-service-2r7zl:tlsportname2/proxy/: tls qux (200; 34.183662ms)
Nov  4 18:18:19.015: INFO: (19) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname2/proxy/: bar (200; 37.557785ms)
Nov  4 18:18:19.016: INFO: (19) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname1/proxy/: foo (200; 38.390113ms)
Nov  4 18:18:19.024: INFO: (19) /api/v1/namespaces/proxy-7000/services/http:proxy-service-2r7zl:portname2/proxy/: bar (200; 46.110079ms)
Nov  4 18:18:19.024: INFO: (19) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:160/proxy/: foo (200; 47.030375ms)
Nov  4 18:18:19.024: INFO: (19) /api/v1/namespaces/proxy-7000/services/proxy-service-2r7zl:portname1/proxy/: foo (200; 46.483717ms)
Nov  4 18:18:19.034: INFO: (19) /api/v1/namespaces/proxy-7000/pods/proxy-service-2r7zl-lkm4q:162/proxy/: bar (200; 57.146362ms)
STEP: deleting ReplicationController proxy-service-2r7zl in namespace proxy-7000, will wait for the garbage collector to delete the pods
Nov  4 18:18:19.159: INFO: Deleting ReplicationController proxy-service-2r7zl took: 55.170176ms
Nov  4 18:18:19.360: INFO: Terminating ReplicationController proxy-service-2r7zl pods took: 200.259198ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:18:23.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7000" for this suite.
Nov  4 18:18:31.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:18:32.059: INFO: namespace proxy-7000 deletion completed in 8.576727705s

• [SLOW TEST:23.680 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:18:32.062: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-42
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:18:32.873: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:18:34.930: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488312, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488312, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488312, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708488312, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:18:38.075: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:18:38.091: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Registering the custom resource webhook via the AdmissionRegistration API
Nov  4 18:18:48.727: INFO: Waiting for webhook configuration to be ready...
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:18:50.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-42" for this suite.
Nov  4 18:18:58.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:18:59.093: INFO: namespace webhook-42 deletion completed in 8.575801553s
STEP: Destroying namespace "webhook-42-markers" for this suite.
Nov  4 18:19:05.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:05.723: INFO: namespace webhook-42-markers deletion completed in 6.629968627s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:33.763 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:05.825: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Nov  4 18:19:06.244: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-756 /api/v1/namespaces/watch-756/configmaps/e2e-watch-test-watch-closed 3754bcb9-31fb-49f9-b3f8-5b4f53944a57 29335 0 2019-11-04 18:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 18:19:06.244: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-756 /api/v1/namespaces/watch-756/configmaps/e2e-watch-test-watch-closed 3754bcb9-31fb-49f9-b3f8-5b4f53944a57 29336 0 2019-11-04 18:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Nov  4 18:19:06.326: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-756 /api/v1/namespaces/watch-756/configmaps/e2e-watch-test-watch-closed 3754bcb9-31fb-49f9-b3f8-5b4f53944a57 29337 0 2019-11-04 18:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 18:19:06.326: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-756 /api/v1/namespaces/watch-756/configmaps/e2e-watch-test-watch-closed 3754bcb9-31fb-49f9-b3f8-5b4f53944a57 29338 0 2019-11-04 18:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:06.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-756" for this suite.
Nov  4 18:19:12.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:13.086: INFO: namespace watch-756 deletion completed in 6.727939104s

• [SLOW TEST:7.261 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:13.088: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-9442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:13.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9442" for this suite.
Nov  4 18:19:19.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:20.032: INFO: namespace tables-9442 deletion completed in 6.602491209s

• [SLOW TEST:6.945 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:20.033: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7315
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7062
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1651
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:29.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7315" for this suite.
Nov  4 18:19:35.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:35.851: INFO: namespace namespaces-7315 deletion completed in 6.588536913s
STEP: Destroying namespace "nsdeletetest-7062" for this suite.
Nov  4 18:19:35.868: INFO: Namespace nsdeletetest-7062 was already deleted
STEP: Destroying namespace "nsdeletetest-1651" for this suite.
Nov  4 18:19:41.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:19:42.437: INFO: namespace nsdeletetest-1651 deletion completed in 6.568980352s

• [SLOW TEST:22.404 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:19:42.437: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2689
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:19:42.715: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Nov  4 18:19:47.726: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Nov  4 18:19:47.727: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 18:19:53.857: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2689 /apis/apps/v1/namespaces/deployment-2689/deployments/test-cleanup-deployment 650188da-bb34-40ce-af68-cd91b9c2829f 29534 1 2019-11-04 18:19:47 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001519a58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-11-04 18:19:47 +0000 UTC,LastTransitionTime:2019-11-04 18:19:47 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-11-04 18:19:52 +0000 UTC,LastTransitionTime:2019-11-04 18:19:47 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Nov  4 18:19:53.877: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-2689 /apis/apps/v1/namespaces/deployment-2689/replicasets/test-cleanup-deployment-65db99849b 2a9baa47-c83d-4a1e-8f1a-6fc86d842bd3 29519 1 2019-11-04 18:19:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 650188da-bb34-40ce-af68-cd91b9c2829f 0xc001519e97 0xc001519e98}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001519ef8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Nov  4 18:19:53.897: INFO: Pod "test-cleanup-deployment-65db99849b-bfbrx" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-bfbrx test-cleanup-deployment-65db99849b- deployment-2689 /api/v1/namespaces/deployment-2689/pods/test-cleanup-deployment-65db99849b-bfbrx 2f70a126-58b1-45ce-84b6-e8c50c70c0dc 29518 0 2019-11-04 18:19:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 2a9baa47-c83d-4a1e-8f1a-6fc86d842bd3 0xc002ed8297 0xc002ed8298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2qpcj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2qpcj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2qpcj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:19:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:19:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:19:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 18:19:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:172.30.102.15,StartTime:2019-11-04 18:19:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-11-04 18:19:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://249dc8b2128ab75dfc765567986e49578f46f8bb6e6b0f555cc8dd1c81314b4c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.102.15,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:19:53.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2689" for this suite.
Nov  4 18:20:01.983: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:02.689: INFO: namespace deployment-2689 deletion completed in 8.771579775s

• [SLOW TEST:20.252 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:02.690: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3598
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3598.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3598.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3598.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3598.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3598.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3598.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:20:13.254: INFO: DNS probes using dns-3598/dns-test-2ef78d20-69ac-4e16-af50-ce67c8306f62 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:20:13.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3598" for this suite.
Nov  4 18:20:21.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:20:22.009: INFO: namespace dns-3598 deletion completed in 8.617223128s

• [SLOW TEST:19.318 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:20:22.009: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9463
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Nov  4 18:21:02.460: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:02.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1104 18:21:02.460743      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9463" for this suite.
Nov  4 18:21:12.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:21:13.109: INFO: namespace gc-9463 deletion completed in 10.630667009s

• [SLOW TEST:51.100 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:21:13.109: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-120
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:21:13.475: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 18:21:13.538: INFO: Number of nodes with available pods: 0
Nov  4 18:21:13.538: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:21:14.578: INFO: Number of nodes with available pods: 0
Nov  4 18:21:14.578: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:21:15.574: INFO: Number of nodes with available pods: 3
Nov  4 18:21:15.574: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Nov  4 18:21:15.704: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:15.704: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:15.704: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:16.734: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:16.734: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:16.734: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:17.734: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:17.735: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:17.735: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:18.738: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:18.738: INFO: Pod daemon-set-64mnx is not available
Nov  4 18:21:18.738: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:18.738: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:19.734: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:19.734: INFO: Pod daemon-set-64mnx is not available
Nov  4 18:21:19.734: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:19.734: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:20.969: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:20.969: INFO: Pod daemon-set-64mnx is not available
Nov  4 18:21:20.969: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:20.969: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:21.738: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:21.738: INFO: Pod daemon-set-64mnx is not available
Nov  4 18:21:21.738: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:21.738: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:22.735: INFO: Wrong image for pod: daemon-set-64mnx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:22.735: INFO: Pod daemon-set-64mnx is not available
Nov  4 18:21:22.735: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:22.735: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:23.741: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:23.741: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:23.741: INFO: Pod daemon-set-vnp5h is not available
Nov  4 18:21:24.735: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:24.735: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:24.735: INFO: Pod daemon-set-vnp5h is not available
Nov  4 18:21:25.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:25.733: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:26.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:26.733: INFO: Wrong image for pod: daemon-set-n76bw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:26.733: INFO: Pod daemon-set-n76bw is not available
Nov  4 18:21:27.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:27.733: INFO: Pod daemon-set-lnqgn is not available
Nov  4 18:21:28.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:28.733: INFO: Pod daemon-set-lnqgn is not available
Nov  4 18:21:29.737: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:29.737: INFO: Pod daemon-set-lnqgn is not available
Nov  4 18:21:30.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:30.733: INFO: Pod daemon-set-lnqgn is not available
Nov  4 18:21:31.736: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:32.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:32.734: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:33.734: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:33.734: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:34.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:34.733: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:35.746: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:35.746: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:36.733: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:36.733: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:37.736: INFO: Wrong image for pod: daemon-set-kzfzz. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Nov  4 18:21:37.736: INFO: Pod daemon-set-kzfzz is not available
Nov  4 18:21:38.733: INFO: Pod daemon-set-vdkc2 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Nov  4 18:21:38.809: INFO: Number of nodes with available pods: 2
Nov  4 18:21:38.809: INFO: Node 10.93.34.38 is running more than one daemon pod
Nov  4 18:21:39.842: INFO: Number of nodes with available pods: 2
Nov  4 18:21:39.842: INFO: Node 10.93.34.38 is running more than one daemon pod
Nov  4 18:21:40.843: INFO: Number of nodes with available pods: 3
Nov  4 18:21:40.843: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-120, will wait for the garbage collector to delete the pods
Nov  4 18:21:41.015: INFO: Deleting DaemonSet.extensions daemon-set took: 40.994649ms
Nov  4 18:21:41.215: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.307566ms
Nov  4 18:21:53.529: INFO: Number of nodes with available pods: 0
Nov  4 18:21:53.529: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 18:21:53.547: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-120/daemonsets","resourceVersion":"30223"},"items":null}

Nov  4 18:21:53.562: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-120/pods","resourceVersion":"30223"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:21:53.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-120" for this suite.
Nov  4 18:22:01.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:02.525: INFO: namespace daemonsets-120 deletion completed in 8.86204857s

• [SLOW TEST:49.415 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:02.526: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-5148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:22:02.842: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-3ff10691-8f4d-4a49-8a98-68c5d70fb0dd" in namespace "security-context-test-5148" to be "success or failure"
Nov  4 18:22:02.859: INFO: Pod "alpine-nnp-false-3ff10691-8f4d-4a49-8a98-68c5d70fb0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 17.053856ms
Nov  4 18:22:04.889: INFO: Pod "alpine-nnp-false-3ff10691-8f4d-4a49-8a98-68c5d70fb0dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.046827459s
Nov  4 18:22:06.900: INFO: Pod "alpine-nnp-false-3ff10691-8f4d-4a49-8a98-68c5d70fb0dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057786287s
Nov  4 18:22:06.900: INFO: Pod "alpine-nnp-false-3ff10691-8f4d-4a49-8a98-68c5d70fb0dd" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:06.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-5148" for this suite.
Nov  4 18:22:15.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:15.585: INFO: namespace security-context-test-5148 deletion completed in 8.578010276s

• [SLOW TEST:13.059 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:15.585: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5161
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 18:22:15.871: INFO: Waiting up to 5m0s for pod "pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f" in namespace "emptydir-5161" to be "success or failure"
Nov  4 18:22:15.884: INFO: Pod "pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.754811ms
Nov  4 18:22:17.911: INFO: Pod "pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040350985s
Nov  4 18:22:19.922: INFO: Pod "pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051545647s
STEP: Saw pod success
Nov  4 18:22:19.922: INFO: Pod "pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f" satisfied condition "success or failure"
Nov  4 18:22:19.933: INFO: Trying to get logs from node 10.93.34.21 pod pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f container test-container: <nil>
STEP: delete the pod
Nov  4 18:22:19.993: INFO: Waiting for pod pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f to disappear
Nov  4 18:22:20.004: INFO: Pod pod-1a2c1273-0f0f-43c2-922d-c4514b4cd74f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:20.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5161" for this suite.
Nov  4 18:22:28.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:28.659: INFO: namespace emptydir-5161 deletion completed in 8.630363554s

• [SLOW TEST:13.074 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:28.659: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3688
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-3bc5f396-fb24-4a26-bd59-ba92e2e2a0d1
STEP: Creating a pod to test consume secrets
Nov  4 18:22:28.975: INFO: Waiting up to 5m0s for pod "pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd" in namespace "secrets-3688" to be "success or failure"
Nov  4 18:22:28.994: INFO: Pod "pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.713097ms
Nov  4 18:22:31.008: INFO: Pod "pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03207012s
STEP: Saw pod success
Nov  4 18:22:31.008: INFO: Pod "pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd" satisfied condition "success or failure"
Nov  4 18:22:31.019: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:22:31.076: INFO: Waiting for pod pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd to disappear
Nov  4 18:22:31.086: INFO: Pod pod-secrets-e30b46f5-36ea-4e2f-91b7-bd4a9c6c72bd no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:31.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3688" for this suite.
Nov  4 18:22:37.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:37.704: INFO: namespace secrets-3688 deletion completed in 6.594433428s

• [SLOW TEST:9.045 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:37.706: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 18:22:37.996: INFO: Waiting up to 5m0s for pod "pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f" in namespace "emptydir-6547" to be "success or failure"
Nov  4 18:22:38.008: INFO: Pod "pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.14444ms
Nov  4 18:22:40.021: INFO: Pod "pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025815516s
STEP: Saw pod success
Nov  4 18:22:40.021: INFO: Pod "pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f" satisfied condition "success or failure"
Nov  4 18:22:40.033: INFO: Trying to get logs from node 10.93.34.21 pod pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f container test-container: <nil>
STEP: delete the pod
Nov  4 18:22:40.093: INFO: Waiting for pod pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f to disappear
Nov  4 18:22:40.105: INFO: Pod pod-92053aeb-d54a-4f7c-8826-6077ebc1fb4f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:22:40.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6547" for this suite.
Nov  4 18:22:48.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:22:48.706: INFO: namespace emptydir-6547 deletion completed in 8.574127874s

• [SLOW TEST:11.001 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:22:48.706: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4186
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-cfc2ae9e-d30c-469b-99b2-6a4300ede6f0
STEP: Creating secret with name s-test-opt-upd-0fa76298-303f-4be4-9f58-6e5feee9951f
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-cfc2ae9e-d30c-469b-99b2-6a4300ede6f0
STEP: Updating secret s-test-opt-upd-0fa76298-303f-4be4-9f58-6e5feee9951f
STEP: Creating secret with name s-test-opt-create-8eb30936-ab59-4f74-8d9f-2841617000c5
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:23:57.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4186" for this suite.
Nov  4 18:24:15.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:24:16.238: INFO: namespace secrets-4186 deletion completed in 18.573065318s

• [SLOW TEST:87.532 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:24:16.240: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:24:16.598: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Nov  4 18:24:16.624: INFO: Number of nodes with available pods: 0
Nov  4 18:24:16.624: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Nov  4 18:24:16.688: INFO: Number of nodes with available pods: 0
Nov  4 18:24:16.688: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:17.700: INFO: Number of nodes with available pods: 0
Nov  4 18:24:17.700: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:18.701: INFO: Number of nodes with available pods: 0
Nov  4 18:24:18.701: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:19.702: INFO: Number of nodes with available pods: 1
Nov  4 18:24:19.702: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Nov  4 18:24:19.771: INFO: Number of nodes with available pods: 1
Nov  4 18:24:19.771: INFO: Number of running nodes: 0, number of available pods: 1
Nov  4 18:24:20.782: INFO: Number of nodes with available pods: 0
Nov  4 18:24:20.782: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Nov  4 18:24:20.812: INFO: Number of nodes with available pods: 0
Nov  4 18:24:20.812: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:21.823: INFO: Number of nodes with available pods: 0
Nov  4 18:24:21.823: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:22.823: INFO: Number of nodes with available pods: 0
Nov  4 18:24:22.823: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:23.824: INFO: Number of nodes with available pods: 0
Nov  4 18:24:23.824: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:24.824: INFO: Number of nodes with available pods: 0
Nov  4 18:24:24.824: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:25.823: INFO: Number of nodes with available pods: 0
Nov  4 18:24:25.823: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:26.824: INFO: Number of nodes with available pods: 0
Nov  4 18:24:26.824: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:27.833: INFO: Number of nodes with available pods: 0
Nov  4 18:24:27.834: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:28.823: INFO: Number of nodes with available pods: 0
Nov  4 18:24:28.823: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:31.056: INFO: Number of nodes with available pods: 0
Nov  4 18:24:31.056: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:31.823: INFO: Number of nodes with available pods: 0
Nov  4 18:24:31.823: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:32.822: INFO: Number of nodes with available pods: 0
Nov  4 18:24:32.822: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:33.822: INFO: Number of nodes with available pods: 0
Nov  4 18:24:33.822: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 18:24:34.824: INFO: Number of nodes with available pods: 1
Nov  4 18:24:34.824: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2679, will wait for the garbage collector to delete the pods
Nov  4 18:24:35.181: INFO: Deleting DaemonSet.extensions daemon-set took: 40.335313ms
Nov  4 18:24:35.381: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.352266ms
Nov  4 18:24:43.393: INFO: Number of nodes with available pods: 0
Nov  4 18:24:43.393: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 18:24:43.408: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2679/daemonsets","resourceVersion":"30769"},"items":null}

Nov  4 18:24:43.420: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2679/pods","resourceVersion":"30769"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:24:43.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2679" for this suite.
Nov  4 18:24:51.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:24:52.099: INFO: namespace daemonsets-2679 deletion completed in 8.571421026s

• [SLOW TEST:35.859 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:24:52.099: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2810
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Nov  4 18:24:52.360: INFO: Waiting up to 5m0s for pod "pod-345d259c-e06d-4c07-a674-426546d6b95f" in namespace "emptydir-2810" to be "success or failure"
Nov  4 18:24:52.373: INFO: Pod "pod-345d259c-e06d-4c07-a674-426546d6b95f": Phase="Pending", Reason="", readiness=false. Elapsed: 11.969894ms
Nov  4 18:24:54.395: INFO: Pod "pod-345d259c-e06d-4c07-a674-426546d6b95f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034598803s
STEP: Saw pod success
Nov  4 18:24:54.395: INFO: Pod "pod-345d259c-e06d-4c07-a674-426546d6b95f" satisfied condition "success or failure"
Nov  4 18:24:54.405: INFO: Trying to get logs from node 10.93.34.21 pod pod-345d259c-e06d-4c07-a674-426546d6b95f container test-container: <nil>
STEP: delete the pod
Nov  4 18:24:54.478: INFO: Waiting for pod pod-345d259c-e06d-4c07-a674-426546d6b95f to disappear
Nov  4 18:24:54.515: INFO: Pod pod-345d259c-e06d-4c07-a674-426546d6b95f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:24:54.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2810" for this suite.
Nov  4 18:25:00.612: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:01.163: INFO: namespace emptydir-2810 deletion completed in 6.625404426s

• [SLOW TEST:9.064 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:01.163: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:25:01.482: INFO: Waiting up to 5m0s for pod "busybox-user-65534-9ff4f860-0c5f-49c8-8a61-b09cd5824180" in namespace "security-context-test-1718" to be "success or failure"
Nov  4 18:25:01.493: INFO: Pod "busybox-user-65534-9ff4f860-0c5f-49c8-8a61-b09cd5824180": Phase="Pending", Reason="", readiness=false. Elapsed: 11.27481ms
Nov  4 18:25:03.507: INFO: Pod "busybox-user-65534-9ff4f860-0c5f-49c8-8a61-b09cd5824180": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024655745s
Nov  4 18:25:05.518: INFO: Pod "busybox-user-65534-9ff4f860-0c5f-49c8-8a61-b09cd5824180": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035567517s
Nov  4 18:25:05.518: INFO: Pod "busybox-user-65534-9ff4f860-0c5f-49c8-8a61-b09cd5824180" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:25:05.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1718" for this suite.
Nov  4 18:25:13.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:14.179: INFO: namespace security-context-test-1718 deletion completed in 8.638611668s

• [SLOW TEST:13.015 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:14.179: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:25:15.123: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:25:18.238: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:25:18.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3826" for this suite.
Nov  4 18:25:26.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:26.985: INFO: namespace webhook-3826 deletion completed in 8.551433054s
STEP: Destroying namespace "webhook-3826-markers" for this suite.
Nov  4 18:25:35.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:25:36.731: INFO: namespace webhook-3826-markers deletion completed in 9.746304624s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.646 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:25:36.825: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Nov  4 18:25:37.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8934'
Nov  4 18:25:37.429: INFO: stderr: ""
Nov  4 18:25:37.429: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 18:25:38.455: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:25:38.455: INFO: Found 0 / 1
Nov  4 18:25:39.441: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:25:39.441: INFO: Found 0 / 1
Nov  4 18:25:40.440: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:25:40.440: INFO: Found 1 / 1
Nov  4 18:25:40.440: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Nov  4 18:25:40.450: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:25:40.450: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 18:25:40.451: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 patch pod redis-master-fglv2 --namespace=kubectl-8934 -p {"metadata":{"annotations":{"x":"y"}}}'
Nov  4 18:25:40.617: INFO: stderr: ""
Nov  4 18:25:40.617: INFO: stdout: "pod/redis-master-fglv2 patched\n"
STEP: checking annotations
Nov  4 18:25:40.633: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:25:40.633: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:25:40.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8934" for this suite.
Nov  4 18:26:10.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:26:11.318: INFO: namespace kubectl-8934 deletion completed in 30.651062165s

• [SLOW TEST:34.493 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:26:11.318: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:26:11.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-8676'
Nov  4 18:26:11.926: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 18:26:11.926: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Nov  4 18:26:11.952: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-z4zh6]
Nov  4 18:26:11.952: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-z4zh6" in namespace "kubectl-8676" to be "running and ready"
Nov  4 18:26:11.967: INFO: Pod "e2e-test-httpd-rc-z4zh6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.308869ms
Nov  4 18:26:13.981: INFO: Pod "e2e-test-httpd-rc-z4zh6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029518316s
Nov  4 18:26:15.996: INFO: Pod "e2e-test-httpd-rc-z4zh6": Phase="Running", Reason="", readiness=true. Elapsed: 4.044119866s
Nov  4 18:26:15.996: INFO: Pod "e2e-test-httpd-rc-z4zh6" satisfied condition "running and ready"
Nov  4 18:26:15.996: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-z4zh6]
Nov  4 18:26:15.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 logs rc/e2e-test-httpd-rc --namespace=kubectl-8676'
Nov  4 18:26:16.163: INFO: stderr: ""
Nov  4 18:26:16.163: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.102.32. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.102.32. Set the 'ServerName' directive globally to suppress this message\n[Mon Nov 04 18:26:14.515237 2019] [mpm_event:notice] [pid 1:tid 140002764553064] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Nov 04 18:26:14.515296 2019] [core:notice] [pid 1:tid 140002764553064] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Nov  4 18:26:16.163: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete rc e2e-test-httpd-rc --namespace=kubectl-8676'
Nov  4 18:26:16.399: INFO: stderr: ""
Nov  4 18:26:16.399: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:26:16.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8676" for this suite.
Nov  4 18:26:28.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:26:29.215: INFO: namespace kubectl-8676 deletion completed in 12.793041899s

• [SLOW TEST:17.897 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:26:29.216: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-453
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:26:29.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-453" for this suite.
Nov  4 18:26:59.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:27:00.133: INFO: namespace pods-453 deletion completed in 30.591717897s

• [SLOW TEST:30.917 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:27:00.133: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 18:27:00.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2300'
Nov  4 18:27:00.578: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Nov  4 18:27:00.578: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Nov  4 18:27:02.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete deployment e2e-test-httpd-deployment --namespace=kubectl-2300'
Nov  4 18:27:02.779: INFO: stderr: ""
Nov  4 18:27:02.779: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:27:02.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2300" for this suite.
Nov  4 18:27:08.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:27:09.422: INFO: namespace kubectl-2300 deletion completed in 6.60605882s

• [SLOW TEST:9.289 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:27:09.423: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5068
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:27:09.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5068" for this suite.
Nov  4 18:27:15.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:27:16.427: INFO: namespace resourcequota-5068 deletion completed in 6.615440831s

• [SLOW TEST:7.005 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:27:16.428: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-480
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-70c6641c-6d81-4e31-b441-8099cede7822
STEP: Creating a pod to test consume configMaps
Nov  4 18:27:16.746: INFO: Waiting up to 5m0s for pod "pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f" in namespace "configmap-480" to be "success or failure"
Nov  4 18:27:16.760: INFO: Pod "pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.941886ms
Nov  4 18:27:18.771: INFO: Pod "pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024877676s
Nov  4 18:27:20.783: INFO: Pod "pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037691969s
STEP: Saw pod success
Nov  4 18:27:20.783: INFO: Pod "pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f" satisfied condition "success or failure"
Nov  4 18:27:20.794: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:27:20.855: INFO: Waiting for pod pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f to disappear
Nov  4 18:27:20.869: INFO: Pod pod-configmaps-1fa9f371-f26b-4fe5-ad1b-d859fb51e84f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:27:20.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-480" for this suite.
Nov  4 18:27:26.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:27:27.457: INFO: namespace configmap-480 deletion completed in 6.566360032s

• [SLOW TEST:11.029 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:27:27.461: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2003
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Nov  4 18:27:35.876: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 18:27:35.886: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 18:27:37.886: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 18:27:37.898: INFO: Pod pod-with-poststart-http-hook still exists
Nov  4 18:27:39.886: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Nov  4 18:27:39.896: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:27:39.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2003" for this suite.
Nov  4 18:28:09.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:28:10.560: INFO: namespace container-lifecycle-hook-2003 deletion completed in 30.642139943s

• [SLOW TEST:43.099 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:28:10.560: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6331
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-d1216e2a-a1dd-4240-9a3e-83118b607227
STEP: Creating configMap with name cm-test-opt-upd-e0b79503-7f94-449f-8533-6ac8aeab9fed
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-d1216e2a-a1dd-4240-9a3e-83118b607227
STEP: Updating configmap cm-test-opt-upd-e0b79503-7f94-449f-8533-6ac8aeab9fed
STEP: Creating configMap with name cm-test-opt-create-02f9cf3c-e639-4d11-805a-59fcc0d458e8
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:29:24.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6331" for this suite.
Nov  4 18:29:44.619: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:29:45.135: INFO: namespace projected-6331 deletion completed in 20.576551432s

• [SLOW TEST:94.575 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:29:45.136: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-457
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:29:45.475: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0" in namespace "projected-457" to be "success or failure"
Nov  4 18:29:45.487: INFO: Pod "downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0": Phase="Pending", Reason="", readiness=false. Elapsed: 11.76898ms
Nov  4 18:29:47.498: INFO: Pod "downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022828083s
STEP: Saw pod success
Nov  4 18:29:47.498: INFO: Pod "downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0" satisfied condition "success or failure"
Nov  4 18:29:47.508: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0 container client-container: <nil>
STEP: delete the pod
Nov  4 18:29:47.563: INFO: Waiting for pod downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0 to disappear
Nov  4 18:29:47.573: INFO: Pod downwardapi-volume-9f0b7930-4177-4edc-b199-26e1adab60b0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:29:47.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-457" for this suite.
Nov  4 18:29:53.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:29:54.127: INFO: namespace projected-457 deletion completed in 6.535067459s

• [SLOW TEST:8.991 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:29:54.127: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-58
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Nov  4 18:29:54.414: INFO: Waiting up to 5m0s for pod "pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704" in namespace "emptydir-58" to be "success or failure"
Nov  4 18:29:54.455: INFO: Pod "pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704": Phase="Pending", Reason="", readiness=false. Elapsed: 40.814444ms
Nov  4 18:29:56.465: INFO: Pod "pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.051366473s
STEP: Saw pod success
Nov  4 18:29:56.465: INFO: Pod "pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704" satisfied condition "success or failure"
Nov  4 18:29:56.475: INFO: Trying to get logs from node 10.93.34.21 pod pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704 container test-container: <nil>
STEP: delete the pod
Nov  4 18:29:56.526: INFO: Waiting for pod pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704 to disappear
Nov  4 18:29:56.540: INFO: Pod pod-f4de18be-a8c7-4f84-8f33-0fbfa28f8704 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:29:56.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-58" for this suite.
Nov  4 18:30:04.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:05.143: INFO: namespace emptydir-58 deletion completed in 8.570537931s

• [SLOW TEST:11.016 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:05.143: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Nov  4 18:30:36.052: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1104 18:30:36.052208      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:36.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2099" for this suite.
Nov  4 18:30:44.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:44.640: INFO: namespace gc-2099 deletion completed in 8.572681751s

• [SLOW TEST:39.497 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:44.641: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8809
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:30:44.916: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958" in namespace "downward-api-8809" to be "success or failure"
Nov  4 18:30:44.925: INFO: Pod "downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958": Phase="Pending", Reason="", readiness=false. Elapsed: 9.653797ms
Nov  4 18:30:46.941: INFO: Pod "downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025605795s
STEP: Saw pod success
Nov  4 18:30:46.942: INFO: Pod "downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958" satisfied condition "success or failure"
Nov  4 18:30:46.953: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958 container client-container: <nil>
STEP: delete the pod
Nov  4 18:30:47.005: INFO: Waiting for pod downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958 to disappear
Nov  4 18:30:47.015: INFO: Pod downwardapi-volume-0a79ea14-a714-47fc-87f0-984a229a7958 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8809" for this suite.
Nov  4 18:30:55.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:30:55.626: INFO: namespace downward-api-8809 deletion completed in 8.591147611s

• [SLOW TEST:10.986 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:30:55.626: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5467
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-a06e5fb5-9405-44af-a6f4-859417f62f26
STEP: Creating a pod to test consume secrets
Nov  4 18:30:55.915: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329" in namespace "projected-5467" to be "success or failure"
Nov  4 18:30:55.927: INFO: Pod "pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329": Phase="Pending", Reason="", readiness=false. Elapsed: 11.616084ms
Nov  4 18:30:57.938: INFO: Pod "pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022976943s
STEP: Saw pod success
Nov  4 18:30:57.938: INFO: Pod "pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329" satisfied condition "success or failure"
Nov  4 18:30:57.948: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:30:58.011: INFO: Waiting for pod pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329 to disappear
Nov  4 18:30:58.024: INFO: Pod pod-projected-secrets-dcc02c68-723c-4c22-9f56-a73b9a393329 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:30:58.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5467" for this suite.
Nov  4 18:31:04.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:31:04.610: INFO: namespace projected-5467 deletion completed in 6.566611231s

• [SLOW TEST:8.984 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:31:04.611: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-511
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 18:31:04.876: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:31:25.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-511" for this suite.
Nov  4 18:31:33.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:31:33.702: INFO: namespace crd-publish-openapi-511 deletion completed in 8.574166587s

• [SLOW TEST:29.091 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:31:33.702: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:31:36.050: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1880" for this suite.
Nov  4 18:32:26.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:26.791: INFO: namespace kubelet-test-1880 deletion completed in 50.720225662s

• [SLOW TEST:53.090 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:26.792: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3640
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-eb53f295-852a-4fe0-bc62-b44595b2f25c
STEP: Creating a pod to test consume secrets
Nov  4 18:32:27.104: INFO: Waiting up to 5m0s for pod "pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98" in namespace "secrets-3640" to be "success or failure"
Nov  4 18:32:27.117: INFO: Pod "pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98": Phase="Pending", Reason="", readiness=false. Elapsed: 13.093411ms
Nov  4 18:32:29.129: INFO: Pod "pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024633374s
STEP: Saw pod success
Nov  4 18:32:29.129: INFO: Pod "pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98" satisfied condition "success or failure"
Nov  4 18:32:29.139: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 18:32:29.202: INFO: Waiting for pod pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98 to disappear
Nov  4 18:32:29.212: INFO: Pod pod-secrets-13fbf3be-0c0e-4df6-88bb-ec8a30df2e98 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:32:29.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3640" for this suite.
Nov  4 18:32:35.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:32:35.931: INFO: namespace secrets-3640 deletion completed in 6.694508273s

• [SLOW TEST:9.139 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:32:35.931: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6996
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6996
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6996
Nov  4 18:32:36.241: INFO: Found 0 stateful pods, waiting for 1
Nov  4 18:32:46.253: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:32:46.449: INFO: Deleting all statefulset in ns statefulset-6996
Nov  4 18:32:46.464: INFO: Scaling statefulset ss to 0
Nov  4 18:33:06.523: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:33:06.540: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:33:06.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6996" for this suite.
Nov  4 18:33:14.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:33:15.213: INFO: namespace statefulset-6996 deletion completed in 8.586700321s

• [SLOW TEST:39.282 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:33:15.216: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2394
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:33:19.626: INFO: Waiting up to 5m0s for pod "client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a" in namespace "pods-2394" to be "success or failure"
Nov  4 18:33:19.638: INFO: Pod "client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a": Phase="Pending", Reason="", readiness=false. Elapsed: 11.830995ms
Nov  4 18:33:21.650: INFO: Pod "client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0243016s
Nov  4 18:33:23.662: INFO: Pod "client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036134849s
STEP: Saw pod success
Nov  4 18:33:23.662: INFO: Pod "client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a" satisfied condition "success or failure"
Nov  4 18:33:23.673: INFO: Trying to get logs from node 10.93.34.21 pod client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a container env3cont: <nil>
STEP: delete the pod
Nov  4 18:33:23.736: INFO: Waiting for pod client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a to disappear
Nov  4 18:33:23.762: INFO: Pod client-envvars-9fbe0d2b-095a-4682-b983-80adde010f4a no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:33:23.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2394" for this suite.
Nov  4 18:33:35.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:33:36.319: INFO: namespace pods-2394 deletion completed in 12.5349995s

• [SLOW TEST:21.104 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:33:36.320: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5736
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:33:36.592: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35" in namespace "downward-api-5736" to be "success or failure"
Nov  4 18:33:36.605: INFO: Pod "downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35": Phase="Pending", Reason="", readiness=false. Elapsed: 13.723683ms
Nov  4 18:33:38.618: INFO: Pod "downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026315661s
Nov  4 18:33:40.628: INFO: Pod "downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036513745s
STEP: Saw pod success
Nov  4 18:33:40.628: INFO: Pod "downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35" satisfied condition "success or failure"
Nov  4 18:33:40.640: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35 container client-container: <nil>
STEP: delete the pod
Nov  4 18:33:40.712: INFO: Waiting for pod downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35 to disappear
Nov  4 18:33:40.722: INFO: Pod downwardapi-volume-8017def7-651f-41c9-8d6d-03bbcc4acf35 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:33:40.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5736" for this suite.
Nov  4 18:33:47.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:33:47.703: INFO: namespace downward-api-5736 deletion completed in 6.949779799s

• [SLOW TEST:11.383 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:33:47.704: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Nov  4 18:33:50.050: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-229262933 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  4 18:33:55.471: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:33:55.481: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7984" for this suite.
Nov  4 18:34:01.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:34:02.436: INFO: namespace pods-7984 deletion completed in 6.938087746s

• [SLOW TEST:14.733 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:34:02.437: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-718
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 18:34:02.793: INFO: Found 0 stateful pods, waiting for 3
Nov  4 18:34:12.808: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:34:12.808: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:34:12.808: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 18:34:12.938: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Nov  4 18:34:23.044: INFO: Updating stateful set ss2
Nov  4 18:34:23.100: INFO: Waiting for Pod statefulset-718/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:34:33.127: INFO: Waiting for Pod statefulset-718/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Nov  4 18:34:43.224: INFO: Found 2 stateful pods, waiting for 3
Nov  4 18:34:53.239: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:34:53.239: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 18:34:53.239: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Nov  4 18:34:53.316: INFO: Updating stateful set ss2
Nov  4 18:34:53.346: INFO: Waiting for Pod statefulset-718/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:35:03.374: INFO: Waiting for Pod statefulset-718/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:35:13.440: INFO: Updating stateful set ss2
Nov  4 18:35:13.466: INFO: Waiting for StatefulSet statefulset-718/ss2 to complete update
Nov  4 18:35:13.466: INFO: Waiting for Pod statefulset-718/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:35:23.508: INFO: Waiting for StatefulSet statefulset-718/ss2 to complete update
Nov  4 18:35:23.508: INFO: Waiting for Pod statefulset-718/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Nov  4 18:35:33.499: INFO: Waiting for StatefulSet statefulset-718/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 18:35:43.493: INFO: Deleting all statefulset in ns statefulset-718
Nov  4 18:35:43.509: INFO: Scaling statefulset ss2 to 0
Nov  4 18:36:23.576: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 18:36:23.610: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:36:23.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-718" for this suite.
Nov  4 18:36:33.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:36:34.332: INFO: namespace statefulset-718 deletion completed in 10.621550608s

• [SLOW TEST:151.894 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:36:34.333: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5194
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5194
STEP: creating replication controller externalsvc in namespace services-5194
I1104 18:36:34.728010      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5194, replica count: 2
I1104 18:36:37.778459      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Nov  4 18:36:37.887: INFO: Creating new exec pod
Nov  4 18:36:41.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-5194 execpodhrqzr -- /bin/sh -x -c nslookup nodeport-service'
Nov  4 18:36:42.570: INFO: stderr: "+ nslookup nodeport-service\n"
Nov  4 18:36:42.570: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-5194.svc.cluster.local\tcanonical name = externalsvc.services-5194.svc.cluster.local.\nName:\texternalsvc.services-5194.svc.cluster.local\nAddress: 172.21.133.74\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5194, will wait for the garbage collector to delete the pods
Nov  4 18:36:42.681: INFO: Deleting ReplicationController externalsvc took: 45.744502ms
Nov  4 18:36:42.781: INFO: Terminating ReplicationController externalsvc pods took: 100.274694ms
Nov  4 18:36:57.086: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:36:57.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5194" for this suite.
Nov  4 18:37:05.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:37:05.802: INFO: namespace services-5194 deletion completed in 8.611600729s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:31.470 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:37:05.804: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2297
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:37:10.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2297" for this suite.
Nov  4 18:37:56.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:37:56.835: INFO: namespace kubelet-test-2297 deletion completed in 46.585109417s

• [SLOW TEST:51.031 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:37:56.836: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2102
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Nov  4 18:37:57.085: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Nov  4 18:38:11.782: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:38:15.562: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:38:30.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2102" for this suite.
Nov  4 18:38:36.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:38:37.066: INFO: namespace crd-publish-openapi-2102 deletion completed in 6.595231257s

• [SLOW TEST:40.231 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:38:37.067: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:38:45.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7126" for this suite.
Nov  4 18:38:53.420: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:38:53.985: INFO: namespace job-7126 deletion completed in 8.632711078s

• [SLOW TEST:16.918 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:38:53.986: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4158
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Nov  4 18:38:54.268: INFO: Waiting up to 5m0s for pod "pod-c850734c-519e-413b-bc5b-64c6ff3866ef" in namespace "emptydir-4158" to be "success or failure"
Nov  4 18:38:54.281: INFO: Pod "pod-c850734c-519e-413b-bc5b-64c6ff3866ef": Phase="Pending", Reason="", readiness=false. Elapsed: 12.98556ms
Nov  4 18:38:56.292: INFO: Pod "pod-c850734c-519e-413b-bc5b-64c6ff3866ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024045716s
Nov  4 18:38:58.306: INFO: Pod "pod-c850734c-519e-413b-bc5b-64c6ff3866ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038661799s
STEP: Saw pod success
Nov  4 18:38:58.306: INFO: Pod "pod-c850734c-519e-413b-bc5b-64c6ff3866ef" satisfied condition "success or failure"
Nov  4 18:38:58.317: INFO: Trying to get logs from node 10.93.34.21 pod pod-c850734c-519e-413b-bc5b-64c6ff3866ef container test-container: <nil>
STEP: delete the pod
Nov  4 18:38:58.413: INFO: Waiting for pod pod-c850734c-519e-413b-bc5b-64c6ff3866ef to disappear
Nov  4 18:38:58.428: INFO: Pod pod-c850734c-519e-413b-bc5b-64c6ff3866ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:38:58.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4158" for this suite.
Nov  4 18:39:04.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:39:05.094: INFO: namespace emptydir-4158 deletion completed in 6.646893404s

• [SLOW TEST:11.109 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:39:05.097: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4349
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:39:07.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4349" for this suite.
Nov  4 18:39:15.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:39:16.223: INFO: namespace emptydir-wrapper-4349 deletion completed in 8.575985853s

• [SLOW TEST:11.126 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:39:16.223: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5345
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:39:17.420: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:39:19.489: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489557, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489557, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489557, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489557, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:39:22.554: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:39:22.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5345" for this suite.
Nov  4 18:39:30.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:39:31.492: INFO: namespace webhook-5345 deletion completed in 8.588257105s
STEP: Destroying namespace "webhook-5345-markers" for this suite.
Nov  4 18:39:37.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:39:38.073: INFO: namespace webhook-5345-markers deletion completed in 6.581148774s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.943 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:39:38.167: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4866
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Nov  4 18:39:38.413: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 18:39:42.195: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:39:57.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4866" for this suite.
Nov  4 18:40:03.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:03.804: INFO: namespace crd-publish-openapi-4866 deletion completed in 6.668135159s

• [SLOW TEST:25.638 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:03.805: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:40:04.612: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:40:06.665: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489604, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489604, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489604, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489604, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:40:09.727: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:40:09.744: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8015-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:11.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8628" for this suite.
Nov  4 18:40:19.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:19.818: INFO: namespace webhook-8628 deletion completed in 8.581496506s
STEP: Destroying namespace "webhook-8628-markers" for this suite.
Nov  4 18:40:25.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:26.390: INFO: namespace webhook-8628-markers deletion completed in 6.572157962s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.670 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:26.475: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:40:37.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-599" for this suite.
Nov  4 18:40:43.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:40:44.489: INFO: namespace resourcequota-599 deletion completed in 6.552770198s

• [SLOW TEST:18.014 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:40:44.490: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8198
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-5wtp
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 18:40:44.818: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-5wtp" in namespace "subpath-8198" to be "success or failure"
Nov  4 18:40:44.827: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Pending", Reason="", readiness=false. Elapsed: 9.214965ms
Nov  4 18:40:46.839: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 2.020366818s
Nov  4 18:40:48.853: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 4.034981917s
Nov  4 18:40:50.864: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 6.045494072s
Nov  4 18:40:52.874: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 8.055995576s
Nov  4 18:40:54.885: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 10.066837078s
Nov  4 18:40:56.910: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 12.091546776s
Nov  4 18:40:58.921: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 14.10318737s
Nov  4 18:41:00.934: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 16.11632935s
Nov  4 18:41:02.948: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 18.129765003s
Nov  4 18:41:04.959: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Running", Reason="", readiness=true. Elapsed: 20.140399817s
Nov  4 18:41:06.971: INFO: Pod "pod-subpath-test-projected-5wtp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.153102041s
STEP: Saw pod success
Nov  4 18:41:06.971: INFO: Pod "pod-subpath-test-projected-5wtp" satisfied condition "success or failure"
Nov  4 18:41:06.983: INFO: Trying to get logs from node 10.93.34.21 pod pod-subpath-test-projected-5wtp container test-container-subpath-projected-5wtp: <nil>
STEP: delete the pod
Nov  4 18:41:07.096: INFO: Waiting for pod pod-subpath-test-projected-5wtp to disappear
Nov  4 18:41:07.110: INFO: Pod pod-subpath-test-projected-5wtp no longer exists
STEP: Deleting pod pod-subpath-test-projected-5wtp
Nov  4 18:41:07.110: INFO: Deleting pod "pod-subpath-test-projected-5wtp" in namespace "subpath-8198"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:41:07.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8198" for this suite.
Nov  4 18:41:15.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:16.402: INFO: namespace subpath-8198 deletion completed in 9.243362805s

• [SLOW TEST:31.912 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:16.402: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1009
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:41:17.663: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:41:19.715: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489677, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489677, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489677, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489677, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:41:22.786: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Nov  4 18:41:24.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 attach --namespace=webhook-1009 to-be-attached-pod -i -c=container1'
Nov  4 18:41:25.172: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:41:25.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1009" for this suite.
Nov  4 18:41:39.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:39.796: INFO: namespace webhook-1009 deletion completed in 14.565333389s
STEP: Destroying namespace "webhook-1009-markers" for this suite.
Nov  4 18:41:45.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:41:46.385: INFO: namespace webhook-1009-markers deletion completed in 6.589301736s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.066 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:41:46.469: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4525
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4525.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4525.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4525.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4525.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4525.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4525.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:41:48.833: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.847: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.860: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.877: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.946: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.961: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.979: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:48.992: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:49.037: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:41:54.254: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:54.273: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:54.366: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:54.379: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:54.452: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:41:59.052: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:59.067: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:59.147: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:59.166: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:41:59.225: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:42:04.052: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:04.071: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:04.202: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:04.217: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:04.294: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:42:09.071: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:09.085: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:09.162: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:09.179: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:09.246: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:42:14.053: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:14.072: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:14.173: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:14.190: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:14.267: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:42:19.200: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:19.218: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local from pod dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da: the server could not find the requested resource (get pods dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da)
Nov  4 18:42:19.402: INFO: Lookups using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4525.svc.cluster.local]

Nov  4 18:42:24.238: INFO: DNS probes using dns-4525/dns-test-5eaf95ae-8e41-4fb4-9de9-19b1216454da succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:24.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4525" for this suite.
Nov  4 18:42:32.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:32.955: INFO: namespace dns-4525 deletion completed in 8.583789784s

• [SLOW TEST:46.486 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:32.955: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7686.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7686.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:42:37.429: INFO: DNS probes using dns-7686/dns-test-692dfec6-ada8-48ed-ab62-184c44ba6360 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:37.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7686" for this suite.
Nov  4 18:42:45.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:46.018: INFO: namespace dns-7686 deletion completed in 8.536410672s

• [SLOW TEST:13.063 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:46.019: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:42:46.289: INFO: Waiting up to 5m0s for pod "downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c" in namespace "downward-api-1596" to be "success or failure"
Nov  4 18:42:46.298: INFO: Pod "downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.051484ms
Nov  4 18:42:48.310: INFO: Pod "downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020255433s
STEP: Saw pod success
Nov  4 18:42:48.310: INFO: Pod "downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c" satisfied condition "success or failure"
Nov  4 18:42:48.320: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c container client-container: <nil>
STEP: delete the pod
Nov  4 18:42:48.433: INFO: Waiting for pod downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c to disappear
Nov  4 18:42:48.451: INFO: Pod downwardapi-volume-39a4f00a-4d6d-4d30-b5f8-c401c62d854c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:48.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1596" for this suite.
Nov  4 18:42:54.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:42:55.407: INFO: namespace downward-api-1596 deletion completed in 6.929598625s

• [SLOW TEST:9.388 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:42:55.407: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9561
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 18:42:55.650: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:42:59.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9561" for this suite.
Nov  4 18:43:07.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:08.744: INFO: namespace init-container-9561 deletion completed in 8.832197462s

• [SLOW TEST:13.337 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:08.745: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Nov  4 18:43:08.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-5798'
Nov  4 18:43:09.351: INFO: stderr: ""
Nov  4 18:43:09.351: INFO: stdout: "pod/pause created\n"
Nov  4 18:43:09.351: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Nov  4 18:43:09.351: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-5798" to be "running and ready"
Nov  4 18:43:09.364: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.823711ms
Nov  4 18:43:11.375: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.024000465s
Nov  4 18:43:11.375: INFO: Pod "pause" satisfied condition "running and ready"
Nov  4 18:43:11.376: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Nov  4 18:43:11.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 label pods pause testing-label=testing-label-value --namespace=kubectl-5798'
Nov  4 18:43:11.538: INFO: stderr: ""
Nov  4 18:43:11.538: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Nov  4 18:43:11.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pod pause -L testing-label --namespace=kubectl-5798'
Nov  4 18:43:11.663: INFO: stderr: ""
Nov  4 18:43:11.663: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Nov  4 18:43:11.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 label pods pause testing-label- --namespace=kubectl-5798'
Nov  4 18:43:11.824: INFO: stderr: ""
Nov  4 18:43:11.824: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Nov  4 18:43:11.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pod pause -L testing-label --namespace=kubectl-5798'
Nov  4 18:43:11.966: INFO: stderr: ""
Nov  4 18:43:11.966: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Nov  4 18:43:11.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-5798'
Nov  4 18:43:12.145: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 18:43:12.145: INFO: stdout: "pod \"pause\" force deleted\n"
Nov  4 18:43:12.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get rc,svc -l name=pause --no-headers --namespace=kubectl-5798'
Nov  4 18:43:12.300: INFO: stderr: "No resources found in kubectl-5798 namespace.\n"
Nov  4 18:43:12.300: INFO: stdout: ""
Nov  4 18:43:12.300: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -l name=pause --namespace=kubectl-5798 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 18:43:12.430: INFO: stderr: ""
Nov  4 18:43:12.430: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:12.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5798" for this suite.
Nov  4 18:43:18.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:19.010: INFO: namespace kubectl-5798 deletion completed in 6.558810484s

• [SLOW TEST:10.265 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:19.011: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Nov  4 18:43:21.882: INFO: Successfully updated pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a"
Nov  4 18:43:21.882: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a" in namespace "pods-7771" to be "terminated due to deadline exceeded"
Nov  4 18:43:21.894: INFO: Pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a": Phase="Running", Reason="", readiness=true. Elapsed: 12.457049ms
Nov  4 18:43:23.905: INFO: Pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a": Phase="Running", Reason="", readiness=true. Elapsed: 2.022766934s
Nov  4 18:43:25.916: INFO: Pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.033831507s
Nov  4 18:43:25.916: INFO: Pod "pod-update-activedeadlineseconds-383b32d7-88d1-4476-9d77-1a26bbab897a" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:25.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7771" for this suite.
Nov  4 18:43:35.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:36.471: INFO: namespace pods-7771 deletion completed in 10.534125308s

• [SLOW TEST:17.460 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:36.472: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5378
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Nov  4 18:43:36.748: INFO: Waiting up to 5m0s for pod "var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3" in namespace "var-expansion-5378" to be "success or failure"
Nov  4 18:43:36.758: INFO: Pod "var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.392764ms
Nov  4 18:43:38.781: INFO: Pod "var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.033312602s
Nov  4 18:43:40.792: INFO: Pod "var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.044445547s
STEP: Saw pod success
Nov  4 18:43:40.792: INFO: Pod "var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3" satisfied condition "success or failure"
Nov  4 18:43:40.802: INFO: Trying to get logs from node 10.93.34.21 pod var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3 container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:43:40.858: INFO: Waiting for pod var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3 to disappear
Nov  4 18:43:40.870: INFO: Pod var-expansion-7eca8a25-610a-4fc9-b465-5677337128b3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:43:40.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5378" for this suite.
Nov  4 18:43:48.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:43:49.455: INFO: namespace var-expansion-5378 deletion completed in 8.564180703s

• [SLOW TEST:12.984 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:43:49.458: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9378
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:44:49.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9378" for this suite.
Nov  4 18:45:19.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:20.443: INFO: namespace container-probe-9378 deletion completed in 30.673025435s

• [SLOW TEST:90.985 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:20.444: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9489
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:45:20.740: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d" in namespace "projected-9489" to be "success or failure"
Nov  4 18:45:20.756: INFO: Pod "downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d": Phase="Pending", Reason="", readiness=false. Elapsed: 15.518532ms
Nov  4 18:45:22.767: INFO: Pod "downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02652577s
STEP: Saw pod success
Nov  4 18:45:22.767: INFO: Pod "downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d" satisfied condition "success or failure"
Nov  4 18:45:22.777: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d container client-container: <nil>
STEP: delete the pod
Nov  4 18:45:22.886: INFO: Waiting for pod downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d to disappear
Nov  4 18:45:22.897: INFO: Pod downwardapi-volume-4ae09dcb-9b40-478a-b705-ce15dd19063d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:22.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9489" for this suite.
Nov  4 18:45:28.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:29.521: INFO: namespace projected-9489 deletion completed in 6.601371636s

• [SLOW TEST:9.077 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:29.523: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7360
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 18:45:29.772: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:33.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7360" for this suite.
Nov  4 18:45:41.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:41.766: INFO: namespace init-container-7360 deletion completed in 8.553602007s

• [SLOW TEST:12.243 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:41.766: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2979
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:45:42.029: INFO: Waiting up to 5m0s for pod "downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd" in namespace "projected-2979" to be "success or failure"
Nov  4 18:45:42.041: INFO: Pod "downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd": Phase="Pending", Reason="", readiness=false. Elapsed: 11.387976ms
Nov  4 18:45:44.064: INFO: Pod "downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034737274s
Nov  4 18:45:46.088: INFO: Pod "downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.058520151s
STEP: Saw pod success
Nov  4 18:45:46.088: INFO: Pod "downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd" satisfied condition "success or failure"
Nov  4 18:45:46.100: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd container client-container: <nil>
STEP: delete the pod
Nov  4 18:45:46.177: INFO: Waiting for pod downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd to disappear
Nov  4 18:45:46.187: INFO: Pod downwardapi-volume-529d35ca-c1cc-4eec-be8e-2290bd11cbbd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:45:46.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2979" for this suite.
Nov  4 18:45:52.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:45:52.833: INFO: namespace projected-2979 deletion completed in 6.624562067s

• [SLOW TEST:11.067 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:45:52.834: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1141
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:45:53.088: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Nov  4 18:45:56.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 create -f -'
Nov  4 18:45:57.504: INFO: stderr: ""
Nov  4 18:45:57.504: INFO: stdout: "e2e-test-crd-publish-openapi-935-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 18:45:57.504: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 delete e2e-test-crd-publish-openapi-935-crds test-foo'
Nov  4 18:45:57.788: INFO: stderr: ""
Nov  4 18:45:57.788: INFO: stdout: "e2e-test-crd-publish-openapi-935-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Nov  4 18:45:57.788: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 apply -f -'
Nov  4 18:45:58.223: INFO: stderr: ""
Nov  4 18:45:58.223: INFO: stdout: "e2e-test-crd-publish-openapi-935-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Nov  4 18:45:58.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 delete e2e-test-crd-publish-openapi-935-crds test-foo'
Nov  4 18:45:58.430: INFO: stderr: ""
Nov  4 18:45:58.430: INFO: stdout: "e2e-test-crd-publish-openapi-935-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Nov  4 18:45:58.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 create -f -'
Nov  4 18:45:58.787: INFO: rc: 1
Nov  4 18:45:58.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 apply -f -'
Nov  4 18:45:59.023: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Nov  4 18:45:59.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 create -f -'
Nov  4 18:45:59.242: INFO: rc: 1
Nov  4 18:45:59.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-1141 apply -f -'
Nov  4 18:45:59.605: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Nov  4 18:45:59.605: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-935-crds'
Nov  4 18:45:59.953: INFO: stderr: ""
Nov  4 18:45:59.953: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-935-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Nov  4 18:45:59.953: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-935-crds.metadata'
Nov  4 18:46:00.168: INFO: stderr: ""
Nov  4 18:46:00.168: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-935-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Nov  4 18:46:00.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-935-crds.spec'
Nov  4 18:46:00.505: INFO: stderr: ""
Nov  4 18:46:00.505: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-935-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Nov  4 18:46:00.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-935-crds.spec.bars'
Nov  4 18:46:00.727: INFO: stderr: ""
Nov  4 18:46:00.727: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-935-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Nov  4 18:46:00.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-935-crds.spec.bars2'
Nov  4 18:46:01.091: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:46:04.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1141" for this suite.
Nov  4 18:46:10.966: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:46:11.493: INFO: namespace crd-publish-openapi-1141 deletion completed in 6.591669605s

• [SLOW TEST:18.660 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:46:11.494: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-100b26da-9ab8-4809-9e10-6d49ba95f756
STEP: Creating a pod to test consume configMaps
Nov  4 18:46:11.810: INFO: Waiting up to 5m0s for pod "pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2" in namespace "configmap-3807" to be "success or failure"
Nov  4 18:46:11.822: INFO: Pod "pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2": Phase="Pending", Reason="", readiness=false. Elapsed: 12.222701ms
Nov  4 18:46:13.835: INFO: Pod "pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025516836s
Nov  4 18:46:15.846: INFO: Pod "pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036272195s
STEP: Saw pod success
Nov  4 18:46:15.846: INFO: Pod "pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2" satisfied condition "success or failure"
Nov  4 18:46:15.859: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:46:15.931: INFO: Waiting for pod pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2 to disappear
Nov  4 18:46:15.941: INFO: Pod pod-configmaps-36c67dd4-9d4c-48ba-93d1-ba1e0f4efda2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:46:15.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3807" for this suite.
Nov  4 18:46:24.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:46:24.556: INFO: namespace configmap-3807 deletion completed in 8.593901993s

• [SLOW TEST:13.062 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:46:24.556: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9970
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:46:25.431: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:46:27.486: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489985, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489985, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489985, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708489985, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:46:30.554: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
Nov  4 18:46:31.812: INFO: Waiting for webhook configuration to be ready...
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:46:43.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9970" for this suite.
Nov  4 18:46:51.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:46:51.964: INFO: namespace webhook-9970 deletion completed in 8.612559094s
STEP: Destroying namespace "webhook-9970-markers" for this suite.
Nov  4 18:47:00.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:47:00.520: INFO: namespace webhook-9970-markers deletion completed in 8.556019458s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:36.069 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:47:00.626: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8280
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Nov  4 18:47:00.900: INFO: Waiting up to 5m0s for pod "pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2" in namespace "emptydir-8280" to be "success or failure"
Nov  4 18:47:00.911: INFO: Pod "pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.259486ms
Nov  4 18:47:02.929: INFO: Pod "pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02869594s
Nov  4 18:47:04.941: INFO: Pod "pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.040554005s
STEP: Saw pod success
Nov  4 18:47:04.941: INFO: Pod "pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2" satisfied condition "success or failure"
Nov  4 18:47:04.951: INFO: Trying to get logs from node 10.93.34.21 pod pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2 container test-container: <nil>
STEP: delete the pod
Nov  4 18:47:05.026: INFO: Waiting for pod pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2 to disappear
Nov  4 18:47:05.038: INFO: Pod pod-82dddd90-8a35-4e8a-b4c4-1714ee5c21d2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:47:05.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8280" for this suite.
Nov  4 18:47:11.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:47:11.636: INFO: namespace emptydir-8280 deletion completed in 6.57808316s

• [SLOW TEST:11.011 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:47:11.637: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 18:47:11.932: INFO: Waiting up to 5m0s for pod "downward-api-386ca61a-3788-4234-9d49-8c242301d96c" in namespace "downward-api-3588" to be "success or failure"
Nov  4 18:47:11.952: INFO: Pod "downward-api-386ca61a-3788-4234-9d49-8c242301d96c": Phase="Pending", Reason="", readiness=false. Elapsed: 19.918448ms
Nov  4 18:47:13.963: INFO: Pod "downward-api-386ca61a-3788-4234-9d49-8c242301d96c": Phase="Running", Reason="", readiness=true. Elapsed: 2.031362141s
Nov  4 18:47:15.975: INFO: Pod "downward-api-386ca61a-3788-4234-9d49-8c242301d96c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.043289148s
STEP: Saw pod success
Nov  4 18:47:15.976: INFO: Pod "downward-api-386ca61a-3788-4234-9d49-8c242301d96c" satisfied condition "success or failure"
Nov  4 18:47:15.986: INFO: Trying to get logs from node 10.93.34.21 pod downward-api-386ca61a-3788-4234-9d49-8c242301d96c container dapi-container: <nil>
STEP: delete the pod
Nov  4 18:47:16.046: INFO: Waiting for pod downward-api-386ca61a-3788-4234-9d49-8c242301d96c to disappear
Nov  4 18:47:16.055: INFO: Pod downward-api-386ca61a-3788-4234-9d49-8c242301d96c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:47:16.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3588" for this suite.
Nov  4 18:47:24.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:47:24.908: INFO: namespace downward-api-3588 deletion completed in 8.832003505s

• [SLOW TEST:13.271 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:47:24.908: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-9658
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-9658
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9658
STEP: Deleting pre-stop pod
Nov  4 18:47:40.205: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:47:40.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9658" for this suite.
Nov  4 18:48:10.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:48:10.889: INFO: namespace prestop-9658 deletion completed in 30.637428131s

• [SLOW TEST:45.981 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:48:10.890: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4508
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:48:11.164: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf" in namespace "downward-api-4508" to be "success or failure"
Nov  4 18:48:11.176: INFO: Pod "downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.294238ms
Nov  4 18:48:13.188: INFO: Pod "downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023463112s
Nov  4 18:48:15.218: INFO: Pod "downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053639427s
STEP: Saw pod success
Nov  4 18:48:15.218: INFO: Pod "downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf" satisfied condition "success or failure"
Nov  4 18:48:15.229: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf container client-container: <nil>
STEP: delete the pod
Nov  4 18:48:15.294: INFO: Waiting for pod downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf to disappear
Nov  4 18:48:15.308: INFO: Pod downwardapi-volume-f9ece9bf-8716-40e7-a582-13f4fbe701bf no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:48:15.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4508" for this suite.
Nov  4 18:48:21.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:48:21.907: INFO: namespace downward-api-4508 deletion completed in 6.577979887s

• [SLOW TEST:11.017 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:48:21.908: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Nov  4 18:48:22.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 api-versions'
Nov  4 18:48:22.294: INFO: stderr: ""
Nov  4 18:48:22.294: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\noperators.coreos.com/v1alpha2\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:48:22.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4272" for this suite.
Nov  4 18:48:28.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:48:28.900: INFO: namespace kubectl-4272 deletion completed in 6.58786642s

• [SLOW TEST:6.992 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:48:28.900: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7318
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:48:29.153: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:48:33.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7318" for this suite.
Nov  4 18:49:19.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:49:20.302: INFO: namespace pods-7318 deletion completed in 46.864827639s

• [SLOW TEST:51.402 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:49:20.303: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6054
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-6054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6054 to expose endpoints map[]
Nov  4 18:49:20.637: INFO: successfully validated that service endpoint-test2 in namespace services-6054 exposes endpoints map[] (21.260283ms elapsed)
STEP: Creating pod pod1 in namespace services-6054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6054 to expose endpoints map[pod1:[80]]
Nov  4 18:49:22.756: INFO: successfully validated that service endpoint-test2 in namespace services-6054 exposes endpoints map[pod1:[80]] (2.092986564s elapsed)
STEP: Creating pod pod2 in namespace services-6054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6054 to expose endpoints map[pod1:[80] pod2:[80]]
Nov  4 18:49:24.914: INFO: successfully validated that service endpoint-test2 in namespace services-6054 exposes endpoints map[pod1:[80] pod2:[80]] (2.134574605s elapsed)
STEP: Deleting pod pod1 in namespace services-6054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6054 to expose endpoints map[pod2:[80]]
Nov  4 18:49:24.973: INFO: successfully validated that service endpoint-test2 in namespace services-6054 exposes endpoints map[pod2:[80]] (38.10483ms elapsed)
STEP: Deleting pod pod2 in namespace services-6054
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6054 to expose endpoints map[]
Nov  4 18:49:25.011: INFO: successfully validated that service endpoint-test2 in namespace services-6054 exposes endpoints map[] (16.581939ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:49:25.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6054" for this suite.
Nov  4 18:49:55.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:49:55.740: INFO: namespace services-6054 deletion completed in 30.615331893s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:35.437 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:49:55.740: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Nov  4 18:50:06.309: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:06.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1104 18:50:06.309783      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6044" for this suite.
Nov  4 18:50:16.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:50:16.956: INFO: namespace gc-6044 deletion completed in 10.61973076s

• [SLOW TEST:21.216 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:50:16.956: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3256
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-75aa012a-ef7a-466b-8bba-44de40306d46
STEP: Creating a pod to test consume configMaps
Nov  4 18:50:17.279: INFO: Waiting up to 5m0s for pod "pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2" in namespace "configmap-3256" to be "success or failure"
Nov  4 18:50:17.293: INFO: Pod "pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2": Phase="Pending", Reason="", readiness=false. Elapsed: 14.441281ms
Nov  4 18:50:19.305: INFO: Pod "pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026010658s
STEP: Saw pod success
Nov  4 18:50:19.305: INFO: Pod "pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2" satisfied condition "success or failure"
Nov  4 18:50:19.316: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:50:19.435: INFO: Waiting for pod pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2 to disappear
Nov  4 18:50:19.447: INFO: Pod pod-configmaps-7407b603-4bcb-46ee-99e9-583e2129f6b2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:19.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3256" for this suite.
Nov  4 18:50:27.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:50:28.046: INFO: namespace configmap-3256 deletion completed in 8.568094205s

• [SLOW TEST:11.090 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:50:28.047: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1ddec4f7-0533-481f-91e3-7ce398e558c5
STEP: Creating a pod to test consume configMaps
Nov  4 18:50:28.361: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955" in namespace "projected-3677" to be "success or failure"
Nov  4 18:50:28.373: INFO: Pod "pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955": Phase="Pending", Reason="", readiness=false. Elapsed: 12.35434ms
Nov  4 18:50:30.385: INFO: Pod "pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023873328s
STEP: Saw pod success
Nov  4 18:50:30.385: INFO: Pod "pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955" satisfied condition "success or failure"
Nov  4 18:50:30.395: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 18:50:30.473: INFO: Waiting for pod pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955 to disappear
Nov  4 18:50:30.488: INFO: Pod pod-projected-configmaps-4f45edc0-1ba1-4f02-badc-ec339f3bf955 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:30.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3677" for this suite.
Nov  4 18:50:36.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:50:37.086: INFO: namespace projected-3677 deletion completed in 6.577326701s

• [SLOW TEST:9.040 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:50:37.087: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7165
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-7165
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7165
STEP: creating replication controller externalsvc in namespace services-7165
I1104 18:50:37.459966      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7165, replica count: 2
I1104 18:50:40.510689      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Nov  4 18:50:40.640: INFO: Creating new exec pod
Nov  4 18:50:44.691: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-7165 execpod7p2ww -- /bin/sh -x -c nslookup clusterip-service'
Nov  4 18:50:45.093: INFO: stderr: "+ nslookup clusterip-service\n"
Nov  4 18:50:45.093: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-7165.svc.cluster.local\tcanonical name = externalsvc.services-7165.svc.cluster.local.\nName:\texternalsvc.services-7165.svc.cluster.local\nAddress: 172.21.210.59\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7165, will wait for the garbage collector to delete the pods
Nov  4 18:50:45.201: INFO: Deleting ReplicationController externalsvc took: 42.305639ms
Nov  4 18:50:45.402: INFO: Terminating ReplicationController externalsvc pods took: 200.248979ms
Nov  4 18:50:56.999: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:50:57.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7165" for this suite.
Nov  4 18:51:05.180: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:51:05.958: INFO: namespace services-7165 deletion completed in 8.838825557s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.871 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:51:05.959: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:51:08.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6823" for this suite.
Nov  4 18:51:56.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:51:56.918: INFO: namespace kubelet-test-6823 deletion completed in 48.583039414s

• [SLOW TEST:50.959 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:51:56.919: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 18:51:57.969: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 18:52:00.046: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490317, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490317, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490318, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490317, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 18:52:03.132: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:52:03.148: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6175-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:52:04.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7309" for this suite.
Nov  4 18:52:12.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:12.920: INFO: namespace webhook-7309 deletion completed in 8.670089258s
STEP: Destroying namespace "webhook-7309-markers" for this suite.
Nov  4 18:52:20.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:21.484: INFO: namespace webhook-7309-markers deletion completed in 8.564730563s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.652 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:52:21.572: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2121
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:52:21.847: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867" in namespace "downward-api-2121" to be "success or failure"
Nov  4 18:52:21.860: INFO: Pod "downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867": Phase="Pending", Reason="", readiness=false. Elapsed: 12.944236ms
Nov  4 18:52:23.874: INFO: Pod "downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.026923689s
Nov  4 18:52:25.885: INFO: Pod "downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038405514s
STEP: Saw pod success
Nov  4 18:52:25.885: INFO: Pod "downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867" satisfied condition "success or failure"
Nov  4 18:52:25.895: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867 container client-container: <nil>
STEP: delete the pod
Nov  4 18:52:25.950: INFO: Waiting for pod downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867 to disappear
Nov  4 18:52:25.967: INFO: Pod downwardapi-volume-b65dabbd-3e7d-4171-ad85-4a658c3f1867 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:52:25.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2121" for this suite.
Nov  4 18:52:34.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:34.592: INFO: namespace downward-api-2121 deletion completed in 8.602997018s

• [SLOW TEST:13.020 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:52:34.594: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8608
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:52:38.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8608" for this suite.
Nov  4 18:52:45.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:52:45.556: INFO: namespace kubelet-test-8608 deletion completed in 6.566183586s

• [SLOW TEST:10.962 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:52:45.558: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:53:07.857: INFO: Container started at 2019-11-04 18:52:47 +0000 UTC, pod became ready at 2019-11-04 18:53:05 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:53:07.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5359" for this suite.
Nov  4 18:53:37.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:53:38.435: INFO: namespace container-probe-5359 deletion completed in 30.55773187s

• [SLOW TEST:52.877 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:53:38.436: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6480
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[]
Nov  4 18:53:38.736: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[] (16.128451ms elapsed)
STEP: Creating pod pod1 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod1:[100]]
Nov  4 18:53:40.851: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod1:[100]] (2.089034892s elapsed)
STEP: Creating pod pod2 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod1:[100] pod2:[101]]
Nov  4 18:53:44.030: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod1:[100] pod2:[101]] (3.159457481s elapsed)
STEP: Deleting pod pod1 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[pod2:[101]]
Nov  4 18:53:44.075: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[pod2:[101]] (27.963559ms elapsed)
STEP: Deleting pod pod2 in namespace services-6480
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6480 to expose endpoints map[]
Nov  4 18:53:44.112: INFO: successfully validated that service multi-endpoint-test in namespace services-6480 exposes endpoints map[] (18.701685ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:53:44.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6480" for this suite.
Nov  4 18:53:58.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:53:58.907: INFO: namespace services-6480 deletion completed in 14.687066574s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.471 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:53:58.907: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-8967/secret-test-fabe74c2-fb1d-4f58-ac26-c98a5516ae10
STEP: Creating a pod to test consume secrets
Nov  4 18:53:59.200: INFO: Waiting up to 5m0s for pod "pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149" in namespace "secrets-8967" to be "success or failure"
Nov  4 18:53:59.213: INFO: Pod "pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149": Phase="Pending", Reason="", readiness=false. Elapsed: 12.701515ms
Nov  4 18:54:01.223: INFO: Pod "pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023590841s
STEP: Saw pod success
Nov  4 18:54:01.224: INFO: Pod "pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149" satisfied condition "success or failure"
Nov  4 18:54:01.235: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149 container env-test: <nil>
STEP: delete the pod
Nov  4 18:54:01.358: INFO: Waiting for pod pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149 to disappear
Nov  4 18:54:01.371: INFO: Pod pod-configmaps-c93989a2-6395-498a-8bd5-b5a8a5b11149 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:54:01.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8967" for this suite.
Nov  4 18:54:09.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:54:10.006: INFO: namespace secrets-8967 deletion completed in 8.610642203s

• [SLOW TEST:11.099 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:54:10.007: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2025
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:54:10.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-2025'
Nov  4 18:54:10.792: INFO: stderr: ""
Nov  4 18:54:10.792: INFO: stdout: "replicationcontroller/redis-master created\n"
Nov  4 18:54:10.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-2025'
Nov  4 18:54:11.050: INFO: stderr: ""
Nov  4 18:54:11.050: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Nov  4 18:54:12.066: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:54:12.066: INFO: Found 0 / 1
Nov  4 18:54:13.088: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:54:13.088: INFO: Found 0 / 1
Nov  4 18:54:14.062: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:54:14.062: INFO: Found 1 / 1
Nov  4 18:54:14.062: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Nov  4 18:54:14.094: INFO: Selector matched 1 pods for map[app:redis]
Nov  4 18:54:14.094: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Nov  4 18:54:14.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 describe pod redis-master-49fvn --namespace=kubectl-2025'
Nov  4 18:54:14.297: INFO: stderr: ""
Nov  4 18:54:14.297: INFO: stdout: "Name:         redis-master-49fvn\nNamespace:    kubectl-2025\nPriority:     0\nNode:         10.93.34.21/10.93.34.21\nStart Time:   Mon, 04 Nov 2019 18:54:10 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.102.53\nIPs:\n  IP:           172.30.102.53\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://faca9f3fbd461531dc81be1948025d12ed1f8b71ca8e0e8de44eac0ca28023a6\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 04 Nov 2019 18:54:12 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-54cc4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-54cc4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-54cc4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age        From                  Message\n  ----    ------     ----       ----                  -------\n  Normal  Scheduled  <unknown>  default-scheduler     Successfully assigned kubectl-2025/redis-master-49fvn to 10.93.34.21\n  Normal  Pulled     3s         kubelet, 10.93.34.21  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, 10.93.34.21  Created container redis-master\n  Normal  Started    2s         kubelet, 10.93.34.21  Started container redis-master\n"
Nov  4 18:54:14.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 describe rc redis-master --namespace=kubectl-2025'
Nov  4 18:54:14.527: INFO: stderr: ""
Nov  4 18:54:14.527: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2025\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  4s    replication-controller  Created pod: redis-master-49fvn\n"
Nov  4 18:54:14.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 describe service redis-master --namespace=kubectl-2025'
Nov  4 18:54:14.701: INFO: stderr: ""
Nov  4 18:54:14.701: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2025\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.14.114\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.102.53:6379\nSession Affinity:  None\nEvents:            <none>\n"
Nov  4 18:54:14.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 describe node 10.93.34.21'
Nov  4 18:54:14.947: INFO: stderr: ""
Nov  4 18:54:14.947: INFO: stdout: "Name:               10.93.34.21\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal10\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.63.203.101\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.93.34.21\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bn04h68d050fvqlslpo0-kubee2epvg1-default-000003d2\n                    ibm-cloud.kubernetes.io/worker-pool-id=bn04h68d050fvqlslpo0-e586c09\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.2_1514\n                    ibm-cloud.kubernetes.io/zone=dal10\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.93.34.21\n                    kubernetes.io/os=linux\n                    privateVLAN=2257397\n                    publicVLAN=2257383\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 04 Nov 2019 16:08:54 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 04 Nov 2019 18:53:59 +0000   Mon, 04 Nov 2019 16:08:54 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 04 Nov 2019 18:53:59 +0000   Mon, 04 Nov 2019 16:08:54 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 04 Nov 2019 18:53:59 +0000   Mon, 04 Nov 2019 16:08:54 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 04 Nov 2019 18:53:59 +0000   Mon, 04 Nov 2019 16:09:04 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.93.34.21\n  ExternalIP:  169.63.203.101\n  Hostname:    10.93.34.21\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419952Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627504Ki\n pods:               110\nSystem Info:\n Machine ID:                 a12bf22bf22d451f9a0b2516e22ebcb9\n System UUID:                C8266193-AF4C-0464-AD0D-7D153347E4DA\n Boot ID:                    1f749e6a-0442-41c9-9d1a-dd65443dc7bd\n Kernel Version:             4.15.0-66-generic\n OS Image:                   Ubuntu 18.04.3 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.0\n Kubelet Version:            v1.16.2+IKS\n Kube-Proxy Version:         v1.16.2+IKS\nProviderID:                  ibm://cc7530878c499d74ad77f31c918c626e///bn04h68d050fvqlslpo0/kube-bn04h68d050fvqlslpo0-kubee2epvg1-default-000003d2\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-rqnj2                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         165m\n  kube-system                ibm-keepalived-watcher-6p6hf                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         165m\n  kube-system                ibm-kube-fluentd-jskbg                                     25m (0%)      300m (7%)   150Mi (1%)       800M (5%)      164m\n  kube-system                ibm-master-proxy-static-10.93.34.21                        25m (0%)      300m (7%)   32M (0%)         512M (3%)      165m\n  kubectl-2025               redis-master-49fvn                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z    0 (0%)        0 (0%)      0 (0%)           0 (0%)         77m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                305m (7%)      600m (15%)\n  memory             277010Ki (2%)  1312M (9%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Nov  4 18:54:14.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 describe namespace kubectl-2025'
Nov  4 18:54:15.147: INFO: stderr: ""
Nov  4 18:54:15.147: INFO: stdout: "Name:         kubectl-2025\nLabels:       e2e-framework=kubectl\n              e2e-run=46823a00-03e7-4748-92ac-87ea7b15eaa7\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:54:15.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2025" for this suite.
Nov  4 18:54:45.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:54:46.752: INFO: namespace kubectl-2025 deletion completed in 31.581640989s

• [SLOW TEST:36.745 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:54:46.752: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3872
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:55:10.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3872" for this suite.
Nov  4 18:55:18.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:55:19.268: INFO: namespace container-runtime-3872 deletion completed in 8.565360897s

• [SLOW TEST:32.516 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:55:19.269: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6220
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 18:55:19.556: INFO: Waiting up to 5m0s for pod "downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8" in namespace "downward-api-6220" to be "success or failure"
Nov  4 18:55:19.568: INFO: Pod "downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.995905ms
Nov  4 18:55:21.583: INFO: Pod "downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027047826s
STEP: Saw pod success
Nov  4 18:55:21.583: INFO: Pod "downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8" satisfied condition "success or failure"
Nov  4 18:55:21.600: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8 container client-container: <nil>
STEP: delete the pod
Nov  4 18:55:21.675: INFO: Waiting for pod downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8 to disappear
Nov  4 18:55:21.686: INFO: Pod downwardapi-volume-26900aa0-3e32-4055-8878-a85274a0b2f8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:55:21.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6220" for this suite.
Nov  4 18:55:27.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:55:28.235: INFO: namespace downward-api-6220 deletion completed in 6.525139114s

• [SLOW TEST:8.966 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:55:28.235: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2992
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:55:28.505: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Nov  4 18:55:29.620: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:55:29.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2992" for this suite.
Nov  4 18:55:37.723: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:55:38.232: INFO: namespace replication-controller-2992 deletion completed in 8.569413585s

• [SLOW TEST:9.997 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:55:38.232: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-f4tx
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 18:55:38.550: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-f4tx" in namespace "subpath-3084" to be "success or failure"
Nov  4 18:55:38.565: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Pending", Reason="", readiness=false. Elapsed: 14.858263ms
Nov  4 18:55:40.575: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 2.025252553s
Nov  4 18:55:42.585: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 4.035708503s
Nov  4 18:55:44.605: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 6.054908433s
Nov  4 18:55:46.616: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 8.065942568s
Nov  4 18:55:48.626: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 10.076760556s
Nov  4 18:55:50.648: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 12.09846769s
Nov  4 18:55:52.661: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 14.110990322s
Nov  4 18:55:54.672: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 16.122549774s
Nov  4 18:55:56.684: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 18.134012909s
Nov  4 18:55:58.694: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Running", Reason="", readiness=true. Elapsed: 20.143883227s
Nov  4 18:56:00.706: INFO: Pod "pod-subpath-test-downwardapi-f4tx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.156315506s
STEP: Saw pod success
Nov  4 18:56:00.706: INFO: Pod "pod-subpath-test-downwardapi-f4tx" satisfied condition "success or failure"
Nov  4 18:56:00.716: INFO: Trying to get logs from node 10.93.34.21 pod pod-subpath-test-downwardapi-f4tx container test-container-subpath-downwardapi-f4tx: <nil>
STEP: delete the pod
Nov  4 18:56:00.777: INFO: Waiting for pod pod-subpath-test-downwardapi-f4tx to disappear
Nov  4 18:56:00.790: INFO: Pod pod-subpath-test-downwardapi-f4tx no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-f4tx
Nov  4 18:56:00.790: INFO: Deleting pod "pod-subpath-test-downwardapi-f4tx" in namespace "subpath-3084"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:56:00.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3084" for this suite.
Nov  4 18:56:08.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:56:09.528: INFO: namespace subpath-3084 deletion completed in 8.7057496s

• [SLOW TEST:31.296 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:56:09.528: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8783
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 18:56:11.932: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:56:11.975: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8783" for this suite.
Nov  4 18:56:18.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:56:18.654: INFO: namespace container-runtime-8783 deletion completed in 6.655789784s

• [SLOW TEST:9.126 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:56:18.655: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6423
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6423
I1104 18:56:19.012746      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6423, replica count: 2
I1104 18:56:22.063279      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 18:56:22.063: INFO: Creating new exec pod
Nov  4 18:56:25.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-6423 execpod6b79h -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Nov  4 18:56:25.541: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Nov  4 18:56:25.541: INFO: stdout: ""
Nov  4 18:56:25.541: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-6423 execpod6b79h -- /bin/sh -x -c nc -zv -t -w 2 172.21.229.212 80'
Nov  4 18:56:25.876: INFO: stderr: "+ nc -zv -t -w 2 172.21.229.212 80\nConnection to 172.21.229.212 80 port [tcp/http] succeeded!\n"
Nov  4 18:56:25.877: INFO: stdout: ""
Nov  4 18:56:25.877: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:56:25.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6423" for this suite.
Nov  4 18:56:34.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:56:34.594: INFO: namespace services-6423 deletion completed in 8.600527947s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.939 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:56:34.594: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5715
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-58d844d0-6a3e-411a-9dc7-73c395e6ca8e
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:56:37.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5715" for this suite.
Nov  4 18:56:55.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:56:55.656: INFO: namespace configmap-5715 deletion completed in 18.610568131s

• [SLOW TEST:21.062 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:56:55.656: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2115
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-2115.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2115.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.77.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.77.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.77.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.77.231_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-2115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-2115.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-2115.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-2115.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-2115.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2115.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 231.77.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.77.231_udp@PTR;check="$$(dig +tcp +noall +answer +search 231.77.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.77.231_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 18:57:00.141: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:00.283: INFO: Unable to read jessie_udp@dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:00.301: INFO: Unable to read jessie_tcp@dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:00.329: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:00.429: INFO: Lookups using dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa failed for: [wheezy_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local jessie_udp@dns-test-service.dns-2115.svc.cluster.local jessie_tcp@dns-test-service.dns-2115.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local]

Nov  4 18:57:05.627: INFO: Unable to read jessie_udp@dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:05.692: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local from pod dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa: the server could not find the requested resource (get pods dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa)
Nov  4 18:57:05.820: INFO: Lookups using dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa failed for: [jessie_udp@dns-test-service.dns-2115.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-2115.svc.cluster.local]

Nov  4 18:57:10.811: INFO: DNS probes using dns-2115/dns-test-9b34a45b-f8ae-4cac-948a-1a1ecca62caa succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:57:11.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2115" for this suite.
Nov  4 18:57:19.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:57:20.313: INFO: namespace dns-2115 deletion completed in 9.26750023s

• [SLOW TEST:24.657 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:57:20.313: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Nov  4 18:57:20.595: INFO: Waiting up to 5m0s for pod "client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f" in namespace "containers-1876" to be "success or failure"
Nov  4 18:57:20.605: INFO: Pod "client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.370983ms
Nov  4 18:57:22.619: INFO: Pod "client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024438324s
Nov  4 18:57:24.631: INFO: Pod "client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036580159s
STEP: Saw pod success
Nov  4 18:57:24.631: INFO: Pod "client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f" satisfied condition "success or failure"
Nov  4 18:57:24.642: INFO: Trying to get logs from node 10.93.34.21 pod client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f container test-container: <nil>
STEP: delete the pod
Nov  4 18:57:24.702: INFO: Waiting for pod client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f to disappear
Nov  4 18:57:24.717: INFO: Pod client-containers-7fa4fcef-e284-4fb1-a5fb-be48426b3e0f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:57:24.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1876" for this suite.
Nov  4 18:57:32.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:57:33.342: INFO: namespace containers-1876 deletion completed in 8.602090745s

• [SLOW TEST:13.029 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:57:33.342: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 18:57:33.584: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 18:57:33.648: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 18:57:33.681: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.21 before test
Nov  4 18:57:33.708: INFO: ibm-kube-fluentd-jskbg from kube-system started at 2019-11-04 16:09:19 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.708: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 18:57:33.708: INFO: ibm-master-proxy-static-10.93.34.21 from kube-system started at 2019-11-04 16:08:53 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.708: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 18:57:33.708: INFO: 	Container pause ready: true, restart count 0
Nov  4 18:57:33.708: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.708: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:57:33.708: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:57:33.708: INFO: calico-node-rqnj2 from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.708: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 18:57:33.708: INFO: ibm-keepalived-watcher-6p6hf from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.708: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 18:57:33.708: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.26 before test
Nov  4 18:57:33.786: INFO: coredns-6db888bf8c-pmtf2 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:57:33.786: INFO: ibm-keepalived-watcher-pnc97 from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 18:57:33.786: INFO: calico-node-dzhkq from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 18:57:33.786: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:57:33.786: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:57:33.786: INFO: calico-kube-controllers-77467ddb99-wgj9v from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  4 18:57:33.786: INFO: olm-operator-58994486f9-wlsgz from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container olm-operator ready: true, restart count 0
Nov  4 18:57:33.786: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-mjds9 from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 18:57:33.786: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 18:57:33.786: INFO: catalog-operator-7885df777c-gnrwp from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container catalog-operator ready: true, restart count 0
Nov  4 18:57:33.786: INFO: ibm-master-proxy-static-10.93.34.26 from kube-system started at 2019-11-04 16:12:06 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 	Container pause ready: true, restart count 0
Nov  4 18:57:33.786: INFO: coredns-6db888bf8c-5vkjd from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:57:33.786: INFO: sonobuoy-e2e-job-f11cbcc8e8e5452a from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container e2e ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 18:57:33.786: INFO: ibm-kube-fluentd-sjtjl from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.786: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 18:57:33.786: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.38 before test
Nov  4 18:57:33.881: INFO: coredns-autoscaler-65c89858bf-h4zm6 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container autoscaler ready: true, restart count 0
Nov  4 18:57:33.881: INFO: ibm-keepalived-watcher-n9c7j from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 18:57:33.881: INFO: kubernetes-dashboard-5fc98b6f46-g2rxn from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 18:57:33.881: INFO: dashboard-metrics-scraper-dff9cbb9c-85pzm from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  4 18:57:33.881: INFO: ibm-master-proxy-static-10.93.34.38 from kube-system started at 2019-11-04 16:16:27 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 18:57:33.881: INFO: 	Container pause ready: true, restart count 0
Nov  4 18:57:33.881: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 18:57:33.881: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 18:57:33.881: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 18:57:33.881: INFO: ibm-storage-watcher-77c86866cb-sjs6n from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov  4 18:57:33.881: INFO: metrics-server-d7b79fbb6-hhzpg from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container metrics-server ready: true, restart count 0
Nov  4 18:57:33.881: INFO: coredns-6db888bf8c-mgznm from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container coredns ready: true, restart count 0
Nov  4 18:57:33.881: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-04 16:17:52 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov  4 18:57:33.881: INFO: calico-node-k8p8l from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 18:57:33.881: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 18:57:33.881: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 18:57:33.881: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 18:57:33.881: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 18:57:33.881: INFO: sonobuoy from sonobuoy started at 2019-11-04 17:36:13 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 18:57:33.881: INFO: vpn-79845b6f9d-5q6t9 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container vpn ready: true, restart count 0
Nov  4 18:57:33.881: INFO: ibm-file-plugin-7c6d445669-p8xxj from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov  4 18:57:33.881: INFO: ibm-kube-fluentd-zwc56 from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 18:57:33.881: INFO: 	Container fluentd ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-5f955030-174f-40cf-80b7-2993607eb932 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-5f955030-174f-40cf-80b7-2993607eb932 off the node 10.93.34.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-5f955030-174f-40cf-80b7-2993607eb932
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:57:38.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5636" for this suite.
Nov  4 18:57:46.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:57:46.814: INFO: namespace sched-pred-5636 deletion completed in 8.623590892s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:13.473 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:57:46.816: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8329
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Nov  4 18:57:47.073: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:58:09.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8329" for this suite.
Nov  4 18:58:15.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:58:15.926: INFO: namespace crd-publish-openapi-8329 deletion completed in 6.847166378s

• [SLOW TEST:29.110 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:58:15.926: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-1681
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 18:58:16.186: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Creating first CR 
Nov  4 18:58:16.920: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:16Z generation:1 name:name1 resourceVersion:38133 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:c4184784-cc6f-4802-af9f-b69de9150f2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Nov  4 18:58:26.940: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:26Z generation:1 name:name2 resourceVersion:38147 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:653b5490-9579-43aa-9222-63907ba0c826] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Nov  4 18:58:36.960: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:16Z generation:2 name:name1 resourceVersion:38162 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:c4184784-cc6f-4802-af9f-b69de9150f2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Nov  4 18:58:47.000: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:26Z generation:2 name:name2 resourceVersion:38176 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:653b5490-9579-43aa-9222-63907ba0c826] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Nov  4 18:58:57.039: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:16Z generation:2 name:name1 resourceVersion:38191 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:c4184784-cc6f-4802-af9f-b69de9150f2a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Nov  4 18:59:07.081: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-11-04T18:58:26Z generation:2 name:name2 resourceVersion:38205 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:653b5490-9579-43aa-9222-63907ba0c826] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 18:59:17.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1681" for this suite.
Nov  4 18:59:25.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 18:59:26.563: INFO: namespace crd-watch-1681 deletion completed in 8.918356293s

• [SLOW TEST:70.637 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 18:59:26.563: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-594
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-594, will wait for the garbage collector to delete the pods
Nov  4 18:59:30.941: INFO: Deleting Job.batch foo took: 21.073246ms
Nov  4 18:59:31.142: INFO: Terminating Job.batch foo pods took: 200.267909ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:00:13.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-594" for this suite.
Nov  4 19:00:21.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:00:22.104: INFO: namespace job-594 deletion completed in 8.622239753s

• [SLOW TEST:55.541 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:00:22.105: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 19:00:22.384: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935" in namespace "downward-api-2887" to be "success or failure"
Nov  4 19:00:22.398: INFO: Pod "downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935": Phase="Pending", Reason="", readiness=false. Elapsed: 14.210895ms
Nov  4 19:00:24.425: INFO: Pod "downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041224919s
Nov  4 19:00:26.440: INFO: Pod "downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055545737s
STEP: Saw pod success
Nov  4 19:00:26.440: INFO: Pod "downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935" satisfied condition "success or failure"
Nov  4 19:00:26.451: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935 container client-container: <nil>
STEP: delete the pod
Nov  4 19:00:26.545: INFO: Waiting for pod downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935 to disappear
Nov  4 19:00:26.561: INFO: Pod downwardapi-volume-c9f4de38-a94b-453f-98ee-f9ebc7bce935 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:00:26.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2887" for this suite.
Nov  4 19:00:34.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:00:35.184: INFO: namespace downward-api-2887 deletion completed in 8.599631181s

• [SLOW TEST:13.080 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:00:35.187: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 19:00:37.520: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:00:37.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2704" for this suite.
Nov  4 19:00:43.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:00:44.285: INFO: namespace container-runtime-2704 deletion completed in 6.700973316s

• [SLOW TEST:9.098 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:00:44.286: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-4027
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Nov  4 19:00:47.657: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:00:48.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-4027" for this suite.
Nov  4 19:01:04.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:01:05.359: INFO: namespace replicaset-4027 deletion completed in 16.633233928s

• [SLOW TEST:21.073 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:01:05.359: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-5184
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Nov  4 19:01:10.194: INFO: Successfully updated pod "adopt-release-pg6d9"
STEP: Checking that the Job readopts the Pod
Nov  4 19:01:10.194: INFO: Waiting up to 15m0s for pod "adopt-release-pg6d9" in namespace "job-5184" to be "adopted"
Nov  4 19:01:10.211: INFO: Pod "adopt-release-pg6d9": Phase="Running", Reason="", readiness=true. Elapsed: 17.289471ms
Nov  4 19:01:12.222: INFO: Pod "adopt-release-pg6d9": Phase="Running", Reason="", readiness=true. Elapsed: 2.027802474s
Nov  4 19:01:12.222: INFO: Pod "adopt-release-pg6d9" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Nov  4 19:01:12.762: INFO: Successfully updated pod "adopt-release-pg6d9"
STEP: Checking that the Job releases the Pod
Nov  4 19:01:12.762: INFO: Waiting up to 15m0s for pod "adopt-release-pg6d9" in namespace "job-5184" to be "released"
Nov  4 19:01:12.776: INFO: Pod "adopt-release-pg6d9": Phase="Running", Reason="", readiness=true. Elapsed: 14.068309ms
Nov  4 19:01:12.777: INFO: Pod "adopt-release-pg6d9" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:01:12.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-5184" for this suite.
Nov  4 19:01:58.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:01:59.377: INFO: namespace job-5184 deletion completed in 46.57309655s

• [SLOW TEST:54.018 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:01:59.379: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:02:00.605: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Nov  4 19:02:02.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490921, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490921, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490921, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708490921, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:02:05.758: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:02:06.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-811" for this suite.
Nov  4 19:02:14.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:02:15.162: INFO: namespace webhook-811 deletion completed in 8.629222165s
STEP: Destroying namespace "webhook-811-markers" for this suite.
Nov  4 19:02:21.226: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:02:21.781: INFO: namespace webhook-811-markers deletion completed in 6.619243159s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.501 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:02:21.881: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 19:02:22.137: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 19:02:22.190: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 19:02:22.205: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.21 before test
Nov  4 19:02:22.291: INFO: ibm-keepalived-watcher-6p6hf from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.291: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:02:22.291: INFO: ibm-kube-fluentd-jskbg from kube-system started at 2019-11-04 16:09:19 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.291: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:02:22.291: INFO: ibm-master-proxy-static-10.93.34.21 from kube-system started at 2019-11-04 16:08:53 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.291: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:02:22.291: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:02:22.291: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.291: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:02:22.291: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:02:22.292: INFO: calico-node-rqnj2 from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.292: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:02:22.292: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.26 before test
Nov  4 19:02:22.424: INFO: calico-kube-controllers-77467ddb99-wgj9v from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.424: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  4 19:02:22.424: INFO: olm-operator-58994486f9-wlsgz from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.425: INFO: 	Container olm-operator ready: true, restart count 0
Nov  4 19:02:22.425: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-mjds9 from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.425: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 19:02:22.425: INFO: ibm-master-proxy-static-10.93.34.26 from kube-system started at 2019-11-04 16:12:06 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.425: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:02:22.425: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:02:22.425: INFO: coredns-6db888bf8c-5vkjd from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.425: INFO: 	Container coredns ready: true, restart count 0
Nov  4 19:02:22.425: INFO: sonobuoy-e2e-job-f11cbcc8e8e5452a from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.425: INFO: 	Container e2e ready: true, restart count 0
Nov  4 19:02:22.426: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 19:02:22.426: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 19:02:22.426: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 19:02:22.426: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 19:02:22.426: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 19:02:22.426: INFO: catalog-operator-7885df777c-gnrwp from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container catalog-operator ready: true, restart count 0
Nov  4 19:02:22.426: INFO: ibm-kube-fluentd-sjtjl from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:02:22.426: INFO: ibm-keepalived-watcher-pnc97 from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:02:22.426: INFO: calico-node-dzhkq from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:02:22.426: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:02:22.426: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:02:22.426: INFO: coredns-6db888bf8c-pmtf2 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.426: INFO: 	Container coredns ready: true, restart count 0
Nov  4 19:02:22.426: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.38 before test
Nov  4 19:02:22.507: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-04 16:17:52 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.507: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov  4 19:02:22.507: INFO: calico-node-k8p8l from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.507: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:02:22.507: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 19:02:22.507: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 19:02:22.508: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 19:02:22.508: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 19:02:22.508: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 19:02:22.508: INFO: sonobuoy from sonobuoy started at 2019-11-04 17:36:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.508: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 19:02:22.508: INFO: vpn-79845b6f9d-5q6t9 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.508: INFO: 	Container vpn ready: true, restart count 0
Nov  4 19:02:22.508: INFO: ibm-file-plugin-7c6d445669-p8xxj from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.508: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov  4 19:02:22.508: INFO: ibm-kube-fluentd-zwc56 from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.509: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:02:22.509: INFO: coredns-autoscaler-65c89858bf-h4zm6 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.509: INFO: 	Container autoscaler ready: true, restart count 0
Nov  4 19:02:22.509: INFO: ibm-keepalived-watcher-n9c7j from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.509: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:02:22.509: INFO: kubernetes-dashboard-5fc98b6f46-g2rxn from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.509: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Nov  4 19:02:22.509: INFO: dashboard-metrics-scraper-dff9cbb9c-85pzm from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.509: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  4 19:02:22.509: INFO: ibm-master-proxy-static-10.93.34.38 from kube-system started at 2019-11-04 16:16:27 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.510: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:02:22.510: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:02:22.510: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.510: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 19:02:22.510: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:02:22.510: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:02:22.510: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:02:22.510: INFO: ibm-storage-watcher-77c86866cb-sjs6n from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.510: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov  4 19:02:22.510: INFO: metrics-server-d7b79fbb6-hhzpg from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.510: INFO: 	Container metrics-server ready: true, restart count 0
Nov  4 19:02:22.511: INFO: coredns-6db888bf8c-mgznm from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 19:02:22.511: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6e357544-1ea2-4784-a048-c8de9b9f1ea5 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-6e357544-1ea2-4784-a048-c8de9b9f1ea5 off the node 10.93.34.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6e357544-1ea2-4784-a048-c8de9b9f1ea5
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:07:26.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6835" for this suite.
Nov  4 19:07:46.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:07:47.340: INFO: namespace sched-pred-6835 deletion completed in 20.533318304s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:325.459 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:07:47.340: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-920348f8-5776-4f10-889c-72f42f597044
STEP: Creating a pod to test consume configMaps
Nov  4 19:07:47.644: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f" in namespace "projected-3864" to be "success or failure"
Nov  4 19:07:47.658: INFO: Pod "pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 13.528587ms
Nov  4 19:07:49.669: INFO: Pod "pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0247381s
Nov  4 19:07:51.680: INFO: Pod "pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.035182737s
STEP: Saw pod success
Nov  4 19:07:51.680: INFO: Pod "pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f" satisfied condition "success or failure"
Nov  4 19:07:51.691: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:07:51.799: INFO: Waiting for pod pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f to disappear
Nov  4 19:07:51.809: INFO: Pod pod-projected-configmaps-f658fa6c-5183-48a9-a754-4dee80d26a7f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:07:51.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3864" for this suite.
Nov  4 19:07:58.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:07:58.528: INFO: namespace projected-3864 deletion completed in 6.545124466s

• [SLOW TEST:11.188 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:07:58.528: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-d1e3bcf8-2bc2-43f6-a8d8-adce68dbb4ba in namespace container-probe-8379
Nov  4 19:08:00.838: INFO: Started pod liveness-d1e3bcf8-2bc2-43f6-a8d8-adce68dbb4ba in namespace container-probe-8379
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 19:08:00.848: INFO: Initial restart count of pod liveness-d1e3bcf8-2bc2-43f6-a8d8-adce68dbb4ba is 0
Nov  4 19:08:22.993: INFO: Restart count of pod container-probe-8379/liveness-d1e3bcf8-2bc2-43f6-a8d8-adce68dbb4ba is now 1 (22.145005503s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:08:23.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8379" for this suite.
Nov  4 19:08:31.104: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:08:31.600: INFO: namespace container-probe-8379 deletion completed in 8.555311909s

• [SLOW TEST:33.072 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:08:31.601: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1922
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:08:32.517: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:08:35.607: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:08:35.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1922" for this suite.
Nov  4 19:08:44.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:08:44.523: INFO: namespace webhook-1922 deletion completed in 8.561346478s
STEP: Destroying namespace "webhook-1922-markers" for this suite.
Nov  4 19:08:50.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:08:51.104: INFO: namespace webhook-1922-markers deletion completed in 6.58094971s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.581 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:08:51.183: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1028
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:08:51.558: INFO: Create a RollingUpdate DaemonSet
Nov  4 19:08:51.575: INFO: Check that daemon pods launch on every node of the cluster
Nov  4 19:08:51.605: INFO: Number of nodes with available pods: 0
Nov  4 19:08:51.605: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:08:52.645: INFO: Number of nodes with available pods: 0
Nov  4 19:08:52.645: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:08:53.638: INFO: Number of nodes with available pods: 2
Nov  4 19:08:53.638: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:08:54.639: INFO: Number of nodes with available pods: 3
Nov  4 19:08:54.639: INFO: Number of running nodes: 3, number of available pods: 3
Nov  4 19:08:54.639: INFO: Update the DaemonSet to trigger a rollout
Nov  4 19:08:54.672: INFO: Updating DaemonSet daemon-set
Nov  4 19:08:58.729: INFO: Roll back the DaemonSet before rollout is complete
Nov  4 19:08:58.778: INFO: Updating DaemonSet daemon-set
Nov  4 19:08:58.778: INFO: Make sure DaemonSet rollback is complete
Nov  4 19:08:58.789: INFO: Wrong image for pod: daemon-set-fl66r. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 19:08:58.789: INFO: Pod daemon-set-fl66r is not available
Nov  4 19:08:59.841: INFO: Wrong image for pod: daemon-set-fl66r. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Nov  4 19:08:59.842: INFO: Pod daemon-set-fl66r is not available
Nov  4 19:09:00.841: INFO: Pod daemon-set-c4dh6 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1028, will wait for the garbage collector to delete the pods
Nov  4 19:09:01.016: INFO: Deleting DaemonSet.extensions daemon-set took: 50.973901ms
Nov  4 19:09:01.216: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.349464ms
Nov  4 19:09:08.027: INFO: Number of nodes with available pods: 0
Nov  4 19:09:08.027: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 19:09:08.043: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1028/daemonsets","resourceVersion":"39771"},"items":null}

Nov  4 19:09:08.053: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1028/pods","resourceVersion":"39771"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:09:08.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1028" for this suite.
Nov  4 19:09:16.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:09:16.895: INFO: namespace daemonsets-1028 deletion completed in 8.759198127s

• [SLOW TEST:25.712 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:09:16.895: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5863
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 19:09:17.180: INFO: Waiting up to 5m0s for pod "downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0" in namespace "downward-api-5863" to be "success or failure"
Nov  4 19:09:17.197: INFO: Pod "downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.801708ms
Nov  4 19:09:19.209: INFO: Pod "downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029171456s
STEP: Saw pod success
Nov  4 19:09:19.209: INFO: Pod "downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0" satisfied condition "success or failure"
Nov  4 19:09:19.221: INFO: Trying to get logs from node 10.93.34.21 pod downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0 container dapi-container: <nil>
STEP: delete the pod
Nov  4 19:09:19.390: INFO: Waiting for pod downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0 to disappear
Nov  4 19:09:19.403: INFO: Pod downward-api-544f08c9-b9c2-454b-9f1c-81fca3d40ad0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:09:19.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5863" for this suite.
Nov  4 19:09:25.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:09:25.978: INFO: namespace downward-api-5863 deletion completed in 6.548358082s

• [SLOW TEST:9.083 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:09:25.979: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2075
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Nov  4 19:09:28.333: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec pod-sharedvolume-58240664-1999-4cfe-b19c-199d49eed31b -c busybox-main-container --namespace=emptydir-2075 -- cat /usr/share/volumeshare/shareddata.txt'
Nov  4 19:09:28.778: INFO: stderr: ""
Nov  4 19:09:28.778: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:09:28.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2075" for this suite.
Nov  4 19:09:34.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:09:35.359: INFO: namespace emptydir-2075 deletion completed in 6.560846642s

• [SLOW TEST:9.381 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:09:35.360: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3633
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:09:48.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3633" for this suite.
Nov  4 19:09:54.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:09:55.387: INFO: namespace resourcequota-3633 deletion completed in 6.560455193s

• [SLOW TEST:20.027 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:09:55.387: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-d5a7456b-6573-46e5-9286-a1b72be97401
STEP: Creating a pod to test consume secrets
Nov  4 19:09:55.704: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd" in namespace "projected-8768" to be "success or failure"
Nov  4 19:09:55.716: INFO: Pod "pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.165397ms
Nov  4 19:09:57.727: INFO: Pod "pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.022947386s
Nov  4 19:09:59.739: INFO: Pod "pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.034578645s
STEP: Saw pod success
Nov  4 19:09:59.739: INFO: Pod "pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd" satisfied condition "success or failure"
Nov  4 19:09:59.750: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:09:59.812: INFO: Waiting for pod pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd to disappear
Nov  4 19:09:59.822: INFO: Pod pod-projected-secrets-0f5d0b83-e418-4b3c-9291-ebd6babbf2fd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:09:59.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8768" for this suite.
Nov  4 19:10:05.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:10:06.524: INFO: namespace projected-8768 deletion completed in 6.682101341s

• [SLOW TEST:11.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:10:06.524: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:10:06.793: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 version'
Nov  4 19:10:06.941: INFO: stderr: ""
Nov  4 19:10:06.941: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2+IKS\", GitCommit:\"df77605282a1d5e545052c5c66a4ecfc1cf0fe0e\", GitTreeState:\"clean\", BuildDate:\"2019-10-24T10:08:52Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:10:06.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2115" for this suite.
Nov  4 19:10:13.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:10:13.778: INFO: namespace kubectl-2115 deletion completed in 6.809558194s

• [SLOW TEST:7.254 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:10:13.778: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-4062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:10:14.931: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Nov  4 19:10:16.988: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491414, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491414, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491414, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491414, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:10:20.051: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:10:20.067: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:10:21.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-4062" for this suite.
Nov  4 19:10:29.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:10:30.052: INFO: namespace crd-webhook-4062 deletion completed in 8.593738663s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:16.354 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:10:30.133: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-781
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-781
STEP: creating replication controller nodeport-test in namespace services-781
I1104 19:10:30.482832      25 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-781, replica count: 2
Nov  4 19:10:33.533: INFO: Creating new exec pod
I1104 19:10:33.533324      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Nov  4 19:10:36.617: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Nov  4 19:10:37.218: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Nov  4 19:10:37.218: INFO: stdout: ""
Nov  4 19:10:37.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 172.21.130.199 80'
Nov  4 19:10:38.632: INFO: stderr: "+ nc -zv -t -w 2 172.21.130.199 80\nConnection to 172.21.130.199 80 port [tcp/http] succeeded!\n"
Nov  4 19:10:38.632: INFO: stdout: ""
Nov  4 19:10:38.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 10.93.34.21 30128'
Nov  4 19:10:38.973: INFO: stderr: "+ nc -zv -t -w 2 10.93.34.21 30128\nConnection to 10.93.34.21 30128 port [tcp/30128] succeeded!\n"
Nov  4 19:10:38.974: INFO: stdout: ""
Nov  4 19:10:38.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 10.93.34.26 30128'
Nov  4 19:10:39.377: INFO: stderr: "+ nc -zv -t -w 2 10.93.34.26 30128\nConnection to 10.93.34.26 30128 port [tcp/30128] succeeded!\n"
Nov  4 19:10:39.377: INFO: stdout: ""
Nov  4 19:10:39.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 169.63.203.101 30128'
Nov  4 19:10:39.767: INFO: stderr: "+ nc -zv -t -w 2 169.63.203.101 30128\nConnection to 169.63.203.101 30128 port [tcp/30128] succeeded!\n"
Nov  4 19:10:39.767: INFO: stdout: ""
Nov  4 19:10:39.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=services-781 execpodgt68f -- /bin/sh -x -c nc -zv -t -w 2 169.63.203.126 30128'
Nov  4 19:10:40.171: INFO: stderr: "+ nc -zv -t -w 2 169.63.203.126 30128\nConnection to 169.63.203.126 30128 port [tcp/30128] succeeded!\n"
Nov  4 19:10:40.171: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:10:40.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-781" for this suite.
Nov  4 19:10:48.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:10:48.793: INFO: namespace services-781 deletion completed in 8.598122691s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.660 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:10:48.793: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9447
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c936f65f-95a0-4dc6-91b8-0135be0d5fbb
STEP: Creating a pod to test consume secrets
Nov  4 19:10:49.077: INFO: Waiting up to 5m0s for pod "pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6" in namespace "secrets-9447" to be "success or failure"
Nov  4 19:10:49.090: INFO: Pod "pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6": Phase="Pending", Reason="", readiness=false. Elapsed: 12.602445ms
Nov  4 19:10:51.100: INFO: Pod "pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.023022738s
Nov  4 19:10:53.114: INFO: Pod "pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036833473s
STEP: Saw pod success
Nov  4 19:10:53.114: INFO: Pod "pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6" satisfied condition "success or failure"
Nov  4 19:10:53.126: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6 container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:10:53.179: INFO: Waiting for pod pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6 to disappear
Nov  4 19:10:53.188: INFO: Pod pod-secrets-6782c14d-b044-412b-b99f-77828b17beb6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:10:53.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9447" for this suite.
Nov  4 19:11:01.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:11:01.967: INFO: namespace secrets-9447 deletion completed in 8.752798001s

• [SLOW TEST:13.174 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:11:01.968: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:11:02.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8504" for this suite.
Nov  4 19:11:08.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:11:08.912: INFO: namespace services-8504 deletion completed in 6.609043531s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.945 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:11:08.913: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6090
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-lhqf
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 19:11:09.239: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-lhqf" in namespace "subpath-6090" to be "success or failure"
Nov  4 19:11:09.251: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Pending", Reason="", readiness=false. Elapsed: 11.959706ms
Nov  4 19:11:11.266: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 2.027085353s
Nov  4 19:11:13.281: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 4.041945379s
Nov  4 19:11:15.292: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 6.053142363s
Nov  4 19:11:17.304: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 8.065225216s
Nov  4 19:11:19.318: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 10.078721613s
Nov  4 19:11:21.330: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 12.090620636s
Nov  4 19:11:23.342: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 14.103055304s
Nov  4 19:11:25.354: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 16.115111826s
Nov  4 19:11:27.366: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 18.12698843s
Nov  4 19:11:29.377: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Running", Reason="", readiness=true. Elapsed: 20.137508265s
Nov  4 19:11:31.389: INFO: Pod "pod-subpath-test-configmap-lhqf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.149626295s
STEP: Saw pod success
Nov  4 19:11:31.389: INFO: Pod "pod-subpath-test-configmap-lhqf" satisfied condition "success or failure"
Nov  4 19:11:31.400: INFO: Trying to get logs from node 10.93.34.21 pod pod-subpath-test-configmap-lhqf container test-container-subpath-configmap-lhqf: <nil>
STEP: delete the pod
Nov  4 19:11:31.454: INFO: Waiting for pod pod-subpath-test-configmap-lhqf to disappear
Nov  4 19:11:31.466: INFO: Pod pod-subpath-test-configmap-lhqf no longer exists
STEP: Deleting pod pod-subpath-test-configmap-lhqf
Nov  4 19:11:31.467: INFO: Deleting pod "pod-subpath-test-configmap-lhqf" in namespace "subpath-6090"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:11:31.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6090" for this suite.
Nov  4 19:11:37.561: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:11:38.080: INFO: namespace subpath-6090 deletion completed in 6.582549708s

• [SLOW TEST:29.167 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:11:38.082: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6093
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:11:54.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6093" for this suite.
Nov  4 19:12:00.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:12:01.175: INFO: namespace resourcequota-6093 deletion completed in 6.628727288s

• [SLOW TEST:23.093 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:12:01.175: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-a3c8759b-5aeb-4333-b9ae-7492eca9f816
STEP: Creating a pod to test consume configMaps
Nov  4 19:12:01.483: INFO: Waiting up to 5m0s for pod "pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a" in namespace "configmap-733" to be "success or failure"
Nov  4 19:12:01.528: INFO: Pod "pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a": Phase="Pending", Reason="", readiness=false. Elapsed: 44.665803ms
Nov  4 19:12:03.539: INFO: Pod "pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.056239614s
STEP: Saw pod success
Nov  4 19:12:03.540: INFO: Pod "pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a" satisfied condition "success or failure"
Nov  4 19:12:03.556: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:12:03.639: INFO: Waiting for pod pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a to disappear
Nov  4 19:12:03.651: INFO: Pod pod-configmaps-4e010c68-0ab3-4ca7-97c1-66067d05327a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:12:03.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-733" for this suite.
Nov  4 19:12:09.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:12:10.426: INFO: namespace configmap-733 deletion completed in 6.750503262s

• [SLOW TEST:9.251 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:12:10.426: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:12:21.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2586" for this suite.
Nov  4 19:12:27.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:12:28.471: INFO: namespace resourcequota-2586 deletion completed in 6.548018223s

• [SLOW TEST:18.045 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:12:28.471: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-9877
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:12:28.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-9877" for this suite.
Nov  4 19:12:34.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:12:35.311: INFO: namespace custom-resource-definition-9877 deletion completed in 6.546264433s

• [SLOW TEST:6.839 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:12:35.311: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Nov  4 19:12:35.700: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9220 /api/v1/namespaces/watch-9220/configmaps/e2e-watch-test-resource-version 5dfb5c4b-ecb3-4439-ac81-c80be3282b0b 40630 0 2019-11-04 19:12:35 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 19:12:35.700: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-9220 /api/v1/namespaces/watch-9220/configmaps/e2e-watch-test-resource-version 5dfb5c4b-ecb3-4439-ac81-c80be3282b0b 40631 0 2019-11-04 19:12:35 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:12:35.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9220" for this suite.
Nov  4 19:12:41.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:12:42.284: INFO: namespace watch-9220 deletion completed in 6.560907914s

• [SLOW TEST:6.973 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:12:42.284: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6787
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-bf02bab0-f2e8-4d72-a9d8-838f9fa1edff in namespace container-probe-6787
Nov  4 19:12:44.576: INFO: Started pod busybox-bf02bab0-f2e8-4d72-a9d8-838f9fa1edff in namespace container-probe-6787
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 19:12:44.588: INFO: Initial restart count of pod busybox-bf02bab0-f2e8-4d72-a9d8-838f9fa1edff is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:16:45.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6787" for this suite.
Nov  4 19:16:53.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:16:53.929: INFO: namespace container-probe-6787 deletion completed in 8.556227232s

• [SLOW TEST:251.644 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:16:53.931: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3070
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:16:54.194: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:16:54.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3070" for this suite.
Nov  4 19:17:00.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:17:01.490: INFO: namespace custom-resource-definition-3070 deletion completed in 6.661299422s

• [SLOW TEST:7.560 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:17:01.491: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7160
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:17:02.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7160" for this suite.
Nov  4 19:17:08.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:17:09.193: INFO: namespace kubelet-test-7160 deletion completed in 6.665208498s

• [SLOW TEST:7.702 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:17:09.193: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2
Nov  4 19:17:09.477: INFO: Pod name my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2: Found 0 pods out of 1
Nov  4 19:17:14.496: INFO: Pod name my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2: Found 1 pods out of 1
Nov  4 19:17:14.496: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2" are running
Nov  4 19:17:14.515: INFO: Pod "my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2-ps7tz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:17:09 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:17:11 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:17:11 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:17:09 +0000 UTC Reason: Message:}])
Nov  4 19:17:14.515: INFO: Trying to dial the pod
Nov  4 19:17:19.575: INFO: Controller my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2: Got expected result from replica 1 [my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2-ps7tz]: "my-hostname-basic-1624fe26-8e00-4c48-82cc-871f1b76dbf2-ps7tz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:17:19.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3939" for this suite.
Nov  4 19:17:25.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:17:26.164: INFO: namespace replication-controller-3939 deletion completed in 6.567950711s

• [SLOW TEST:16.971 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:17:26.165: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8031
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Nov  4 19:17:26.436: INFO: PodSpec: initContainers in spec.initContainers
Nov  4 19:18:17.025: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-53ad60b9-3b97-4751-8b01-4711746847ad", GenerateName:"", Namespace:"init-container-8031", SelfLink:"/api/v1/namespaces/init-container-8031/pods/pod-init-53ad60b9-3b97-4751-8b01-4711746847ad", UID:"01c7aeb7-3f42-44f5-ab1a-ed511330ac04", ResourceVersion:"41251", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63708491846, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"436354960"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-4rkts", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc004f32000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4rkts", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4rkts", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-4rkts", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc002a78168), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.93.34.21", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc00810a000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002a78280)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc002a782a0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc002a782a8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc002a782ac), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491846, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491846, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491846, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708491846, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.93.34.21", PodIP:"172.30.102.35", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.102.35"}}, StartTime:(*v1.Time)(0xc0026b3200), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(0xc0026b33c0), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0034d6070)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://51bc5f5ff1d2a61106f33356710c152c71bab2bee1e4d7fcfc375749fce940a6", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026b3460), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0026b32c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc002a7833f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:18:17.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8031" for this suite.
Nov  4 19:18:47.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:18:47.587: INFO: namespace init-container-8031 deletion completed in 30.537985393s

• [SLOW TEST:81.422 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:18:47.587: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6463
STEP: Creating secret with name secret-test-6c70d533-dd6c-4840-8e87-8b4bf83529cd
STEP: Creating a pod to test consume secrets
Nov  4 19:18:48.178: INFO: Waiting up to 5m0s for pod "pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b" in namespace "secrets-3199" to be "success or failure"
Nov  4 19:18:48.190: INFO: Pod "pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b": Phase="Pending", Reason="", readiness=false. Elapsed: 11.813996ms
Nov  4 19:18:50.203: INFO: Pod "pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024934168s
STEP: Saw pod success
Nov  4 19:18:50.203: INFO: Pod "pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b" satisfied condition "success or failure"
Nov  4 19:18:50.214: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:18:50.338: INFO: Waiting for pod pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b to disappear
Nov  4 19:18:50.358: INFO: Pod pod-secrets-b2b54016-412e-4050-bf4b-eee6f0f6657b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:18:50.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3199" for this suite.
Nov  4 19:18:58.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:18:58.958: INFO: namespace secrets-3199 deletion completed in 8.577380992s
STEP: Destroying namespace "secret-namespace-6463" for this suite.
Nov  4 19:19:05.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:19:05.655: INFO: namespace secret-namespace-6463 deletion completed in 6.696954769s

• [SLOW TEST:18.068 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:19:05.657: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-2136
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Nov  4 19:19:05.927: INFO: Waiting up to 1m0s for all nodes to be ready
Nov  4 19:20:06.006: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:20:06.037: INFO: Starting informer...
STEP: Starting pod...
Nov  4 19:20:06.101: INFO: Pod is running on 10.93.34.21. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Nov  4 19:20:06.162: INFO: Pod wasn't evicted. Proceeding
Nov  4 19:20:06.162: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Nov  4 19:21:21.204: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:21:21.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-2136" for this suite.
Nov  4 19:21:51.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:21:51.802: INFO: namespace taint-single-pod-2136 deletion completed in 30.573101309s

• [SLOW TEST:166.146 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:21:51.805: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9159
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9159
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Nov  4 19:21:52.051: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Nov  4 19:22:16.305: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.102.36:8080/dial?request=hostName&protocol=http&host=172.30.75.206&port=8080&tries=1'] Namespace:pod-network-test-9159 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:22:16.305: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:22:16.532: INFO: Waiting for endpoints: map[]
Nov  4 19:22:16.545: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.102.36:8080/dial?request=hostName&protocol=http&host=172.30.168.105&port=8080&tries=1'] Namespace:pod-network-test-9159 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:22:16.545: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:22:16.792: INFO: Waiting for endpoints: map[]
Nov  4 19:22:16.805: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.102.36:8080/dial?request=hostName&protocol=http&host=172.30.102.40&port=8080&tries=1'] Namespace:pod-network-test-9159 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:22:16.805: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:22:17.410: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:22:17.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9159" for this suite.
Nov  4 19:22:31.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:22:32.278: INFO: namespace pod-network-test-9159 deletion completed in 14.846384065s

• [SLOW TEST:40.473 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:22:32.279: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9292
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Nov  4 19:22:32.554: INFO: Waiting up to 5m0s for pod "downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7" in namespace "downward-api-9292" to be "success or failure"
Nov  4 19:22:32.564: INFO: Pod "downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.101364ms
Nov  4 19:22:35.207: INFO: Pod "downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.652691148s
Nov  4 19:22:37.218: INFO: Pod "downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.663344086s
STEP: Saw pod success
Nov  4 19:22:37.218: INFO: Pod "downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7" satisfied condition "success or failure"
Nov  4 19:22:37.227: INFO: Trying to get logs from node 10.93.34.21 pod downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7 container dapi-container: <nil>
STEP: delete the pod
Nov  4 19:22:37.337: INFO: Waiting for pod downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7 to disappear
Nov  4 19:22:37.347: INFO: Pod downward-api-6a3fcb14-d550-4daf-a9bc-41e5c62ac8f7 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:22:37.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9292" for this suite.
Nov  4 19:22:43.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:22:43.978: INFO: namespace downward-api-9292 deletion completed in 6.610328361s

• [SLOW TEST:11.699 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:22:43.978: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7288
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-dd2c2cb4-bf29-467d-aef4-f99ee8abebbc
STEP: Creating a pod to test consume configMaps
Nov  4 19:22:44.558: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621" in namespace "projected-7288" to be "success or failure"
Nov  4 19:22:44.572: INFO: Pod "pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621": Phase="Pending", Reason="", readiness=false. Elapsed: 13.756883ms
Nov  4 19:22:46.584: INFO: Pod "pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025756997s
STEP: Saw pod success
Nov  4 19:22:46.584: INFO: Pod "pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621" satisfied condition "success or failure"
Nov  4 19:22:46.595: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:22:46.646: INFO: Waiting for pod pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621 to disappear
Nov  4 19:22:46.655: INFO: Pod pod-projected-configmaps-c3e5ac71-a019-4918-a659-4b10745dd621 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:22:46.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7288" for this suite.
Nov  4 19:22:52.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:22:53.236: INFO: namespace projected-7288 deletion completed in 6.559709432s

• [SLOW TEST:9.258 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:22:53.237: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Nov  4 19:22:53.495: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Nov  4 19:22:53.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:53.998: INFO: stderr: ""
Nov  4 19:22:53.998: INFO: stdout: "service/redis-slave created\n"
Nov  4 19:22:53.998: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Nov  4 19:22:53.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:54.291: INFO: stderr: ""
Nov  4 19:22:54.291: INFO: stdout: "service/redis-master created\n"
Nov  4 19:22:54.291: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Nov  4 19:22:54.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:54.647: INFO: stderr: ""
Nov  4 19:22:54.647: INFO: stdout: "service/frontend created\n"
Nov  4 19:22:54.647: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Nov  4 19:22:54.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:54.996: INFO: stderr: ""
Nov  4 19:22:54.996: INFO: stdout: "deployment.apps/frontend created\n"
Nov  4 19:22:54.996: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Nov  4 19:22:54.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:55.375: INFO: stderr: ""
Nov  4 19:22:55.375: INFO: stdout: "deployment.apps/redis-master created\n"
Nov  4 19:22:55.375: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Nov  4 19:22:55.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-8764'
Nov  4 19:22:55.740: INFO: stderr: ""
Nov  4 19:22:55.740: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Nov  4 19:22:55.740: INFO: Waiting for all frontend pods to be Running.
Nov  4 19:23:10.792: INFO: Waiting for frontend to serve content.
Nov  4 19:23:10.829: INFO: Trying to add a new entry to the guestbook.
Nov  4 19:23:10.869: INFO: Verifying that added entry can be retrieved.
Nov  4 19:23:10.908: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:15.948: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:20.986: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:26.028: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:31.067: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:36.100: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:41.143: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:46.182: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:51.218: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Nov  4 19:23:56.256: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Nov  4 19:24:01.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:01.554: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:01.554: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 19:24:01.554: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:01.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:01.812: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 19:24:01.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:02.061: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:02.061: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 19:24:02.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:02.236: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:02.236: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 19:24:02.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:02.437: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:02.437: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Nov  4 19:24:02.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Nov  4 19:24:02.666: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:24:02.666: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:24:02.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8764" for this suite.
Nov  4 19:24:16.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:24:17.281: INFO: namespace kubectl-8764 deletion completed in 14.588773084s

• [SLOW TEST:84.043 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:24:17.281: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a40513f5-5eed-4bc0-858f-2a83eccdd09a
STEP: Creating a pod to test consume secrets
Nov  4 19:24:17.617: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8" in namespace "projected-1047" to be "success or failure"
Nov  4 19:24:17.630: INFO: Pod "pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8": Phase="Pending", Reason="", readiness=false. Elapsed: 12.405535ms
Nov  4 19:24:19.641: INFO: Pod "pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023638312s
STEP: Saw pod success
Nov  4 19:24:19.641: INFO: Pod "pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8" satisfied condition "success or failure"
Nov  4 19:24:19.652: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:24:19.747: INFO: Waiting for pod pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8 to disappear
Nov  4 19:24:19.762: INFO: Pod pod-projected-secrets-34026277-16ba-4ebe-9b21-6ecc06bb99f8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:24:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1047" for this suite.
Nov  4 19:24:26.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:24:26.461: INFO: namespace projected-1047 deletion completed in 6.671271659s

• [SLOW TEST:9.181 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:24:26.461: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-71
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:24:26.731: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:24:28.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-71" for this suite.
Nov  4 19:25:14.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:25:15.523: INFO: namespace pods-71 deletion completed in 46.599817117s

• [SLOW TEST:49.062 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:25:15.523: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Nov  4 19:25:18.430: INFO: Successfully updated pod "labelsupdate90963669-ea6e-48da-bf19-cdbd4aa167d9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:25:20.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2978" for this suite.
Nov  4 19:25:34.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:25:35.362: INFO: namespace projected-2978 deletion completed in 14.560131992s

• [SLOW TEST:19.839 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:25:35.363: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2266
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Nov  4 19:25:35.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-2266'
Nov  4 19:25:36.019: INFO: stderr: ""
Nov  4 19:25:36.019: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 19:25:36.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2266'
Nov  4 19:25:36.165: INFO: stderr: ""
Nov  4 19:25:36.165: INFO: stdout: "update-demo-nautilus-ltcsg update-demo-nautilus-vdc94 "
Nov  4 19:25:36.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-ltcsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:25:36.323: INFO: stderr: ""
Nov  4 19:25:36.323: INFO: stdout: ""
Nov  4 19:25:36.323: INFO: update-demo-nautilus-ltcsg is created but not running
Nov  4 19:25:41.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2266'
Nov  4 19:25:41.444: INFO: stderr: ""
Nov  4 19:25:41.444: INFO: stdout: "update-demo-nautilus-ltcsg update-demo-nautilus-vdc94 "
Nov  4 19:25:41.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-ltcsg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:25:41.564: INFO: stderr: ""
Nov  4 19:25:41.564: INFO: stdout: "true"
Nov  4 19:25:41.564: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-ltcsg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:25:41.707: INFO: stderr: ""
Nov  4 19:25:41.707: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:25:41.707: INFO: validating pod update-demo-nautilus-ltcsg
Nov  4 19:25:41.725: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:25:41.725: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:25:41.725: INFO: update-demo-nautilus-ltcsg is verified up and running
Nov  4 19:25:41.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-vdc94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:25:41.849: INFO: stderr: ""
Nov  4 19:25:41.849: INFO: stdout: "true"
Nov  4 19:25:41.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-vdc94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:25:41.974: INFO: stderr: ""
Nov  4 19:25:41.974: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:25:41.974: INFO: validating pod update-demo-nautilus-vdc94
Nov  4 19:25:41.991: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:25:41.991: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:25:41.991: INFO: update-demo-nautilus-vdc94 is verified up and running
STEP: rolling-update to new replication controller
Nov  4 19:25:41.993: INFO: scanned /root for discovery docs: <nil>
Nov  4 19:25:41.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-2266'
Nov  4 19:26:05.078: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Nov  4 19:26:05.078: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 19:26:05.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2266'
Nov  4 19:26:05.207: INFO: stderr: ""
Nov  4 19:26:05.207: INFO: stdout: "update-demo-kitten-c2cmk update-demo-kitten-jcblv "
Nov  4 19:26:05.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-kitten-c2cmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:26:05.331: INFO: stderr: ""
Nov  4 19:26:05.331: INFO: stdout: "true"
Nov  4 19:26:05.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-kitten-c2cmk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:26:05.483: INFO: stderr: ""
Nov  4 19:26:05.483: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 19:26:05.483: INFO: validating pod update-demo-kitten-c2cmk
Nov  4 19:26:05.500: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 19:26:05.500: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 19:26:05.500: INFO: update-demo-kitten-c2cmk is verified up and running
Nov  4 19:26:05.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-kitten-jcblv -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:26:05.632: INFO: stderr: ""
Nov  4 19:26:05.632: INFO: stdout: "true"
Nov  4 19:26:05.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-kitten-jcblv -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2266'
Nov  4 19:26:05.773: INFO: stderr: ""
Nov  4 19:26:05.773: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Nov  4 19:26:05.773: INFO: validating pod update-demo-kitten-jcblv
Nov  4 19:26:05.797: INFO: got data: {
  "image": "kitten.jpg"
}

Nov  4 19:26:05.797: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Nov  4 19:26:05.797: INFO: update-demo-kitten-jcblv is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:26:05.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2266" for this suite.
Nov  4 19:26:35.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:26:36.869: INFO: namespace kubectl-2266 deletion completed in 31.051314849s

• [SLOW TEST:61.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:26:36.869: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3409
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3409.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3409.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3409.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3409.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3409.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3409.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 19:26:41.305: INFO: DNS probes using dns-3409/dns-test-91bb33f6-ec89-4ee9-a772-fed93b21914a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:26:41.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3409" for this suite.
Nov  4 19:26:49.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:26:49.945: INFO: namespace dns-3409 deletion completed in 8.573470978s

• [SLOW TEST:13.076 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:26:49.945: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6513
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:27:07.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6513" for this suite.
Nov  4 19:27:13.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:27:14.077: INFO: namespace resourcequota-6513 deletion completed in 6.639585422s

• [SLOW TEST:24.132 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:27:14.078: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2921
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-l4jx
STEP: Creating a pod to test atomic-volume-subpath
Nov  4 19:27:14.416: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-l4jx" in namespace "subpath-2921" to be "success or failure"
Nov  4 19:27:14.430: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Pending", Reason="", readiness=false. Elapsed: 13.890099ms
Nov  4 19:27:16.447: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 2.030260064s
Nov  4 19:27:18.560: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 4.143218792s
Nov  4 19:27:20.570: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 6.15377009s
Nov  4 19:27:22.583: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 8.166525417s
Nov  4 19:27:24.597: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 10.180223933s
Nov  4 19:27:26.607: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 12.190759815s
Nov  4 19:27:28.617: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 14.200803188s
Nov  4 19:27:30.628: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 16.211922115s
Nov  4 19:27:32.642: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 18.225145459s
Nov  4 19:27:34.653: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Running", Reason="", readiness=true. Elapsed: 20.23642307s
Nov  4 19:27:36.663: INFO: Pod "pod-subpath-test-secret-l4jx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.246719785s
STEP: Saw pod success
Nov  4 19:27:36.663: INFO: Pod "pod-subpath-test-secret-l4jx" satisfied condition "success or failure"
Nov  4 19:27:36.673: INFO: Trying to get logs from node 10.93.34.21 pod pod-subpath-test-secret-l4jx container test-container-subpath-secret-l4jx: <nil>
STEP: delete the pod
Nov  4 19:27:36.770: INFO: Waiting for pod pod-subpath-test-secret-l4jx to disappear
Nov  4 19:27:36.780: INFO: Pod pod-subpath-test-secret-l4jx no longer exists
STEP: Deleting pod pod-subpath-test-secret-l4jx
Nov  4 19:27:36.780: INFO: Deleting pod "pod-subpath-test-secret-l4jx" in namespace "subpath-2921"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:27:36.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2921" for this suite.
Nov  4 19:27:44.870: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:27:45.377: INFO: namespace subpath-2921 deletion completed in 8.565709673s

• [SLOW TEST:31.299 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:27:45.378: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Nov  4 19:27:49.708: INFO: Pod pod-hostip-de50909f-345d-4b35-b3aa-2aec48771f52 has hostIP: 10.93.34.21
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:27:49.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4968" for this suite.
Nov  4 19:28:19.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:28:20.346: INFO: namespace pods-4968 deletion completed in 30.617129879s

• [SLOW TEST:34.968 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:28:20.346: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-87fc96ea-d5be-4a9d-ab45-4eb8e47a75c3
STEP: Creating a pod to test consume configMaps
Nov  4 19:28:21.499: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7" in namespace "projected-2521" to be "success or failure"
Nov  4 19:28:21.512: INFO: Pod "pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.6016ms
Nov  4 19:28:23.525: INFO: Pod "pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025134429s
STEP: Saw pod success
Nov  4 19:28:23.525: INFO: Pod "pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7" satisfied condition "success or failure"
Nov  4 19:28:23.535: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:28:23.593: INFO: Waiting for pod pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7 to disappear
Nov  4 19:28:23.607: INFO: Pod pod-projected-configmaps-ffe0ee3d-9249-4b3f-83b4-78f932bd16c7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:28:23.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2521" for this suite.
Nov  4 19:28:29.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:28:30.187: INFO: namespace projected-2521 deletion completed in 6.547469021s

• [SLOW TEST:9.841 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:28:30.189: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-9080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Nov  4 19:28:31.412: INFO: Pod name wrapped-volume-race-c534c9ec-be05-4729-bc7c-a74a363213ed: Found 0 pods out of 5
Nov  4 19:28:36.429: INFO: Pod name wrapped-volume-race-c534c9ec-be05-4729-bc7c-a74a363213ed: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c534c9ec-be05-4729-bc7c-a74a363213ed in namespace emptydir-wrapper-9080, will wait for the garbage collector to delete the pods
Nov  4 19:28:36.592: INFO: Deleting ReplicationController wrapped-volume-race-c534c9ec-be05-4729-bc7c-a74a363213ed took: 41.141363ms
Nov  4 19:28:36.792: INFO: Terminating ReplicationController wrapped-volume-race-c534c9ec-be05-4729-bc7c-a74a363213ed pods took: 200.576419ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 19:29:13.791: INFO: Pod name wrapped-volume-race-93e64f8a-e658-466e-9e0e-6b7e36357794: Found 0 pods out of 5
Nov  4 19:29:18.812: INFO: Pod name wrapped-volume-race-93e64f8a-e658-466e-9e0e-6b7e36357794: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-93e64f8a-e658-466e-9e0e-6b7e36357794 in namespace emptydir-wrapper-9080, will wait for the garbage collector to delete the pods
Nov  4 19:29:18.980: INFO: Deleting ReplicationController wrapped-volume-race-93e64f8a-e658-466e-9e0e-6b7e36357794 took: 46.119543ms
Nov  4 19:29:19.181: INFO: Terminating ReplicationController wrapped-volume-race-93e64f8a-e658-466e-9e0e-6b7e36357794 pods took: 200.333118ms
STEP: Creating RC which spawns configmap-volume pods
Nov  4 19:30:03.564: INFO: Pod name wrapped-volume-race-5f6187f7-0dd6-437e-9562-fefaff7eec69: Found 0 pods out of 5
Nov  4 19:30:08.593: INFO: Pod name wrapped-volume-race-5f6187f7-0dd6-437e-9562-fefaff7eec69: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5f6187f7-0dd6-437e-9562-fefaff7eec69 in namespace emptydir-wrapper-9080, will wait for the garbage collector to delete the pods
Nov  4 19:30:08.755: INFO: Deleting ReplicationController wrapped-volume-race-5f6187f7-0dd6-437e-9562-fefaff7eec69 took: 38.113149ms
Nov  4 19:30:08.956: INFO: Terminating ReplicationController wrapped-volume-race-5f6187f7-0dd6-437e-9562-fefaff7eec69 pods took: 200.537799ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:30:46.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9080" for this suite.
Nov  4 19:30:56.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:30:57.192: INFO: namespace emptydir-wrapper-9080 deletion completed in 10.574946187s

• [SLOW TEST:147.003 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:30:57.192: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2680
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Nov  4 19:30:57.454: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Nov  4 19:31:04.630: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:31:04.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2680" for this suite.
Nov  4 19:31:12.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:31:13.481: INFO: namespace pods-2680 deletion completed in 8.815425755s

• [SLOW TEST:16.289 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:31:13.482: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5682
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-9ff0b61e-a958-43f2-9c36-f11ab73d32ee
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:31:13.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5682" for this suite.
Nov  4 19:31:19.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:31:20.357: INFO: namespace configmap-5682 deletion completed in 6.5780206s

• [SLOW TEST:6.875 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:31:20.358: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Nov  4 19:31:20.624: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Nov  4 19:31:20.677: INFO: Waiting for terminating namespaces to be deleted...
Nov  4 19:31:20.692: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.21 before test
Nov  4 19:31:20.727: INFO: ibm-keepalived-watcher-6p6hf from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.727: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:31:20.727: INFO: ibm-kube-fluentd-jskbg from kube-system started at 2019-11-04 16:09:19 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.727: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:31:20.727: INFO: ibm-master-proxy-static-10.93.34.21 from kube-system started at 2019-11-04 16:08:53 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.727: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:31:20.727: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:31:20.727: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-clq4z from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.727: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:31:20.727: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:31:20.728: INFO: calico-node-rqnj2 from kube-system started at 2019-11-04 16:08:55 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.728: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:31:20.728: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.26 before test
Nov  4 19:31:20.840: INFO: calico-kube-controllers-77467ddb99-wgj9v from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.840: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Nov  4 19:31:20.840: INFO: olm-operator-58994486f9-wlsgz from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container olm-operator ready: true, restart count 0
Nov  4 19:31:20.841: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-mjds9 from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 19:31:20.841: INFO: ibm-master-proxy-static-10.93.34.26 from kube-system started at 2019-11-04 16:12:06 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:31:20.841: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:31:20.841: INFO: coredns-6db888bf8c-5vkjd from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container coredns ready: true, restart count 0
Nov  4 19:31:20.841: INFO: sonobuoy-e2e-job-f11cbcc8e8e5452a from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container e2e ready: true, restart count 0
Nov  4 19:31:20.841: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Nov  4 19:31:20.841: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-g9kk2 from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 19:31:20.841: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 19:31:20.841: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 19:31:20.841: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 19:31:20.841: INFO: catalog-operator-7885df777c-gnrwp from ibm-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container catalog-operator ready: true, restart count 0
Nov  4 19:31:20.841: INFO: ibm-kube-fluentd-sjtjl from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:31:20.841: INFO: ibm-keepalived-watcher-pnc97 from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.841: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:31:20.842: INFO: calico-node-dzhkq from kube-system started at 2019-11-04 16:12:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.842: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:31:20.842: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-gcg4f from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.842: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:31:20.842: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:31:20.842: INFO: coredns-6db888bf8c-pmtf2 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.842: INFO: 	Container coredns ready: true, restart count 0
Nov  4 19:31:20.842: INFO: 
Logging pods the kubelet thinks is on node 10.93.34.38 before test
Nov  4 19:31:20.929: INFO: ibm-storage-watcher-77c86866cb-sjs6n from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.929: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Nov  4 19:31:20.929: INFO: metrics-server-d7b79fbb6-hhzpg from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.929: INFO: 	Container metrics-server ready: true, restart count 0
Nov  4 19:31:20.929: INFO: coredns-6db888bf8c-mgznm from kube-system started at 2019-11-04 16:32:57 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.929: INFO: 	Container coredns ready: true, restart count 0
Nov  4 19:31:20.929: INFO: ibm-cloud-provider-ip-169-48-129-162-7dc94bf8f8-wczn2 from ibm-system started at 2019-11-04 16:52:46 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.929: INFO: 	Container ibm-cloud-provider-ip-169-48-129-162 ready: true, restart count 0
Nov  4 19:31:20.930: INFO: sonobuoy-systemd-logs-daemon-set-462421946a62497f-l78gt from sonobuoy started at 2019-11-04 17:36:18 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.930: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Nov  4 19:31:20.930: INFO: 	Container systemd-logs ready: true, restart count 1
Nov  4 19:31:20.930: INFO: public-crbn04h68d050fvqlslpo0-alb1-54b8457d66-tgtbj from kube-system started at 2019-11-04 16:53:50 +0000 UTC (4 container statuses recorded)
Nov  4 19:31:20.930: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Nov  4 19:31:20.930: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Nov  4 19:31:20.930: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Nov  4 19:31:20.930: INFO: 	Container nginx-ingress ready: true, restart count 0
Nov  4 19:31:20.930: INFO: sonobuoy from sonobuoy started at 2019-11-04 17:36:13 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.930: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Nov  4 19:31:20.930: INFO: vpn-79845b6f9d-5q6t9 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.930: INFO: 	Container vpn ready: true, restart count 0
Nov  4 19:31:20.930: INFO: ibm-file-plugin-7c6d445669-p8xxj from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Nov  4 19:31:20.931: INFO: ibm-kube-fluentd-zwc56 from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container fluentd ready: true, restart count 0
Nov  4 19:31:20.931: INFO: test-k8s-e2e-pvg-master-verification from default started at 2019-11-04 16:17:52 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Nov  4 19:31:20.931: INFO: calico-node-k8p8l from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container calico-node ready: true, restart count 0
Nov  4 19:31:20.931: INFO: coredns-autoscaler-65c89858bf-h4zm6 from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container autoscaler ready: true, restart count 0
Nov  4 19:31:20.931: INFO: dashboard-metrics-scraper-dff9cbb9c-85pzm from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Nov  4 19:31:20.931: INFO: ibm-master-proxy-static-10.93.34.38 from kube-system started at 2019-11-04 16:16:27 +0000 UTC (2 container statuses recorded)
Nov  4 19:31:20.931: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Nov  4 19:31:20.931: INFO: 	Container pause ready: true, restart count 0
Nov  4 19:31:20.931: INFO: ibm-keepalived-watcher-n9c7j from kube-system started at 2019-11-04 16:16:34 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.932: INFO: 	Container keepalived-watcher ready: true, restart count 0
Nov  4 19:31:20.932: INFO: kubernetes-dashboard-5fc98b6f46-g2rxn from kube-system started at 2019-11-04 18:09:17 +0000 UTC (1 container statuses recorded)
Nov  4 19:31:20.932: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-70a2773d-6ffd-4bfb-8acf-902dc53ba211 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-70a2773d-6ffd-4bfb-8acf-902dc53ba211 off the node 10.93.34.21
STEP: verifying the node doesn't have the label kubernetes.io/e2e-70a2773d-6ffd-4bfb-8acf-902dc53ba211
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:31:35.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9565" for this suite.
Nov  4 19:31:55.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:31:55.819: INFO: namespace sched-pred-9565 deletion completed in 20.544516469s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:35.461 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:31:55.819: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-0
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-0
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Nov  4 19:31:56.153: INFO: Found 0 stateful pods, waiting for 3
Nov  4 19:32:06.167: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 19:32:06.167: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 19:32:06.167: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 19:32:06.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-0 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:32:06.762: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:32:06.762: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:32:06.762: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Nov  4 19:32:16.863: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Nov  4 19:32:26.931: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-0 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:32:27.294: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:32:27.294: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:32:27.294: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Nov  4 19:32:47.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-0 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:32:47.740: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:32:47.740: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:32:47.740: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 19:32:57.837: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Nov  4 19:33:07.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-0 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:33:08.484: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:33:08.484: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:33:08.484: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 19:33:18.596: INFO: Waiting for StatefulSet statefulset-0/ss2 to complete update
Nov  4 19:33:18.596: INFO: Waiting for Pod statefulset-0/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 19:33:18.596: INFO: Waiting for Pod statefulset-0/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Nov  4 19:33:28.624: INFO: Waiting for StatefulSet statefulset-0/ss2 to complete update
Nov  4 19:33:28.624: INFO: Waiting for Pod statefulset-0/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 19:33:38.624: INFO: Deleting all statefulset in ns statefulset-0
Nov  4 19:33:38.639: INFO: Scaling statefulset ss2 to 0
Nov  4 19:33:58.692: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 19:33:58.709: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:33:58.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-0" for this suite.
Nov  4 19:34:06.855: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:34:07.354: INFO: namespace statefulset-0 deletion completed in 8.564024064s

• [SLOW TEST:131.535 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:34:07.355: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:34:07.615: INFO: Creating deployment "test-recreate-deployment"
Nov  4 19:34:07.636: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Nov  4 19:34:07.680: INFO: Waiting deployment "test-recreate-deployment" to complete
Nov  4 19:34:07.695: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-68fc85c7bb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:34:09.712: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708492847, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:34:11.712: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Nov  4 19:34:11.752: INFO: Updating deployment test-recreate-deployment
Nov  4 19:34:11.752: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Nov  4 19:34:11.907: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6139 /apis/apps/v1/namespaces/deployment-6139/deployments/test-recreate-deployment 7e875a4a-9dec-4e8a-9e64-cbdaf48ed6a1 44726 2 2019-11-04 19:34:07 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004988658 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-11-04 19:34:11 +0000 UTC,LastTransitionTime:2019-11-04 19:34:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-11-04 19:34:11 +0000 UTC,LastTransitionTime:2019-11-04 19:34:07 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Nov  4 19:34:11.934: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-6139 /apis/apps/v1/namespaces/deployment-6139/replicasets/test-recreate-deployment-5f94c574ff 8abef168-171a-4589-a969-fa0eaf358749 44724 1 2019-11-04 19:34:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 7e875a4a-9dec-4e8a-9e64-cbdaf48ed6a1 0xc004988a37 0xc004988a38}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004988a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 19:34:11.934: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Nov  4 19:34:11.935: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-6139 /apis/apps/v1/namespaces/deployment-6139/replicasets/test-recreate-deployment-68fc85c7bb 3a2c6a36-e9da-46d0-a896-126cc9cb7c56 44713 2 2019-11-04 19:34:07 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 7e875a4a-9dec-4e8a-9e64-cbdaf48ed6a1 0xc004988b07 0xc004988b08}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004988b68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Nov  4 19:34:11.945: INFO: Pod "test-recreate-deployment-5f94c574ff-9799k" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-9799k test-recreate-deployment-5f94c574ff- deployment-6139 /api/v1/namespaces/deployment-6139/pods/test-recreate-deployment-5f94c574ff-9799k 04761559-ec3b-4fce-972e-7072ec90ac57 44727 0 2019-11-04 19:34:11 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 8abef168-171a-4589-a969-fa0eaf358749 0xc004988ff7 0xc004988ff8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f4wnd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f4wnd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f4wnd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.93.34.21,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 19:34:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 19:34:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 19:34:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-11-04 19:34:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.93.34.21,PodIP:,StartTime:2019-11-04 19:34:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:34:11.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6139" for this suite.
Nov  4 19:34:20.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:34:20.589: INFO: namespace deployment-6139 deletion completed in 8.621959345s

• [SLOW TEST:13.235 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:34:20.590: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7541
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:34:25.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7541" for this suite.
Nov  4 19:34:31.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:34:32.298: INFO: namespace watch-7541 deletion completed in 6.652702007s

• [SLOW TEST:11.708 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:34:32.299: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6193
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 19:34:32.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb" in namespace "projected-6193" to be "success or failure"
Nov  4 19:34:32.604: INFO: Pod "downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb": Phase="Pending", Reason="", readiness=false. Elapsed: 11.084521ms
Nov  4 19:34:35.699: INFO: Pod "downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb": Phase="Pending", Reason="", readiness=false. Elapsed: 3.106444436s
Nov  4 19:34:37.712: INFO: Pod "downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 5.119176205s
STEP: Saw pod success
Nov  4 19:34:37.712: INFO: Pod "downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb" satisfied condition "success or failure"
Nov  4 19:34:37.722: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb container client-container: <nil>
STEP: delete the pod
Nov  4 19:34:37.816: INFO: Waiting for pod downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb to disappear
Nov  4 19:34:37.827: INFO: Pod downwardapi-volume-5578206c-3c91-4f87-9b12-2b7e074052eb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:34:37.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6193" for this suite.
Nov  4 19:34:43.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:34:44.429: INFO: namespace projected-6193 deletion completed in 6.581367514s

• [SLOW TEST:12.131 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:34:44.430: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-8914
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:34:44.711: INFO: Creating ReplicaSet my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f
Nov  4 19:34:44.742: INFO: Pod name my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f: Found 0 pods out of 1
Nov  4 19:34:49.753: INFO: Pod name my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f: Found 1 pods out of 1
Nov  4 19:34:49.753: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f" is running
Nov  4 19:34:49.764: INFO: Pod "my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f-hd45t" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:34:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:34:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:34:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-11-04 19:34:44 +0000 UTC Reason: Message:}])
Nov  4 19:34:49.764: INFO: Trying to dial the pod
Nov  4 19:34:54.807: INFO: Controller my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f: Got expected result from replica 1 [my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f-hd45t]: "my-hostname-basic-72214ca6-bdb7-45a6-b62a-9c4ea5a8b36f-hd45t", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:34:54.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8914" for this suite.
Nov  4 19:35:02.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:35:03.400: INFO: namespace replicaset-8914 deletion completed in 8.571312941s

• [SLOW TEST:18.971 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:35:03.401: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9131
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-25e2afcb-a1d0-41fa-a573-cafb56a7c40e
STEP: Creating a pod to test consume secrets
Nov  4 19:35:03.695: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3" in namespace "projected-9131" to be "success or failure"
Nov  4 19:35:03.706: INFO: Pod "pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.847494ms
Nov  4 19:35:05.720: INFO: Pod "pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025408752s
Nov  4 19:35:07.732: INFO: Pod "pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.036646754s
STEP: Saw pod success
Nov  4 19:35:07.732: INFO: Pod "pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3" satisfied condition "success or failure"
Nov  4 19:35:07.742: INFO: Trying to get logs from node 10.93.34.21 pod pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:35:07.803: INFO: Waiting for pod pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3 to disappear
Nov  4 19:35:07.814: INFO: Pod pod-projected-secrets-974a1136-a955-4b33-8330-29d5ea7121c3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:35:07.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9131" for this suite.
Nov  4 19:35:15.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:35:17.087: INFO: namespace projected-9131 deletion completed in 9.249612586s

• [SLOW TEST:13.687 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:35:17.088: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9381
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:35:17.350: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Nov  4 19:35:21.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9381 create -f -'
Nov  4 19:35:21.804: INFO: stderr: ""
Nov  4 19:35:21.804: INFO: stdout: "e2e-test-crd-publish-openapi-5369-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 19:35:21.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9381 delete e2e-test-crd-publish-openapi-5369-crds test-cr'
Nov  4 19:35:22.068: INFO: stderr: ""
Nov  4 19:35:22.068: INFO: stdout: "e2e-test-crd-publish-openapi-5369-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Nov  4 19:35:22.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9381 apply -f -'
Nov  4 19:35:22.323: INFO: stderr: ""
Nov  4 19:35:22.323: INFO: stdout: "e2e-test-crd-publish-openapi-5369-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Nov  4 19:35:22.323: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 --namespace=crd-publish-openapi-9381 delete e2e-test-crd-publish-openapi-5369-crds test-cr'
Nov  4 19:35:22.518: INFO: stderr: ""
Nov  4 19:35:22.518: INFO: stdout: "e2e-test-crd-publish-openapi-5369-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Nov  4 19:35:22.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 explain e2e-test-crd-publish-openapi-5369-crds'
Nov  4 19:35:22.852: INFO: stderr: ""
Nov  4 19:35:22.852: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5369-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:35:27.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9381" for this suite.
Nov  4 19:35:33.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:35:34.433: INFO: namespace crd-publish-openapi-9381 deletion completed in 7.287867427s

• [SLOW TEST:17.345 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:35:34.433: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1239
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Nov  4 19:35:44.838: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:35:44.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1104 19:35:44.838601      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-1239" for this suite.
Nov  4 19:35:52.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:35:53.450: INFO: namespace gc-1239 deletion completed in 8.59598759s

• [SLOW TEST:19.017 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:35:53.451: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-5700
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Nov  4 19:35:59.826: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:35:59.826: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:00.093: INFO: Exec stderr: ""
Nov  4 19:36:00.093: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:00.093: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:00.391: INFO: Exec stderr: ""
Nov  4 19:36:00.392: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:00.392: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:00.618: INFO: Exec stderr: ""
Nov  4 19:36:00.618: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:00.619: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:01.153: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Nov  4 19:36:01.153: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:01.153: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:01.467: INFO: Exec stderr: ""
Nov  4 19:36:01.467: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:01.467: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:01.827: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Nov  4 19:36:01.827: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:01.827: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:02.130: INFO: Exec stderr: ""
Nov  4 19:36:02.130: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:02.130: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:02.475: INFO: Exec stderr: ""
Nov  4 19:36:02.475: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:02.475: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:02.768: INFO: Exec stderr: ""
Nov  4 19:36:02.768: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5700 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Nov  4 19:36:02.768: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:36:03.010: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:36:03.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5700" for this suite.
Nov  4 19:36:49.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:36:49.604: INFO: namespace e2e-kubelet-etc-hosts-5700 deletion completed in 46.569128724s

• [SLOW TEST:56.153 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:36:49.605: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-767
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Nov  4 19:36:49.889: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Nov  4 19:36:51.053: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:36:53.072: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:36:55.070: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:36:57.076: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:36:59.092: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493010, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Nov  4 19:37:02.234: INFO: Waited 1.142814977s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:37:03.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-767" for this suite.
Nov  4 19:37:11.215: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:37:11.744: INFO: namespace aggregator-767 deletion completed in 8.592973176s

• [SLOW TEST:22.140 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:37:11.747: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-3941
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:37:12.464: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:37:15.588: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:37:15.605: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
Nov  4 19:37:46.308: INFO: error waiting for conversion to succeed during setup: Timeout: request did not complete within requested timeout 30s
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:37:47.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-3941" for this suite.
Nov  4 19:37:55.462: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:37:55.968: INFO: namespace crd-webhook-3941 deletion completed in 8.563758568s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:44.299 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:37:56.047: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Nov  4 19:37:56.329: INFO: Waiting up to 5m0s for pod "pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962" in namespace "emptydir-9868" to be "success or failure"
Nov  4 19:37:56.340: INFO: Pod "pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962": Phase="Pending", Reason="", readiness=false. Elapsed: 11.217633ms
Nov  4 19:37:58.354: INFO: Pod "pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024947335s
STEP: Saw pod success
Nov  4 19:37:58.354: INFO: Pod "pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962" satisfied condition "success or failure"
Nov  4 19:37:58.365: INFO: Trying to get logs from node 10.93.34.21 pod pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962 container test-container: <nil>
STEP: delete the pod
Nov  4 19:37:58.480: INFO: Waiting for pod pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962 to disappear
Nov  4 19:37:58.491: INFO: Pod pod-1fb2e200-92ae-49d7-b2ba-4df5155dd962 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:37:58.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9868" for this suite.
Nov  4 19:38:04.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:38:05.080: INFO: namespace emptydir-9868 deletion completed in 6.565922053s

• [SLOW TEST:9.033 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:38:05.080: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-e9787a00-0c38-4aff-ad70-f7bee56e4b82
STEP: Creating a pod to test consume secrets
Nov  4 19:38:05.373: INFO: Waiting up to 5m0s for pod "pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f" in namespace "secrets-9102" to be "success or failure"
Nov  4 19:38:05.395: INFO: Pod "pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.248415ms
Nov  4 19:38:07.407: INFO: Pod "pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.033597921s
STEP: Saw pod success
Nov  4 19:38:07.407: INFO: Pod "pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f" satisfied condition "success or failure"
Nov  4 19:38:07.419: INFO: Trying to get logs from node 10.93.34.21 pod pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f container secret-volume-test: <nil>
STEP: delete the pod
Nov  4 19:38:07.489: INFO: Waiting for pod pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f to disappear
Nov  4 19:38:07.499: INFO: Pod pod-secrets-5913032f-aa91-47ce-a7e2-9314d332828f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:38:07.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9102" for this suite.
Nov  4 19:38:13.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:38:14.117: INFO: namespace secrets-9102 deletion completed in 6.596162522s

• [SLOW TEST:9.037 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:38:14.118: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b0303e0f-00af-45ae-9cb3-304fb00f9e84 in namespace container-probe-2289
Nov  4 19:38:16.496: INFO: Started pod busybox-b0303e0f-00af-45ae-9cb3-304fb00f9e84 in namespace container-probe-2289
STEP: checking the pod's current state and verifying that restartCount is present
Nov  4 19:38:16.508: INFO: Initial restart count of pod busybox-b0303e0f-00af-45ae-9cb3-304fb00f9e84 is 0
Nov  4 19:39:04.822: INFO: Restart count of pod container-probe-2289/busybox-b0303e0f-00af-45ae-9cb3-304fb00f9e84 is now 1 (48.313996534s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:39:04.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2289" for this suite.
Nov  4 19:39:12.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:39:13.597: INFO: namespace container-probe-2289 deletion completed in 8.720113584s

• [SLOW TEST:59.479 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:39:13.598: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Nov  4 19:39:13.879: INFO: Waiting up to 5m0s for pod "var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a" in namespace "var-expansion-165" to be "success or failure"
Nov  4 19:39:13.892: INFO: Pod "var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a": Phase="Pending", Reason="", readiness=false. Elapsed: 12.555254ms
Nov  4 19:39:15.903: INFO: Pod "var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024079112s
STEP: Saw pod success
Nov  4 19:39:15.903: INFO: Pod "var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a" satisfied condition "success or failure"
Nov  4 19:39:15.914: INFO: Trying to get logs from node 10.93.34.21 pod var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a container dapi-container: <nil>
STEP: delete the pod
Nov  4 19:39:16.022: INFO: Waiting for pod var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a to disappear
Nov  4 19:39:16.036: INFO: Pod var-expansion-276d10a6-6aa5-468f-97fa-f90d874fb24a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:39:16.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-165" for this suite.
Nov  4 19:39:22.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:39:22.687: INFO: namespace var-expansion-165 deletion completed in 6.622223065s

• [SLOW TEST:9.089 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:39:22.687: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-2664
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5078
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4285
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:39:57.564: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2664" for this suite.
Nov  4 19:40:03.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:40:04.204: INFO: namespace namespaces-2664 deletion completed in 6.619468749s
STEP: Destroying namespace "nsdeletetest-5078" for this suite.
Nov  4 19:40:04.220: INFO: Namespace nsdeletetest-5078 was already deleted
STEP: Destroying namespace "nsdeletetest-4285" for this suite.
Nov  4 19:40:10.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:40:10.925: INFO: namespace nsdeletetest-4285 deletion completed in 6.705421125s

• [SLOW TEST:48.239 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:40:10.926: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Nov  4 19:40:11.187: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-229262933 proxy --unix-socket=/tmp/kubectl-proxy-unix513372964/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:40:11.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9504" for this suite.
Nov  4 19:40:17.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:40:18.236: INFO: namespace kubectl-9504 deletion completed in 6.957700344s

• [SLOW TEST:7.310 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:40:18.236: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-d8bbfea0-1ba4-431f-b430-798c07add70b
STEP: Creating a pod to test consume configMaps
Nov  4 19:40:18.690: INFO: Waiting up to 5m0s for pod "pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113" in namespace "configmap-1058" to be "success or failure"
Nov  4 19:40:18.705: INFO: Pod "pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113": Phase="Pending", Reason="", readiness=false. Elapsed: 14.938144ms
Nov  4 19:40:20.720: INFO: Pod "pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030003996s
STEP: Saw pod success
Nov  4 19:40:20.720: INFO: Pod "pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113" satisfied condition "success or failure"
Nov  4 19:40:20.731: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113 container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:40:20.825: INFO: Waiting for pod pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113 to disappear
Nov  4 19:40:20.836: INFO: Pod pod-configmaps-782cd3df-166e-4a06-9760-86995e7bf113 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:40:20.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1058" for this suite.
Nov  4 19:40:26.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:40:28.222: INFO: namespace configmap-1058 deletion completed in 7.365447198s

• [SLOW TEST:9.986 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:40:28.222: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Nov  4 19:40:28.501: INFO: Waiting up to 5m0s for pod "client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54" in namespace "containers-4429" to be "success or failure"
Nov  4 19:40:28.511: INFO: Pod "client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54": Phase="Pending", Reason="", readiness=false. Elapsed: 10.231849ms
Nov  4 19:40:30.522: INFO: Pod "client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021206785s
Nov  4 19:40:32.533: INFO: Pod "client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032140594s
STEP: Saw pod success
Nov  4 19:40:32.533: INFO: Pod "client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54" satisfied condition "success or failure"
Nov  4 19:40:32.544: INFO: Trying to get logs from node 10.93.34.21 pod client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54 container test-container: <nil>
STEP: delete the pod
Nov  4 19:40:32.606: INFO: Waiting for pod client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54 to disappear
Nov  4 19:40:32.617: INFO: Pod client-containers-f22f9fec-38fd-4092-b45a-59efc435fd54 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:40:32.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4429" for this suite.
Nov  4 19:40:38.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:40:39.375: INFO: namespace containers-4429 deletion completed in 6.737408423s

• [SLOW TEST:11.153 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:40:39.375: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Nov  4 19:40:39.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 create -f - --namespace=kubectl-2551'
Nov  4 19:40:40.007: INFO: stderr: ""
Nov  4 19:40:40.007: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 19:40:40.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:40.175: INFO: stderr: ""
Nov  4 19:40:40.175: INFO: stdout: "update-demo-nautilus-m5dhr update-demo-nautilus-tlbls "
Nov  4 19:40:40.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-m5dhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:40.321: INFO: stderr: ""
Nov  4 19:40:40.321: INFO: stdout: ""
Nov  4 19:40:40.321: INFO: update-demo-nautilus-m5dhr is created but not running
Nov  4 19:40:45.322: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:45.567: INFO: stderr: ""
Nov  4 19:40:45.567: INFO: stdout: "update-demo-nautilus-m5dhr update-demo-nautilus-tlbls "
Nov  4 19:40:45.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-m5dhr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:45.733: INFO: stderr: ""
Nov  4 19:40:45.733: INFO: stdout: "true"
Nov  4 19:40:45.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-m5dhr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:45.878: INFO: stderr: ""
Nov  4 19:40:45.878: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:40:45.878: INFO: validating pod update-demo-nautilus-m5dhr
Nov  4 19:40:45.900: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:40:45.901: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:40:45.901: INFO: update-demo-nautilus-m5dhr is verified up and running
Nov  4 19:40:45.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:46.052: INFO: stderr: ""
Nov  4 19:40:46.052: INFO: stdout: "true"
Nov  4 19:40:46.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:46.210: INFO: stderr: ""
Nov  4 19:40:46.210: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:40:46.210: INFO: validating pod update-demo-nautilus-tlbls
Nov  4 19:40:46.234: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:40:46.234: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:40:46.234: INFO: update-demo-nautilus-tlbls is verified up and running
STEP: scaling down the replication controller
Nov  4 19:40:46.236: INFO: scanned /root for discovery docs: <nil>
Nov  4 19:40:46.236: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2551'
Nov  4 19:40:47.494: INFO: stderr: ""
Nov  4 19:40:47.494: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 19:40:47.494: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:47.645: INFO: stderr: ""
Nov  4 19:40:47.645: INFO: stdout: "update-demo-nautilus-m5dhr update-demo-nautilus-tlbls "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  4 19:40:52.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:52.808: INFO: stderr: ""
Nov  4 19:40:52.808: INFO: stdout: "update-demo-nautilus-m5dhr update-demo-nautilus-tlbls "
STEP: Replicas for name=update-demo: expected=1 actual=2
Nov  4 19:40:57.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:57.938: INFO: stderr: ""
Nov  4 19:40:57.939: INFO: stdout: "update-demo-nautilus-tlbls "
Nov  4 19:40:57.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:58.074: INFO: stderr: ""
Nov  4 19:40:58.074: INFO: stdout: "true"
Nov  4 19:40:58.074: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:58.217: INFO: stderr: ""
Nov  4 19:40:58.217: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:40:58.217: INFO: validating pod update-demo-nautilus-tlbls
Nov  4 19:40:58.238: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:40:58.238: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:40:58.238: INFO: update-demo-nautilus-tlbls is verified up and running
STEP: scaling up the replication controller
Nov  4 19:40:58.240: INFO: scanned /root for discovery docs: <nil>
Nov  4 19:40:58.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2551'
Nov  4 19:40:59.476: INFO: stderr: ""
Nov  4 19:40:59.476: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Nov  4 19:40:59.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:40:59.630: INFO: stderr: ""
Nov  4 19:40:59.630: INFO: stdout: "update-demo-nautilus-rr6pj update-demo-nautilus-tlbls "
Nov  4 19:40:59.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-rr6pj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:40:59.755: INFO: stderr: ""
Nov  4 19:40:59.755: INFO: stdout: ""
Nov  4 19:40:59.755: INFO: update-demo-nautilus-rr6pj is created but not running
Nov  4 19:41:04.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2551'
Nov  4 19:41:04.966: INFO: stderr: ""
Nov  4 19:41:04.966: INFO: stdout: "update-demo-nautilus-rr6pj update-demo-nautilus-tlbls "
Nov  4 19:41:04.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-rr6pj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:41:05.137: INFO: stderr: ""
Nov  4 19:41:05.137: INFO: stdout: "true"
Nov  4 19:41:05.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-rr6pj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:41:05.276: INFO: stderr: ""
Nov  4 19:41:05.276: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:41:05.276: INFO: validating pod update-demo-nautilus-rr6pj
Nov  4 19:41:05.321: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:41:05.321: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:41:05.321: INFO: update-demo-nautilus-rr6pj is verified up and running
Nov  4 19:41:05.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:41:05.510: INFO: stderr: ""
Nov  4 19:41:05.510: INFO: stdout: "true"
Nov  4 19:41:05.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods update-demo-nautilus-tlbls -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2551'
Nov  4 19:41:05.669: INFO: stderr: ""
Nov  4 19:41:05.669: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Nov  4 19:41:05.669: INFO: validating pod update-demo-nautilus-tlbls
Nov  4 19:41:05.686: INFO: got data: {
  "image": "nautilus.jpg"
}

Nov  4 19:41:05.686: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Nov  4 19:41:05.686: INFO: update-demo-nautilus-tlbls is verified up and running
STEP: using delete to clean up resources
Nov  4 19:41:05.686: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete --grace-period=0 --force -f - --namespace=kubectl-2551'
Nov  4 19:41:05.879: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Nov  4 19:41:05.879: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Nov  4 19:41:05.879: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2551'
Nov  4 19:41:06.063: INFO: stderr: "No resources found in kubectl-2551 namespace.\n"
Nov  4 19:41:06.063: INFO: stdout: ""
Nov  4 19:41:06.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pods -l name=update-demo --namespace=kubectl-2551 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Nov  4 19:41:06.260: INFO: stderr: ""
Nov  4 19:41:06.260: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:41:06.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2551" for this suite.
Nov  4 19:41:20.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:41:20.983: INFO: namespace kubectl-2551 deletion completed in 14.690574799s

• [SLOW TEST:41.608 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:41:20.983: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2298
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Nov  4 19:41:21.252: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:41:26.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2298" for this suite.
Nov  4 19:41:32.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:41:32.739: INFO: namespace custom-resource-definition-2298 deletion completed in 6.610486901s

• [SLOW TEST:11.756 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:41:32.742: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1908
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1908
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1908
Nov  4 19:41:33.080: INFO: Found 0 stateful pods, waiting for 1
Nov  4 19:41:43.093: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Nov  4 19:41:43.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:41:43.628: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:41:43.628: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:41:43.628: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 19:41:43.650: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Nov  4 19:41:53.667: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 19:41:53.667: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 19:41:53.748: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998136s
Nov  4 19:41:54.764: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.97976729s
Nov  4 19:41:55.777: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.963697225s
Nov  4 19:41:56.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.950935362s
Nov  4 19:41:57.802: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.939406841s
Nov  4 19:41:58.823: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.926426359s
Nov  4 19:41:59.836: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.904783638s
Nov  4 19:42:00.849: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.892346442s
Nov  4 19:42:01.881: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.863777257s
Nov  4 19:42:02.909: INFO: Verifying statefulset ss doesn't scale past 1 for another 847.509739ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1908
Nov  4 19:42:03.930: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:42:04.525: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:42:04.525: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:42:04.525: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 19:42:04.536: INFO: Found 1 stateful pods, waiting for 3
Nov  4 19:42:14.562: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 19:42:14.562: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Nov  4 19:42:14.562: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Nov  4 19:42:14.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:42:15.072: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:42:15.072: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:42:15.072: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 19:42:15.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:42:15.626: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:42:15.626: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:42:15.626: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 19:42:15.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Nov  4 19:42:16.100: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Nov  4 19:42:16.100: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Nov  4 19:42:16.100: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Nov  4 19:42:16.100: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 19:42:16.124: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Nov  4 19:42:26.152: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 19:42:26.153: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 19:42:26.153: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Nov  4 19:42:26.200: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.99999808s
Nov  4 19:42:27.217: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.988438935s
Nov  4 19:42:28.240: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.968783472s
Nov  4 19:42:29.252: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.948777501s
Nov  4 19:42:30.268: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.936816364s
Nov  4 19:42:31.281: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.921092177s
Nov  4 19:42:32.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.907835595s
Nov  4 19:42:33.306: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.895258883s
Nov  4 19:42:34.318: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.883050875s
Nov  4 19:42:35.343: INFO: Verifying statefulset ss doesn't scale past 3 for another 870.210394ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1908
Nov  4 19:42:36.359: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:42:36.781: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:42:36.781: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:42:36.781: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 19:42:36.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:42:37.265: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:42:37.265: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:42:37.265: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 19:42:37.265: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 exec --namespace=statefulset-1908 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Nov  4 19:42:37.762: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Nov  4 19:42:37.762: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Nov  4 19:42:37.762: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Nov  4 19:42:37.762: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Nov  4 19:42:57.825: INFO: Deleting all statefulset in ns statefulset-1908
Nov  4 19:42:57.844: INFO: Scaling statefulset ss to 0
Nov  4 19:42:57.888: INFO: Waiting for statefulset status.replicas updated to 0
Nov  4 19:42:57.903: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:42:57.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1908" for this suite.
Nov  4 19:43:06.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:43:06.663: INFO: namespace statefulset-1908 deletion completed in 8.657316369s

• [SLOW TEST:93.921 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:43:06.674: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2152
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Nov  4 19:43:07.001: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46820 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 19:43:07.001: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46820 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Nov  4 19:43:17.041: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46835 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Nov  4 19:43:17.041: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46835 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Nov  4 19:43:27.091: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46849 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 19:43:27.091: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46849 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Nov  4 19:43:37.269: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46865 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Nov  4 19:43:37.269: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-a e715fdaf-ab47-4dfb-8b0b-546115477eed 46865 0 2019-11-04 19:43:06 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Nov  4 19:43:47.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-b 1dac4cf8-a7df-4640-ba5b-238bd7b92842 46878 0 2019-11-04 19:43:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 19:43:47.301: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-b 1dac4cf8-a7df-4640-ba5b-238bd7b92842 46878 0 2019-11-04 19:43:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Nov  4 19:43:57.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-b 1dac4cf8-a7df-4640-ba5b-238bd7b92842 46892 0 2019-11-04 19:43:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Nov  4 19:43:57.346: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-2152 /api/v1/namespaces/watch-2152/configmaps/e2e-watch-test-configmap-b 1dac4cf8-a7df-4640-ba5b-238bd7b92842 46892 0 2019-11-04 19:43:47 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:44:07.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2152" for this suite.
Nov  4 19:44:15.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:44:16.011: INFO: namespace watch-2152 deletion completed in 8.638210521s

• [SLOW TEST:69.339 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:44:16.012: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Nov  4 19:44:16.432: INFO: Number of nodes with available pods: 0
Nov  4 19:44:16.432: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:17.487: INFO: Number of nodes with available pods: 0
Nov  4 19:44:17.487: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:18.467: INFO: Number of nodes with available pods: 2
Nov  4 19:44:18.467: INFO: Node 10.93.34.26 is running more than one daemon pod
Nov  4 19:44:19.468: INFO: Number of nodes with available pods: 3
Nov  4 19:44:19.468: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Nov  4 19:44:19.547: INFO: Number of nodes with available pods: 2
Nov  4 19:44:19.547: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:20.582: INFO: Number of nodes with available pods: 2
Nov  4 19:44:20.582: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:21.601: INFO: Number of nodes with available pods: 2
Nov  4 19:44:21.601: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:22.584: INFO: Number of nodes with available pods: 2
Nov  4 19:44:22.584: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:23.591: INFO: Number of nodes with available pods: 2
Nov  4 19:44:23.591: INFO: Node 10.93.34.21 is running more than one daemon pod
Nov  4 19:44:24.596: INFO: Number of nodes with available pods: 3
Nov  4 19:44:24.596: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3133, will wait for the garbage collector to delete the pods
Nov  4 19:44:24.730: INFO: Deleting DaemonSet.extensions daemon-set took: 49.510871ms
Nov  4 19:44:24.931: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.582922ms
Nov  4 19:44:37.942: INFO: Number of nodes with available pods: 0
Nov  4 19:44:37.942: INFO: Number of running nodes: 0, number of available pods: 0
Nov  4 19:44:37.959: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3133/daemonsets","resourceVersion":"47054"},"items":null}

Nov  4 19:44:37.969: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3133/pods","resourceVersion":"47054"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:44:38.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3133" for this suite.
Nov  4 19:44:46.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:44:46.660: INFO: namespace daemonsets-3133 deletion completed in 8.602919832s

• [SLOW TEST:30.648 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:44:46.660: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1433
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:44:48.060: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 19:44:50.118: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493488, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493488, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493488, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493488, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:44:53.337: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:44:53.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1433" for this suite.
Nov  4 19:45:01.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:02.696: INFO: namespace webhook-1433 deletion completed in 8.976491471s
STEP: Destroying namespace "webhook-1433-markers" for this suite.
Nov  4 19:45:08.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:09.344: INFO: namespace webhook-1433-markers deletion completed in 6.647925882s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.778 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:45:09.439: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7643
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:45:10.654: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 19:45:12.716: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493510, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493510, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493510, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493510, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:45:15.785: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:45:16.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7643" for this suite.
Nov  4 19:45:24.828: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:25.462: INFO: namespace webhook-7643 deletion completed in 8.718542504s
STEP: Destroying namespace "webhook-7643-markers" for this suite.
Nov  4 19:45:33.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:34.207: INFO: namespace webhook-7643-markers deletion completed in 8.744643987s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.849 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:45:34.288: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2997
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Nov  4 19:45:36.650: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:45:36.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2997" for this suite.
Nov  4 19:45:42.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:43.585: INFO: namespace container-runtime-2997 deletion completed in 6.86134565s

• [SLOW TEST:9.297 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:45:43.586: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Nov  4 19:45:45.092: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Nov  4 19:45:47.176: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493545, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493545, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493545, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63708493545, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Nov  4 19:45:50.276: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:45:50.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7082" for this suite.
Nov  4 19:45:58.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:45:59.834: INFO: namespace webhook-7082 deletion completed in 9.211423008s
STEP: Destroying namespace "webhook-7082-markers" for this suite.
Nov  4 19:46:05.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:46:06.467: INFO: namespace webhook-7082-markers deletion completed in 6.633157687s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.997 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:46:06.584: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9771
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Nov  4 19:46:06.873: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc" in namespace "downward-api-9771" to be "success or failure"
Nov  4 19:46:06.886: INFO: Pod "downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 13.372306ms
Nov  4 19:46:08.898: INFO: Pod "downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024451515s
Nov  4 19:46:10.911: INFO: Pod "downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037386841s
STEP: Saw pod success
Nov  4 19:46:10.911: INFO: Pod "downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc" satisfied condition "success or failure"
Nov  4 19:46:10.926: INFO: Trying to get logs from node 10.93.34.21 pod downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc container client-container: <nil>
STEP: delete the pod
Nov  4 19:46:11.050: INFO: Waiting for pod downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc to disappear
Nov  4 19:46:11.063: INFO: Pod downwardapi-volume-5ed59981-5447-4aae-ba30-d08670062fcc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:46:11.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9771" for this suite.
Nov  4 19:46:17.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:46:17.849: INFO: namespace downward-api-9771 deletion completed in 6.758473489s

• [SLOW TEST:11.265 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:46:17.850: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 19:46:20.334: INFO: DNS probes using dns-test-46171c96-7c96-4c78-83bc-071e5373892f succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 19:46:24.672: INFO: File jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:24.672: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:29.696: INFO: File wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:29.713: INFO: File jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:29.713: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:34.717: INFO: File jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:34.717: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:39.727: INFO: File jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:39.727: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:44.710: INFO: File jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:44.710: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:49.706: INFO: File wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local from pod  dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 contains 'foo.example.com.
' instead of 'bar.example.com.'
Nov  4 19:46:49.726: INFO: Lookups using dns-7721/dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 failed for: [wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local]

Nov  4 19:46:54.706: INFO: DNS probes using dns-test-84b6ae87-a980-4c0b-83f6-e44293488837 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7721.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7721.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Nov  4 19:46:58.958: INFO: DNS probes using dns-test-1404974a-b937-4484-a746-d312532731dc succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:46:59.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7721" for this suite.
Nov  4 19:47:07.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:47:07.793: INFO: namespace dns-7721 deletion completed in 8.671650744s

• [SLOW TEST:49.943 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:47:07.793: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7220
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-db796a2f-a6e9-4a23-b7b6-33c0a41db479
STEP: Creating a pod to test consume configMaps
Nov  4 19:47:08.089: INFO: Waiting up to 5m0s for pod "pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c" in namespace "configmap-7220" to be "success or failure"
Nov  4 19:47:08.105: INFO: Pod "pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c": Phase="Pending", Reason="", readiness=false. Elapsed: 15.556645ms
Nov  4 19:47:10.118: INFO: Pod "pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028207263s
Nov  4 19:47:12.131: INFO: Pod "pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041887612s
STEP: Saw pod success
Nov  4 19:47:12.131: INFO: Pod "pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c" satisfied condition "success or failure"
Nov  4 19:47:12.142: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c container configmap-volume-test: <nil>
STEP: delete the pod
Nov  4 19:47:12.217: INFO: Waiting for pod pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c to disappear
Nov  4 19:47:12.236: INFO: Pod pod-configmaps-a8ccf519-4c9e-47a9-a789-3b2f28e3b05c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:47:12.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7220" for this suite.
Nov  4 19:47:18.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:47:18.931: INFO: namespace configmap-7220 deletion completed in 6.670839736s

• [SLOW TEST:11.138 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:47:18.931: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9465
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Nov  4 19:47:19.191: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-9465'
Nov  4 19:47:19.924: INFO: stderr: ""
Nov  4 19:47:19.924: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Nov  4 19:47:24.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 get pod e2e-test-httpd-pod --namespace=kubectl-9465 -o json'
Nov  4 19:47:25.124: INFO: stderr: ""
Nov  4 19:47:25.124: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-11-04T19:47:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9465\",\n        \"resourceVersion\": \"47846\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9465/pods/e2e-test-httpd-pod\",\n        \"uid\": \"4e3d2bbe-fe4b-40fe-aff7-f251cba15b53\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-dnvjt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.93.34.21\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-dnvjt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-dnvjt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T19:47:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T19:47:21Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T19:47:21Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-11-04T19:47:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://d60479aa50ab9d21238bf0f1c89eb71067ac29606837adc4c60db1acc73de07e\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-11-04T19:47:21Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.93.34.21\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.102.27\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.102.27\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-11-04T19:47:19Z\"\n    }\n}\n"
STEP: replace the image in the pod
Nov  4 19:47:25.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 replace -f - --namespace=kubectl-9465'
Nov  4 19:47:25.539: INFO: stderr: ""
Nov  4 19:47:25.539: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Nov  4 19:47:25.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-229262933 delete pods e2e-test-httpd-pod --namespace=kubectl-9465'
Nov  4 19:47:27.382: INFO: stderr: ""
Nov  4 19:47:27.382: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:47:27.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9465" for this suite.
Nov  4 19:47:35.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:47:36.040: INFO: namespace kubectl-9465 deletion completed in 8.635232403s

• [SLOW TEST:17.109 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:47:36.041: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2165/configmap-test-6fb833a6-ce75-4b55-bb6b-4c3d29719a99
STEP: Creating a pod to test consume configMaps
Nov  4 19:47:36.347: INFO: Waiting up to 5m0s for pod "pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116" in namespace "configmap-2165" to be "success or failure"
Nov  4 19:47:36.362: INFO: Pod "pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116": Phase="Pending", Reason="", readiness=false. Elapsed: 14.085629ms
Nov  4 19:47:38.371: INFO: Pod "pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023743279s
STEP: Saw pod success
Nov  4 19:47:38.371: INFO: Pod "pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116" satisfied condition "success or failure"
Nov  4 19:47:38.381: INFO: Trying to get logs from node 10.93.34.21 pod pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116 container env-test: <nil>
STEP: delete the pod
Nov  4 19:47:38.438: INFO: Waiting for pod pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116 to disappear
Nov  4 19:47:38.453: INFO: Pod pod-configmaps-058c1b04-6486-4af2-9bd9-42f0d7b00116 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:47:38.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2165" for this suite.
Nov  4 19:47:46.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:47:47.119: INFO: namespace configmap-2165 deletion completed in 8.642812153s

• [SLOW TEST:11.078 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Nov  4 19:47:47.120: INFO: >>> kubeConfig: /tmp/kubeconfig-229262933
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Nov  4 19:47:47.408: INFO: Waiting up to 5m0s for pod "pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599" in namespace "emptydir-9766" to be "success or failure"
Nov  4 19:47:47.420: INFO: Pod "pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599": Phase="Pending", Reason="", readiness=false. Elapsed: 12.515546ms
Nov  4 19:47:49.433: INFO: Pod "pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025076395s
STEP: Saw pod success
Nov  4 19:47:49.433: INFO: Pod "pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599" satisfied condition "success or failure"
Nov  4 19:47:49.444: INFO: Trying to get logs from node 10.93.34.21 pod pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599 container test-container: <nil>
STEP: delete the pod
Nov  4 19:47:49.513: INFO: Waiting for pod pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599 to disappear
Nov  4 19:47:49.527: INFO: Pod pod-1b1e1de7-6d18-41c6-809a-9a210b2c6599 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Nov  4 19:47:49.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9766" for this suite.
Nov  4 19:47:55.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Nov  4 19:47:56.182: INFO: namespace emptydir-9766 deletion completed in 6.627073686s

• [SLOW TEST:9.063 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSNov  4 19:47:56.183: INFO: Running AfterSuite actions on all nodes
Nov  4 19:47:56.183: INFO: Running AfterSuite actions on node 1
Nov  4 19:47:56.183: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 7872.711 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 2h11m14.467626898s
Test Suite Passed
