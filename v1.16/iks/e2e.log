I0217 16:03:38.113447      25 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-964215725
I0217 16:03:38.113570      25 e2e.go:92] Starting e2e run "9ed24eed-badd-482a-9326-08f836c65933" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1581955416 - Will randomize all specs
Will run 276 of 4731 specs

Feb 17 16:03:38.126: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 16:03:38.128: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Feb 17 16:03:38.212: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Feb 17 16:03:38.317: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Feb 17 16:03:38.317: INFO: expected 13 pod replicas in namespace 'kube-system', 13 are Running and Ready.
Feb 17 16:03:38.317: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Feb 17 16:03:38.339: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'ibm-keepalived-watcher' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'ibm-master-proxy' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'node-local-dns' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-driver-installer' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Feb 17 16:03:38.339: INFO: e2e test version: v1.16.7
Feb 17 16:03:38.347: INFO: kube-apiserver version: v1.16.7+IKS
Feb 17 16:03:38.347: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 16:03:38.368: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:03:38.369: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
Feb 17 16:03:38.518: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Feb 17 16:03:38.577: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5075
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Feb 17 16:03:38.727: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Feb 17 16:04:25.505: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 16:04:30.125: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:05:01.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5075" for this suite.
Feb 17 16:05:09.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:05:10.159: INFO: namespace crd-publish-openapi-5075 deletion completed in 8.835592811s

• [SLOW TEST:91.790 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:05:10.159: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4289
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Feb 17 16:05:10.481: INFO: Waiting up to 5m0s for pod "client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1" in namespace "containers-4289" to be "success or failure"
Feb 17 16:05:10.499: INFO: Pod "client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.656491ms
Feb 17 16:05:12.517: INFO: Pod "client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03661398s
Feb 17 16:05:14.529: INFO: Pod "client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048615504s
STEP: Saw pod success
Feb 17 16:05:14.529: INFO: Pod "client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1" satisfied condition "success or failure"
Feb 17 16:05:14.543: INFO: Trying to get logs from node 10.241.69.130 pod client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1 container test-container: <nil>
STEP: delete the pod
Feb 17 16:05:14.675: INFO: Waiting for pod client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1 to disappear
Feb 17 16:05:14.690: INFO: Pod client-containers-8d3999e4-ba50-4ea6-b87e-baf85ee760a1 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:05:14.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4289" for this suite.
Feb 17 16:05:22.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:05:23.342: INFO: namespace containers-4289 deletion completed in 8.631184609s

• [SLOW TEST:13.183 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:05:23.342: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9140
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:05:23.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9140" for this suite.
Feb 17 16:05:29.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:05:30.259: INFO: namespace services-9140 deletion completed in 6.60255454s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.917 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:05:30.259: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:05:30.583: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6" in namespace "security-context-test-9504" to be "success or failure"
Feb 17 16:05:30.602: INFO: Pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 18.805488ms
Feb 17 16:05:32.616: INFO: Pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.032545355s
Feb 17 16:05:34.630: INFO: Pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046335193s
Feb 17 16:05:34.630: INFO: Pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6" satisfied condition "success or failure"
Feb 17 16:05:34.719: INFO: Got logs for pod "busybox-privileged-false-8dd4da2b-ed48-4442-8208-f33261d86bd6": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:05:34.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9504" for this suite.
Feb 17 16:05:42.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:05:43.359: INFO: namespace security-context-test-9504 deletion completed in 8.611775364s

• [SLOW TEST:13.100 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:05:43.359: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4812
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-8f432e03-cfb8-449e-b03c-a4cc759debd4
STEP: Creating configMap with name cm-test-opt-upd-c8f0bfe2-9a81-4aab-b651-2f4cb8bce4a3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-8f432e03-cfb8-449e-b03c-a4cc759debd4
STEP: Updating configmap cm-test-opt-upd-c8f0bfe2-9a81-4aab-b651-2f4cb8bce4a3
STEP: Creating configMap with name cm-test-opt-create-7cbd9d5b-e293-4e12-b115-7abed8196780
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:07:09.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4812" for this suite.
Feb 17 16:07:39.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:07:40.495: INFO: namespace projected-4812 deletion completed in 30.702404624s

• [SLOW TEST:117.136 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:07:40.497: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-73
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-fc34ec32-41ab-404e-a70d-8615088c41c7
STEP: Creating a pod to test consume configMaps
Feb 17 16:07:40.899: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da" in namespace "projected-73" to be "success or failure"
Feb 17 16:07:40.939: INFO: Pod "pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da": Phase="Pending", Reason="", readiness=false. Elapsed: 40.164636ms
Feb 17 16:07:42.955: INFO: Pod "pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055416074s
Feb 17 16:07:44.969: INFO: Pod "pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070045608s
STEP: Saw pod success
Feb 17 16:07:44.969: INFO: Pod "pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da" satisfied condition "success or failure"
Feb 17 16:07:44.985: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:07:45.121: INFO: Waiting for pod pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da to disappear
Feb 17 16:07:45.145: INFO: Pod pod-projected-configmaps-b1b1b95b-3497-4358-98cb-aac89a3ce6da no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:07:45.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-73" for this suite.
Feb 17 16:07:53.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:07:53.749: INFO: namespace projected-73 deletion completed in 8.585435934s

• [SLOW TEST:13.252 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:07:53.751: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7325
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:07:54.026: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Feb 17 16:07:59.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 create -f -'
Feb 17 16:07:59.723: INFO: stderr: ""
Feb 17 16:07:59.723: INFO: stdout: "e2e-test-crd-publish-openapi-4733-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 17 16:07:59.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 delete e2e-test-crd-publish-openapi-4733-crds test-foo'
Feb 17 16:07:59.985: INFO: stderr: ""
Feb 17 16:07:59.985: INFO: stdout: "e2e-test-crd-publish-openapi-4733-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Feb 17 16:07:59.985: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 apply -f -'
Feb 17 16:08:00.446: INFO: stderr: ""
Feb 17 16:08:00.446: INFO: stdout: "e2e-test-crd-publish-openapi-4733-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Feb 17 16:08:00.446: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 delete e2e-test-crd-publish-openapi-4733-crds test-foo'
Feb 17 16:08:00.666: INFO: stderr: ""
Feb 17 16:08:00.666: INFO: stdout: "e2e-test-crd-publish-openapi-4733-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Feb 17 16:08:00.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 create -f -'
Feb 17 16:08:01.029: INFO: rc: 1
Feb 17 16:08:01.029: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 apply -f -'
Feb 17 16:08:02.690: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Feb 17 16:08:02.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 create -f -'
Feb 17 16:08:03.107: INFO: rc: 1
Feb 17 16:08:03.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-7325 apply -f -'
Feb 17 16:08:03.477: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Feb 17 16:08:03.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4733-crds'
Feb 17 16:08:03.834: INFO: stderr: ""
Feb 17 16:08:03.834: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4733-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Feb 17 16:08:03.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4733-crds.metadata'
Feb 17 16:08:04.808: INFO: stderr: ""
Feb 17 16:08:04.808: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4733-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Feb 17 16:08:04.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4733-crds.spec'
Feb 17 16:08:05.183: INFO: stderr: ""
Feb 17 16:08:05.183: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4733-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Feb 17 16:08:05.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4733-crds.spec.bars'
Feb 17 16:08:06.747: INFO: stderr: ""
Feb 17 16:08:06.747: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4733-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Feb 17 16:08:06.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4733-crds.spec.bars2'
Feb 17 16:08:07.145: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:08:18.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7325" for this suite.
Feb 17 16:08:24.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:08:25.704: INFO: namespace crd-publish-openapi-7325 deletion completed in 6.891980836s

• [SLOW TEST:31.953 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:08:25.704: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-3629
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3629 to expose endpoints map[]
Feb 17 16:08:26.072: INFO: Get endpoints failed (19.748144ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Feb 17 16:08:27.094: INFO: successfully validated that service multi-endpoint-test in namespace services-3629 exposes endpoints map[] (1.04118785s elapsed)
STEP: Creating pod pod1 in namespace services-3629
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3629 to expose endpoints map[pod1:[100]]
Feb 17 16:08:31.293: INFO: successfully validated that service multi-endpoint-test in namespace services-3629 exposes endpoints map[pod1:[100]] (4.169785325s elapsed)
STEP: Creating pod pod2 in namespace services-3629
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3629 to expose endpoints map[pod1:[100] pod2:[101]]
Feb 17 16:08:35.832: INFO: successfully validated that service multi-endpoint-test in namespace services-3629 exposes endpoints map[pod1:[100] pod2:[101]] (4.513246021s elapsed)
STEP: Deleting pod pod1 in namespace services-3629
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3629 to expose endpoints map[pod2:[101]]
Feb 17 16:08:35.887: INFO: successfully validated that service multi-endpoint-test in namespace services-3629 exposes endpoints map[pod2:[101]] (28.775107ms elapsed)
STEP: Deleting pod pod2 in namespace services-3629
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3629 to expose endpoints map[]
Feb 17 16:08:35.927: INFO: successfully validated that service multi-endpoint-test in namespace services-3629 exposes endpoints map[] (16.724436ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:08:36.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3629" for this suite.
Feb 17 16:08:50.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:08:51.193: INFO: namespace services-3629 deletion completed in 15.154004052s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.488 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:08:51.193: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1067
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:08:51.527: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:08:54.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1067" for this suite.
Feb 17 16:09:00.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:09:00.781: INFO: namespace custom-resource-definition-1067 deletion completed in 6.751276429s

• [SLOW TEST:9.588 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:09:00.782: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:09:01.199: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a38c4220-536c-4782-83c2-7373013a8d55" in namespace "security-context-test-4069" to be "success or failure"
Feb 17 16:09:01.230: INFO: Pod "busybox-user-65534-a38c4220-536c-4782-83c2-7373013a8d55": Phase="Pending", Reason="", readiness=false. Elapsed: 31.505805ms
Feb 17 16:09:03.257: INFO: Pod "busybox-user-65534-a38c4220-536c-4782-83c2-7373013a8d55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058100354s
Feb 17 16:09:05.277: INFO: Pod "busybox-user-65534-a38c4220-536c-4782-83c2-7373013a8d55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078561102s
Feb 17 16:09:05.277: INFO: Pod "busybox-user-65534-a38c4220-536c-4782-83c2-7373013a8d55" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:09:05.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4069" for this suite.
Feb 17 16:09:13.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:09:14.123: INFO: namespace security-context-test-4069 deletion completed in 8.804579645s

• [SLOW TEST:13.342 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:09:14.124: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 17 16:09:14.405: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 16:09:14.487: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 16:09:14.504: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.130 before test
Feb 17 16:09:14.642: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.642: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:09:14.642: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 16:09:14.642: INFO: ibm-master-proxy-static-10.241.69.130 from kube-system started at 2020-02-17 14:48:46 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.642: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:09:14.642: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:09:14.642: INFO: ibm-keepalived-watcher-qgfgw from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.642: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:09:14.642: INFO: calico-node-nrkf6 from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.642: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:09:14.643: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 from ibm-system started at 2020-02-17 14:49:07 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.643: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 16:09:14.643: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:03:08 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.643: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 16:09:14.643: INFO: coredns-bc786c74-79vl2 from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.643: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:09:14.643: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 from kube-system started at 2020-02-17 14:49:07 +0000 UTC (4 container statuses recorded)
Feb 17 16:09:14.643: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 16:09:14.643: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 16:09:14.643: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 16:09:14.643: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 16:09:14.643: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.147 before test
Feb 17 16:09:14.787: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.787: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:09:14.787: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 16:09:14.787: INFO: metrics-server-5bf499b69-qpwpl from kube-system started at 2020-02-17 14:41:05 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.787: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 16:09:14.787: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 16:09:14.787: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-cd97g from kube-system started at 2020-02-17 14:44:20 +0000 UTC (4 container statuses recorded)
Feb 17 16:09:14.787: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 16:09:14.788: INFO: 	Container ingress-auth-2 ready: true, restart count 1
Feb 17 16:09:14.788: INFO: 	Container ingress-auth-3 ready: true, restart count 1
Feb 17 16:09:14.788: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 16:09:14.788: INFO: addon-catalog-source-bqjh8 from ibm-system started at 2020-02-17 14:44:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.788: INFO: 	Container configmap-registry-server ready: true, restart count 0
Feb 17 16:09:14.788: INFO: olm-operator-7bf4dbc978-zqnns from ibm-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.788: INFO: 	Container olm-operator ready: true, restart count 0
Feb 17 16:09:14.788: INFO: calico-kube-controllers-598ddbf99d-f4lpv from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.788: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 16:09:14.788: INFO: ibm-file-plugin-5568fbb4d7-qbx4l from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.788: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb 17 16:09:14.788: INFO: coredns-bc786c74-hl7pk from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.788: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:09:14.789: INFO: catalog-operator-6d6c965db-km9dc from ibm-system started at 2020-02-17 14:40:42 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container catalog-operator ready: true, restart count 0
Feb 17 16:09:14.789: INFO: dashboard-metrics-scraper-5cbd6549b8-bcj4r from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Feb 17 16:09:14.789: INFO: coredns-autoscaler-65c89858bf-vb4s4 from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 16:09:14.789: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-x7lgw from ibm-system started at 2020-02-17 14:43:30 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 16:09:14.789: INFO: ibm-storage-watcher-799f6c5b69-6fmr2 from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb 17 16:09:14.789: INFO: vpn-79845b6f9d-5r66z from kube-system started at 2020-02-17 14:56:31 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container vpn ready: true, restart count 0
Feb 17 16:09:14.789: INFO: ibm-master-proxy-static-10.241.69.147 from kube-system started at 2020-02-17 14:40:19 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.789: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:09:14.789: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:09:14.789: INFO: ibm-keepalived-watcher-rh8sm from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.790: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:09:14.790: INFO: calico-node-4vlb4 from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.790: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:09:14.790: INFO: kubernetes-dashboard-6dbd4db8bf-6dwql from kube-system started at 2020-02-17 14:40:44 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.790: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 16:09:14.790: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.151 before test
Feb 17 16:09:14.931: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:52:12 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.931: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 16:09:14.931: INFO: ibm-keepalived-watcher-4n299 from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.931: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:09:14.931: INFO: calico-node-nr68s from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.931: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:09:14.931: INFO: sonobuoy-e2e-job-ae741cd10f3545c2 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.931: INFO: 	Container e2e ready: true, restart count 0
Feb 17 16:09:14.931: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:09:14.931: INFO: ibm-master-proxy-static-10.241.69.151 from kube-system started at 2020-02-17 14:50:33 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.931: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:09:14.931: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:09:14.932: INFO: coredns-bc786c74-x59lf from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 16:09:14.932: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:09:14.932: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:09:14.932: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:09:14.932: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15f43c60ad496053], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:09:16.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9538" for this suite.
Feb 17 16:09:24.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:09:24.879: INFO: namespace sched-pred-9538 deletion completed in 8.795068973s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:10.755 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:09:24.879: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 16:09:25.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-7205'
Feb 17 16:09:25.403: INFO: stderr: ""
Feb 17 16:09:25.403: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Feb 17 16:09:35.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pod e2e-test-httpd-pod --namespace=kubectl-7205 -o json'
Feb 17 16:09:35.651: INFO: stderr: ""
Feb 17 16:09:35.651: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2020-02-17T16:09:25Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-7205\",\n        \"resourceVersion\": \"18238\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-7205/pods/e2e-test-httpd-pod\",\n        \"uid\": \"bb64c057-1e7d-46e4-841d-61d1b223b16d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-bmv95\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.241.69.151\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 600\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-bmv95\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-bmv95\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T16:09:25Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T16:09:32Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T16:09:32Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-02-17T16:09:25Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"containerd://8c3afa836fefe0cff67f17c749962875fac6a5911200e527490cac736d1559cf\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-02-17T16:09:31Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.241.69.151\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.30.104.48\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.30.104.48\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-02-17T16:09:25Z\"\n    }\n}\n"
STEP: replace the image in the pod
Feb 17 16:09:35.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 replace -f - --namespace=kubectl-7205'
Feb 17 16:09:36.040: INFO: stderr: ""
Feb 17 16:09:36.040: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Feb 17 16:09:36.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete pods e2e-test-httpd-pod --namespace=kubectl-7205'
Feb 17 16:09:37.522: INFO: stderr: ""
Feb 17 16:09:37.522: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:09:37.522: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7205" for this suite.
Feb 17 16:09:45.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:09:46.414: INFO: namespace kubectl-7205 deletion completed in 8.867850564s

• [SLOW TEST:21.534 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:09:46.414: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9039
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-9039
Feb 17 16:09:46.738: INFO: Found 0 stateful pods, waiting for 1
Feb 17 16:09:56.759: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 16:09:56.872: INFO: Deleting all statefulset in ns statefulset-9039
Feb 17 16:09:56.889: INFO: Scaling statefulset ss to 0
Feb 17 16:10:06.979: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:10:06.998: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:10:07.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9039" for this suite.
Feb 17 16:10:15.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:10:15.936: INFO: namespace statefulset-9039 deletion completed in 8.819915059s

• [SLOW TEST:29.522 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:10:15.936: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7973
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-75ms
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 16:10:16.325: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-75ms" in namespace "subpath-7973" to be "success or failure"
Feb 17 16:10:16.374: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Pending", Reason="", readiness=false. Elapsed: 48.617625ms
Feb 17 16:10:18.391: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Pending", Reason="", readiness=false. Elapsed: 2.065748109s
Feb 17 16:10:20.413: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 4.08781715s
Feb 17 16:10:22.428: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 6.102852649s
Feb 17 16:10:24.449: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 8.123250318s
Feb 17 16:10:26.471: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 10.145769685s
Feb 17 16:10:28.499: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 12.173843821s
Feb 17 16:10:30.518: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 14.192503353s
Feb 17 16:10:32.535: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 16.210092215s
Feb 17 16:10:34.575: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 18.250040362s
Feb 17 16:10:36.594: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 20.2684976s
Feb 17 16:10:38.610: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Running", Reason="", readiness=true. Elapsed: 22.284696573s
Feb 17 16:10:40.634: INFO: Pod "pod-subpath-test-downwardapi-75ms": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.30834287s
STEP: Saw pod success
Feb 17 16:10:40.634: INFO: Pod "pod-subpath-test-downwardapi-75ms" satisfied condition "success or failure"
Feb 17 16:10:40.667: INFO: Trying to get logs from node 10.241.69.147 pod pod-subpath-test-downwardapi-75ms container test-container-subpath-downwardapi-75ms: <nil>
STEP: delete the pod
Feb 17 16:10:40.769: INFO: Waiting for pod pod-subpath-test-downwardapi-75ms to disappear
Feb 17 16:10:40.784: INFO: Pod pod-subpath-test-downwardapi-75ms no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-75ms
Feb 17 16:10:40.784: INFO: Deleting pod "pod-subpath-test-downwardapi-75ms" in namespace "subpath-7973"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:10:40.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7973" for this suite.
Feb 17 16:10:48.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:10:49.468: INFO: namespace subpath-7973 deletion completed in 8.639336214s

• [SLOW TEST:33.532 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:10:49.469: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e
Feb 17 16:10:49.786: INFO: Pod name my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e: Found 0 pods out of 1
Feb 17 16:10:54.807: INFO: Pod name my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e: Found 1 pods out of 1
Feb 17 16:10:54.807: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e" are running
Feb 17 16:10:54.821: INFO: Pod "my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e-xb5vw" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:10:49 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:10:51 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:10:51 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:10:49 +0000 UTC Reason: Message:}])
Feb 17 16:10:54.821: INFO: Trying to dial the pod
Feb 17 16:10:59.892: INFO: Controller my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e: Got expected result from replica 1 [my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e-xb5vw]: "my-hostname-basic-34a75d45-cdc3-4d26-94e8-68a6955d649e-xb5vw", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:10:59.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2475" for this suite.
Feb 17 16:11:07.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:11:09.225: INFO: namespace replication-controller-2475 deletion completed in 9.313412441s

• [SLOW TEST:19.755 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:11:09.225: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4565
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Feb 17 16:11:09.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-4565'
Feb 17 16:11:11.439: INFO: stderr: ""
Feb 17 16:11:11.439: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:11:11.439: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4565'
Feb 17 16:11:11.604: INFO: stderr: ""
Feb 17 16:11:11.604: INFO: stdout: "update-demo-nautilus-4lvk2 update-demo-nautilus-p2jpc "
Feb 17 16:11:11.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-4lvk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:11.738: INFO: stderr: ""
Feb 17 16:11:11.738: INFO: stdout: ""
Feb 17 16:11:11.738: INFO: update-demo-nautilus-4lvk2 is created but not running
Feb 17 16:11:16.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4565'
Feb 17 16:11:16.869: INFO: stderr: ""
Feb 17 16:11:16.869: INFO: stdout: "update-demo-nautilus-4lvk2 update-demo-nautilus-p2jpc "
Feb 17 16:11:16.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-4lvk2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:17.007: INFO: stderr: ""
Feb 17 16:11:17.007: INFO: stdout: "true"
Feb 17 16:11:17.007: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-4lvk2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:17.139: INFO: stderr: ""
Feb 17 16:11:17.139: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:11:17.139: INFO: validating pod update-demo-nautilus-4lvk2
Feb 17 16:11:17.169: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:11:17.169: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:11:17.169: INFO: update-demo-nautilus-4lvk2 is verified up and running
Feb 17 16:11:17.169: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-p2jpc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:17.301: INFO: stderr: ""
Feb 17 16:11:17.301: INFO: stdout: "true"
Feb 17 16:11:17.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-p2jpc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:17.461: INFO: stderr: ""
Feb 17 16:11:17.461: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:11:17.461: INFO: validating pod update-demo-nautilus-p2jpc
Feb 17 16:11:17.494: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:11:17.494: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:11:17.494: INFO: update-demo-nautilus-p2jpc is verified up and running
STEP: rolling-update to new replication controller
Feb 17 16:11:17.496: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:11:17.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4565'
Feb 17 16:11:40.608: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 17 16:11:40.608: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:11:40.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4565'
Feb 17 16:11:40.745: INFO: stderr: ""
Feb 17 16:11:40.745: INFO: stdout: "update-demo-kitten-kgcw5 update-demo-kitten-l5kmr "
Feb 17 16:11:40.745: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-kitten-kgcw5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:40.876: INFO: stderr: ""
Feb 17 16:11:40.876: INFO: stdout: "true"
Feb 17 16:11:40.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-kitten-kgcw5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:41.023: INFO: stderr: ""
Feb 17 16:11:41.023: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 17 16:11:41.024: INFO: validating pod update-demo-kitten-kgcw5
Feb 17 16:11:41.068: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 17 16:11:41.068: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 17 16:11:41.068: INFO: update-demo-kitten-kgcw5 is verified up and running
Feb 17 16:11:41.068: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-kitten-l5kmr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:41.392: INFO: stderr: ""
Feb 17 16:11:41.392: INFO: stdout: "true"
Feb 17 16:11:41.392: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-kitten-l5kmr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4565'
Feb 17 16:11:41.528: INFO: stderr: ""
Feb 17 16:11:41.528: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Feb 17 16:11:41.528: INFO: validating pod update-demo-kitten-l5kmr
Feb 17 16:11:41.594: INFO: got data: {
  "image": "kitten.jpg"
}

Feb 17 16:11:41.594: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Feb 17 16:11:41.594: INFO: update-demo-kitten-l5kmr is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:11:41.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4565" for this suite.
Feb 17 16:12:11.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:12:12.605: INFO: namespace kubectl-4565 deletion completed in 30.974694416s

• [SLOW TEST:63.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:12:12.605: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8939
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-485f5a50-138c-4530-ad30-37004cc6718c
STEP: Creating a pod to test consume configMaps
Feb 17 16:12:12.997: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f" in namespace "projected-8939" to be "success or failure"
Feb 17 16:12:13.021: INFO: Pod "pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.03525ms
Feb 17 16:12:15.037: INFO: Pod "pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039500196s
STEP: Saw pod success
Feb 17 16:12:15.037: INFO: Pod "pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f" satisfied condition "success or failure"
Feb 17 16:12:15.055: INFO: Trying to get logs from node 10.241.69.130 pod pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:12:15.229: INFO: Waiting for pod pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f to disappear
Feb 17 16:12:15.246: INFO: Pod pod-projected-configmaps-63ebd5f6-e59b-413b-9914-b0c71b0d238f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:12:15.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8939" for this suite.
Feb 17 16:12:23.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:12:24.199: INFO: namespace projected-8939 deletion completed in 8.931820178s

• [SLOW TEST:11.594 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:12:24.200: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:12:24.543: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:12:28.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9415" for this suite.
Feb 17 16:13:18.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:13:19.481: INFO: namespace pods-9415 deletion completed in 50.691118277s

• [SLOW TEST:55.281 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:13:19.481: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4107
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:13:37.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4107" for this suite.
Feb 17 16:13:43.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:13:43.744: INFO: namespace resourcequota-4107 deletion completed in 6.642584187s

• [SLOW TEST:24.263 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:13:43.745: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Feb 17 16:13:47.186: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:13:47.270: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5964" for this suite.
Feb 17 16:14:17.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:14:18.017: INFO: namespace replicaset-5964 deletion completed in 30.722904987s

• [SLOW TEST:34.272 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:14:18.017: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1060
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:14:36.410: INFO: Container started at 2020-02-17 16:14:20 +0000 UTC, pod became ready at 2020-02-17 16:14:35 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:14:36.410: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1060" for this suite.
Feb 17 16:14:48.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:14:49.032: INFO: namespace container-probe-1060 deletion completed in 12.604027413s

• [SLOW TEST:31.015 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:14:49.035: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Feb 17 16:14:49.353: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-964215725 proxy --unix-socket=/tmp/kubectl-proxy-unix843055912/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:14:49.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5682" for this suite.
Feb 17 16:14:55.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:14:56.121: INFO: namespace kubectl-5682 deletion completed in 6.672412023s

• [SLOW TEST:7.086 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:14:56.122: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 17 16:14:56.936: INFO: namespace kubectl-6463
Feb 17 16:14:56.937: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-6463'
Feb 17 16:14:57.189: INFO: stderr: ""
Feb 17 16:14:57.189: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 16:14:58.204: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:14:58.204: INFO: Found 0 / 1
Feb 17 16:14:59.209: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:14:59.209: INFO: Found 0 / 1
Feb 17 16:15:00.211: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:15:00.211: INFO: Found 0 / 1
Feb 17 16:15:01.223: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:15:01.223: INFO: Found 1 / 1
Feb 17 16:15:01.223: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 17 16:15:01.252: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 16:15:01.252: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 16:15:01.252: INFO: wait on redis-master startup in kubectl-6463 
Feb 17 16:15:01.252: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs redis-master-p7whb redis-master --namespace=kubectl-6463'
Feb 17 16:15:01.518: INFO: stderr: ""
Feb 17 16:15:01.518: INFO: stdout: "1:C 17 Feb 2020 16:15:00.460 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Feb 2020 16:15:00.460 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Feb 2020 16:15:00.460 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 17 Feb 2020 16:15:00.462 * Running mode=standalone, port=6379.\n1:M 17 Feb 2020 16:15:00.462 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Feb 2020 16:15:00.462 # Server initialized\n1:M 17 Feb 2020 16:15:00.462 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Feb 2020 16:15:00.462 * Ready to accept connections\n"
STEP: exposing RC
Feb 17 16:15:01.518: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6463'
Feb 17 16:15:01.717: INFO: stderr: ""
Feb 17 16:15:01.717: INFO: stdout: "service/rm2 exposed\n"
Feb 17 16:15:01.751: INFO: Service rm2 in namespace kubectl-6463 found.
STEP: exposing service
Feb 17 16:15:03.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6463'
Feb 17 16:15:04.022: INFO: stderr: ""
Feb 17 16:15:04.022: INFO: stdout: "service/rm3 exposed\n"
Feb 17 16:15:04.078: INFO: Service rm3 in namespace kubectl-6463 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:15:06.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6463" for this suite.
Feb 17 16:15:36.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:15:36.898: INFO: namespace kubectl-6463 deletion completed in 30.740009034s

• [SLOW TEST:40.776 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:15:36.899: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-5719
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Feb 17 16:15:37.266: INFO: Waiting up to 5m0s for pod "var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a" in namespace "var-expansion-5719" to be "success or failure"
Feb 17 16:15:37.282: INFO: Pod "var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.590273ms
Feb 17 16:15:39.298: INFO: Pod "var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031562854s
Feb 17 16:15:41.313: INFO: Pod "var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.046265837s
STEP: Saw pod success
Feb 17 16:15:41.313: INFO: Pod "var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a" satisfied condition "success or failure"
Feb 17 16:15:41.327: INFO: Trying to get logs from node 10.241.69.147 pod var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a container dapi-container: <nil>
STEP: delete the pod
Feb 17 16:15:41.498: INFO: Waiting for pod var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a to disappear
Feb 17 16:15:41.512: INFO: Pod var-expansion-07a3bf03-0881-4698-b2b9-e7a2125cf87a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:15:41.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-5719" for this suite.
Feb 17 16:15:49.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:15:50.208: INFO: namespace var-expansion-5719 deletion completed in 8.663977117s

• [SLOW TEST:13.309 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:15:50.208: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9977
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Feb 17 16:16:00.682: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0217 16:16:00.682530      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 17 16:16:00.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9977" for this suite.
Feb 17 16:16:08.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:09.643: INFO: namespace gc-9977 deletion completed in 8.936355451s

• [SLOW TEST:19.434 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:16:09.643: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 16:16:09.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1945'
Feb 17 16:16:10.110: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:16:10.110: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Feb 17 16:16:12.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1945'
Feb 17 16:16:12.384: INFO: stderr: ""
Feb 17 16:16:12.384: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:16:12.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1945" for this suite.
Feb 17 16:16:20.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:21.147: INFO: namespace kubectl-1945 deletion completed in 8.720876562s

• [SLOW TEST:11.504 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:16:21.147: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:16:21.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9517" for this suite.
Feb 17 16:16:29.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:30.209: INFO: namespace kubelet-test-9517 deletion completed in 8.671711886s

• [SLOW TEST:9.062 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:16:30.211: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:16:38.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-547" for this suite.
Feb 17 16:16:46.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:16:47.242: INFO: namespace job-547 deletion completed in 8.677492845s

• [SLOW TEST:17.032 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:16:47.243: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-k9v9
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 16:16:47.627: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-k9v9" in namespace "subpath-3728" to be "success or failure"
Feb 17 16:16:47.653: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Pending", Reason="", readiness=false. Elapsed: 25.683615ms
Feb 17 16:16:49.671: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044453218s
Feb 17 16:16:51.688: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 4.061344479s
Feb 17 16:16:53.704: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 6.076817992s
Feb 17 16:16:55.722: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 8.094584091s
Feb 17 16:16:57.742: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 10.114769653s
Feb 17 16:16:59.758: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 12.130878885s
Feb 17 16:17:01.781: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 14.15396263s
Feb 17 16:17:03.808: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 16.181275542s
Feb 17 16:17:05.841: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 18.214399396s
Feb 17 16:17:07.865: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 20.238481944s
Feb 17 16:17:09.893: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Running", Reason="", readiness=true. Elapsed: 22.265734578s
Feb 17 16:17:11.920: INFO: Pod "pod-subpath-test-configmap-k9v9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.293402016s
STEP: Saw pod success
Feb 17 16:17:11.921: INFO: Pod "pod-subpath-test-configmap-k9v9" satisfied condition "success or failure"
Feb 17 16:17:11.938: INFO: Trying to get logs from node 10.241.69.151 pod pod-subpath-test-configmap-k9v9 container test-container-subpath-configmap-k9v9: <nil>
STEP: delete the pod
Feb 17 16:17:12.270: INFO: Waiting for pod pod-subpath-test-configmap-k9v9 to disappear
Feb 17 16:17:12.294: INFO: Pod pod-subpath-test-configmap-k9v9 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-k9v9
Feb 17 16:17:12.294: INFO: Deleting pod "pod-subpath-test-configmap-k9v9" in namespace "subpath-3728"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:17:12.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3728" for this suite.
Feb 17 16:17:18.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:17:19.495: INFO: namespace subpath-3728 deletion completed in 7.104214838s

• [SLOW TEST:32.252 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:17:19.496: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3481
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:17:20.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3481" for this suite.
Feb 17 16:17:26.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:17:26.765: INFO: namespace resourcequota-3481 deletion completed in 6.640100318s

• [SLOW TEST:7.269 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:17:26.766: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5105
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-59fb10f0-33cf-4653-913b-f71525b2ed11
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-59fb10f0-33cf-4653-913b-f71525b2ed11
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:17:31.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5105" for this suite.
Feb 17 16:18:01.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:02.488: INFO: namespace configmap-5105 deletion completed in 31.09179693s

• [SLOW TEST:35.723 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:18:02.496: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 16:18:05.052: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:18:05.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7876" for this suite.
Feb 17 16:18:13.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:18:13.996: INFO: namespace container-runtime-7876 deletion completed in 8.72765688s

• [SLOW TEST:11.500 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:18:13.996: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:18:18.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1709" for this suite.
Feb 17 16:19:08.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:19:09.418: INFO: namespace kubelet-test-1709 deletion completed in 50.907769558s

• [SLOW TEST:55.422 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:19:09.419: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-5469
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Feb 17 16:19:09.721: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 17 16:20:09.833: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:20:09.865: INFO: Starting informer...
STEP: Starting pod...
Feb 17 16:20:09.964: INFO: Pod is running on 10.241.69.147. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Feb 17 16:20:10.082: INFO: Pod wasn't evicted. Proceeding
Feb 17 16:20:10.082: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Feb 17 16:21:25.657: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:21:25.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5469" for this suite.
Feb 17 16:21:37.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:21:38.354: INFO: namespace taint-single-pod-5469 deletion completed in 12.650851071s

• [SLOW TEST:148.935 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:21:38.354: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8446
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-1e9c98d5-33fe-48af-a52e-7be60f6a1dfe
STEP: Creating a pod to test consume configMaps
Feb 17 16:21:38.715: INFO: Waiting up to 5m0s for pod "pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0" in namespace "configmap-8446" to be "success or failure"
Feb 17 16:21:38.738: INFO: Pod "pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0": Phase="Pending", Reason="", readiness=false. Elapsed: 22.739654ms
Feb 17 16:21:40.762: INFO: Pod "pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.046888421s
STEP: Saw pod success
Feb 17 16:21:40.762: INFO: Pod "pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0" satisfied condition "success or failure"
Feb 17 16:21:41.405: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:21:41.577: INFO: Waiting for pod pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0 to disappear
Feb 17 16:21:41.591: INFO: Pod pod-configmaps-4467cc2c-2f43-4760-9bbf-c11d75a911b0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:21:41.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8446" for this suite.
Feb 17 16:21:49.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:21:50.321: INFO: namespace configmap-8446 deletion completed in 8.707004319s

• [SLOW TEST:11.967 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:21:50.322: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1661
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 17 16:21:50.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-1661'
Feb 17 16:21:50.944: INFO: stderr: ""
Feb 17 16:21:50.944: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:21:50.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:21:51.091: INFO: stderr: ""
Feb 17 16:21:51.091: INFO: stdout: "update-demo-nautilus-rw8ns update-demo-nautilus-vl8hs "
Feb 17 16:21:51.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:21:51.219: INFO: stderr: ""
Feb 17 16:21:51.219: INFO: stdout: ""
Feb 17 16:21:51.219: INFO: update-demo-nautilus-rw8ns is created but not running
Feb 17 16:21:56.219: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:21:56.355: INFO: stderr: ""
Feb 17 16:21:56.355: INFO: stdout: "update-demo-nautilus-rw8ns update-demo-nautilus-vl8hs "
Feb 17 16:21:56.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:21:56.508: INFO: stderr: ""
Feb 17 16:21:56.508: INFO: stdout: "true"
Feb 17 16:21:56.508: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:21:56.637: INFO: stderr: ""
Feb 17 16:21:56.637: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:21:56.637: INFO: validating pod update-demo-nautilus-rw8ns
Feb 17 16:21:56.680: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:21:56.680: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:21:56.680: INFO: update-demo-nautilus-rw8ns is verified up and running
Feb 17 16:21:56.680: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-vl8hs -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:21:56.824: INFO: stderr: ""
Feb 17 16:21:56.824: INFO: stdout: "true"
Feb 17 16:21:56.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-vl8hs -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:21:56.939: INFO: stderr: ""
Feb 17 16:21:56.939: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:21:56.939: INFO: validating pod update-demo-nautilus-vl8hs
Feb 17 16:21:56.977: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:21:56.977: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:21:56.977: INFO: update-demo-nautilus-vl8hs is verified up and running
STEP: scaling down the replication controller
Feb 17 16:21:56.979: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:21:56.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1661'
Feb 17 16:21:58.193: INFO: stderr: ""
Feb 17 16:21:58.193: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:21:58.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:21:58.332: INFO: stderr: ""
Feb 17 16:21:58.332: INFO: stdout: "update-demo-nautilus-rw8ns update-demo-nautilus-vl8hs "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 17 16:22:03.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:22:03.478: INFO: stderr: ""
Feb 17 16:22:03.478: INFO: stdout: "update-demo-nautilus-rw8ns update-demo-nautilus-vl8hs "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 17 16:22:08.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:22:08.641: INFO: stderr: ""
Feb 17 16:22:08.641: INFO: stdout: "update-demo-nautilus-rw8ns update-demo-nautilus-vl8hs "
STEP: Replicas for name=update-demo: expected=1 actual=2
Feb 17 16:22:13.641: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:22:13.863: INFO: stderr: ""
Feb 17 16:22:13.863: INFO: stdout: "update-demo-nautilus-rw8ns "
Feb 17 16:22:13.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:13.999: INFO: stderr: ""
Feb 17 16:22:13.999: INFO: stdout: "true"
Feb 17 16:22:13.999: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:14.143: INFO: stderr: ""
Feb 17 16:22:14.143: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:22:14.143: INFO: validating pod update-demo-nautilus-rw8ns
Feb 17 16:22:14.179: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:22:14.179: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:22:14.179: INFO: update-demo-nautilus-rw8ns is verified up and running
STEP: scaling up the replication controller
Feb 17 16:22:14.180: INFO: scanned /root for discovery docs: <nil>
Feb 17 16:22:14.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1661'
Feb 17 16:22:15.566: INFO: stderr: ""
Feb 17 16:22:15.567: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 16:22:15.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:22:15.720: INFO: stderr: ""
Feb 17 16:22:15.720: INFO: stdout: "update-demo-nautilus-5tgt2 update-demo-nautilus-rw8ns "
Feb 17 16:22:15.720: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-5tgt2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:15.872: INFO: stderr: ""
Feb 17 16:22:15.872: INFO: stdout: ""
Feb 17 16:22:15.873: INFO: update-demo-nautilus-5tgt2 is created but not running
Feb 17 16:22:20.873: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1661'
Feb 17 16:22:21.067: INFO: stderr: ""
Feb 17 16:22:21.067: INFO: stdout: "update-demo-nautilus-5tgt2 update-demo-nautilus-rw8ns "
Feb 17 16:22:21.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-5tgt2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:21.209: INFO: stderr: ""
Feb 17 16:22:21.209: INFO: stdout: "true"
Feb 17 16:22:21.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-5tgt2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:21.445: INFO: stderr: ""
Feb 17 16:22:21.445: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:22:21.445: INFO: validating pod update-demo-nautilus-5tgt2
Feb 17 16:22:21.535: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:22:21.535: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:22:21.535: INFO: update-demo-nautilus-5tgt2 is verified up and running
Feb 17 16:22:21.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:21.699: INFO: stderr: ""
Feb 17 16:22:21.699: INFO: stdout: "true"
Feb 17 16:22:21.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-rw8ns -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1661'
Feb 17 16:22:21.855: INFO: stderr: ""
Feb 17 16:22:21.855: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 16:22:21.855: INFO: validating pod update-demo-nautilus-rw8ns
Feb 17 16:22:21.889: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 16:22:21.889: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 16:22:21.889: INFO: update-demo-nautilus-rw8ns is verified up and running
STEP: using delete to clean up resources
Feb 17 16:22:21.889: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-1661'
Feb 17 16:22:22.079: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 16:22:22.079: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 17 16:22:22.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1661'
Feb 17 16:22:22.226: INFO: stderr: "No resources found in kubectl-1661 namespace.\n"
Feb 17 16:22:22.226: INFO: stdout: ""
Feb 17 16:22:22.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -l name=update-demo --namespace=kubectl-1661 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 16:22:22.361: INFO: stderr: ""
Feb 17 16:22:22.361: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:22:22.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1661" for this suite.
Feb 17 16:22:36.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:22:37.087: INFO: namespace kubectl-1661 deletion completed in 14.699933077s

• [SLOW TEST:46.766 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:22:37.088: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4750
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-s622
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 16:22:37.429: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-s622" in namespace "subpath-4750" to be "success or failure"
Feb 17 16:22:37.450: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Pending", Reason="", readiness=false. Elapsed: 20.69797ms
Feb 17 16:22:39.478: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048528647s
Feb 17 16:22:41.506: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 4.076584033s
Feb 17 16:22:43.520: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 6.091304377s
Feb 17 16:22:45.552: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 8.12329151s
Feb 17 16:22:47.570: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 10.141070856s
Feb 17 16:22:49.583: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 12.154324739s
Feb 17 16:22:51.603: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 14.173585865s
Feb 17 16:22:53.620: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 16.190984661s
Feb 17 16:22:55.640: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 18.211420676s
Feb 17 16:22:57.661: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Running", Reason="", readiness=true. Elapsed: 20.232149623s
Feb 17 16:22:59.675: INFO: Pod "pod-subpath-test-configmap-s622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.245446929s
STEP: Saw pod success
Feb 17 16:22:59.675: INFO: Pod "pod-subpath-test-configmap-s622" satisfied condition "success or failure"
Feb 17 16:22:59.693: INFO: Trying to get logs from node 10.241.69.147 pod pod-subpath-test-configmap-s622 container test-container-subpath-configmap-s622: <nil>
STEP: delete the pod
Feb 17 16:22:59.775: INFO: Waiting for pod pod-subpath-test-configmap-s622 to disappear
Feb 17 16:22:59.807: INFO: Pod pod-subpath-test-configmap-s622 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-s622
Feb 17 16:22:59.807: INFO: Deleting pod "pod-subpath-test-configmap-s622" in namespace "subpath-4750"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:22:59.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4750" for this suite.
Feb 17 16:23:07.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:23:08.792: INFO: namespace subpath-4750 deletion completed in 8.94386189s

• [SLOW TEST:31.704 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:23:08.797: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8616
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 16:23:09.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-8616'
Feb 17 16:23:09.314: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:23:09.314: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Feb 17 16:23:09.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete jobs e2e-test-httpd-job --namespace=kubectl-8616'
Feb 17 16:23:09.507: INFO: stderr: ""
Feb 17 16:23:09.507: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:23:09.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8616" for this suite.
Feb 17 16:23:17.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:23:18.381: INFO: namespace kubectl-8616 deletion completed in 8.849386912s

• [SLOW TEST:9.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:23:18.381: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-826
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 16:23:18.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-826'
Feb 17 16:23:18.818: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 16:23:18.818: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Feb 17 16:23:18.864: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-h9rnp]
Feb 17 16:23:18.864: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-h9rnp" in namespace "kubectl-826" to be "running and ready"
Feb 17 16:23:18.883: INFO: Pod "e2e-test-httpd-rc-h9rnp": Phase="Pending", Reason="", readiness=false. Elapsed: 18.503063ms
Feb 17 16:23:20.902: INFO: Pod "e2e-test-httpd-rc-h9rnp": Phase="Running", Reason="", readiness=true. Elapsed: 2.037751649s
Feb 17 16:23:20.902: INFO: Pod "e2e-test-httpd-rc-h9rnp" satisfied condition "running and ready"
Feb 17 16:23:20.902: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-h9rnp]
Feb 17 16:23:20.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs rc/e2e-test-httpd-rc --namespace=kubectl-826'
Feb 17 16:23:21.185: INFO: stderr: ""
Feb 17 16:23:21.185: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.84.11. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.30.84.11. Set the 'ServerName' directive globally to suppress this message\n[Mon Feb 17 16:23:20.273573 2020] [mpm_event:notice] [pid 1:tid 140260825291624] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Feb 17 16:23:20.273632 2020] [core:notice] [pid 1:tid 140260825291624] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Feb 17 16:23:21.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete rc e2e-test-httpd-rc --namespace=kubectl-826'
Feb 17 16:23:21.323: INFO: stderr: ""
Feb 17 16:23:21.323: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:23:21.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-826" for this suite.
Feb 17 16:23:33.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:23:34.187: INFO: namespace kubectl-826 deletion completed in 12.843508481s

• [SLOW TEST:15.806 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:23:34.187: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9927
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:23:34.455: INFO: Creating ReplicaSet my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f
Feb 17 16:23:34.514: INFO: Pod name my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f: Found 0 pods out of 1
Feb 17 16:23:39.711: INFO: Pod name my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f: Found 1 pods out of 1
Feb 17 16:23:39.711: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f" is running
Feb 17 16:23:39.728: INFO: Pod "my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f-6l8p4" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:23:34 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:23:36 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:23:36 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-02-17 16:23:34 +0000 UTC Reason: Message:}])
Feb 17 16:23:39.728: INFO: Trying to dial the pod
Feb 17 16:23:44.786: INFO: Controller my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f: Got expected result from replica 1 [my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f-6l8p4]: "my-hostname-basic-17543727-3c1d-4a9c-a6e1-e4433666b68f-6l8p4", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:23:44.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9927" for this suite.
Feb 17 16:23:52.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:23:54.048: INFO: namespace replicaset-9927 deletion completed in 9.237350437s

• [SLOW TEST:19.861 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:23:54.049: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-62
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:23:58.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-62" for this suite.
Feb 17 16:24:47.058: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:24:47.755: INFO: namespace kubelet-test-62 deletion completed in 48.757155532s

• [SLOW TEST:53.707 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:24:47.756: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2191
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Feb 17 16:24:48.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 cluster-info'
Feb 17 16:24:48.186: INFO: stderr: ""
Feb 17 16:24:48.186: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://172.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:24:48.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2191" for this suite.
Feb 17 16:24:54.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:24:54.838: INFO: namespace kubectl-2191 deletion completed in 6.63093948s

• [SLOW TEST:7.082 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:24:54.838: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:25:06.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4509" for this suite.
Feb 17 16:25:14.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:15.329: INFO: namespace resourcequota-4509 deletion completed in 8.873975509s

• [SLOW TEST:20.491 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:25:15.331: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-9607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9607
I0217 16:25:15.661450      25 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9607, replica count: 1
I0217 16:25:16.712084      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:25:17.712449      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 16:25:18.712842      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 16:25:18.919: INFO: Created: latency-svc-b9tcg
Feb 17 16:25:18.953: INFO: Got endpoints: latency-svc-b9tcg [140.518399ms]
Feb 17 16:25:18.995: INFO: Created: latency-svc-str4t
Feb 17 16:25:19.006: INFO: Got endpoints: latency-svc-str4t [52.201589ms]
Feb 17 16:25:19.010: INFO: Created: latency-svc-x6pd7
Feb 17 16:25:19.029: INFO: Got endpoints: latency-svc-x6pd7 [75.463542ms]
Feb 17 16:25:19.035: INFO: Created: latency-svc-g2zkt
Feb 17 16:25:19.052: INFO: Created: latency-svc-2fwf5
Feb 17 16:25:19.053: INFO: Got endpoints: latency-svc-g2zkt [99.088012ms]
Feb 17 16:25:19.071: INFO: Got endpoints: latency-svc-2fwf5 [117.015701ms]
Feb 17 16:25:19.071: INFO: Created: latency-svc-p2zpv
Feb 17 16:25:19.088: INFO: Got endpoints: latency-svc-p2zpv [133.878337ms]
Feb 17 16:25:19.090: INFO: Created: latency-svc-zdjb6
Feb 17 16:25:19.105: INFO: Got endpoints: latency-svc-zdjb6 [151.090149ms]
Feb 17 16:25:19.105: INFO: Created: latency-svc-l9sk6
Feb 17 16:25:19.120: INFO: Got endpoints: latency-svc-l9sk6 [166.119724ms]
Feb 17 16:25:19.130: INFO: Created: latency-svc-cmmpr
Feb 17 16:25:19.150: INFO: Created: latency-svc-lbnv5
Feb 17 16:25:19.152: INFO: Got endpoints: latency-svc-cmmpr [198.362883ms]
Feb 17 16:25:19.170: INFO: Got endpoints: latency-svc-lbnv5 [216.498027ms]
Feb 17 16:25:19.171: INFO: Created: latency-svc-bdzkv
Feb 17 16:25:19.189: INFO: Created: latency-svc-k59g8
Feb 17 16:25:19.199: INFO: Got endpoints: latency-svc-bdzkv [245.06056ms]
Feb 17 16:25:19.212: INFO: Got endpoints: latency-svc-k59g8 [258.537481ms]
Feb 17 16:25:19.219: INFO: Created: latency-svc-8lrmw
Feb 17 16:25:19.234: INFO: Got endpoints: latency-svc-8lrmw [63.307074ms]
Feb 17 16:25:19.238: INFO: Created: latency-svc-fl7hk
Feb 17 16:25:19.275: INFO: Got endpoints: latency-svc-fl7hk [320.777933ms]
Feb 17 16:25:19.465: INFO: Created: latency-svc-2bxbt
Feb 17 16:25:19.465: INFO: Got endpoints: latency-svc-2bxbt [510.809639ms]
Feb 17 16:25:19.474: INFO: Created: latency-svc-2b4m2
Feb 17 16:25:19.474: INFO: Got endpoints: latency-svc-2b4m2 [519.593302ms]
Feb 17 16:25:19.474: INFO: Created: latency-svc-r7h5h
Feb 17 16:25:19.474: INFO: Got endpoints: latency-svc-r7h5h [444.928636ms]
Feb 17 16:25:19.474: INFO: Created: latency-svc-hhsjx
Feb 17 16:25:19.475: INFO: Created: latency-svc-sn4q6
Feb 17 16:25:19.475: INFO: Got endpoints: latency-svc-sn4q6 [519.393662ms]
Feb 17 16:25:19.475: INFO: Created: latency-svc-dkkcm
Feb 17 16:25:19.475: INFO: Got endpoints: latency-svc-dkkcm [387.285309ms]
Feb 17 16:25:19.475: INFO: Created: latency-svc-lmglh
Feb 17 16:25:19.475: INFO: Got endpoints: latency-svc-lmglh [422.424547ms]
Feb 17 16:25:19.475: INFO: Created: latency-svc-tqz9q
Feb 17 16:25:19.475: INFO: Got endpoints: latency-svc-tqz9q [370.49718ms]
Feb 17 16:25:19.476: INFO: Created: latency-svc-5dg8n
Feb 17 16:25:19.476: INFO: Got endpoints: latency-svc-5dg8n [404.663368ms]
Feb 17 16:25:19.476: INFO: Created: latency-svc-7j4kl
Feb 17 16:25:19.476: INFO: Got endpoints: latency-svc-7j4kl [470.02591ms]
Feb 17 16:25:19.497: INFO: Created: latency-svc-5qmqt
Feb 17 16:25:19.497: INFO: Got endpoints: latency-svc-hhsjx [377.119869ms]
Feb 17 16:25:19.502: INFO: Created: latency-svc-z7dfz
Feb 17 16:25:19.510: INFO: Got endpoints: latency-svc-5qmqt [357.8572ms]
Feb 17 16:25:19.534: INFO: Got endpoints: latency-svc-z7dfz [335.091127ms]
Feb 17 16:25:19.554: INFO: Created: latency-svc-hjhwj
Feb 17 16:25:19.559: INFO: Created: latency-svc-td9xs
Feb 17 16:25:19.568: INFO: Got endpoints: latency-svc-hjhwj [355.175987ms]
Feb 17 16:25:19.582: INFO: Got endpoints: latency-svc-td9xs [347.496713ms]
Feb 17 16:25:19.582: INFO: Created: latency-svc-rzbfd
Feb 17 16:25:19.602: INFO: Got endpoints: latency-svc-rzbfd [327.276024ms]
Feb 17 16:25:19.606: INFO: Created: latency-svc-gqd2j
Feb 17 16:25:19.616: INFO: Created: latency-svc-6skfg
Feb 17 16:25:19.622: INFO: Got endpoints: latency-svc-gqd2j [157.51532ms]
Feb 17 16:25:19.630: INFO: Created: latency-svc-jk2qp
Feb 17 16:25:19.635: INFO: Got endpoints: latency-svc-6skfg [161.60071ms]
Feb 17 16:25:19.651: INFO: Got endpoints: latency-svc-jk2qp [175.961525ms]
Feb 17 16:25:19.654: INFO: Created: latency-svc-dmsgr
Feb 17 16:25:19.671: INFO: Got endpoints: latency-svc-dmsgr [195.61652ms]
Feb 17 16:25:19.677: INFO: Created: latency-svc-hzm2c
Feb 17 16:25:19.698: INFO: Created: latency-svc-vcdv8
Feb 17 16:25:19.707: INFO: Got endpoints: latency-svc-hzm2c [231.061773ms]
Feb 17 16:25:19.711: INFO: Created: latency-svc-cj8k9
Feb 17 16:25:19.716: INFO: Got endpoints: latency-svc-vcdv8 [240.992741ms]
Feb 17 16:25:19.723: INFO: Created: latency-svc-462w6
Feb 17 16:25:19.727: INFO: Got endpoints: latency-svc-cj8k9 [252.489482ms]
Feb 17 16:25:19.735: INFO: Got endpoints: latency-svc-462w6 [259.918563ms]
Feb 17 16:25:19.743: INFO: Created: latency-svc-mtmcb
Feb 17 16:25:19.757: INFO: Created: latency-svc-hcxv4
Feb 17 16:25:19.757: INFO: Got endpoints: latency-svc-mtmcb [283.634088ms]
Feb 17 16:25:19.772: INFO: Got endpoints: latency-svc-hcxv4 [274.997139ms]
Feb 17 16:25:19.788: INFO: Created: latency-svc-4xfrz
Feb 17 16:25:19.790: INFO: Got endpoints: latency-svc-4xfrz [279.580282ms]
Feb 17 16:25:19.797: INFO: Created: latency-svc-nwdj8
Feb 17 16:25:19.816: INFO: Created: latency-svc-tn7ts
Feb 17 16:25:19.829: INFO: Got endpoints: latency-svc-nwdj8 [294.64198ms]
Feb 17 16:25:19.834: INFO: Created: latency-svc-69tvc
Feb 17 16:25:19.838: INFO: Got endpoints: latency-svc-tn7ts [270.054532ms]
Feb 17 16:25:19.846: INFO: Created: latency-svc-w7d9v
Feb 17 16:25:19.852: INFO: Got endpoints: latency-svc-69tvc [269.802634ms]
Feb 17 16:25:19.859: INFO: Created: latency-svc-dv99l
Feb 17 16:25:19.875: INFO: Got endpoints: latency-svc-dv99l [252.823083ms]
Feb 17 16:25:19.875: INFO: Got endpoints: latency-svc-w7d9v [273.128645ms]
Feb 17 16:25:19.879: INFO: Created: latency-svc-wtxlj
Feb 17 16:25:19.895: INFO: Got endpoints: latency-svc-wtxlj [259.256842ms]
Feb 17 16:25:19.895: INFO: Created: latency-svc-9fd6l
Feb 17 16:25:19.914: INFO: Created: latency-svc-hmc4q
Feb 17 16:25:19.914: INFO: Got endpoints: latency-svc-9fd6l [262.640858ms]
Feb 17 16:25:19.934: INFO: Got endpoints: latency-svc-hmc4q [263.505321ms]
Feb 17 16:25:19.937: INFO: Created: latency-svc-m5wfc
Feb 17 16:25:19.951: INFO: Created: latency-svc-mlmgx
Feb 17 16:25:19.964: INFO: Got endpoints: latency-svc-m5wfc [257.148275ms]
Feb 17 16:25:19.973: INFO: Got endpoints: latency-svc-mlmgx [256.850062ms]
Feb 17 16:25:19.988: INFO: Created: latency-svc-lp9mg
Feb 17 16:25:19.995: INFO: Created: latency-svc-dc4kb
Feb 17 16:25:20.018: INFO: Created: latency-svc-h8mnp
Feb 17 16:25:20.020: INFO: Got endpoints: latency-svc-lp9mg [292.456493ms]
Feb 17 16:25:20.021: INFO: Got endpoints: latency-svc-dc4kb [285.959763ms]
Feb 17 16:25:20.035: INFO: Got endpoints: latency-svc-h8mnp [277.842026ms]
Feb 17 16:25:20.044: INFO: Created: latency-svc-pzzq4
Feb 17 16:25:20.067: INFO: Got endpoints: latency-svc-pzzq4 [295.037784ms]
Feb 17 16:25:20.070: INFO: Created: latency-svc-rkfdg
Feb 17 16:25:20.090: INFO: Created: latency-svc-ctjdm
Feb 17 16:25:20.090: INFO: Got endpoints: latency-svc-rkfdg [300.108488ms]
Feb 17 16:25:20.105: INFO: Got endpoints: latency-svc-ctjdm [275.948353ms]
Feb 17 16:25:20.109: INFO: Created: latency-svc-b688q
Feb 17 16:25:20.124: INFO: Got endpoints: latency-svc-b688q [286.330721ms]
Feb 17 16:25:20.136: INFO: Created: latency-svc-j25sh
Feb 17 16:25:20.151: INFO: Created: latency-svc-5pjxs
Feb 17 16:25:20.157: INFO: Got endpoints: latency-svc-j25sh [304.925273ms]
Feb 17 16:25:20.164: INFO: Got endpoints: latency-svc-5pjxs [288.044526ms]
Feb 17 16:25:20.164: INFO: Created: latency-svc-v8wqj
Feb 17 16:25:20.181: INFO: Got endpoints: latency-svc-v8wqj [305.524953ms]
Feb 17 16:25:20.181: INFO: Created: latency-svc-cvhr6
Feb 17 16:25:20.197: INFO: Got endpoints: latency-svc-cvhr6 [302.49061ms]
Feb 17 16:25:20.198: INFO: Created: latency-svc-6rnn7
Feb 17 16:25:20.216: INFO: Got endpoints: latency-svc-6rnn7 [301.848526ms]
Feb 17 16:25:20.218: INFO: Created: latency-svc-6hmxv
Feb 17 16:25:20.242: INFO: Got endpoints: latency-svc-6hmxv [307.210502ms]
Feb 17 16:25:20.251: INFO: Created: latency-svc-78m2c
Feb 17 16:25:20.264: INFO: Created: latency-svc-bzmfg
Feb 17 16:25:20.271: INFO: Got endpoints: latency-svc-78m2c [307.121412ms]
Feb 17 16:25:20.282: INFO: Created: latency-svc-n7pz6
Feb 17 16:25:20.293: INFO: Got endpoints: latency-svc-bzmfg [319.673262ms]
Feb 17 16:25:20.298: INFO: Got endpoints: latency-svc-n7pz6 [278.324944ms]
Feb 17 16:25:20.306: INFO: Created: latency-svc-lmmh4
Feb 17 16:25:20.319: INFO: Created: latency-svc-ggf9f
Feb 17 16:25:20.336: INFO: Got endpoints: latency-svc-lmmh4 [315.212115ms]
Feb 17 16:25:20.347: INFO: Created: latency-svc-fppsn
Feb 17 16:25:20.350: INFO: Got endpoints: latency-svc-ggf9f [315.329979ms]
Feb 17 16:25:20.363: INFO: Got endpoints: latency-svc-fppsn [295.433045ms]
Feb 17 16:25:20.363: INFO: Created: latency-svc-mxdnk
Feb 17 16:25:20.381: INFO: Got endpoints: latency-svc-mxdnk [291.149808ms]
Feb 17 16:25:20.382: INFO: Created: latency-svc-77crc
Feb 17 16:25:20.404: INFO: Got endpoints: latency-svc-77crc [298.964586ms]
Feb 17 16:25:20.405: INFO: Created: latency-svc-8m8xp
Feb 17 16:25:20.426: INFO: Got endpoints: latency-svc-8m8xp [302.15565ms]
Feb 17 16:25:20.434: INFO: Created: latency-svc-4dw54
Feb 17 16:25:20.440: INFO: Got endpoints: latency-svc-4dw54 [283.181675ms]
Feb 17 16:25:20.457: INFO: Created: latency-svc-lff5m
Feb 17 16:25:20.457: INFO: Got endpoints: latency-svc-lff5m [292.731005ms]
Feb 17 16:25:20.465: INFO: Created: latency-svc-jws9p
Feb 17 16:25:20.479: INFO: Got endpoints: latency-svc-jws9p [298.123578ms]
Feb 17 16:25:20.485: INFO: Created: latency-svc-lvw5n
Feb 17 16:25:20.507: INFO: Got endpoints: latency-svc-lvw5n [309.243824ms]
Feb 17 16:25:20.507: INFO: Created: latency-svc-2bffv
Feb 17 16:25:20.521: INFO: Got endpoints: latency-svc-2bffv [304.504551ms]
Feb 17 16:25:20.522: INFO: Created: latency-svc-rg2nr
Feb 17 16:25:20.537: INFO: Got endpoints: latency-svc-rg2nr [295.747746ms]
Feb 17 16:25:20.546: INFO: Created: latency-svc-xm4zm
Feb 17 16:25:20.560: INFO: Created: latency-svc-df2h2
Feb 17 16:25:20.563: INFO: Got endpoints: latency-svc-xm4zm [291.662478ms]
Feb 17 16:25:20.579: INFO: Got endpoints: latency-svc-df2h2 [286.205691ms]
Feb 17 16:25:20.588: INFO: Created: latency-svc-cb7sn
Feb 17 16:25:20.604: INFO: Got endpoints: latency-svc-cb7sn [305.469772ms]
Feb 17 16:25:20.635: INFO: Created: latency-svc-2rcwl
Feb 17 16:25:20.635: INFO: Created: latency-svc-9sg49
Feb 17 16:25:20.644: INFO: Got endpoints: latency-svc-9sg49 [307.754925ms]
Feb 17 16:25:20.657: INFO: Got endpoints: latency-svc-2rcwl [305.999782ms]
Feb 17 16:25:20.683: INFO: Created: latency-svc-phsqv
Feb 17 16:25:20.700: INFO: Got endpoints: latency-svc-phsqv [337.36303ms]
Feb 17 16:25:20.720: INFO: Created: latency-svc-f9x7q
Feb 17 16:25:20.727: INFO: Created: latency-svc-ncfzp
Feb 17 16:25:20.745: INFO: Got endpoints: latency-svc-f9x7q [363.885293ms]
Feb 17 16:25:20.755: INFO: Got endpoints: latency-svc-ncfzp [351.310869ms]
Feb 17 16:25:20.756: INFO: Created: latency-svc-q555p
Feb 17 16:25:20.762: INFO: Got endpoints: latency-svc-q555p [335.82572ms]
Feb 17 16:25:20.792: INFO: Created: latency-svc-tbn2g
Feb 17 16:25:20.803: INFO: Created: latency-svc-8bdz5
Feb 17 16:25:20.808: INFO: Got endpoints: latency-svc-tbn2g [367.899343ms]
Feb 17 16:25:20.821: INFO: Created: latency-svc-pmdxx
Feb 17 16:25:20.831: INFO: Got endpoints: latency-svc-8bdz5 [374.755223ms]
Feb 17 16:25:20.841: INFO: Got endpoints: latency-svc-pmdxx [362.067549ms]
Feb 17 16:25:20.842: INFO: Created: latency-svc-zlrtw
Feb 17 16:25:20.854: INFO: Got endpoints: latency-svc-zlrtw [347.397548ms]
Feb 17 16:25:20.858: INFO: Created: latency-svc-n4jj4
Feb 17 16:25:20.876: INFO: Got endpoints: latency-svc-n4jj4 [355.288913ms]
Feb 17 16:25:20.888: INFO: Created: latency-svc-9xqdp
Feb 17 16:25:20.916: INFO: Got endpoints: latency-svc-9xqdp [379.039829ms]
Feb 17 16:25:20.919: INFO: Created: latency-svc-6rgvw
Feb 17 16:25:20.955: INFO: Got endpoints: latency-svc-6rgvw [391.649415ms]
Feb 17 16:25:20.967: INFO: Created: latency-svc-bcfg2
Feb 17 16:25:20.986: INFO: Got endpoints: latency-svc-bcfg2 [406.681723ms]
Feb 17 16:25:20.986: INFO: Created: latency-svc-8c999
Feb 17 16:25:21.014: INFO: Created: latency-svc-c54x4
Feb 17 16:25:21.015: INFO: Got endpoints: latency-svc-8c999 [410.815475ms]
Feb 17 16:25:21.030: INFO: Got endpoints: latency-svc-c54x4 [385.85033ms]
Feb 17 16:25:21.034: INFO: Created: latency-svc-d77s7
Feb 17 16:25:21.050: INFO: Got endpoints: latency-svc-d77s7 [393.252044ms]
Feb 17 16:25:21.054: INFO: Created: latency-svc-6hsc6
Feb 17 16:25:21.067: INFO: Created: latency-svc-qc4m8
Feb 17 16:25:21.068: INFO: Got endpoints: latency-svc-6hsc6 [367.362172ms]
Feb 17 16:25:21.086: INFO: Got endpoints: latency-svc-qc4m8 [340.732993ms]
Feb 17 16:25:21.087: INFO: Created: latency-svc-zm6sn
Feb 17 16:25:21.109: INFO: Created: latency-svc-rwvqf
Feb 17 16:25:21.109: INFO: Got endpoints: latency-svc-zm6sn [354.027461ms]
Feb 17 16:25:21.126: INFO: Got endpoints: latency-svc-rwvqf [363.72623ms]
Feb 17 16:25:21.126: INFO: Created: latency-svc-tn62v
Feb 17 16:25:21.145: INFO: Created: latency-svc-bgr7t
Feb 17 16:25:21.148: INFO: Got endpoints: latency-svc-tn62v [340.483121ms]
Feb 17 16:25:21.161: INFO: Created: latency-svc-ghh4s
Feb 17 16:25:21.168: INFO: Got endpoints: latency-svc-bgr7t [336.5322ms]
Feb 17 16:25:21.174: INFO: Got endpoints: latency-svc-ghh4s [333.283199ms]
Feb 17 16:25:21.190: INFO: Created: latency-svc-khdn9
Feb 17 16:25:21.197: INFO: Created: latency-svc-qcmbr
Feb 17 16:25:21.206: INFO: Got endpoints: latency-svc-khdn9 [351.281513ms]
Feb 17 16:25:21.210: INFO: Created: latency-svc-jmpf9
Feb 17 16:25:21.210: INFO: Got endpoints: latency-svc-qcmbr [334.300076ms]
Feb 17 16:25:21.226: INFO: Got endpoints: latency-svc-jmpf9 [308.725666ms]
Feb 17 16:25:21.228: INFO: Created: latency-svc-4ts52
Feb 17 16:25:21.246: INFO: Got endpoints: latency-svc-4ts52 [291.613026ms]
Feb 17 16:25:21.250: INFO: Created: latency-svc-27hpv
Feb 17 16:25:21.281: INFO: Created: latency-svc-w64p2
Feb 17 16:25:21.297: INFO: Got endpoints: latency-svc-27hpv [310.702278ms]
Feb 17 16:25:21.309: INFO: Got endpoints: latency-svc-w64p2 [294.555073ms]
Feb 17 16:25:21.310: INFO: Created: latency-svc-xw4sb
Feb 17 16:25:21.316: INFO: Created: latency-svc-rv5fm
Feb 17 16:25:21.322: INFO: Got endpoints: latency-svc-xw4sb [291.60258ms]
Feb 17 16:25:21.333: INFO: Got endpoints: latency-svc-rv5fm [283.04626ms]
Feb 17 16:25:21.333: INFO: Created: latency-svc-zppdt
Feb 17 16:25:21.345: INFO: Created: latency-svc-kdp7k
Feb 17 16:25:21.370: INFO: Created: latency-svc-mmqq5
Feb 17 16:25:21.370: INFO: Got endpoints: latency-svc-zppdt [302.48477ms]
Feb 17 16:25:21.374: INFO: Got endpoints: latency-svc-kdp7k [288.283513ms]
Feb 17 16:25:21.394: INFO: Got endpoints: latency-svc-mmqq5 [284.219757ms]
Feb 17 16:25:21.421: INFO: Created: latency-svc-k8xzh
Feb 17 16:25:21.423: INFO: Got endpoints: latency-svc-k8xzh [297.258363ms]
Feb 17 16:25:21.432: INFO: Created: latency-svc-dqlpn
Feb 17 16:25:21.440: INFO: Got endpoints: latency-svc-dqlpn [291.664878ms]
Feb 17 16:25:21.451: INFO: Created: latency-svc-zb9db
Feb 17 16:25:21.467: INFO: Got endpoints: latency-svc-zb9db [298.638648ms]
Feb 17 16:25:21.470: INFO: Created: latency-svc-v6dgp
Feb 17 16:25:21.499: INFO: Got endpoints: latency-svc-v6dgp [324.980645ms]
Feb 17 16:25:21.511: INFO: Created: latency-svc-gr2d5
Feb 17 16:25:21.527: INFO: Got endpoints: latency-svc-gr2d5 [321.374752ms]
Feb 17 16:25:21.528: INFO: Created: latency-svc-xls4d
Feb 17 16:25:21.562: INFO: Got endpoints: latency-svc-xls4d [351.200496ms]
Feb 17 16:25:21.579: INFO: Created: latency-svc-qs5tp
Feb 17 16:25:21.589: INFO: Got endpoints: latency-svc-qs5tp [363.368998ms]
Feb 17 16:25:21.594: INFO: Created: latency-svc-4smf5
Feb 17 16:25:21.612: INFO: Created: latency-svc-52zcn
Feb 17 16:25:21.615: INFO: Got endpoints: latency-svc-4smf5 [368.211754ms]
Feb 17 16:25:21.626: INFO: Got endpoints: latency-svc-52zcn [329.087144ms]
Feb 17 16:25:21.635: INFO: Created: latency-svc-rwz7h
Feb 17 16:25:21.653: INFO: Got endpoints: latency-svc-rwz7h [343.411287ms]
Feb 17 16:25:21.662: INFO: Created: latency-svc-bpg5n
Feb 17 16:25:21.680: INFO: Got endpoints: latency-svc-bpg5n [358.576175ms]
Feb 17 16:25:21.682: INFO: Created: latency-svc-5rhw6
Feb 17 16:25:21.702: INFO: Got endpoints: latency-svc-5rhw6 [368.956392ms]
Feb 17 16:25:21.702: INFO: Created: latency-svc-976mb
Feb 17 16:25:21.719: INFO: Created: latency-svc-fnfx9
Feb 17 16:25:21.722: INFO: Got endpoints: latency-svc-976mb [351.435246ms]
Feb 17 16:25:21.734: INFO: Created: latency-svc-rkznm
Feb 17 16:25:21.743: INFO: Got endpoints: latency-svc-fnfx9 [368.546299ms]
Feb 17 16:25:21.757: INFO: Got endpoints: latency-svc-rkznm [363.069901ms]
Feb 17 16:25:21.760: INFO: Created: latency-svc-5msv6
Feb 17 16:25:21.788: INFO: Got endpoints: latency-svc-5msv6 [364.994758ms]
Feb 17 16:25:21.790: INFO: Created: latency-svc-bw6vb
Feb 17 16:25:21.815: INFO: Created: latency-svc-kgxk7
Feb 17 16:25:21.816: INFO: Got endpoints: latency-svc-bw6vb [376.172165ms]
Feb 17 16:25:21.829: INFO: Got endpoints: latency-svc-kgxk7 [362.539239ms]
Feb 17 16:25:21.839: INFO: Created: latency-svc-nmg9f
Feb 17 16:25:21.856: INFO: Got endpoints: latency-svc-nmg9f [356.253584ms]
Feb 17 16:25:21.860: INFO: Created: latency-svc-d5fqd
Feb 17 16:25:21.875: INFO: Created: latency-svc-jqdcn
Feb 17 16:25:21.887: INFO: Got endpoints: latency-svc-d5fqd [360.144157ms]
Feb 17 16:25:21.895: INFO: Created: latency-svc-2bl6k
Feb 17 16:25:21.904: INFO: Got endpoints: latency-svc-jqdcn [342.434264ms]
Feb 17 16:25:21.915: INFO: Got endpoints: latency-svc-2bl6k [325.62049ms]
Feb 17 16:25:21.916: INFO: Created: latency-svc-g9qqm
Feb 17 16:25:21.932: INFO: Got endpoints: latency-svc-g9qqm [317.652459ms]
Feb 17 16:25:21.936: INFO: Created: latency-svc-cj6z4
Feb 17 16:25:21.956: INFO: Created: latency-svc-4srjj
Feb 17 16:25:21.956: INFO: Got endpoints: latency-svc-cj6z4 [330.06453ms]
Feb 17 16:25:21.977: INFO: Got endpoints: latency-svc-4srjj [323.764979ms]
Feb 17 16:25:21.986: INFO: Created: latency-svc-nlfcm
Feb 17 16:25:22.007: INFO: Got endpoints: latency-svc-nlfcm [326.802041ms]
Feb 17 16:25:22.011: INFO: Created: latency-svc-68l84
Feb 17 16:25:22.031: INFO: Got endpoints: latency-svc-68l84 [328.441873ms]
Feb 17 16:25:22.033: INFO: Created: latency-svc-d2smq
Feb 17 16:25:22.046: INFO: Created: latency-svc-8rtvd
Feb 17 16:25:22.046: INFO: Got endpoints: latency-svc-d2smq [324.214615ms]
Feb 17 16:25:22.067: INFO: Created: latency-svc-429cq
Feb 17 16:25:22.067: INFO: Got endpoints: latency-svc-8rtvd [324.026435ms]
Feb 17 16:25:22.084: INFO: Got endpoints: latency-svc-429cq [326.862016ms]
Feb 17 16:25:22.205: INFO: Created: latency-svc-kbc9h
Feb 17 16:25:22.228: INFO: Got endpoints: latency-svc-kbc9h [439.725815ms]
Feb 17 16:25:22.231: INFO: Created: latency-svc-bvjqx
Feb 17 16:25:22.270: INFO: Created: latency-svc-mjws4
Feb 17 16:25:22.272: INFO: Got endpoints: latency-svc-bvjqx [455.469002ms]
Feb 17 16:25:22.325: INFO: Created: latency-svc-zvkd9
Feb 17 16:25:22.330: INFO: Got endpoints: latency-svc-mjws4 [500.292894ms]
Feb 17 16:25:22.342: INFO: Got endpoints: latency-svc-zvkd9 [486.07887ms]
Feb 17 16:25:22.354: INFO: Created: latency-svc-vmz97
Feb 17 16:25:22.382: INFO: Got endpoints: latency-svc-vmz97 [494.569051ms]
Feb 17 16:25:22.392: INFO: Created: latency-svc-vc2wc
Feb 17 16:25:22.434: INFO: Created: latency-svc-7x5xx
Feb 17 16:25:22.457: INFO: Got endpoints: latency-svc-vc2wc [553.029214ms]
Feb 17 16:25:22.462: INFO: Got endpoints: latency-svc-7x5xx [546.912763ms]
Feb 17 16:25:22.513: INFO: Created: latency-svc-qpvv2
Feb 17 16:25:22.544: INFO: Got endpoints: latency-svc-qpvv2 [611.745582ms]
Feb 17 16:25:22.560: INFO: Created: latency-svc-sxqmj
Feb 17 16:25:22.581: INFO: Got endpoints: latency-svc-sxqmj [624.641135ms]
Feb 17 16:25:22.616: INFO: Created: latency-svc-575q6
Feb 17 16:25:22.634: INFO: Got endpoints: latency-svc-575q6 [657.762807ms]
Feb 17 16:25:22.654: INFO: Created: latency-svc-fmdvl
Feb 17 16:25:22.693: INFO: Got endpoints: latency-svc-fmdvl [685.318657ms]
Feb 17 16:25:22.715: INFO: Created: latency-svc-98gkt
Feb 17 16:25:22.763: INFO: Created: latency-svc-ngxk2
Feb 17 16:25:22.834: INFO: Created: latency-svc-65h2m
Feb 17 16:25:22.855: INFO: Created: latency-svc-b9jm6
Feb 17 16:25:22.860: INFO: Got endpoints: latency-svc-ngxk2 [813.625915ms]
Feb 17 16:25:22.860: INFO: Got endpoints: latency-svc-98gkt [829.22202ms]
Feb 17 16:25:22.867: INFO: Got endpoints: latency-svc-65h2m [799.82348ms]
Feb 17 16:25:22.887: INFO: Got endpoints: latency-svc-b9jm6 [802.865357ms]
Feb 17 16:25:22.899: INFO: Created: latency-svc-p9674
Feb 17 16:25:22.913: INFO: Got endpoints: latency-svc-p9674 [685.07507ms]
Feb 17 16:25:22.926: INFO: Created: latency-svc-mp2vw
Feb 17 16:25:22.959: INFO: Got endpoints: latency-svc-mp2vw [686.836446ms]
Feb 17 16:25:22.973: INFO: Created: latency-svc-nc2bm
Feb 17 16:25:23.000: INFO: Created: latency-svc-qwwwb
Feb 17 16:25:23.004: INFO: Got endpoints: latency-svc-nc2bm [673.984269ms]
Feb 17 16:25:23.016: INFO: Got endpoints: latency-svc-qwwwb [673.783056ms]
Feb 17 16:25:23.028: INFO: Created: latency-svc-nzhw2
Feb 17 16:25:23.044: INFO: Got endpoints: latency-svc-nzhw2 [662.038826ms]
Feb 17 16:25:23.054: INFO: Created: latency-svc-m4hls
Feb 17 16:25:23.074: INFO: Got endpoints: latency-svc-m4hls [617.006216ms]
Feb 17 16:25:23.082: INFO: Created: latency-svc-b425g
Feb 17 16:25:23.105: INFO: Created: latency-svc-p8tg2
Feb 17 16:25:23.108: INFO: Got endpoints: latency-svc-b425g [646.39891ms]
Feb 17 16:25:23.124: INFO: Got endpoints: latency-svc-p8tg2 [580.029397ms]
Feb 17 16:25:23.129: INFO: Created: latency-svc-vxplb
Feb 17 16:25:23.144: INFO: Created: latency-svc-q4db6
Feb 17 16:25:23.160: INFO: Got endpoints: latency-svc-vxplb [578.6538ms]
Feb 17 16:25:23.178: INFO: Created: latency-svc-5xn26
Feb 17 16:25:23.179: INFO: Got endpoints: latency-svc-q4db6 [544.041636ms]
Feb 17 16:25:23.180: INFO: Got endpoints: latency-svc-5xn26 [487.355563ms]
Feb 17 16:25:23.211: INFO: Created: latency-svc-r7lfp
Feb 17 16:25:23.228: INFO: Got endpoints: latency-svc-r7lfp [368.25061ms]
Feb 17 16:25:23.235: INFO: Created: latency-svc-w2nwr
Feb 17 16:25:23.261: INFO: Got endpoints: latency-svc-w2nwr [401.426993ms]
Feb 17 16:25:23.264: INFO: Created: latency-svc-b2s6m
Feb 17 16:25:23.292: INFO: Got endpoints: latency-svc-b2s6m [424.825546ms]
Feb 17 16:25:23.297: INFO: Created: latency-svc-c2stl
Feb 17 16:25:23.314: INFO: Created: latency-svc-xk9w2
Feb 17 16:25:23.342: INFO: Created: latency-svc-6c8np
Feb 17 16:25:23.359: INFO: Created: latency-svc-dsrn2
Feb 17 16:25:23.389: INFO: Created: latency-svc-zf9rq
Feb 17 16:25:23.394: INFO: Got endpoints: latency-svc-6c8np [435.619198ms]
Feb 17 16:25:23.394: INFO: Got endpoints: latency-svc-c2stl [507.390755ms]
Feb 17 16:25:23.394: INFO: Got endpoints: latency-svc-xk9w2 [480.991694ms]
Feb 17 16:25:23.395: INFO: Got endpoints: latency-svc-dsrn2 [391.314971ms]
Feb 17 16:25:23.407: INFO: Got endpoints: latency-svc-zf9rq [391.017579ms]
Feb 17 16:25:23.412: INFO: Created: latency-svc-qqbgf
Feb 17 16:25:23.432: INFO: Got endpoints: latency-svc-qqbgf [387.751365ms]
Feb 17 16:25:23.448: INFO: Created: latency-svc-95qxn
Feb 17 16:25:23.459: INFO: Got endpoints: latency-svc-95qxn [384.382896ms]
Feb 17 16:25:23.474: INFO: Created: latency-svc-7fxtl
Feb 17 16:25:23.491: INFO: Got endpoints: latency-svc-7fxtl [382.811049ms]
Feb 17 16:25:23.498: INFO: Created: latency-svc-6nqz8
Feb 17 16:25:23.515: INFO: Got endpoints: latency-svc-6nqz8 [390.813485ms]
Feb 17 16:25:23.522: INFO: Created: latency-svc-9gftr
Feb 17 16:25:23.543: INFO: Got endpoints: latency-svc-9gftr [383.234273ms]
Feb 17 16:25:23.546: INFO: Created: latency-svc-69r8s
Feb 17 16:25:23.562: INFO: Got endpoints: latency-svc-69r8s [383.159466ms]
Feb 17 16:25:23.562: INFO: Created: latency-svc-prm6w
Feb 17 16:25:23.578: INFO: Got endpoints: latency-svc-prm6w [397.309965ms]
Feb 17 16:25:23.591: INFO: Created: latency-svc-szzdr
Feb 17 16:25:23.608: INFO: Got endpoints: latency-svc-szzdr [379.803887ms]
Feb 17 16:25:23.611: INFO: Created: latency-svc-w2ctz
Feb 17 16:25:23.637: INFO: Got endpoints: latency-svc-w2ctz [375.363055ms]
Feb 17 16:25:23.637: INFO: Created: latency-svc-scjw8
Feb 17 16:25:23.648: INFO: Created: latency-svc-d9w6v
Feb 17 16:25:23.649: INFO: Got endpoints: latency-svc-scjw8 [357.181652ms]
Feb 17 16:25:23.672: INFO: Created: latency-svc-klqbf
Feb 17 16:25:23.679: INFO: Got endpoints: latency-svc-d9w6v [284.26379ms]
Feb 17 16:25:23.687: INFO: Got endpoints: latency-svc-klqbf [292.667597ms]
Feb 17 16:25:23.698: INFO: Created: latency-svc-s25vw
Feb 17 16:25:23.715: INFO: Got endpoints: latency-svc-s25vw [320.716039ms]
Feb 17 16:25:23.730: INFO: Created: latency-svc-m4fp9
Feb 17 16:25:23.750: INFO: Got endpoints: latency-svc-m4fp9 [354.860902ms]
Feb 17 16:25:23.757: INFO: Created: latency-svc-9tmvw
Feb 17 16:25:23.772: INFO: Created: latency-svc-2plgn
Feb 17 16:25:23.772: INFO: Got endpoints: latency-svc-9tmvw [365.545459ms]
Feb 17 16:25:23.801: INFO: Created: latency-svc-47zh9
Feb 17 16:25:23.803: INFO: Got endpoints: latency-svc-2plgn [370.686672ms]
Feb 17 16:25:23.821: INFO: Got endpoints: latency-svc-47zh9 [362.177144ms]
Feb 17 16:25:23.827: INFO: Created: latency-svc-v8gk9
Feb 17 16:25:23.852: INFO: Created: latency-svc-bncdf
Feb 17 16:25:23.857: INFO: Got endpoints: latency-svc-v8gk9 [365.697089ms]
Feb 17 16:25:23.868: INFO: Got endpoints: latency-svc-bncdf [352.450624ms]
Feb 17 16:25:23.873: INFO: Created: latency-svc-r6h6j
Feb 17 16:25:23.892: INFO: Got endpoints: latency-svc-r6h6j [349.542545ms]
Feb 17 16:25:23.892: INFO: Created: latency-svc-ncwcz
Feb 17 16:25:23.910: INFO: Got endpoints: latency-svc-ncwcz [347.839622ms]
Feb 17 16:25:23.910: INFO: Latencies: [52.201589ms 63.307074ms 75.463542ms 99.088012ms 117.015701ms 133.878337ms 151.090149ms 157.51532ms 161.60071ms 166.119724ms 175.961525ms 195.61652ms 198.362883ms 216.498027ms 231.061773ms 240.992741ms 245.06056ms 252.489482ms 252.823083ms 256.850062ms 257.148275ms 258.537481ms 259.256842ms 259.918563ms 262.640858ms 263.505321ms 269.802634ms 270.054532ms 273.128645ms 274.997139ms 275.948353ms 277.842026ms 278.324944ms 279.580282ms 283.04626ms 283.181675ms 283.634088ms 284.219757ms 284.26379ms 285.959763ms 286.205691ms 286.330721ms 288.044526ms 288.283513ms 291.149808ms 291.60258ms 291.613026ms 291.662478ms 291.664878ms 292.456493ms 292.667597ms 292.731005ms 294.555073ms 294.64198ms 295.037784ms 295.433045ms 295.747746ms 297.258363ms 298.123578ms 298.638648ms 298.964586ms 300.108488ms 301.848526ms 302.15565ms 302.48477ms 302.49061ms 304.504551ms 304.925273ms 305.469772ms 305.524953ms 305.999782ms 307.121412ms 307.210502ms 307.754925ms 308.725666ms 309.243824ms 310.702278ms 315.212115ms 315.329979ms 317.652459ms 319.673262ms 320.716039ms 320.777933ms 321.374752ms 323.764979ms 324.026435ms 324.214615ms 324.980645ms 325.62049ms 326.802041ms 326.862016ms 327.276024ms 328.441873ms 329.087144ms 330.06453ms 333.283199ms 334.300076ms 335.091127ms 335.82572ms 336.5322ms 337.36303ms 340.483121ms 340.732993ms 342.434264ms 343.411287ms 347.397548ms 347.496713ms 347.839622ms 349.542545ms 351.200496ms 351.281513ms 351.310869ms 351.435246ms 352.450624ms 354.027461ms 354.860902ms 355.175987ms 355.288913ms 356.253584ms 357.181652ms 357.8572ms 358.576175ms 360.144157ms 362.067549ms 362.177144ms 362.539239ms 363.069901ms 363.368998ms 363.72623ms 363.885293ms 364.994758ms 365.545459ms 365.697089ms 367.362172ms 367.899343ms 368.211754ms 368.25061ms 368.546299ms 368.956392ms 370.49718ms 370.686672ms 374.755223ms 375.363055ms 376.172165ms 377.119869ms 379.039829ms 379.803887ms 382.811049ms 383.159466ms 383.234273ms 384.382896ms 385.85033ms 387.285309ms 387.751365ms 390.813485ms 391.017579ms 391.314971ms 391.649415ms 393.252044ms 397.309965ms 401.426993ms 404.663368ms 406.681723ms 410.815475ms 422.424547ms 424.825546ms 435.619198ms 439.725815ms 444.928636ms 455.469002ms 470.02591ms 480.991694ms 486.07887ms 487.355563ms 494.569051ms 500.292894ms 507.390755ms 510.809639ms 519.393662ms 519.593302ms 544.041636ms 546.912763ms 553.029214ms 578.6538ms 580.029397ms 611.745582ms 617.006216ms 624.641135ms 646.39891ms 657.762807ms 662.038826ms 673.783056ms 673.984269ms 685.07507ms 685.318657ms 686.836446ms 799.82348ms 802.865357ms 813.625915ms 829.22202ms]
Feb 17 16:25:23.910: INFO: 50 %ile: 337.36303ms
Feb 17 16:25:23.910: INFO: 90 %ile: 544.041636ms
Feb 17 16:25:23.910: INFO: 99 %ile: 813.625915ms
Feb 17 16:25:23.910: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:25:23.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9607" for this suite.
Feb 17 16:25:52.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:25:52.712: INFO: namespace svc-latency-9607 deletion completed in 28.780263574s

• [SLOW TEST:37.381 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:25:52.712: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9112
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:25:55.254: INFO: Waiting up to 5m0s for pod "client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7" in namespace "pods-9112" to be "success or failure"
Feb 17 16:25:55.272: INFO: Pod "client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7": Phase="Pending", Reason="", readiness=false. Elapsed: 17.183369ms
Feb 17 16:25:57.286: INFO: Pod "client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03127826s
STEP: Saw pod success
Feb 17 16:25:57.286: INFO: Pod "client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7" satisfied condition "success or failure"
Feb 17 16:25:57.300: INFO: Trying to get logs from node 10.241.69.147 pod client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7 container env3cont: <nil>
STEP: delete the pod
Feb 17 16:25:57.447: INFO: Waiting for pod client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7 to disappear
Feb 17 16:25:57.463: INFO: Pod client-envvars-4b45d532-4422-4592-8e5d-1c3f1baaded7 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:25:57.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9112" for this suite.
Feb 17 16:26:11.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:26:12.614: INFO: namespace pods-9112 deletion completed in 15.130752971s

• [SLOW TEST:19.903 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:26:12.615: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 16:26:23.151: INFO: DNS probes using dns-test-d507d65c-93ba-4a0b-8c0b-a69d088f315e succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 16:26:27.396: INFO: File wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:27.430: INFO: File jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:27.430: INFO: Lookups using dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d failed for: [wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local]

Feb 17 16:26:32.469: INFO: File wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:32.503: INFO: File jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:32.503: INFO: Lookups using dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d failed for: [wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local]

Feb 17 16:26:37.462: INFO: File wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:37.486: INFO: File jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:37.486: INFO: Lookups using dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d failed for: [wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local]

Feb 17 16:26:42.462: INFO: File wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:42.504: INFO: File jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local from pod  dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d contains 'foo.example.com.
' instead of 'bar.example.com.'
Feb 17 16:26:42.504: INFO: Lookups using dns-2178/dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d failed for: [wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local]

Feb 17 16:26:47.479: INFO: DNS probes using dns-test-13d8fd9b-987e-4cd9-81c2-131325f3ad1d succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2178.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2178.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 16:26:51.782: INFO: DNS probes using dns-test-f30fa5bb-0be5-4b81-977a-9a6d4e2b4a48 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:26:51.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2178" for this suite.
Feb 17 16:27:00.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:00.573: INFO: namespace dns-2178 deletion completed in 8.641674395s

• [SLOW TEST:47.959 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:27:00.574: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 16:27:00.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5566'
Feb 17 16:27:01.174: INFO: stderr: ""
Feb 17 16:27:01.174: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Feb 17 16:27:01.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete pods e2e-test-httpd-pod --namespace=kubectl-5566'
Feb 17 16:27:04.201: INFO: stderr: ""
Feb 17 16:27:04.201: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:27:04.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5566" for this suite.
Feb 17 16:27:12.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:13.135: INFO: namespace kubectl-5566 deletion completed in 8.893671617s

• [SLOW TEST:12.561 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:27:13.136: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b2972610-1e55-4e46-9aae-84b69a3de9de
STEP: Creating a pod to test consume secrets
Feb 17 16:27:13.511: INFO: Waiting up to 5m0s for pod "pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de" in namespace "secrets-9211" to be "success or failure"
Feb 17 16:27:13.533: INFO: Pod "pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de": Phase="Pending", Reason="", readiness=false. Elapsed: 22.375279ms
Feb 17 16:27:15.554: INFO: Pod "pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043255846s
STEP: Saw pod success
Feb 17 16:27:15.554: INFO: Pod "pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de" satisfied condition "success or failure"
Feb 17 16:27:15.568: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de container secret-env-test: <nil>
STEP: delete the pod
Feb 17 16:27:15.700: INFO: Waiting for pod pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de to disappear
Feb 17 16:27:15.724: INFO: Pod pod-secrets-06f8ff69-d717-4270-9132-1f4adeabf9de no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:27:15.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9211" for this suite.
Feb 17 16:27:23.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:24.468: INFO: namespace secrets-9211 deletion completed in 8.722843485s

• [SLOW TEST:11.332 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:27:24.468: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 17 16:27:24.767: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 16:27:24.835: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 16:27:24.853: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.130 before test
Feb 17 16:27:25.051: INFO: coredns-autoscaler-65c89858bf-df7mx from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 16:27:25.051: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:27:25.051: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 16:27:25.051: INFO: ibm-keepalived-watcher-qgfgw from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:27:25.051: INFO: calico-node-nrkf6 from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:27:25.051: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 from ibm-system started at 2020-02-17 14:49:07 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 16:27:25.051: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:03:08 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 16:27:25.051: INFO: coredns-bc786c74-624xw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:27:25.051: INFO: ibm-master-proxy-static-10.241.69.130 from kube-system started at 2020-02-17 14:48:46 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:27:25.051: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:27:25.051: INFO: coredns-bc786c74-79vl2 from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:27:25.051: INFO: dashboard-metrics-scraper-5cbd6549b8-r5tv4 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Feb 17 16:27:25.051: INFO: ibm-storage-watcher-799f6c5b69-zhj9j from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.051: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb 17 16:27:25.052: INFO: calico-kube-controllers-598ddbf99d-vhtrf from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.052: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 16:27:25.052: INFO: olm-operator-7bf4dbc978-4rx8l from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.052: INFO: 	Container olm-operator ready: true, restart count 0
Feb 17 16:27:25.052: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 from kube-system started at 2020-02-17 14:49:07 +0000 UTC (4 container statuses recorded)
Feb 17 16:27:25.052: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 16:27:25.052: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 16:27:25.052: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 16:27:25.052: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 16:27:25.052: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.147 before test
Feb 17 16:27:25.104: INFO: ibm-master-proxy-static-10.241.69.147 from kube-system started at 2020-02-17 14:40:19 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.104: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:27:25.104: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:27:25.104: INFO: ibm-keepalived-watcher-rh8sm from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.104: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:27:25.104: INFO: calico-node-4vlb4 from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.104: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:27:25.104: INFO: addon-catalog-source-bqjh8 from ibm-system started at 2020-02-17 14:44:25 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.104: INFO: 	Container configmap-registry-server ready: true, restart count 0
Feb 17 16:27:25.104: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.104: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:27:25.104: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 16:27:25.104: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.151 before test
Feb 17 16:27:25.312: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-ml8mw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (4 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 16:27:25.312: INFO: coredns-bc786c74-x59lf from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container coredns ready: true, restart count 0
Feb 17 16:27:25.312: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 16:27:25.312: INFO: catalog-operator-6d6c965db-dxspz from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container catalog-operator ready: true, restart count 0
Feb 17 16:27:25.312: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:52:12 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 16:27:25.312: INFO: ibm-keepalived-watcher-4n299 from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 16:27:25.312: INFO: ibm-file-plugin-5568fbb4d7-8vzx9 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb 17 16:27:25.312: INFO: ibm-master-proxy-static-10.241.69.151 from kube-system started at 2020-02-17 14:50:33 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container pause ready: true, restart count 0
Feb 17 16:27:25.312: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-2hx9m from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 16:27:25.312: INFO: metrics-server-5bf499b69-9cwsk from kube-system started at 2020-02-17 16:20:10 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 16:27:25.312: INFO: vpn-79845b6f9d-zgk7f from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container vpn ready: true, restart count 0
Feb 17 16:27:25.312: INFO: kubernetes-dashboard-6dbd4db8bf-sjswh from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 16:27:25.312: INFO: calico-node-nr68s from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 16:27:25.312: INFO: sonobuoy-e2e-job-ae741cd10f3545c2 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 16:27:25.312: INFO: 	Container e2e ready: true, restart count 0
Feb 17 16:27:25.312: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-df4d50d2-816c-4559-b5de-6a8d39987b38 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-df4d50d2-816c-4559-b5de-6a8d39987b38 off the node 10.241.69.147
STEP: verifying the node doesn't have the label kubernetes.io/e2e-df4d50d2-816c-4559-b5de-6a8d39987b38
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:27:29.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5099" for this suite.
Feb 17 16:27:41.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:42.400: INFO: namespace sched-pred-5099 deletion completed in 12.703797997s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:17.932 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:27:42.403: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6006
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:27:42.704: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85" in namespace "projected-6006" to be "success or failure"
Feb 17 16:27:42.721: INFO: Pod "downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85": Phase="Pending", Reason="", readiness=false. Elapsed: 17.683783ms
Feb 17 16:27:44.742: INFO: Pod "downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85": Phase="Running", Reason="", readiness=true. Elapsed: 2.038079878s
Feb 17 16:27:46.759: INFO: Pod "downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055496119s
STEP: Saw pod success
Feb 17 16:27:46.759: INFO: Pod "downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85" satisfied condition "success or failure"
Feb 17 16:27:46.798: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85 container client-container: <nil>
STEP: delete the pod
Feb 17 16:27:46.878: INFO: Waiting for pod downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85 to disappear
Feb 17 16:27:46.892: INFO: Pod downwardapi-volume-62f74c7b-5761-4cd5-b005-a1820860fa85 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:27:46.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6006" for this suite.
Feb 17 16:27:54.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:27:55.553: INFO: namespace projected-6006 deletion completed in 8.63835134s

• [SLOW TEST:13.150 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:27:55.555: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-4679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Feb 17 16:27:55.899: INFO: Waiting up to 5m0s for pod "client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e" in namespace "containers-4679" to be "success or failure"
Feb 17 16:27:55.921: INFO: Pod "client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 21.940769ms
Feb 17 16:27:57.938: INFO: Pod "client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e": Phase="Running", Reason="", readiness=true. Elapsed: 2.039357805s
Feb 17 16:27:59.952: INFO: Pod "client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052942633s
STEP: Saw pod success
Feb 17 16:27:59.952: INFO: Pod "client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e" satisfied condition "success or failure"
Feb 17 16:27:59.964: INFO: Trying to get logs from node 10.241.69.147 pod client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e container test-container: <nil>
STEP: delete the pod
Feb 17 16:28:00.070: INFO: Waiting for pod client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e to disappear
Feb 17 16:28:00.083: INFO: Pod client-containers-46c21925-5129-4e4b-bf4a-df28141f6f9e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:28:00.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4679" for this suite.
Feb 17 16:28:08.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:08.954: INFO: namespace containers-4679 deletion completed in 8.851109986s

• [SLOW TEST:13.400 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:28:08.955: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1702
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 16:28:09.649: INFO: Number of nodes with available pods: 0
Feb 17 16:28:09.649: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:28:10.707: INFO: Number of nodes with available pods: 0
Feb 17 16:28:10.707: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:28:11.698: INFO: Number of nodes with available pods: 1
Feb 17 16:28:11.698: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:28:12.688: INFO: Number of nodes with available pods: 3
Feb 17 16:28:12.688: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Feb 17 16:28:12.810: INFO: Number of nodes with available pods: 2
Feb 17 16:28:12.810: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 16:28:13.844: INFO: Number of nodes with available pods: 2
Feb 17 16:28:13.844: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 16:28:14.847: INFO: Number of nodes with available pods: 2
Feb 17 16:28:14.847: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 16:28:15.856: INFO: Number of nodes with available pods: 2
Feb 17 16:28:15.857: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 16:28:16.858: INFO: Number of nodes with available pods: 2
Feb 17 16:28:16.858: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 16:28:17.850: INFO: Number of nodes with available pods: 3
Feb 17 16:28:17.850: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1702, will wait for the garbage collector to delete the pods
Feb 17 16:28:17.961: INFO: Deleting DaemonSet.extensions daemon-set took: 35.435233ms
Feb 17 16:28:18.161: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.221935ms
Feb 17 16:28:29.482: INFO: Number of nodes with available pods: 0
Feb 17 16:28:29.482: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 16:28:29.499: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1702/daemonsets","resourceVersion":"24245"},"items":null}

Feb 17 16:28:29.512: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1702/pods","resourceVersion":"24245"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:28:29.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1702" for this suite.
Feb 17 16:28:37.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:28:38.328: INFO: namespace daemonsets-1702 deletion completed in 8.72418585s

• [SLOW TEST:29.374 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:28:38.328: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-488
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Feb 17 16:28:42.749: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-964215725 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Feb 17 16:28:52.979: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:28:53.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-488" for this suite.
Feb 17 16:29:01.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:29:01.832: INFO: namespace pods-488 deletion completed in 8.815359964s

• [SLOW TEST:23.503 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:29:01.832: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:29:02.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2413" for this suite.
Feb 17 16:29:32.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:29:33.332: INFO: namespace pods-2413 deletion completed in 30.969157008s

• [SLOW TEST:31.500 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:29:33.332: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 17 16:29:33.678: INFO: Waiting up to 5m0s for pod "pod-313056cd-e11d-4c31-8f98-eb3b59d4968f" in namespace "emptydir-9706" to be "success or failure"
Feb 17 16:29:33.702: INFO: Pod "pod-313056cd-e11d-4c31-8f98-eb3b59d4968f": Phase="Pending", Reason="", readiness=false. Elapsed: 23.470313ms
Feb 17 16:29:35.721: INFO: Pod "pod-313056cd-e11d-4c31-8f98-eb3b59d4968f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.042343299s
STEP: Saw pod success
Feb 17 16:29:35.721: INFO: Pod "pod-313056cd-e11d-4c31-8f98-eb3b59d4968f" satisfied condition "success or failure"
Feb 17 16:29:35.733: INFO: Trying to get logs from node 10.241.69.147 pod pod-313056cd-e11d-4c31-8f98-eb3b59d4968f container test-container: <nil>
STEP: delete the pod
Feb 17 16:29:35.829: INFO: Waiting for pod pod-313056cd-e11d-4c31-8f98-eb3b59d4968f to disappear
Feb 17 16:29:35.843: INFO: Pod pod-313056cd-e11d-4c31-8f98-eb3b59d4968f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:29:35.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9706" for this suite.
Feb 17 16:29:43.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:29:44.581: INFO: namespace emptydir-9706 deletion completed in 8.705656224s

• [SLOW TEST:11.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:29:44.581: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Feb 17 16:29:44.983: INFO: Waiting up to 5m0s for pod "var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f" in namespace "var-expansion-8546" to be "success or failure"
Feb 17 16:29:45.003: INFO: Pod "var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f": Phase="Pending", Reason="", readiness=false. Elapsed: 19.460959ms
Feb 17 16:29:47.016: INFO: Pod "var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f": Phase="Running", Reason="", readiness=true. Elapsed: 2.032489898s
Feb 17 16:29:49.039: INFO: Pod "var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055381012s
STEP: Saw pod success
Feb 17 16:29:49.039: INFO: Pod "var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f" satisfied condition "success or failure"
Feb 17 16:29:49.057: INFO: Trying to get logs from node 10.241.69.147 pod var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f container dapi-container: <nil>
STEP: delete the pod
Feb 17 16:29:49.145: INFO: Waiting for pod var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f to disappear
Feb 17 16:29:49.159: INFO: Pod var-expansion-d7f05ef3-5e0c-4d69-8948-b321108af97f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:29:49.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8546" for this suite.
Feb 17 16:29:57.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:29:57.817: INFO: namespace var-expansion-8546 deletion completed in 8.636016952s

• [SLOW TEST:13.235 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:29:57.817: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7933, will wait for the garbage collector to delete the pods
Feb 17 16:30:02.265: INFO: Deleting Job.batch foo took: 45.762476ms
Feb 17 16:30:02.565: INFO: Terminating Job.batch foo pods took: 300.417119ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:30:39.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7933" for this suite.
Feb 17 16:30:47.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:30:48.237: INFO: namespace job-7933 deletion completed in 8.633478844s

• [SLOW TEST:50.420 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:30:48.237: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5159
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-5159
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5159
Feb 17 16:30:48.628: INFO: Found 0 stateful pods, waiting for 1
Feb 17 16:30:58.647: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Feb 17 16:30:58.664: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:30:59.050: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:30:59.050: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:30:59.050: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:30:59.070: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 17 16:31:09.100: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:31:09.100: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:31:09.214: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:09.214: INFO: ss-0  10.241.69.147  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:09.214: INFO: ss-1                 Pending         []
Feb 17 16:31:09.214: INFO: 
Feb 17 16:31:09.214: INFO: StatefulSet ss has not reached scale 3, at 2
Feb 17 16:31:10.243: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.948072193s
Feb 17 16:31:11.263: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.919007417s
Feb 17 16:31:12.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.898708288s
Feb 17 16:31:13.299: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.87972464s
Feb 17 16:31:14.316: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.863521542s
Feb 17 16:31:15.333: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.846412994s
Feb 17 16:31:16.361: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.829617188s
Feb 17 16:31:17.381: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.800960603s
Feb 17 16:31:18.396: INFO: Verifying statefulset ss doesn't scale past 3 for another 781.514969ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5159
Feb 17 16:31:19.432: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:31:20.023: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 16:31:20.023: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:31:20.023: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:31:20.024: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:31:20.422: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 17 16:31:20.422: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:31:20.422: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:31:20.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:31:20.778: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Feb 17 16:31:20.778: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:31:20.778: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:31:20.806: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:31:20.807: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:31:20.807: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Feb 17 16:31:20.862: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:31:21.223: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:31:21.223: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:31:21.223: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:31:21.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:31:21.666: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:31:21.666: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:31:21.666: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:31:21.666: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:31:22.030: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:31:22.030: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:31:22.030: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:31:22.030: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:31:22.045: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Feb 17 16:31:32.110: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:31:32.110: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:31:32.110: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:31:32.155: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:32.156: INFO: ss-0  10.241.69.147  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:32.156: INFO: ss-1  10.241.69.130  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:32.156: INFO: ss-2  10.241.69.151  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:32.156: INFO: 
Feb 17 16:31:32.156: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:31:33.175: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:33.175: INFO: ss-0  10.241.69.147  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:33.175: INFO: ss-1  10.241.69.130  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:33.175: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:33.175: INFO: 
Feb 17 16:31:33.175: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:31:34.207: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:34.207: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:34.207: INFO: ss-1  10.241.69.130  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:34.207: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:34.207: INFO: 
Feb 17 16:31:34.207: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:31:35.232: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:35.232: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:35.232: INFO: ss-1  10.241.69.130  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:35.232: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:35.232: INFO: 
Feb 17 16:31:35.232: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:31:36.251: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:36.251: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:36.251: INFO: ss-1  10.241.69.130  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:36.251: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:36.251: INFO: 
Feb 17 16:31:36.251: INFO: StatefulSet ss has not reached scale 0, at 3
Feb 17 16:31:37.268: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:37.268: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:37.268: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:37.268: INFO: 
Feb 17 16:31:37.268: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 17 16:31:38.282: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:38.282: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:38.282: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:38.282: INFO: 
Feb 17 16:31:38.282: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 17 16:31:39.302: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:39.302: INFO: ss-0  10.241.69.147  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:30:48 +0000 UTC  }]
Feb 17 16:31:39.302: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:39.302: INFO: 
Feb 17 16:31:39.302: INFO: StatefulSet ss has not reached scale 0, at 2
Feb 17 16:31:40.322: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:40.322: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:40.322: INFO: 
Feb 17 16:31:40.322: INFO: StatefulSet ss has not reached scale 0, at 1
Feb 17 16:31:41.340: INFO: POD   NODE           PHASE    GRACE  CONDITIONS
Feb 17 16:31:41.340: INFO: ss-2  10.241.69.151  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:22 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-02-17 16:31:09 +0000 UTC  }]
Feb 17 16:31:41.340: INFO: 
Feb 17 16:31:41.340: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5159
Feb 17 16:31:42.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:31:42.656: INFO: rc: 1
Feb 17 16:31:42.656: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb 17 16:31:52.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:31:52.928: INFO: rc: 1
Feb 17 16:31:52.928: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:02.928: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:03.248: INFO: rc: 1
Feb 17 16:32:03.248: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:13.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:13.488: INFO: rc: 1
Feb 17 16:32:13.488: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:23.488: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:23.627: INFO: rc: 1
Feb 17 16:32:23.627: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:33.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:33.786: INFO: rc: 1
Feb 17 16:32:33.786: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:43.786: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:43.964: INFO: rc: 1
Feb 17 16:32:43.964: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:32:53.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:32:54.128: INFO: rc: 1
Feb 17 16:32:54.128: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:04.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:04.303: INFO: rc: 1
Feb 17 16:33:04.303: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:14.304: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:14.455: INFO: rc: 1
Feb 17 16:33:14.455: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:24.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:24.596: INFO: rc: 1
Feb 17 16:33:24.596: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:34.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:34.749: INFO: rc: 1
Feb 17 16:33:34.749: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:44.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:44.890: INFO: rc: 1
Feb 17 16:33:44.890: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:33:54.890: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:33:55.065: INFO: rc: 1
Feb 17 16:33:55.065: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:05.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:05.238: INFO: rc: 1
Feb 17 16:34:05.238: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:15.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:15.384: INFO: rc: 1
Feb 17 16:34:15.384: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:25.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:25.530: INFO: rc: 1
Feb 17 16:34:25.530: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:35.530: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:35.681: INFO: rc: 1
Feb 17 16:34:35.681: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:45.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:45.845: INFO: rc: 1
Feb 17 16:34:45.845: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:34:55.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:34:55.979: INFO: rc: 1
Feb 17 16:34:55.979: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:05.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:06.125: INFO: rc: 1
Feb 17 16:35:06.125: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:16.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:16.282: INFO: rc: 1
Feb 17 16:35:16.283: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:26.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:26.423: INFO: rc: 1
Feb 17 16:35:26.423: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:36.424: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:36.565: INFO: rc: 1
Feb 17 16:35:36.565: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:46.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:46.720: INFO: rc: 1
Feb 17 16:35:46.720: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:35:56.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:35:56.860: INFO: rc: 1
Feb 17 16:35:56.860: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:36:06.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:36:07.044: INFO: rc: 1
Feb 17 16:36:07.044: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:36:17.045: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:36:17.229: INFO: rc: 1
Feb 17 16:36:17.229: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:36:27.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:36:27.384: INFO: rc: 1
Feb 17 16:36:27.384: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:36:37.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:36:37.595: INFO: rc: 1
Feb 17 16:36:37.595: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:36:47.596: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-5159 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:36:47.743: INFO: rc: 1
Feb 17 16:36:47.743: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Feb 17 16:36:47.743: INFO: Scaling statefulset ss to 0
Feb 17 16:36:47.802: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 16:36:47.814: INFO: Deleting all statefulset in ns statefulset-5159
Feb 17 16:36:47.826: INFO: Scaling statefulset ss to 0
Feb 17 16:36:47.873: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:36:47.885: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:36:47.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5159" for this suite.
Feb 17 16:36:56.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:36:56.771: INFO: namespace statefulset-5159 deletion completed in 8.777566219s

• [SLOW TEST:368.534 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:36:56.771: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7324
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 17 16:36:57.066: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:37:31.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7324" for this suite.
Feb 17 16:37:39.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:39.837: INFO: namespace crd-publish-openapi-7324 deletion completed in 8.784868683s

• [SLOW TEST:43.066 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:37:39.838: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-481
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 16:37:40.632: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 16:37:42.680: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554260, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554260, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554260, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554260, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 16:37:45.740: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:37:46.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-481" for this suite.
Feb 17 16:37:54.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:37:54.796: INFO: namespace webhook-481 deletion completed in 8.680858673s
STEP: Destroying namespace "webhook-481-markers" for this suite.
Feb 17 16:38:00.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:38:01.803: INFO: namespace webhook-481-markers deletion completed in 7.007486137s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.076 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:38:01.914: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4309
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:38:02.615: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Feb 17 16:38:02.680: INFO: Number of nodes with available pods: 0
Feb 17 16:38:02.680: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Feb 17 16:38:02.954: INFO: Number of nodes with available pods: 0
Feb 17 16:38:02.954: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:03.996: INFO: Number of nodes with available pods: 0
Feb 17 16:38:03.996: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:04.980: INFO: Number of nodes with available pods: 1
Feb 17 16:38:04.980: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Feb 17 16:38:05.097: INFO: Number of nodes with available pods: 0
Feb 17 16:38:05.097: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Feb 17 16:38:05.265: INFO: Number of nodes with available pods: 0
Feb 17 16:38:05.265: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:06.301: INFO: Number of nodes with available pods: 0
Feb 17 16:38:06.301: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:07.306: INFO: Number of nodes with available pods: 0
Feb 17 16:38:07.306: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:08.295: INFO: Number of nodes with available pods: 0
Feb 17 16:38:08.295: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:09.283: INFO: Number of nodes with available pods: 0
Feb 17 16:38:09.283: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:10.282: INFO: Number of nodes with available pods: 0
Feb 17 16:38:10.282: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 16:38:11.304: INFO: Number of nodes with available pods: 1
Feb 17 16:38:11.304: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4309, will wait for the garbage collector to delete the pods
Feb 17 16:38:11.535: INFO: Deleting DaemonSet.extensions daemon-set took: 71.240803ms
Feb 17 16:38:11.836: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.348263ms
Feb 17 16:38:15.059: INFO: Number of nodes with available pods: 0
Feb 17 16:38:15.059: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 16:38:15.072: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4309/daemonsets","resourceVersion":"25661"},"items":null}

Feb 17 16:38:15.086: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4309/pods","resourceVersion":"25661"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:38:15.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4309" for this suite.
Feb 17 16:38:23.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:38:23.911: INFO: namespace daemonsets-4309 deletion completed in 8.703369906s

• [SLOW TEST:21.997 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:38:23.911: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:38:24.226: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6" in namespace "downward-api-2419" to be "success or failure"
Feb 17 16:38:24.243: INFO: Pod "downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.659578ms
Feb 17 16:38:26.261: INFO: Pod "downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035029166s
Feb 17 16:38:28.278: INFO: Pod "downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052052367s
STEP: Saw pod success
Feb 17 16:38:28.278: INFO: Pod "downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6" satisfied condition "success or failure"
Feb 17 16:38:28.295: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6 container client-container: <nil>
STEP: delete the pod
Feb 17 16:38:28.445: INFO: Waiting for pod downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6 to disappear
Feb 17 16:38:28.469: INFO: Pod downwardapi-volume-1d16ac71-e6ef-4365-a1c6-9d3e118e25c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:38:28.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2419" for this suite.
Feb 17 16:38:36.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:38:37.194: INFO: namespace downward-api-2419 deletion completed in 8.699056044s

• [SLOW TEST:13.283 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:38:37.195: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6669
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 17 16:38:41.739: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 16:38:41.754: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 16:38:43.754: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 16:38:43.767: INFO: Pod pod-with-poststart-exec-hook still exists
Feb 17 16:38:45.754: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Feb 17 16:38:45.772: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:38:45.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6669" for this suite.
Feb 17 16:39:15.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:39:16.663: INFO: namespace container-lifecycle-hook-6669 deletion completed in 30.847788858s

• [SLOW TEST:39.468 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:39:16.663: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Feb 17 16:39:17.038: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25872 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 16:39:17.038: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25873 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 17 16:39:17.038: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25874 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Feb 17 16:39:27.197: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25889 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 16:39:27.197: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25890 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Feb 17 16:39:27.197: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6475 /api/v1/namespaces/watch-6475/configmaps/e2e-watch-test-label-changed ba17144b-88bf-4bcb-b010-9a7b2cae3383 25891 0 2020-02-17 16:39:16 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:39:27.197: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6475" for this suite.
Feb 17 16:39:33.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:39:33.827: INFO: namespace watch-6475 deletion completed in 6.607427528s

• [SLOW TEST:17.164 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:39:33.830: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:39:56.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-196" for this suite.
Feb 17 16:40:04.511: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:40:05.503: INFO: namespace container-runtime-196 deletion completed in 9.074854969s

• [SLOW TEST:31.673 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:40:05.504: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:40:05.954: INFO: Waiting up to 5m0s for pod "downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2" in namespace "downward-api-6717" to be "success or failure"
Feb 17 16:40:06.031: INFO: Pod "downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2": Phase="Pending", Reason="", readiness=false. Elapsed: 76.869291ms
Feb 17 16:40:08.056: INFO: Pod "downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2": Phase="Running", Reason="", readiness=true. Elapsed: 2.102080813s
Feb 17 16:40:10.078: INFO: Pod "downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.123597487s
STEP: Saw pod success
Feb 17 16:40:10.078: INFO: Pod "downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2" satisfied condition "success or failure"
Feb 17 16:40:10.111: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2 container client-container: <nil>
STEP: delete the pod
Feb 17 16:40:10.253: INFO: Waiting for pod downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2 to disappear
Feb 17 16:40:10.303: INFO: Pod downwardapi-volume-924c4163-49e7-4c66-965a-835ba32d6ac2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:40:10.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6717" for this suite.
Feb 17 16:40:18.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:40:19.292: INFO: namespace downward-api-6717 deletion completed in 8.947609729s

• [SLOW TEST:13.788 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:40:19.294: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-37
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:40:19.793: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"77318126-5db5-464c-98e5-3818f65fcc0f", Controller:(*bool)(0xc0028ceaaa), BlockOwnerDeletion:(*bool)(0xc0028ceaab)}}
Feb 17 16:40:19.812: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"cb630bd8-f518-4252-b7e1-060bbfed77d3", Controller:(*bool)(0xc002b5d27e), BlockOwnerDeletion:(*bool)(0xc002b5d27f)}}
Feb 17 16:40:19.843: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"a4e84af7-06bb-42ac-a510-9f0df0e77860", Controller:(*bool)(0xc006a0e196), BlockOwnerDeletion:(*bool)(0xc006a0e197)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:40:24.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-37" for this suite.
Feb 17 16:40:32.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:40:33.597: INFO: namespace gc-37 deletion completed in 8.672565467s

• [SLOW TEST:14.303 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:40:33.597: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8657
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:40:37.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8657" for this suite.
Feb 17 16:40:46.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:40:46.655: INFO: namespace kubelet-test-8657 deletion completed in 8.663379548s

• [SLOW TEST:13.058 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:40:46.656: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-dc43fbc4-669c-4444-acf7-aa81e8cc6595
STEP: Creating a pod to test consume secrets
Feb 17 16:40:47.023: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec" in namespace "projected-7868" to be "success or failure"
Feb 17 16:40:47.050: INFO: Pod "pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec": Phase="Pending", Reason="", readiness=false. Elapsed: 26.975018ms
Feb 17 16:40:49.068: INFO: Pod "pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045342677s
STEP: Saw pod success
Feb 17 16:40:49.068: INFO: Pod "pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec" satisfied condition "success or failure"
Feb 17 16:40:49.083: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:40:49.176: INFO: Waiting for pod pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec to disappear
Feb 17 16:40:49.191: INFO: Pod pod-projected-secrets-66a4a2b4-23b9-4653-96a1-25ac92f4f7ec no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:40:49.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7868" for this suite.
Feb 17 16:40:57.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:40:57.918: INFO: namespace projected-7868 deletion completed in 8.700873672s

• [SLOW TEST:11.262 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:40:57.921: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-2209
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:40:58.348: INFO: (0) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 101.504858ms)
Feb 17 16:40:58.380: INFO: (1) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.981548ms)
Feb 17 16:40:58.429: INFO: (2) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 49.024406ms)
Feb 17 16:40:58.459: INFO: (3) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 30.099741ms)
Feb 17 16:40:58.493: INFO: (4) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.419676ms)
Feb 17 16:40:58.514: INFO: (5) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 21.129421ms)
Feb 17 16:40:58.537: INFO: (6) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.030836ms)
Feb 17 16:40:58.564: INFO: (7) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.453837ms)
Feb 17 16:40:58.592: INFO: (8) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.137907ms)
Feb 17 16:40:58.619: INFO: (9) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.905628ms)
Feb 17 16:40:58.639: INFO: (10) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 20.88808ms)
Feb 17 16:40:58.659: INFO: (11) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 19.504757ms)
Feb 17 16:40:58.691: INFO: (12) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.944941ms)
Feb 17 16:40:58.721: INFO: (13) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 29.911293ms)
Feb 17 16:40:58.749: INFO: (14) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 27.660452ms)
Feb 17 16:40:58.780: INFO: (15) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 31.72126ms)
Feb 17 16:40:58.807: INFO: (16) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 26.462314ms)
Feb 17 16:40:58.831: INFO: (17) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.972796ms)
Feb 17 16:40:58.864: INFO: (18) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 32.839182ms)
Feb 17 16:40:58.887: INFO: (19) /api/v1/nodes/10.241.69.130:10250/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 23.422923ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:40:58.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-2209" for this suite.
Feb 17 16:41:06.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:07.924: INFO: namespace proxy-2209 deletion completed in 9.005286208s

• [SLOW TEST:10.003 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:41:07.924: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5807
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-a7566cd6-bcfd-4a3f-a40b-854efd1bb2fc
STEP: Creating a pod to test consume configMaps
Feb 17 16:41:08.387: INFO: Waiting up to 5m0s for pod "pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9" in namespace "configmap-5807" to be "success or failure"
Feb 17 16:41:08.403: INFO: Pod "pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9": Phase="Pending", Reason="", readiness=false. Elapsed: 15.871841ms
Feb 17 16:41:10.427: INFO: Pod "pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039456853s
Feb 17 16:41:12.447: INFO: Pod "pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060256501s
STEP: Saw pod success
Feb 17 16:41:12.447: INFO: Pod "pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9" satisfied condition "success or failure"
Feb 17 16:41:12.477: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:41:12.681: INFO: Waiting for pod pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9 to disappear
Feb 17 16:41:12.699: INFO: Pod pod-configmaps-cca8861e-993c-4ab0-bfef-85a21c4282c9 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:41:12.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5807" for this suite.
Feb 17 16:41:20.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:21.631: INFO: namespace configmap-5807 deletion completed in 8.902250517s

• [SLOW TEST:13.707 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:41:21.632: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8511
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 17 16:41:22.011: INFO: Waiting up to 5m0s for pod "pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c" in namespace "emptydir-8511" to be "success or failure"
Feb 17 16:41:22.080: INFO: Pod "pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c": Phase="Pending", Reason="", readiness=false. Elapsed: 68.859429ms
Feb 17 16:41:24.097: INFO: Pod "pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.085688008s
STEP: Saw pod success
Feb 17 16:41:24.097: INFO: Pod "pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c" satisfied condition "success or failure"
Feb 17 16:41:24.116: INFO: Trying to get logs from node 10.241.69.147 pod pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c container test-container: <nil>
STEP: delete the pod
Feb 17 16:41:24.253: INFO: Waiting for pod pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c to disappear
Feb 17 16:41:24.287: INFO: Pod pod-7f8760db-56a8-45ca-920d-e3ee7a3f236c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:41:24.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8511" for this suite.
Feb 17 16:41:32.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:32.959: INFO: namespace emptydir-8511 deletion completed in 8.654400877s

• [SLOW TEST:11.328 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:41:32.960: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-5212
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:41:33.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5212" for this suite.
Feb 17 16:41:39.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:41:40.031: INFO: namespace tables-5212 deletion completed in 6.718832694s

• [SLOW TEST:7.071 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:41:40.031: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1533
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:41:53.566: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1533" for this suite.
Feb 17 16:41:59.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:00.227: INFO: namespace resourcequota-1533 deletion completed in 6.638484542s

• [SLOW TEST:20.195 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:42:00.227: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-1053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-1053
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-1053
STEP: Deleting pre-stop pod
Feb 17 16:42:13.885: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:42:13.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-1053" for this suite.
Feb 17 16:42:50.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:42:50.749: INFO: namespace prestop-1053 deletion completed in 36.799446352s

• [SLOW TEST:50.522 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:42:50.751: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7237
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Feb 17 16:43:31.196: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 16:43:31.196875      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:43:31.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7237" for this suite.
Feb 17 16:43:41.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:41.868: INFO: namespace gc-7237 deletion completed in 10.650182721s

• [SLOW TEST:51.117 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:43:41.868: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-542
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-13ca4c90-be2a-4924-9e7a-e50a7a932ba6
STEP: Creating a pod to test consume secrets
Feb 17 16:43:42.194: INFO: Waiting up to 5m0s for pod "pod-secrets-502314a5-3854-4658-b246-193b4c2891b1" in namespace "secrets-542" to be "success or failure"
Feb 17 16:43:42.221: INFO: Pod "pod-secrets-502314a5-3854-4658-b246-193b4c2891b1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.309906ms
Feb 17 16:43:44.236: INFO: Pod "pod-secrets-502314a5-3854-4658-b246-193b4c2891b1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041315433s
STEP: Saw pod success
Feb 17 16:43:44.236: INFO: Pod "pod-secrets-502314a5-3854-4658-b246-193b4c2891b1" satisfied condition "success or failure"
Feb 17 16:43:44.250: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-502314a5-3854-4658-b246-193b4c2891b1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 16:43:44.385: INFO: Waiting for pod pod-secrets-502314a5-3854-4658-b246-193b4c2891b1 to disappear
Feb 17 16:43:44.401: INFO: Pod pod-secrets-502314a5-3854-4658-b246-193b4c2891b1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:43:44.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-542" for this suite.
Feb 17 16:43:52.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:43:53.051: INFO: namespace secrets-542 deletion completed in 8.625437094s

• [SLOW TEST:11.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:43:53.052: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-404
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-33b5355b-068b-47a6-b471-e306d4749650
STEP: Creating a pod to test consume configMaps
Feb 17 16:43:53.411: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c" in namespace "projected-404" to be "success or failure"
Feb 17 16:43:53.450: INFO: Pod "pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c": Phase="Pending", Reason="", readiness=false. Elapsed: 37.991657ms
Feb 17 16:43:55.467: INFO: Pod "pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055573124s
STEP: Saw pod success
Feb 17 16:43:55.467: INFO: Pod "pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c" satisfied condition "success or failure"
Feb 17 16:43:55.491: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:43:55.580: INFO: Waiting for pod pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c to disappear
Feb 17 16:43:55.601: INFO: Pod pod-projected-configmaps-9442b68a-87d3-4f5a-9ad2-6e4fec52bb1c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:43:55.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-404" for this suite.
Feb 17 16:44:03.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:04.738: INFO: namespace projected-404 deletion completed in 9.095604993s

• [SLOW TEST:11.686 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:44:04.738: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7579
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 16:44:05.727: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 16:44:07.791: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554645, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554645, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554645, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717554645, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 16:44:10.854: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:44:11.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7579" for this suite.
Feb 17 16:44:19.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:19.725: INFO: namespace webhook-7579 deletion completed in 8.61383542s
STEP: Destroying namespace "webhook-7579-markers" for this suite.
Feb 17 16:44:25.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:26.339: INFO: namespace webhook-7579-markers deletion completed in 6.614062437s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.667 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:44:26.407: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5945
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-0abddf5f-f0aa-4757-b498-0092e603dcbc
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:44:26.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5945" for this suite.
Feb 17 16:44:32.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:44:33.425: INFO: namespace configmap-5945 deletion completed in 6.693858039s

• [SLOW TEST:7.019 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:44:33.425: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-8e7c8918-a98e-42e4-9f84-8dae14f8b9fd in namespace container-probe-3639
Feb 17 16:44:37.839: INFO: Started pod busybox-8e7c8918-a98e-42e4-9f84-8dae14f8b9fd in namespace container-probe-3639
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 16:44:37.855: INFO: Initial restart count of pod busybox-8e7c8918-a98e-42e4-9f84-8dae14f8b9fd is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:48:38.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3639" for this suite.
Feb 17 16:48:46.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:48:46.986: INFO: namespace container-probe-3639 deletion completed in 8.676386362s

• [SLOW TEST:253.561 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:48:46.988: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 17 16:48:47.343: INFO: Waiting up to 5m0s for pod "pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6" in namespace "emptydir-6207" to be "success or failure"
Feb 17 16:48:47.367: INFO: Pod "pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6": Phase="Pending", Reason="", readiness=false. Elapsed: 23.51685ms
Feb 17 16:48:49.388: INFO: Pod "pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.044217483s
Feb 17 16:48:51.414: INFO: Pod "pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070228426s
STEP: Saw pod success
Feb 17 16:48:51.414: INFO: Pod "pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6" satisfied condition "success or failure"
Feb 17 16:48:51.435: INFO: Trying to get logs from node 10.241.69.147 pod pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6 container test-container: <nil>
STEP: delete the pod
Feb 17 16:48:51.589: INFO: Waiting for pod pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6 to disappear
Feb 17 16:48:51.611: INFO: Pod pod-f5b9640b-1bf6-4599-aa0d-99435d3c43d6 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:48:51.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6207" for this suite.
Feb 17 16:48:59.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:49:00.328: INFO: namespace emptydir-6207 deletion completed in 8.689449433s

• [SLOW TEST:13.340 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:49:00.328: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2743
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Feb 17 16:49:00.641: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 16:49:13.763: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:49:37.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2743" for this suite.
Feb 17 16:49:43.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:49:44.444: INFO: namespace crd-publish-openapi-2743 deletion completed in 7.077519426s

• [SLOW TEST:44.116 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:49:44.444: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Feb 17 16:49:44.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-1637'
Feb 17 16:49:45.238: INFO: stderr: ""
Feb 17 16:49:45.238: INFO: stdout: "pod/pause created\n"
Feb 17 16:49:45.238: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Feb 17 16:49:45.238: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-1637" to be "running and ready"
Feb 17 16:49:45.263: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 25.239717ms
Feb 17 16:49:47.277: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.039444283s
Feb 17 16:49:47.277: INFO: Pod "pause" satisfied condition "running and ready"
Feb 17 16:49:47.277: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Feb 17 16:49:47.278: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 label pods pause testing-label=testing-label-value --namespace=kubectl-1637'
Feb 17 16:49:47.432: INFO: stderr: ""
Feb 17 16:49:47.432: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Feb 17 16:49:47.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pod pause -L testing-label --namespace=kubectl-1637'
Feb 17 16:49:47.570: INFO: stderr: ""
Feb 17 16:49:47.570: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Feb 17 16:49:47.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 label pods pause testing-label- --namespace=kubectl-1637'
Feb 17 16:49:47.735: INFO: stderr: ""
Feb 17 16:49:47.735: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Feb 17 16:49:47.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pod pause -L testing-label --namespace=kubectl-1637'
Feb 17 16:49:47.861: INFO: stderr: ""
Feb 17 16:49:47.861: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Feb 17 16:49:47.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-1637'
Feb 17 16:49:48.054: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 16:49:48.054: INFO: stdout: "pod \"pause\" force deleted\n"
Feb 17 16:49:48.054: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get rc,svc -l name=pause --no-headers --namespace=kubectl-1637'
Feb 17 16:49:48.209: INFO: stderr: "No resources found in kubectl-1637 namespace.\n"
Feb 17 16:49:48.209: INFO: stdout: ""
Feb 17 16:49:48.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -l name=pause --namespace=kubectl-1637 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 16:49:48.340: INFO: stderr: ""
Feb 17 16:49:48.340: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:49:48.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1637" for this suite.
Feb 17 16:49:56.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:49:57.071: INFO: namespace kubectl-1637 deletion completed in 8.709064709s

• [SLOW TEST:12.627 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:49:57.073: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1853
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-4cb71372-f5f1-48e4-b9d6-e20af41289c7
STEP: Creating a pod to test consume configMaps
Feb 17 16:49:57.403: INFO: Waiting up to 5m0s for pod "pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc" in namespace "configmap-1853" to be "success or failure"
Feb 17 16:49:57.416: INFO: Pod "pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc": Phase="Pending", Reason="", readiness=false. Elapsed: 12.81219ms
Feb 17 16:49:59.432: INFO: Pod "pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.029119234s
Feb 17 16:50:01.478: INFO: Pod "pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074487553s
STEP: Saw pod success
Feb 17 16:50:01.478: INFO: Pod "pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc" satisfied condition "success or failure"
Feb 17 16:50:01.504: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 16:50:01.740: INFO: Waiting for pod pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc to disappear
Feb 17 16:50:01.761: INFO: Pod pod-configmaps-c7c48383-2a5e-44d1-bc86-63df764835cc no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:50:01.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1853" for this suite.
Feb 17 16:50:09.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:50:10.839: INFO: namespace configmap-1853 deletion completed in 9.047901179s

• [SLOW TEST:13.766 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:50:10.840: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8620
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 16:50:14.348: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:50:14.478: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8620" for this suite.
Feb 17 16:50:22.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:50:23.159: INFO: namespace container-runtime-8620 deletion completed in 8.644355729s

• [SLOW TEST:12.319 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:50:23.160: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 16:50:23.485: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5" in namespace "projected-8050" to be "success or failure"
Feb 17 16:50:23.507: INFO: Pod "downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5": Phase="Pending", Reason="", readiness=false. Elapsed: 20.029574ms
Feb 17 16:50:25.535: INFO: Pod "downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04752171s
Feb 17 16:50:27.550: INFO: Pod "downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.062603714s
STEP: Saw pod success
Feb 17 16:50:27.550: INFO: Pod "downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5" satisfied condition "success or failure"
Feb 17 16:50:27.563: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5 container client-container: <nil>
STEP: delete the pod
Feb 17 16:50:27.651: INFO: Waiting for pod downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5 to disappear
Feb 17 16:50:27.667: INFO: Pod downwardapi-volume-b4f8f6f4-58b8-4349-883f-c539da2334d5 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:50:27.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8050" for this suite.
Feb 17 16:50:35.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:50:36.350: INFO: namespace projected-8050 deletion completed in 8.656559987s

• [SLOW TEST:13.191 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:50:36.351: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2687
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2687
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2687
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2687
Feb 17 16:50:36.697: INFO: Found 0 stateful pods, waiting for 1
Feb 17 16:50:46.716: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Feb 17 16:50:46.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:50:47.208: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:50:47.208: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:50:47.208: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:50:47.223: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Feb 17 16:50:57.243: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:50:57.243: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:50:57.314: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999998151s
Feb 17 16:50:58.340: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.974511639s
Feb 17 16:50:59.354: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.948624786s
Feb 17 16:51:00.372: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.934374361s
Feb 17 16:51:01.410: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.916936845s
Feb 17 16:51:02.449: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.879193075s
Feb 17 16:51:03.487: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.840109582s
Feb 17 16:51:04.510: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.801315125s
Feb 17 16:51:05.529: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.778879519s
Feb 17 16:51:06.547: INFO: Verifying statefulset ss doesn't scale past 1 for another 759.801856ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2687
Feb 17 16:51:07.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:51:08.353: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 16:51:08.353: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:51:08.353: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:51:08.393: INFO: Found 1 stateful pods, waiting for 3
Feb 17 16:51:18.410: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:51:18.410: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 16:51:18.410: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Feb 17 16:51:18.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:51:18.872: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:51:18.872: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:51:18.872: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:51:18.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:51:19.249: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:51:19.249: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:51:19.249: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:51:19.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 16:51:19.622: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 16:51:19.622: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 16:51:19.622: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 16:51:19.622: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:51:19.635: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Feb 17 16:51:29.665: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:51:29.665: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:51:29.665: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Feb 17 16:51:29.713: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999998126s
Feb 17 16:51:30.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.983022371s
Feb 17 16:51:31.761: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.952521985s
Feb 17 16:51:32.777: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.934716744s
Feb 17 16:51:33.797: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.915809262s
Feb 17 16:51:34.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.8981059s
Feb 17 16:51:35.838: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.876977158s
Feb 17 16:51:36.860: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.857996008s
Feb 17 16:51:37.878: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.835321754s
Feb 17 16:51:38.894: INFO: Verifying statefulset ss doesn't scale past 3 for another 817.557004ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2687
Feb 17 16:51:39.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:51:40.315: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 16:51:40.315: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:51:40.315: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:51:40.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:51:40.671: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 16:51:40.671: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 16:51:40.671: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 16:51:40.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:51:40.973: INFO: rc: 1
Feb 17 16:51:40.973: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Feb 17 16:51:50.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:51:51.112: INFO: rc: 1
Feb 17 16:51:51.112: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:01.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:01.317: INFO: rc: 1
Feb 17 16:52:01.317: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:11.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:11.478: INFO: rc: 1
Feb 17 16:52:11.479: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:21.479: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:21.619: INFO: rc: 1
Feb 17 16:52:21.619: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:31.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:31.779: INFO: rc: 1
Feb 17 16:52:31.779: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:41.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:41.918: INFO: rc: 1
Feb 17 16:52:41.918: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:52:51.918: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:52:52.074: INFO: rc: 1
Feb 17 16:52:52.074: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:02.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:02.455: INFO: rc: 1
Feb 17 16:53:02.455: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:12.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:12.611: INFO: rc: 1
Feb 17 16:53:12.611: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:22.611: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:22.752: INFO: rc: 1
Feb 17 16:53:22.752: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:32.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:32.915: INFO: rc: 1
Feb 17 16:53:32.915: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:42.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:43.090: INFO: rc: 1
Feb 17 16:53:43.090: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:53:53.090: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:53:53.241: INFO: rc: 1
Feb 17 16:53:53.241: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:03.241: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:03.514: INFO: rc: 1
Feb 17 16:54:03.514: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:13.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:13.839: INFO: rc: 1
Feb 17 16:54:13.839: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:23.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:24.009: INFO: rc: 1
Feb 17 16:54:24.009: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:34.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:34.156: INFO: rc: 1
Feb 17 16:54:34.156: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:44.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:44.313: INFO: rc: 1
Feb 17 16:54:44.313: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:54:54.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:54:54.454: INFO: rc: 1
Feb 17 16:54:54.454: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:04.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:04.627: INFO: rc: 1
Feb 17 16:55:04.627: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:14.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:14.785: INFO: rc: 1
Feb 17 16:55:14.785: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:24.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:24.932: INFO: rc: 1
Feb 17 16:55:24.932: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:34.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:35.084: INFO: rc: 1
Feb 17 16:55:35.084: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:45.085: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:45.234: INFO: rc: 1
Feb 17 16:55:45.234: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:55:55.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:55:55.392: INFO: rc: 1
Feb 17 16:55:55.392: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:56:05.393: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:56:05.550: INFO: rc: 1
Feb 17 16:56:05.550: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:56:15.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:56:15.696: INFO: rc: 1
Feb 17 16:56:15.696: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:56:25.697: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:56:25.877: INFO: rc: 1
Feb 17 16:56:25.877: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:56:35.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:56:36.022: INFO: rc: 1
Feb 17 16:56:36.022: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Feb 17 16:56:46.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-2687 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 16:56:46.206: INFO: rc: 1
Feb 17 16:56:46.206: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Feb 17 16:56:46.206: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 16:56:46.254: INFO: Deleting all statefulset in ns statefulset-2687
Feb 17 16:56:46.268: INFO: Scaling statefulset ss to 0
Feb 17 16:56:46.330: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 16:56:46.350: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:56:46.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2687" for this suite.
Feb 17 16:56:54.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:56:55.141: INFO: namespace statefulset-2687 deletion completed in 8.704952858s

• [SLOW TEST:378.791 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:56:55.142: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-3300
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Feb 17 16:57:00.146: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3300 pod-service-account-6c1af9ab-75ae-4cad-8cdd-729cc690dc20 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Feb 17 16:57:00.634: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3300 pod-service-account-6c1af9ab-75ae-4cad-8cdd-729cc690dc20 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Feb 17 16:57:01.235: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3300 pod-service-account-6c1af9ab-75ae-4cad-8cdd-729cc690dc20 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:57:01.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3300" for this suite.
Feb 17 16:57:09.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:57:10.621: INFO: namespace svcaccounts-3300 deletion completed in 8.922057319s

• [SLOW TEST:15.480 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:57:10.622: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9364
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9364.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9364.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9364.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9364.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9364.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9364.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 16:57:15.242: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.279: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.314: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.348: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.442: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.474: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:15.583: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:20.620: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:20.648: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:20.701: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:20.798: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:20.877: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:20.982: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:25.612: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:25.643: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:25.774: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:25.797: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:25.990: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:30.616: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:30.651: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:30.824: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:30.853: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:30.995: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:35.637: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:35.668: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:35.808: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:35.832: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:35.939: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:40.614: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:40.640: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:40.776: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:40.809: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local from pod dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8: the server could not find the requested resource (get pods dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8)
Feb 17 16:57:40.917: INFO: Lookups using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9364.svc.cluster.local]

Feb 17 16:57:46.006: INFO: DNS probes using dns-9364/dns-test-ffa74589-8715-4b24-9aa8-be896fceddb8 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:57:46.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9364" for this suite.
Feb 17 16:57:54.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:57:55.294: INFO: namespace dns-9364 deletion completed in 9.120389242s

• [SLOW TEST:44.672 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:57:55.295: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-676
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 16:57:55.601: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:57:56.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-676" for this suite.
Feb 17 16:58:04.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:58:05.826: INFO: namespace custom-resource-definition-676 deletion completed in 9.075285283s

• [SLOW TEST:10.531 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:58:05.827: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5065
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 16:58:22.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5065" for this suite.
Feb 17 16:58:30.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 16:58:31.617: INFO: namespace resourcequota-5065 deletion completed in 8.748747787s

• [SLOW TEST:25.790 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 16:58:31.617: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Feb 17 16:58:33.012: INFO: Pod name wrapped-volume-race-be897bf5-2512-4b70-b95f-6e64b34fc74f: Found 0 pods out of 5
Feb 17 16:58:38.040: INFO: Pod name wrapped-volume-race-be897bf5-2512-4b70-b95f-6e64b34fc74f: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-be897bf5-2512-4b70-b95f-6e64b34fc74f in namespace emptydir-wrapper-3443, will wait for the garbage collector to delete the pods
Feb 17 16:58:38.252: INFO: Deleting ReplicationController wrapped-volume-race-be897bf5-2512-4b70-b95f-6e64b34fc74f took: 31.090894ms
Feb 17 16:58:38.453: INFO: Terminating ReplicationController wrapped-volume-race-be897bf5-2512-4b70-b95f-6e64b34fc74f pods took: 200.492223ms
STEP: Creating RC which spawns configmap-volume pods
Feb 17 16:59:17.021: INFO: Pod name wrapped-volume-race-f559ae79-d5e6-4d76-a7fa-7bed2653825a: Found 0 pods out of 5
Feb 17 16:59:22.050: INFO: Pod name wrapped-volume-race-f559ae79-d5e6-4d76-a7fa-7bed2653825a: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f559ae79-d5e6-4d76-a7fa-7bed2653825a in namespace emptydir-wrapper-3443, will wait for the garbage collector to delete the pods
Feb 17 16:59:22.226: INFO: Deleting ReplicationController wrapped-volume-race-f559ae79-d5e6-4d76-a7fa-7bed2653825a took: 37.195489ms
Feb 17 16:59:22.526: INFO: Terminating ReplicationController wrapped-volume-race-f559ae79-d5e6-4d76-a7fa-7bed2653825a pods took: 300.291578ms
STEP: Creating RC which spawns configmap-volume pods
Feb 17 17:00:06.839: INFO: Pod name wrapped-volume-race-42eba7d2-b228-478e-8ff8-de6acabfdda1: Found 0 pods out of 5
Feb 17 17:00:11.886: INFO: Pod name wrapped-volume-race-42eba7d2-b228-478e-8ff8-de6acabfdda1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-42eba7d2-b228-478e-8ff8-de6acabfdda1 in namespace emptydir-wrapper-3443, will wait for the garbage collector to delete the pods
Feb 17 17:00:12.153: INFO: Deleting ReplicationController wrapped-volume-race-42eba7d2-b228-478e-8ff8-de6acabfdda1 took: 66.105978ms
Feb 17 17:00:12.453: INFO: Terminating ReplicationController wrapped-volume-race-42eba7d2-b228-478e-8ff8-de6acabfdda1 pods took: 300.282579ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:00:58.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3443" for this suite.
Feb 17 17:01:10.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:01:11.386: INFO: namespace emptydir-wrapper-3443 deletion completed in 12.889821894s

• [SLOW TEST:159.769 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:01:11.386: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 17 17:01:16.229: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:01:16.256: INFO: Pod pod-with-prestop-http-hook still exists
Feb 17 17:01:18.256: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:01:18.272: INFO: Pod pod-with-prestop-http-hook still exists
Feb 17 17:01:20.257: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Feb 17 17:01:20.285: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:01:20.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1534" for this suite.
Feb 17 17:01:34.518: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:01:35.182: INFO: namespace container-lifecycle-hook-1534 deletion completed in 14.73246337s

• [SLOW TEST:23.795 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:01:35.183: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7337
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:01:35.523: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6" in namespace "downward-api-7337" to be "success or failure"
Feb 17 17:01:35.560: INFO: Pod "downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6": Phase="Pending", Reason="", readiness=false. Elapsed: 36.882402ms
Feb 17 17:01:37.581: INFO: Pod "downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.058365583s
Feb 17 17:01:39.711: INFO: Pod "downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.188133988s
STEP: Saw pod success
Feb 17 17:01:39.711: INFO: Pod "downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6" satisfied condition "success or failure"
Feb 17 17:01:39.728: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6 container client-container: <nil>
STEP: delete the pod
Feb 17 17:01:39.824: INFO: Waiting for pod downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6 to disappear
Feb 17 17:01:39.842: INFO: Pod downwardapi-volume-2b050de9-df1c-41d8-8a76-25e10cb9fdf6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:01:39.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7337" for this suite.
Feb 17 17:01:47.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:01:48.487: INFO: namespace downward-api-7337 deletion completed in 8.621064443s

• [SLOW TEST:13.304 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:01:48.488: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9156
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-gppm7 in namespace proxy-9156
I0217 17:01:48.840868      25 runners.go:184] Created replication controller with name: proxy-service-gppm7, namespace: proxy-9156, replica count: 1
I0217 17:01:49.891463      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 17:01:50.891775      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0217 17:01:51.892011      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:52.892320      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:53.893436      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:54.893753      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:55.894034      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:56.894432      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:57.894747      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:58.895047      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0217 17:01:59.895419      25 runners.go:184] proxy-service-gppm7 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 17:01:59.921: INFO: setup took 11.136370474s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 43.787884ms)
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 44.657898ms)
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 44.288347ms)
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 44.483074ms)
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 44.71637ms)
Feb 17 17:01:59.966: INFO: (0) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 44.853244ms)
Feb 17 17:01:59.968: INFO: (0) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 46.629304ms)
Feb 17 17:01:59.977: INFO: (0) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 55.099893ms)
Feb 17 17:01:59.983: INFO: (0) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 61.511673ms)
Feb 17 17:01:59.985: INFO: (0) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 63.358341ms)
Feb 17 17:01:59.985: INFO: (0) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 63.710792ms)
Feb 17 17:01:59.992: INFO: (0) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 70.637268ms)
Feb 17 17:01:59.995: INFO: (0) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 73.7327ms)
Feb 17 17:01:59.995: INFO: (0) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 73.787523ms)
Feb 17 17:01:59.995: INFO: (0) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 73.939283ms)
Feb 17 17:01:59.996: INFO: (0) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 73.973492ms)
Feb 17 17:02:00.026: INFO: (1) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 30.332092ms)
Feb 17 17:02:00.036: INFO: (1) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 37.930907ms)
Feb 17 17:02:00.036: INFO: (1) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 39.410763ms)
Feb 17 17:02:00.036: INFO: (1) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 38.582382ms)
Feb 17 17:02:00.037: INFO: (1) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 38.904723ms)
Feb 17 17:02:00.037: INFO: (1) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 39.095793ms)
Feb 17 17:02:00.037: INFO: (1) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 40.227458ms)
Feb 17 17:02:00.040: INFO: (1) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 43.20231ms)
Feb 17 17:02:00.045: INFO: (1) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 47.227783ms)
Feb 17 17:02:00.046: INFO: (1) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 49.684468ms)
Feb 17 17:02:00.066: INFO: (1) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 68.510528ms)
Feb 17 17:02:00.066: INFO: (1) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 70.038265ms)
Feb 17 17:02:00.070: INFO: (1) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 73.000495ms)
Feb 17 17:02:00.073: INFO: (1) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 76.403139ms)
Feb 17 17:02:00.073: INFO: (1) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 75.127017ms)
Feb 17 17:02:00.079: INFO: (1) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 81.517897ms)
Feb 17 17:02:00.105: INFO: (2) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 26.129461ms)
Feb 17 17:02:00.118: INFO: (2) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 39.206297ms)
Feb 17 17:02:00.119: INFO: (2) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 40.167081ms)
Feb 17 17:02:00.122: INFO: (2) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 43.489765ms)
Feb 17 17:02:00.122: INFO: (2) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 43.286268ms)
Feb 17 17:02:00.123: INFO: (2) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 44.443537ms)
Feb 17 17:02:00.124: INFO: (2) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 44.781314ms)
Feb 17 17:02:00.124: INFO: (2) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 45.318018ms)
Feb 17 17:02:00.124: INFO: (2) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 45.359214ms)
Feb 17 17:02:00.125: INFO: (2) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 46.048178ms)
Feb 17 17:02:00.135: INFO: (2) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 56.169811ms)
Feb 17 17:02:00.135: INFO: (2) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 55.871446ms)
Feb 17 17:02:00.135: INFO: (2) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 55.977256ms)
Feb 17 17:02:00.146: INFO: (2) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 66.666962ms)
Feb 17 17:02:00.146: INFO: (2) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 66.6085ms)
Feb 17 17:02:00.146: INFO: (2) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 66.7752ms)
Feb 17 17:02:00.191: INFO: (3) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 45.223798ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 53.059512ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 52.751108ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 52.858682ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 52.898847ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 52.832803ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 52.957983ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 53.022184ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 53.094957ms)
Feb 17 17:02:00.199: INFO: (3) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 53.135914ms)
Feb 17 17:02:00.213: INFO: (3) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 66.768854ms)
Feb 17 17:02:00.213: INFO: (3) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 66.864515ms)
Feb 17 17:02:00.213: INFO: (3) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 66.843185ms)
Feb 17 17:02:00.213: INFO: (3) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 66.772092ms)
Feb 17 17:02:00.215: INFO: (3) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 68.877382ms)
Feb 17 17:02:00.218: INFO: (3) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 71.71016ms)
Feb 17 17:02:00.255: INFO: (4) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 37.139715ms)
Feb 17 17:02:00.260: INFO: (4) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 41.764187ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 42.210921ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 42.47288ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 42.228293ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 42.941411ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 43.00332ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 42.966669ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 43.057897ms)
Feb 17 17:02:00.261: INFO: (4) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 43.157535ms)
Feb 17 17:02:00.268: INFO: (4) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 50.081676ms)
Feb 17 17:02:00.274: INFO: (4) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 55.330064ms)
Feb 17 17:02:00.283: INFO: (4) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 65.175871ms)
Feb 17 17:02:00.289: INFO: (4) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 70.890593ms)
Feb 17 17:02:00.298: INFO: (4) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 79.348249ms)
Feb 17 17:02:00.298: INFO: (4) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 79.91471ms)
Feb 17 17:02:00.326: INFO: (5) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 27.47489ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 34.212233ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 34.381089ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 34.692033ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 34.557095ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 34.387736ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 34.510743ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 34.772833ms)
Feb 17 17:02:00.333: INFO: (5) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 34.49611ms)
Feb 17 17:02:00.342: INFO: (5) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 42.961962ms)
Feb 17 17:02:00.354: INFO: (5) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 56.222276ms)
Feb 17 17:02:00.361: INFO: (5) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 62.123989ms)
Feb 17 17:02:00.361: INFO: (5) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 62.446814ms)
Feb 17 17:02:00.361: INFO: (5) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 62.268454ms)
Feb 17 17:02:00.369: INFO: (5) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 69.81516ms)
Feb 17 17:02:00.377: INFO: (5) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 77.959163ms)
Feb 17 17:02:00.432: INFO: (6) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 54.909066ms)
Feb 17 17:02:00.435: INFO: (6) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 57.630147ms)
Feb 17 17:02:00.435: INFO: (6) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 57.92443ms)
Feb 17 17:02:00.452: INFO: (6) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 74.447681ms)
Feb 17 17:02:00.457: INFO: (6) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 79.915668ms)
Feb 17 17:02:00.457: INFO: (6) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 79.58671ms)
Feb 17 17:02:00.457: INFO: (6) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 79.747507ms)
Feb 17 17:02:00.461: INFO: (6) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 83.696715ms)
Feb 17 17:02:00.461: INFO: (6) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 83.707024ms)
Feb 17 17:02:00.461: INFO: (6) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 83.769495ms)
Feb 17 17:02:00.462: INFO: (6) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 84.17503ms)
Feb 17 17:02:00.462: INFO: (6) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 84.499606ms)
Feb 17 17:02:00.463: INFO: (6) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 85.313952ms)
Feb 17 17:02:00.473: INFO: (6) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 96.111995ms)
Feb 17 17:02:00.473: INFO: (6) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 96.088555ms)
Feb 17 17:02:00.473: INFO: (6) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 96.226243ms)
Feb 17 17:02:00.503: INFO: (7) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 28.994677ms)
Feb 17 17:02:00.503: INFO: (7) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 29.565462ms)
Feb 17 17:02:00.504: INFO: (7) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 30.349116ms)
Feb 17 17:02:00.504: INFO: (7) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 30.345525ms)
Feb 17 17:02:00.505: INFO: (7) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 31.311536ms)
Feb 17 17:02:00.505: INFO: (7) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 31.460867ms)
Feb 17 17:02:00.505: INFO: (7) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 31.560245ms)
Feb 17 17:02:00.510: INFO: (7) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 36.165305ms)
Feb 17 17:02:00.510: INFO: (7) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 36.368591ms)
Feb 17 17:02:00.510: INFO: (7) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 36.596034ms)
Feb 17 17:02:00.510: INFO: (7) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 36.547095ms)
Feb 17 17:02:00.519: INFO: (7) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 45.582133ms)
Feb 17 17:02:00.519: INFO: (7) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 45.662963ms)
Feb 17 17:02:00.519: INFO: (7) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 45.657898ms)
Feb 17 17:02:00.520: INFO: (7) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 45.972806ms)
Feb 17 17:02:00.522: INFO: (7) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 47.755971ms)
Feb 17 17:02:00.583: INFO: (8) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 61.743617ms)
Feb 17 17:02:00.586: INFO: (8) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 63.917277ms)
Feb 17 17:02:00.586: INFO: (8) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 63.849906ms)
Feb 17 17:02:00.593: INFO: (8) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 71.025108ms)
Feb 17 17:02:00.601: INFO: (8) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 79.562708ms)
Feb 17 17:02:00.601: INFO: (8) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 79.702494ms)
Feb 17 17:02:00.602: INFO: (8) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 79.608526ms)
Feb 17 17:02:00.602: INFO: (8) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 80.175461ms)
Feb 17 17:02:00.602: INFO: (8) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 80.29423ms)
Feb 17 17:02:00.602: INFO: (8) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 80.551728ms)
Feb 17 17:02:00.602: INFO: (8) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 80.363184ms)
Feb 17 17:02:00.625: INFO: (8) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 102.940055ms)
Feb 17 17:02:00.625: INFO: (8) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 102.886323ms)
Feb 17 17:02:00.625: INFO: (8) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 103.041397ms)
Feb 17 17:02:00.625: INFO: (8) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 103.243387ms)
Feb 17 17:02:00.625: INFO: (8) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 103.423042ms)
Feb 17 17:02:00.668: INFO: (9) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 42.591097ms)
Feb 17 17:02:00.669: INFO: (9) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 43.090111ms)
Feb 17 17:02:00.670: INFO: (9) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 43.302236ms)
Feb 17 17:02:00.676: INFO: (9) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 50.099417ms)
Feb 17 17:02:00.712: INFO: (9) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 86.064631ms)
Feb 17 17:02:00.712: INFO: (9) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 86.170804ms)
Feb 17 17:02:00.713: INFO: (9) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 87.545959ms)
Feb 17 17:02:00.713: INFO: (9) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 86.901469ms)
Feb 17 17:02:00.713: INFO: (9) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 86.516999ms)
Feb 17 17:02:00.713: INFO: (9) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 86.8616ms)
Feb 17 17:02:00.742: INFO: (9) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 115.969923ms)
Feb 17 17:02:00.742: INFO: (9) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 115.960937ms)
Feb 17 17:02:00.822: INFO: (9) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 195.479366ms)
Feb 17 17:02:00.822: INFO: (9) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 195.576618ms)
Feb 17 17:02:00.822: INFO: (9) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 195.445248ms)
Feb 17 17:02:00.881: INFO: (9) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 254.539476ms)
Feb 17 17:02:00.952: INFO: (10) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 71.225749ms)
Feb 17 17:02:00.953: INFO: (10) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 71.174491ms)
Feb 17 17:02:00.953: INFO: (10) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 71.183612ms)
Feb 17 17:02:00.953: INFO: (10) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 71.626691ms)
Feb 17 17:02:00.953: INFO: (10) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 71.364002ms)
Feb 17 17:02:00.953: INFO: (10) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 71.360439ms)
Feb 17 17:02:00.955: INFO: (10) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 74.24154ms)
Feb 17 17:02:00.969: INFO: (10) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 88.33397ms)
Feb 17 17:02:00.975: INFO: (10) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 93.328124ms)
Feb 17 17:02:00.984: INFO: (10) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 102.404303ms)
Feb 17 17:02:00.998: INFO: (10) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 116.434974ms)
Feb 17 17:02:00.998: INFO: (10) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 116.490195ms)
Feb 17 17:02:01.010: INFO: (10) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 128.94ms)
Feb 17 17:02:01.033: INFO: (10) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 151.252319ms)
Feb 17 17:02:01.041: INFO: (10) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 160.497669ms)
Feb 17 17:02:01.063: INFO: (10) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 181.826473ms)
Feb 17 17:02:01.114: INFO: (11) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 50.455715ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 93.841226ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 93.580353ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 93.765891ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 93.616038ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 94.083094ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 93.898223ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 94.164523ms)
Feb 17 17:02:01.157: INFO: (11) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 93.883315ms)
Feb 17 17:02:01.158: INFO: (11) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 94.351398ms)
Feb 17 17:02:01.158: INFO: (11) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 94.612896ms)
Feb 17 17:02:01.158: INFO: (11) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 95.143952ms)
Feb 17 17:02:01.165: INFO: (11) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 101.14161ms)
Feb 17 17:02:01.165: INFO: (11) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 101.584236ms)
Feb 17 17:02:01.167: INFO: (11) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 103.228462ms)
Feb 17 17:02:01.167: INFO: (11) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 102.917318ms)
Feb 17 17:02:01.204: INFO: (12) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 36.690298ms)
Feb 17 17:02:01.226: INFO: (12) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 59.180606ms)
Feb 17 17:02:01.227: INFO: (12) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 59.524112ms)
Feb 17 17:02:01.227: INFO: (12) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 59.30589ms)
Feb 17 17:02:01.227: INFO: (12) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 59.721269ms)
Feb 17 17:02:01.227: INFO: (12) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 60.005356ms)
Feb 17 17:02:01.229: INFO: (12) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 61.589038ms)
Feb 17 17:02:01.229: INFO: (12) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 61.792931ms)
Feb 17 17:02:01.229: INFO: (12) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 61.88547ms)
Feb 17 17:02:01.229: INFO: (12) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 61.67282ms)
Feb 17 17:02:01.238: INFO: (12) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 70.492253ms)
Feb 17 17:02:01.256: INFO: (12) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 89.459418ms)
Feb 17 17:02:01.275: INFO: (12) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 107.498542ms)
Feb 17 17:02:01.275: INFO: (12) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 107.439928ms)
Feb 17 17:02:01.275: INFO: (12) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 107.300906ms)
Feb 17 17:02:01.289: INFO: (12) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 122.096901ms)
Feb 17 17:02:01.364: INFO: (13) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 74.30862ms)
Feb 17 17:02:01.364: INFO: (13) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 74.815995ms)
Feb 17 17:02:01.365: INFO: (13) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 75.13779ms)
Feb 17 17:02:01.365: INFO: (13) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 75.391498ms)
Feb 17 17:02:01.365: INFO: (13) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 75.129755ms)
Feb 17 17:02:01.366: INFO: (13) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 75.588205ms)
Feb 17 17:02:01.375: INFO: (13) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 85.552058ms)
Feb 17 17:02:01.398: INFO: (13) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 107.483192ms)
Feb 17 17:02:01.415: INFO: (13) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 125.382468ms)
Feb 17 17:02:01.418: INFO: (13) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 127.769585ms)
Feb 17 17:02:01.418: INFO: (13) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 127.718439ms)
Feb 17 17:02:01.418: INFO: (13) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 127.818935ms)
Feb 17 17:02:01.418: INFO: (13) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 127.964236ms)
Feb 17 17:02:01.418: INFO: (13) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 127.580532ms)
Feb 17 17:02:01.441: INFO: (13) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 150.857651ms)
Feb 17 17:02:01.441: INFO: (13) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 151.602811ms)
Feb 17 17:02:01.506: INFO: (14) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 63.972681ms)
Feb 17 17:02:01.565: INFO: (14) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 123.391641ms)
Feb 17 17:02:01.565: INFO: (14) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 123.607544ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 167.533997ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 167.960885ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 167.813425ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 167.83012ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 167.781837ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 167.842335ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 167.942001ms)
Feb 17 17:02:01.609: INFO: (14) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 167.853469ms)
Feb 17 17:02:01.630: INFO: (14) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 188.475828ms)
Feb 17 17:02:01.630: INFO: (14) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 188.80237ms)
Feb 17 17:02:01.631: INFO: (14) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 189.031112ms)
Feb 17 17:02:01.631: INFO: (14) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 189.12594ms)
Feb 17 17:02:01.631: INFO: (14) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 189.241657ms)
Feb 17 17:02:01.693: INFO: (15) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 62.166422ms)
Feb 17 17:02:01.713: INFO: (15) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 81.552381ms)
Feb 17 17:02:01.713: INFO: (15) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 81.567622ms)
Feb 17 17:02:01.713: INFO: (15) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 81.838047ms)
Feb 17 17:02:01.713: INFO: (15) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 82.423704ms)
Feb 17 17:02:01.717: INFO: (15) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 85.694054ms)
Feb 17 17:02:01.720: INFO: (15) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 88.88399ms)
Feb 17 17:02:01.720: INFO: (15) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 89.013641ms)
Feb 17 17:02:01.732: INFO: (15) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 101.381354ms)
Feb 17 17:02:01.761: INFO: (15) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 130.014914ms)
Feb 17 17:02:01.761: INFO: (15) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 129.988165ms)
Feb 17 17:02:01.778: INFO: (15) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 147.052663ms)
Feb 17 17:02:01.781: INFO: (15) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 150.410909ms)
Feb 17 17:02:01.783: INFO: (15) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 151.572724ms)
Feb 17 17:02:01.783: INFO: (15) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 151.43259ms)
Feb 17 17:02:01.783: INFO: (15) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 152.192315ms)
Feb 17 17:02:01.846: INFO: (16) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 62.371223ms)
Feb 17 17:02:01.846: INFO: (16) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 62.660054ms)
Feb 17 17:02:01.846: INFO: (16) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 62.532119ms)
Feb 17 17:02:01.847: INFO: (16) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 63.426595ms)
Feb 17 17:02:01.848: INFO: (16) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 64.350798ms)
Feb 17 17:02:01.855: INFO: (16) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 70.970702ms)
Feb 17 17:02:01.883: INFO: (16) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 99.000106ms)
Feb 17 17:02:01.883: INFO: (16) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 99.1057ms)
Feb 17 17:02:01.883: INFO: (16) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 98.999437ms)
Feb 17 17:02:01.933: INFO: (16) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 149.650947ms)
Feb 17 17:02:01.934: INFO: (16) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 149.758051ms)
Feb 17 17:02:01.934: INFO: (16) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 149.965598ms)
Feb 17 17:02:01.962: INFO: (16) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 178.608363ms)
Feb 17 17:02:01.962: INFO: (16) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 178.669068ms)
Feb 17 17:02:01.962: INFO: (16) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 178.446681ms)
Feb 17 17:02:01.985: INFO: (16) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 201.514486ms)
Feb 17 17:02:02.061: INFO: (17) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 75.021744ms)
Feb 17 17:02:02.122: INFO: (17) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 136.519698ms)
Feb 17 17:02:02.123: INFO: (17) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 136.797259ms)
Feb 17 17:02:02.156: INFO: (17) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 170.462591ms)
Feb 17 17:02:02.156: INFO: (17) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 170.005875ms)
Feb 17 17:02:02.156: INFO: (17) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 170.470525ms)
Feb 17 17:02:02.156: INFO: (17) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 170.598638ms)
Feb 17 17:02:02.156: INFO: (17) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 170.610058ms)
Feb 17 17:02:02.157: INFO: (17) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 171.151443ms)
Feb 17 17:02:02.157: INFO: (17) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 170.854455ms)
Feb 17 17:02:02.157: INFO: (17) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 171.344539ms)
Feb 17 17:02:02.157: INFO: (17) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 170.828345ms)
Feb 17 17:02:02.203: INFO: (17) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 216.321258ms)
Feb 17 17:02:02.258: INFO: (17) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 272.289912ms)
Feb 17 17:02:02.258: INFO: (17) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 272.082182ms)
Feb 17 17:02:02.258: INFO: (17) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 271.533791ms)
Feb 17 17:02:02.309: INFO: (18) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 50.583413ms)
Feb 17 17:02:02.392: INFO: (18) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 133.575345ms)
Feb 17 17:02:02.392: INFO: (18) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 134.081852ms)
Feb 17 17:02:02.393: INFO: (18) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 134.391358ms)
Feb 17 17:02:02.393: INFO: (18) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 134.73818ms)
Feb 17 17:02:02.394: INFO: (18) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 135.482049ms)
Feb 17 17:02:02.394: INFO: (18) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 135.471116ms)
Feb 17 17:02:02.394: INFO: (18) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 136.067334ms)
Feb 17 17:02:02.394: INFO: (18) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 136.290678ms)
Feb 17 17:02:02.395: INFO: (18) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 137.413173ms)
Feb 17 17:02:02.398: INFO: (18) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 139.866743ms)
Feb 17 17:02:02.404: INFO: (18) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 146.345051ms)
Feb 17 17:02:02.417: INFO: (18) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 158.564927ms)
Feb 17 17:02:02.417: INFO: (18) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 158.353895ms)
Feb 17 17:02:02.417: INFO: (18) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 158.719574ms)
Feb 17 17:02:02.417: INFO: (18) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 158.434472ms)
Feb 17 17:02:02.475: INFO: (19) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:462/proxy/: tls qux (200; 57.767143ms)
Feb 17 17:02:02.501: INFO: (19) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:162/proxy/: bar (200; 83.85557ms)
Feb 17 17:02:02.501: INFO: (19) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:443/proxy/tlsrewritem... (200; 84.144707ms)
Feb 17 17:02:02.503: INFO: (19) /api/v1/namespaces/proxy-9156/pods/https:proxy-service-gppm7-7msr6:460/proxy/: tls baz (200; 86.309989ms)
Feb 17 17:02:02.504: INFO: (19) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6/proxy/rewriteme">test</a> (200; 86.548203ms)
Feb 17 17:02:02.507: INFO: (19) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname2/proxy/: tls qux (200; 90.258271ms)
Feb 17 17:02:02.514: INFO: (19) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname1/proxy/: foo (200; 96.337654ms)
Feb 17 17:02:02.514: INFO: (19) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:1080/proxy/rewriteme">... (200; 96.741053ms)
Feb 17 17:02:02.517: INFO: (19) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:162/proxy/: bar (200; 100.173529ms)
Feb 17 17:02:02.525: INFO: (19) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:160/proxy/: foo (200; 107.622118ms)
Feb 17 17:02:02.536: INFO: (19) /api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/: <a href="/api/v1/namespaces/proxy-9156/pods/proxy-service-gppm7-7msr6:1080/proxy/rewriteme">test<... (200; 118.78453ms)
Feb 17 17:02:02.557: INFO: (19) /api/v1/namespaces/proxy-9156/pods/http:proxy-service-gppm7-7msr6:160/proxy/: foo (200; 139.851505ms)
Feb 17 17:02:02.557: INFO: (19) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname2/proxy/: bar (200; 139.758523ms)
Feb 17 17:02:02.557: INFO: (19) /api/v1/namespaces/proxy-9156/services/proxy-service-gppm7:portname2/proxy/: bar (200; 139.819767ms)
Feb 17 17:02:02.557: INFO: (19) /api/v1/namespaces/proxy-9156/services/https:proxy-service-gppm7:tlsportname1/proxy/: tls baz (200; 140.034458ms)
Feb 17 17:02:02.558: INFO: (19) /api/v1/namespaces/proxy-9156/services/http:proxy-service-gppm7:portname1/proxy/: foo (200; 140.471676ms)
STEP: deleting ReplicationController proxy-service-gppm7 in namespace proxy-9156, will wait for the garbage collector to delete the pods
Feb 17 17:02:02.708: INFO: Deleting ReplicationController proxy-service-gppm7 took: 68.667885ms
Feb 17 17:02:02.908: INFO: Terminating ReplicationController proxy-service-gppm7 pods took: 200.235162ms
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:02:09.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9156" for this suite.
Feb 17 17:02:17.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:02:18.303: INFO: namespace proxy-9156 deletion completed in 8.765341554s

• [SLOW TEST:29.815 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:02:18.306: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 17 17:02:18.636: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:02:18.725: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:02:18.752: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.130 before test
Feb 17 17:02:18.958: INFO: coredns-autoscaler-65c89858bf-df7mx from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.959: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:02:18.959: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:18.959: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:02:18.959: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:02:18.959: INFO: ibm-keepalived-watcher-qgfgw from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.959: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:02:18.959: INFO: calico-node-nrkf6 from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.959: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:02:18.960: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 from ibm-system started at 2020-02-17 14:49:07 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.960: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:02:18.960: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:03:08 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.960: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 17:02:18.960: INFO: coredns-bc786c74-624xw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.960: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:02:18.960: INFO: ibm-master-proxy-static-10.241.69.130 from kube-system started at 2020-02-17 14:48:46 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:18.960: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:02:18.960: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:02:18.960: INFO: coredns-bc786c74-79vl2 from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.960: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:02:18.961: INFO: dashboard-metrics-scraper-5cbd6549b8-r5tv4 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.961: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Feb 17 17:02:18.961: INFO: ibm-storage-watcher-799f6c5b69-zhj9j from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.961: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb 17 17:02:18.961: INFO: calico-kube-controllers-598ddbf99d-vhtrf from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.961: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:02:18.961: INFO: olm-operator-7bf4dbc978-4rx8l from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:18.961: INFO: 	Container olm-operator ready: true, restart count 0
Feb 17 17:02:18.961: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 from kube-system started at 2020-02-17 14:49:07 +0000 UTC (4 container statuses recorded)
Feb 17 17:02:18.961: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:02:18.961: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:02:18.962: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:02:18.962: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:02:18.962: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.147 before test
Feb 17 17:02:19.008: INFO: ibm-master-proxy-static-10.241.69.147 from kube-system started at 2020-02-17 14:40:19 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.008: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:02:19.008: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:02:19.008: INFO: ibm-keepalived-watcher-rh8sm from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.008: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:02:19.008: INFO: calico-node-4vlb4 from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.008: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:02:19.008: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.008: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:02:19.008: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:02:19.008: INFO: addon-catalog-source-bqjh8 from ibm-system started at 2020-02-17 14:44:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.008: INFO: 	Container configmap-registry-server ready: true, restart count 0
Feb 17 17:02:19.008: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.151 before test
Feb 17 17:02:19.148: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:52:12 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:02:19.148: INFO: ibm-keepalived-watcher-4n299 from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:02:19.148: INFO: catalog-operator-6d6c965db-dxspz from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container catalog-operator ready: true, restart count 0
Feb 17 17:02:19.148: INFO: ibm-master-proxy-static-10.241.69.151 from kube-system started at 2020-02-17 14:50:33 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:02:19.148: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-2hx9m from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:02:19.148: INFO: ibm-file-plugin-5568fbb4d7-8vzx9 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb 17 17:02:19.148: INFO: vpn-79845b6f9d-zgk7f from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:02:19.148: INFO: kubernetes-dashboard-6dbd4db8bf-sjswh from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:02:19.148: INFO: calico-node-nr68s from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:02:19.148: INFO: sonobuoy-e2e-job-ae741cd10f3545c2 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:02:19.148: INFO: metrics-server-5bf499b69-9cwsk from kube-system started at 2020-02-17 16:20:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:02:19.148: INFO: coredns-bc786c74-x59lf from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:02:19.148: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:02:19.148: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-ml8mw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (4 container statuses recorded)
Feb 17 17:02:19.148: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:02:19.148: INFO: 	Container nginx-ingress ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-e0d49b62-a61d-4f58-9328-1cbdb52494ca 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-e0d49b62-a61d-4f58-9328-1cbdb52494ca off the node 10.241.69.147
STEP: verifying the node doesn't have the label kubernetes.io/e2e-e0d49b62-a61d-4f58-9328-1cbdb52494ca
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:07:23.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1237" for this suite.
Feb 17 17:07:41.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:07:42.280: INFO: namespace sched-pred-1237 deletion completed in 18.616792008s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:323.974 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:07:42.280: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5839
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:07:44.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5839" for this suite.
Feb 17 17:08:30.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:08:31.490: INFO: namespace kubelet-test-5839 deletion completed in 46.68392366s

• [SLOW TEST:49.209 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:08:31.491: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9517
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Feb 17 17:08:31.787: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Feb 17 17:08:31.787: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:32.308: INFO: stderr: ""
Feb 17 17:08:32.308: INFO: stdout: "service/redis-slave created\n"
Feb 17 17:08:32.308: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Feb 17 17:08:32.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:32.735: INFO: stderr: ""
Feb 17 17:08:32.735: INFO: stdout: "service/redis-master created\n"
Feb 17 17:08:32.735: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Feb 17 17:08:32.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:32.994: INFO: stderr: ""
Feb 17 17:08:32.994: INFO: stdout: "service/frontend created\n"
Feb 17 17:08:32.994: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Feb 17 17:08:32.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:33.231: INFO: stderr: ""
Feb 17 17:08:33.231: INFO: stdout: "deployment.apps/frontend created\n"
Feb 17 17:08:33.231: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Feb 17 17:08:33.231: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:33.457: INFO: stderr: ""
Feb 17 17:08:33.457: INFO: stdout: "deployment.apps/redis-master created\n"
Feb 17 17:08:33.457: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Feb 17 17:08:33.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9517'
Feb 17 17:08:33.893: INFO: stderr: ""
Feb 17 17:08:33.893: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Feb 17 17:08:33.893: INFO: Waiting for all frontend pods to be Running.
Feb 17 17:08:48.944: INFO: Waiting for frontend to serve content.
Feb 17 17:08:49.003: INFO: Trying to add a new entry to the guestbook.
Feb 17 17:08:54.058: INFO: Failed to get response from guestbook. err: <nil>, response: <br />
<b>Fatal error</b>:  Uncaught exception 'Predis\Connection\ConnectionException' with message 'Connection timed out [tcp://redis-master:6379]' in /usr/local/lib/php/Predis/Connection/AbstractConnection.php:155
Stack trace:
#0 /usr/local/lib/php/Predis/Connection/StreamConnection.php(128): Predis\Connection\AbstractConnection-&gt;onConnectionError('Connection time...', 110)
#1 /usr/local/lib/php/Predis/Connection/StreamConnection.php(178): Predis\Connection\StreamConnection-&gt;createStreamSocket(Object(Predis\Connection\Parameters), 'tcp://redis-mas...', 4)
#2 /usr/local/lib/php/Predis/Connection/StreamConnection.php(100): Predis\Connection\StreamConnection-&gt;tcpStreamInitializer(Object(Predis\Connection\Parameters))
#3 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(81): Predis\Connection\StreamConnection-&gt;createResource()
#4 /usr/local/lib/php/Predis/Connection/StreamConnection.php(258): Predis\Connection\AbstractConnection-&gt;connect()
#5 /usr/local/lib/php/Predis/Connection/AbstractConnection.php(180): Predis\Connection\Str in <b>/usr/local/lib/php/Predis/Connection/AbstractConnection.php</b> on line <b>155</b><br />

Feb 17 17:08:59.113: INFO: Verifying that added entry can be retrieved.
Feb 17 17:08:59.158: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:04.243: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:09.324: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:14.402: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:19.466: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:24.522: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:29.605: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:34.661: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:39.738: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Feb 17 17:09:44.824: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Feb 17 17:09:49.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:50.152: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:50.152: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:09:50.153: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:50.411: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:50.411: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:09:50.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:50.659: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:50.659: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:09:50.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:50.851: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:50.851: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:09:50.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:51.035: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:51.035: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Feb 17 17:09:51.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-9517'
Feb 17 17:09:51.210: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:09:51.210: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:09:51.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9517" for this suite.
Feb 17 17:10:05.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:10:06.334: INFO: namespace kubectl-9517 deletion completed in 15.099872552s

• [SLOW TEST:94.843 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:10:06.335: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Feb 17 17:10:11.906: INFO: Successfully updated pod "adopt-release-22r6z"
STEP: Checking that the Job readopts the Pod
Feb 17 17:10:11.906: INFO: Waiting up to 15m0s for pod "adopt-release-22r6z" in namespace "job-1907" to be "adopted"
Feb 17 17:10:11.923: INFO: Pod "adopt-release-22r6z": Phase="Running", Reason="", readiness=true. Elapsed: 16.853914ms
Feb 17 17:10:13.944: INFO: Pod "adopt-release-22r6z": Phase="Running", Reason="", readiness=true. Elapsed: 2.03778083s
Feb 17 17:10:13.944: INFO: Pod "adopt-release-22r6z" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Feb 17 17:10:14.484: INFO: Successfully updated pod "adopt-release-22r6z"
STEP: Checking that the Job releases the Pod
Feb 17 17:10:14.484: INFO: Waiting up to 15m0s for pod "adopt-release-22r6z" in namespace "job-1907" to be "released"
Feb 17 17:10:14.517: INFO: Pod "adopt-release-22r6z": Phase="Running", Reason="", readiness=true. Elapsed: 32.430202ms
Feb 17 17:10:14.517: INFO: Pod "adopt-release-22r6z" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:10:14.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1907" for this suite.
Feb 17 17:11:02.695: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:03.688: INFO: namespace job-1907 deletion completed in 49.082389048s

• [SLOW TEST:57.353 seconds]
[sig-apps] Job
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:11:03.688: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8755
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:11:04.124: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc" in namespace "downward-api-8755" to be "success or failure"
Feb 17 17:11:04.178: INFO: Pod "downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc": Phase="Pending", Reason="", readiness=false. Elapsed: 54.20944ms
Feb 17 17:11:06.201: INFO: Pod "downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.077432896s
STEP: Saw pod success
Feb 17 17:11:06.201: INFO: Pod "downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc" satisfied condition "success or failure"
Feb 17 17:11:06.230: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc container client-container: <nil>
STEP: delete the pod
Feb 17 17:11:06.695: INFO: Waiting for pod downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc to disappear
Feb 17 17:11:06.738: INFO: Pod downwardapi-volume-fe96d6b9-6cf1-4eda-8f8c-52fcd02015bc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:11:06.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8755" for this suite.
Feb 17 17:11:14.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:15.582: INFO: namespace downward-api-8755 deletion completed in 8.809811851s

• [SLOW TEST:11.894 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:11:15.582: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9142
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:11:15.916: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04" in namespace "projected-9142" to be "success or failure"
Feb 17 17:11:15.950: INFO: Pod "downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04": Phase="Pending", Reason="", readiness=false. Elapsed: 34.611779ms
Feb 17 17:11:17.964: INFO: Pod "downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048160413s
Feb 17 17:11:19.984: INFO: Pod "downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068685877s
STEP: Saw pod success
Feb 17 17:11:19.985: INFO: Pod "downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04" satisfied condition "success or failure"
Feb 17 17:11:19.998: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04 container client-container: <nil>
STEP: delete the pod
Feb 17 17:11:20.096: INFO: Waiting for pod downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04 to disappear
Feb 17 17:11:20.109: INFO: Pod downwardapi-volume-6452b40e-89fe-4a4d-b7c4-7b3f1d40ea04 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:11:20.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9142" for this suite.
Feb 17 17:11:28.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:28.827: INFO: namespace projected-9142 deletion completed in 8.695916642s

• [SLOW TEST:13.245 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:11:28.828: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3713
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:11:29.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c" in namespace "projected-3713" to be "success or failure"
Feb 17 17:11:29.177: INFO: Pod "downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c": Phase="Pending", Reason="", readiness=false. Elapsed: 25.556971ms
Feb 17 17:11:31.196: INFO: Pod "downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044029336s
STEP: Saw pod success
Feb 17 17:11:31.196: INFO: Pod "downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c" satisfied condition "success or failure"
Feb 17 17:11:31.212: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c container client-container: <nil>
STEP: delete the pod
Feb 17 17:11:31.295: INFO: Waiting for pod downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c to disappear
Feb 17 17:11:31.311: INFO: Pod downwardapi-volume-41925778-5d9a-43e6-84ec-29876af5b21c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:11:31.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3713" for this suite.
Feb 17 17:11:39.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:11:39.996: INFO: namespace projected-3713 deletion completed in 8.665772985s

• [SLOW TEST:11.169 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:11:39.997: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:11:40.547: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 17:11:40.619: INFO: Number of nodes with available pods: 0
Feb 17 17:11:40.619: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:11:41.661: INFO: Number of nodes with available pods: 0
Feb 17 17:11:41.661: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:11:42.655: INFO: Number of nodes with available pods: 2
Feb 17 17:11:42.655: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:11:43.659: INFO: Number of nodes with available pods: 3
Feb 17 17:11:43.659: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Feb 17 17:11:43.801: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:43.801: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:43.801: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:44.837: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:44.837: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:44.837: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:45.834: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:45.834: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:45.834: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:45.834: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:46.837: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:46.838: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:46.838: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:46.838: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:47.842: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:47.842: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:47.842: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:47.842: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:48.840: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:48.840: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:48.840: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:48.840: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:49.832: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:49.832: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:49.832: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:49.832: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:50.835: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:50.835: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:50.835: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:50.835: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:51.840: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:51.840: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:51.840: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:51.840: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:52.835: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:52.835: INFO: Wrong image for pod: daemon-set-9wgdd. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:52.835: INFO: Pod daemon-set-9wgdd is not available
Feb 17 17:11:52.835: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:53.838: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:53.838: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:53.838: INFO: Pod daemon-set-w7s8r is not available
Feb 17 17:11:54.834: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:54.835: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:54.835: INFO: Pod daemon-set-w7s8r is not available
Feb 17 17:11:55.838: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:55.838: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:56.839: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:56.839: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:57.839: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:57.839: INFO: Pod daemon-set-7256v is not available
Feb 17 17:11:57.839: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:58.842: INFO: Wrong image for pod: daemon-set-7256v. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:58.842: INFO: Pod daemon-set-7256v is not available
Feb 17 17:11:58.842: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:11:59.842: INFO: Pod daemon-set-bh7v7 is not available
Feb 17 17:11:59.842: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:00.839: INFO: Pod daemon-set-bh7v7 is not available
Feb 17 17:12:00.839: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:01.845: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:01.845: INFO: Pod daemon-set-rd7fq is not available
Feb 17 17:12:02.846: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:02.846: INFO: Pod daemon-set-rd7fq is not available
Feb 17 17:12:03.852: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:03.852: INFO: Pod daemon-set-rd7fq is not available
Feb 17 17:12:04.843: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:04.843: INFO: Pod daemon-set-rd7fq is not available
Feb 17 17:12:05.843: INFO: Wrong image for pod: daemon-set-rd7fq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Feb 17 17:12:05.843: INFO: Pod daemon-set-rd7fq is not available
Feb 17 17:12:06.843: INFO: Pod daemon-set-m2j2k is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Feb 17 17:12:06.924: INFO: Number of nodes with available pods: 2
Feb 17 17:12:06.924: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:12:07.975: INFO: Number of nodes with available pods: 2
Feb 17 17:12:07.975: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:12:08.988: INFO: Number of nodes with available pods: 3
Feb 17 17:12:08.989: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8683, will wait for the garbage collector to delete the pods
Feb 17 17:12:09.248: INFO: Deleting DaemonSet.extensions daemon-set took: 46.225072ms
Feb 17 17:12:09.548: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.39717ms
Feb 17 17:12:19.572: INFO: Number of nodes with available pods: 0
Feb 17 17:12:19.572: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 17:12:19.594: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8683/daemonsets","resourceVersion":"31506"},"items":null}

Feb 17 17:12:19.616: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8683/pods","resourceVersion":"31506"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:12:19.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8683" for this suite.
Feb 17 17:12:27.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:12:28.690: INFO: namespace daemonsets-8683 deletion completed in 8.954415122s

• [SLOW TEST:48.693 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:12:28.690: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-874aec9b-7dbb-40e1-950a-cfa20abd5159
STEP: Creating a pod to test consume configMaps
Feb 17 17:12:29.064: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5" in namespace "projected-3677" to be "success or failure"
Feb 17 17:12:29.081: INFO: Pod "pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 16.944778ms
Feb 17 17:12:31.100: INFO: Pod "pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03545097s
Feb 17 17:12:33.131: INFO: Pod "pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066485738s
STEP: Saw pod success
Feb 17 17:12:33.131: INFO: Pod "pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5" satisfied condition "success or failure"
Feb 17 17:12:33.150: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:12:33.258: INFO: Waiting for pod pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5 to disappear
Feb 17 17:12:33.271: INFO: Pod pod-projected-configmaps-484ecc84-1ab0-4c68-9327-72c604c66eb5 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:12:33.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3677" for this suite.
Feb 17 17:12:41.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:12:41.963: INFO: namespace projected-3677 deletion completed in 8.672078695s

• [SLOW TEST:13.273 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:12:41.963: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-298
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 17 17:12:42.255: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:12:46.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-298" for this suite.
Feb 17 17:12:54.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:12:54.843: INFO: namespace init-container-298 deletion completed in 8.648016322s

• [SLOW TEST:12.880 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:12:54.843: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1587
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:12:55.154: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-166076b6-5a45-4866-98e6-0baf2d80555b" in namespace "security-context-test-1587" to be "success or failure"
Feb 17 17:12:55.166: INFO: Pod "busybox-readonly-false-166076b6-5a45-4866-98e6-0baf2d80555b": Phase="Pending", Reason="", readiness=false. Elapsed: 12.757881ms
Feb 17 17:12:57.193: INFO: Pod "busybox-readonly-false-166076b6-5a45-4866-98e6-0baf2d80555b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039352482s
Feb 17 17:12:59.208: INFO: Pod "busybox-readonly-false-166076b6-5a45-4866-98e6-0baf2d80555b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054161258s
Feb 17 17:12:59.208: INFO: Pod "busybox-readonly-false-166076b6-5a45-4866-98e6-0baf2d80555b" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:12:59.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1587" for this suite.
Feb 17 17:13:07.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:13:08.262: INFO: namespace security-context-test-1587 deletion completed in 9.033290541s

• [SLOW TEST:13.419 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:13:08.264: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 17 17:13:08.587: INFO: PodSpec: initContainers in spec.initContainers
Feb 17 17:13:50.298: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-5d3426b0-832d-4f90-b911-dcb7ce5c773b", GenerateName:"", Namespace:"init-container-8325", SelfLink:"/api/v1/namespaces/init-container-8325/pods/pod-init-5d3426b0-832d-4f90-b911-dcb7ce5c773b", UID:"085e9973-0c01-4dcc-9d6b-46deb648183b", ResourceVersion:"31833", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63717556388, loc:(*time.Location)(0x788c6e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"587590293"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-t549h", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc001caa080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t549h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t549h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-t549h", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003bfc0a8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.241.69.147", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002ace000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003bfc130)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003bfc150)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003bfc158), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003bfc15c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717556388, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717556388, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717556388, loc:(*time.Location)(0x788c6e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717556388, loc:(*time.Location)(0x788c6e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.241.69.147", PodIP:"172.30.84.33", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.30.84.33"}}, StartTime:(*v1.Time)(0xc004352060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000d32230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000d322a0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"containerd://995a788e9ed4fbfcb6b48980967f703e15635c2a0e61fc1a8942a4ca1b33d6a2", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0043520a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc004352080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003bfc1df)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:13:50.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8325" for this suite.
Feb 17 17:14:04.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:14:05.241: INFO: namespace init-container-8325 deletion completed in 14.916873998s

• [SLOW TEST:56.976 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:14:05.241: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-8002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Feb 17 17:14:05.677: INFO: Waiting up to 1m0s for all nodes to be ready
Feb 17 17:15:05.758: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:15:05.772: INFO: Starting informer...
STEP: Starting pods...
Feb 17 17:15:05.907: INFO: Pod1 is running on 10.241.69.147. Tainting Node
Feb 17 17:15:10.272: INFO: Pod2 is running on 10.241.69.147. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Feb 17 17:15:17.517: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Feb 17 17:15:37.537: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:15:37.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8002" for this suite.
Feb 17 17:15:45.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:15:46.238: INFO: namespace taint-multiple-pods-8002 deletion completed in 8.613779844s

• [SLOW TEST:100.997 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:15:46.240: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-789
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Feb 17 17:15:48.841: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec pod-sharedvolume-5ed50b2e-6e13-452f-abdf-8b63006d4c1c -c busybox-main-container --namespace=emptydir-789 -- cat /usr/share/volumeshare/shareddata.txt'
Feb 17 17:15:49.231: INFO: stderr: ""
Feb 17 17:15:49.232: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:15:49.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-789" for this suite.
Feb 17 17:15:57.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:15:57.863: INFO: namespace emptydir-789 deletion completed in 8.607994627s

• [SLOW TEST:11.624 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:15:57.864: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7860
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Feb 17 17:15:58.858: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 17:15:58.858274      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:15:58.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7860" for this suite.
Feb 17 17:16:06.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:08.049: INFO: namespace gc-7860 deletion completed in 9.17564652s

• [SLOW TEST:10.186 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:16:08.051: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9117
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-2cf298a2-680a-4334-8579-cb4b26b175ad
STEP: Creating a pod to test consume secrets
Feb 17 17:16:08.501: INFO: Waiting up to 5m0s for pod "pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b" in namespace "secrets-9117" to be "success or failure"
Feb 17 17:16:08.527: INFO: Pod "pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 25.766825ms
Feb 17 17:16:10.553: INFO: Pod "pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.051963626s
Feb 17 17:16:12.578: INFO: Pod "pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.077431121s
STEP: Saw pod success
Feb 17 17:16:12.578: INFO: Pod "pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b" satisfied condition "success or failure"
Feb 17 17:16:12.604: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:16:12.779: INFO: Waiting for pod pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b to disappear
Feb 17 17:16:12.794: INFO: Pod pod-secrets-fb9e5b78-9684-490e-8b3a-70b810883f9b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:16:12.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9117" for this suite.
Feb 17 17:16:20.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:21.492: INFO: namespace secrets-9117 deletion completed in 8.672843919s

• [SLOW TEST:13.441 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:16:21.492: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 17 17:16:24.516: INFO: Successfully updated pod "annotationupdatef1d692cd-085a-4b65-a35a-541765a0e45b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:16:26.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-171" for this suite.
Feb 17 17:16:40.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:16:41.307: INFO: namespace projected-171 deletion completed in 14.689106573s

• [SLOW TEST:19.815 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:16:41.311: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9263
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9263
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9263
STEP: creating replication controller externalsvc in namespace services-9263
I0217 17:16:41.718285      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9263, replica count: 2
I0217 17:16:44.768923      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Feb 17 17:16:44.850: INFO: Creating new exec pod
Feb 17 17:16:46.934: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-9263 execpodnwn7b -- /bin/sh -x -c nslookup clusterip-service'
Feb 17 17:16:47.324: INFO: stderr: "+ nslookup clusterip-service\n"
Feb 17 17:16:47.324: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nclusterip-service.services-9263.svc.cluster.local\tcanonical name = externalsvc.services-9263.svc.cluster.local.\nName:\texternalsvc.services-9263.svc.cluster.local\nAddress: 172.21.224.84\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9263, will wait for the garbage collector to delete the pods
Feb 17 17:16:47.423: INFO: Deleting ReplicationController externalsvc took: 30.62789ms
Feb 17 17:16:47.623: INFO: Terminating ReplicationController externalsvc pods took: 200.262115ms
Feb 17 17:16:56.647: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:16:56.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9263" for this suite.
Feb 17 17:17:04.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:17:05.772: INFO: namespace services-9263 deletion completed in 8.982705773s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:24.462 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:17:05.773: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 17 17:17:08.844: INFO: Successfully updated pod "labelsupdate17d8788e-8e8c-4074-ae56-f495b12113c8"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:17:13.055: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9974" for this suite.
Feb 17 17:17:31.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:17:31.757: INFO: namespace projected-9974 deletion completed in 18.673831469s

• [SLOW TEST:25.985 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:17:31.758: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9331
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:17:32.065: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9331'
Feb 17 17:17:32.299: INFO: stderr: ""
Feb 17 17:17:32.299: INFO: stdout: "replicationcontroller/redis-master created\n"
Feb 17 17:17:32.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-9331'
Feb 17 17:17:32.824: INFO: stderr: ""
Feb 17 17:17:32.824: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 17:17:33.849: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:17:33.849: INFO: Found 0 / 1
Feb 17 17:17:34.842: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:17:34.842: INFO: Found 1 / 1
Feb 17 17:17:34.842: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Feb 17 17:17:34.860: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:17:34.860: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 17:17:34.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 describe pod redis-master-pzvvd --namespace=kubectl-9331'
Feb 17 17:17:35.057: INFO: stderr: ""
Feb 17 17:17:35.057: INFO: stdout: "Name:         redis-master-pzvvd\nNamespace:    kubectl-9331\nPriority:     0\nNode:         10.241.69.147/10.241.69.147\nStart Time:   Mon, 17 Feb 2020 17:17:32 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           172.30.84.41\nIPs:\n  IP:           172.30.84.41\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   containerd://16b7c28f6e6d6278e5475cb685ad314a589536d3235ea46ec20d637446fb468c\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 17 Feb 2020 17:17:33 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-94n4w (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-94n4w:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-94n4w\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 600s\n                 node.kubernetes.io/unreachable:NoExecute for 600s\nEvents:\n  Type    Reason     Age   From                    Message\n  ----    ------     ----  ----                    -------\n  Normal  Scheduled  3s    default-scheduler       Successfully assigned kubectl-9331/redis-master-pzvvd to 10.241.69.147\n  Normal  Pulled     2s    kubelet, 10.241.69.147  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s    kubelet, 10.241.69.147  Created container redis-master\n  Normal  Started    2s    kubelet, 10.241.69.147  Started container redis-master\n"
Feb 17 17:17:35.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 describe rc redis-master --namespace=kubectl-9331'
Feb 17 17:17:35.250: INFO: stderr: ""
Feb 17 17:17:35.250: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9331\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-pzvvd\n"
Feb 17 17:17:35.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 describe service redis-master --namespace=kubectl-9331'
Feb 17 17:17:35.463: INFO: stderr: ""
Feb 17 17:17:35.463: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9331\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                172.21.15.150\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.30.84.41:6379\nSession Affinity:  None\nEvents:            <none>\n"
Feb 17 17:17:35.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 describe node 10.241.69.130'
Feb 17 17:17:35.761: INFO: stderr: ""
Feb 17 17:17:35.761: INFO: stdout: "Name:               10.241.69.130\nRoles:              <none>\nLabels:             arch=amd64\n                    beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=b3c.4x16.encrypted\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=us-south\n                    failure-domain.beta.kubernetes.io/zone=dal12\n                    ibm-cloud.kubernetes.io/encrypted-docker-data=true\n                    ibm-cloud.kubernetes.io/external-ip=169.63.36.186\n                    ibm-cloud.kubernetes.io/ha-worker=true\n                    ibm-cloud.kubernetes.io/iaas-provider=softlayer\n                    ibm-cloud.kubernetes.io/internal-ip=10.241.69.130\n                    ibm-cloud.kubernetes.io/machine-type=b3c.4x16.encrypted\n                    ibm-cloud.kubernetes.io/os=UBUNTU_18_64\n                    ibm-cloud.kubernetes.io/region=us-south\n                    ibm-cloud.kubernetes.io/sgx-enabled=false\n                    ibm-cloud.kubernetes.io/worker-id=kube-bp5a39ad0nomcat41hp0-kubee2epvgo-default-0000015b\n                    ibm-cloud.kubernetes.io/worker-pool-id=bp5a39ad0nomcat41hp0-941a8a4\n                    ibm-cloud.kubernetes.io/worker-pool-name=default\n                    ibm-cloud.kubernetes.io/worker-version=1.16.5_1523\n                    ibm-cloud.kubernetes.io/zone=dal12\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.241.69.130\n                    kubernetes.io/os=linux\n                    privateVLAN=2722938\n                    publicVLAN=2722936\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 17 Feb 2020 14:48:47 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 17 Feb 2020 17:16:51 +0000   Mon, 17 Feb 2020 14:48:47 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 17 Feb 2020 17:16:51 +0000   Mon, 17 Feb 2020 14:48:47 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 17 Feb 2020 17:16:51 +0000   Mon, 17 Feb 2020 14:48:47 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 17 Feb 2020 17:16:51 +0000   Mon, 17 Feb 2020 14:48:58 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.241.69.130\n  ExternalIP:  169.63.36.186\n  Hostname:    10.241.69.130\nCapacity:\n cpu:                4\n ephemeral-storage:  102685624Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16419700Ki\n pods:               110\nAllocatable:\n cpu:                3910m\n ephemeral-storage:  99892574949\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13627252Ki\n pods:               110\nSystem Info:\n Machine ID:                 2c621d7b248049289fb15a2426f0f4f6\n System UUID:                A7524053-39AF-9BDE-04C5-4B69A48AFA51\n Boot ID:                    37954293-06ce-4500-9f9e-a23727e11cbe\n Kernel Version:             4.15.0-76-generic\n OS Image:                   Ubuntu 18.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  containerd://1.3.2\n Kubelet Version:            v1.16.5+IKS\n Kube-Proxy Version:         v1.16.5+IKS\nProviderID:                  ibm://fee034388aa6435883a1f720010ab3a2///bp5a39ad0nomcat41hp0/kube-bp5a39ad0nomcat41hp0-kubee2epvgo-default-0000015b\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  ibm-system                 ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8      5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         154m\n  ibm-system                 olm-operator-7bf4dbc978-4rx8l                              10m (0%)      0 (0%)      160Mi (1%)       0 (0%)         57m\n  kube-system                calico-kube-controllers-598ddbf99d-vhtrf                   10m (0%)      0 (0%)      25Mi (0%)        3Gi (23%)      57m\n  kube-system                calico-node-nrkf6                                          250m (6%)     0 (0%)      80Mi (0%)        0 (0%)         148m\n  kube-system                coredns-autoscaler-65c89858bf-df7mx                        20m (0%)      0 (0%)      10Mi (0%)        0 (0%)         57m\n  kube-system                coredns-bc786c74-624xw                                     100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     57m\n  kube-system                coredns-bc786c74-79vl2                                     100m (2%)     0 (0%)      70Mi (0%)        400Mi (3%)     140m\n  kube-system                dashboard-metrics-scraper-5cbd6549b8-r5tv4                 1m (0%)       0 (0%)      10Mi (0%)        0 (0%)         57m\n  kube-system                ibm-keepalived-watcher-qgfgw                               5m (0%)       0 (0%)      10Mi (0%)        0 (0%)         148m\n  kube-system                ibm-master-proxy-static-10.241.69.130                      25m (0%)      300m (7%)   32M (0%)         512M (3%)      148m\n  kube-system                ibm-storage-watcher-799f6c5b69-zhj9j                       50m (1%)      200m (5%)   100Mi (0%)       0 (0%)         57m\n  kube-system                public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6        10m (0%)      0 (0%)      100Mi (0%)       0 (0%)         153m\n  sonobuoy                   sonobuoy                                                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         74m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb    0 (0%)        0 (0%)      0 (0%)           0 (0%)         74m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests       Limits\n  --------           --------       ------\n  cpu                586m (14%)     500m (12%)\n  memory             691730Ki (5%)  4464928Ki (32%)\n  ephemeral-storage  0 (0%)         0 (0%)\nEvents:              <none>\n"
Feb 17 17:17:35.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 describe namespace kubectl-9331'
Feb 17 17:17:35.931: INFO: stderr: ""
Feb 17 17:17:35.931: INFO: stdout: "Name:         kubectl-9331\nLabels:       e2e-framework=kubectl\n              e2e-run=9ed24eed-badd-482a-9326-08f836c65933\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:17:35.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9331" for this suite.
Feb 17 17:17:50.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:17:50.685: INFO: namespace kubectl-9331 deletion completed in 14.730495634s

• [SLOW TEST:18.928 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:17:50.686: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8133
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8133/configmap-test-cb0e3049-b245-4c3c-8ab6-679180a78415
STEP: Creating a pod to test consume configMaps
Feb 17 17:17:51.056: INFO: Waiting up to 5m0s for pod "pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3" in namespace "configmap-8133" to be "success or failure"
Feb 17 17:17:51.079: INFO: Pod "pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3": Phase="Pending", Reason="", readiness=false. Elapsed: 22.308486ms
Feb 17 17:17:53.094: INFO: Pod "pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.038214046s
STEP: Saw pod success
Feb 17 17:17:53.094: INFO: Pod "pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3" satisfied condition "success or failure"
Feb 17 17:17:53.117: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3 container env-test: <nil>
STEP: delete the pod
Feb 17 17:17:53.196: INFO: Waiting for pod pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3 to disappear
Feb 17 17:17:53.212: INFO: Pod pod-configmaps-a75b6fec-a5e5-4201-97b6-226ba05b72a3 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:17:53.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8133" for this suite.
Feb 17 17:18:01.317: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:02.218: INFO: namespace configmap-8133 deletion completed in 8.984826282s

• [SLOW TEST:11.532 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:18:02.218: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2055
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:18:02.607: INFO: Creating deployment "webserver-deployment"
Feb 17 17:18:02.632: INFO: Waiting for observed generation 1
Feb 17 17:18:04.698: INFO: Waiting for all required pods to come up
Feb 17 17:18:04.727: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Feb 17 17:18:06.862: INFO: Waiting for deployment "webserver-deployment" to complete
Feb 17 17:18:06.897: INFO: Updating deployment "webserver-deployment" with a non-existent image
Feb 17 17:18:06.932: INFO: Updating deployment webserver-deployment
Feb 17 17:18:06.932: INFO: Waiting for observed generation 2
Feb 17 17:18:08.972: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Feb 17 17:18:09.004: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Feb 17 17:18:09.021: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 17 17:18:09.094: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Feb 17 17:18:09.094: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Feb 17 17:18:09.115: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Feb 17 17:18:09.155: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Feb 17 17:18:09.155: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Feb 17 17:18:09.269: INFO: Updating deployment webserver-deployment
Feb 17 17:18:09.269: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Feb 17 17:18:09.342: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Feb 17 17:18:11.423: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 17 17:18:11.509: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-2055 /apis/apps/v1/namespaces/deployment-2055/deployments/webserver-deployment 3b337b99-ddaf-495d-9359-ed9db6a7bae2 33126 3 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000610f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:10,UnavailableReplicas:23,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-17 17:18:09 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-02-17 17:18:11 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,},},ReadyReplicas:10,CollisionCount:nil,},}

Feb 17 17:18:11.547: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-2055 /apis/apps/v1/namespaces/deployment-2055/replicasets/webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 32986 3 2020-02-17 17:18:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 3b337b99-ddaf-495d-9359-ed9db6a7bae2 0xc0006118b7 0xc0006118b8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000611938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 17:18:11.547: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Feb 17 17:18:11.547: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-2055 /apis/apps/v1/namespaces/deployment-2055/replicasets/webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 33122 3 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 3b337b99-ddaf-495d-9359-ed9db6a7bae2 0xc0006116b7 0xc0006116b8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000611768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:10,AvailableReplicas:10,Conditions:[]ReplicaSetCondition{},},}
Feb 17 17:18:11.613: INFO: Pod "webserver-deployment-595b5b9587-2h9j9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2h9j9 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-2h9j9 17bb9f18-e408-4782-9f1c-cc72801ac986 33110 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002828977 0xc002828978}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:172.30.104.14,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://eebe760e80fda14c59af55beee10a84ab7ebc1d02aa7c62b8a1881874f5a3117,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.14,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.614: INFO: Pod "webserver-deployment-595b5b9587-4j8t9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4j8t9 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-4j8t9 67646671-67c6-429d-85ba-b6c739f6e766 32817 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002828bc7 0xc002828bc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.45,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://7d86b8afd0490c5961a54e730a208afaa72bea7a64e810c65b6808911d64e8aa,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.45,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.614: INFO: Pod "webserver-deployment-595b5b9587-6pqzh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6pqzh webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-6pqzh 1d5a65b7-dc93-4eba-8930-4c3b5c96d092 32776 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002828ee7 0xc002828ee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.46,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://a3cfd00420d10ab7de79e097267cfd265f2ceb32082c2c03e2e0292200083596,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.614: INFO: Pod "webserver-deployment-595b5b9587-8lgs2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8lgs2 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-8lgs2 5ff2d569-59b7-425a-92c9-defde9e1b38e 32820 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829117 0xc002829118}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.44,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://6c49f7b69f2e72e7bf084c93b5c0cad7e8290232c40f0e7137fd40c3bcf5bd5f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.44,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.615: INFO: Pod "webserver-deployment-595b5b9587-9t76p" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9t76p webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-9t76p 601ba349-9f1e-49ee-8109-6d35c869846d 32807 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829297 0xc002829298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:172.30.186.179,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://41b94eb6fcfd93f726fb22f01b5acb4fef0eb7535141a819dc52a65351dc6266,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.186.179,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.615: INFO: Pod "webserver-deployment-595b5b9587-b5vsj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-b5vsj webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-b5vsj 24176e38-de2d-40f1-97b7-4c85af1b131e 33004 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829507 0xc002829508}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.615: INFO: Pod "webserver-deployment-595b5b9587-ct78z" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ct78z webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-ct78z 95979a74-c1a9-4d5c-a6f6-8d06ef7fe7e5 33025 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829677 0xc002829678}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.615: INFO: Pod "webserver-deployment-595b5b9587-gdpzp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gdpzp webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-gdpzp 89220eee-6cc8-46bb-bf27-b31359b1e13b 33028 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc0028297d7 0xc0028297d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.616: INFO: Pod "webserver-deployment-595b5b9587-gxd7n" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gxd7n webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-gxd7n 46371baa-ccdf-497c-99e2-5895be3a27ee 33143 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829957 0xc002829958}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:172.30.186.183,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://4e6b8fc454866b0edd4efaee79b4ea8ca29604fc7ea7df0197adeeb41302a37c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.186.183,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.616: INFO: Pod "webserver-deployment-595b5b9587-h9ttl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-h9ttl webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-h9ttl 0be5ad09-9209-41b2-8fd4-ec994d620113 33115 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829ad7 0xc002829ad8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:172.30.104.11,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://51cbc772a4b0e3d4646cdf41e6bec01035477a9ec3de6f4b0bd7483f82682d63,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.616: INFO: Pod "webserver-deployment-595b5b9587-jw8gt" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jw8gt webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-jw8gt 23a1333c-217e-458d-8c14-fb52c2036cd2 33009 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829c57 0xc002829c58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.616: INFO: Pod "webserver-deployment-595b5b9587-l57s6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l57s6 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-l57s6 582bf3b0-e71f-4249-bd12-69cf9c265030 33032 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829db7 0xc002829db8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.617: INFO: Pod "webserver-deployment-595b5b9587-lxwdc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lxwdc webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-lxwdc 79725e71-6fde-4f8f-b2e7-62a4c78b4fac 32814 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002829f17 0xc002829f18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:172.30.186.176,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://e88b215cc6fad0c6a3986d460199bb95787931ee2b9d7d19bdc967b7dd67497e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.186.176,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.617: INFO: Pod "webserver-deployment-595b5b9587-pc7tc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pc7tc webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-pc7tc a174c155-3f17-498a-8a4b-ab0e8fb86676 33036 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630097 0xc002630098}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.617: INFO: Pod "webserver-deployment-595b5b9587-pfnt7" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pfnt7 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-pfnt7 b80bdf01-63cd-4f34-a918-c32c3ff5f65b 32782 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630417 0xc002630418}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.43,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://9e9873c899dd57e3921e3137d5c95e4fac95e1a4e5498130a1c9af235a925a75,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.43,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.617: INFO: Pod "webserver-deployment-595b5b9587-rxhwr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rxhwr webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-rxhwr 38f02a9f-a093-4877-ba2a-b6fd3fc58996 33014 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630807 0xc002630808}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.618: INFO: Pod "webserver-deployment-595b5b9587-vcsk9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vcsk9 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-vcsk9 dc62416b-c571-4288-9895-dc691e6ba5d3 33005 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630aa7 0xc002630aa8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.618: INFO: Pod "webserver-deployment-595b5b9587-vfbxv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vfbxv webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-vfbxv d526b87a-c056-427a-84b3-c4e666e194c8 33020 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630e27 0xc002630e28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.618: INFO: Pod "webserver-deployment-595b5b9587-vlmkc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vlmkc webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-vlmkc 40ead25d-08c1-4bb7-973f-037058422f04 32798 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc002630f87 0xc002630f88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:172.30.104.7,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://f999eee021bcab1b5b61439664871177066325d223f7db8e12cde8f22086ea42,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.619: INFO: Pod "webserver-deployment-595b5b9587-w2np6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-w2np6 webserver-deployment-595b5b9587- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-595b5b9587-w2np6 8272e8e4-4e75-4549-9f81-e0ad331772ae 32823 0 2020-02-17 17:18:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 589e15b1-3890-4bc0-a15b-5d2ced12ff83 0xc0026311f7 0xc0026311f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.48,StartTime:2020-02-17 17:18:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:18:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://2b487b306e422b672865c7e51f1912483423cbcf150f5a2ea71e32f0fa95d6ef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.48,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.619: INFO: Pod "webserver-deployment-c7997dcc8-5fvmf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5fvmf webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-5fvmf 2e9b4d47-1383-4f1b-a367-0d1de4924989 33015 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc002631387 0xc002631388}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.620: INFO: Pod "webserver-deployment-c7997dcc8-8n484" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8n484 webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-8n484 d554baf8-71e5-4726-a4c6-6de417ffda4d 33019 0 2020-02-17 17:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc0026315e7 0xc0026315e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:172.30.186.182,StartTime:2020-02-17 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.186.182,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.620: INFO: Pod "webserver-deployment-c7997dcc8-dmw2z" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dmw2z webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-dmw2z e57d9c8b-6167-49f5-b859-9aa519b04062 33013 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc002631967 0xc002631968}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.620: INFO: Pod "webserver-deployment-c7997dcc8-f2dj8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f2dj8 webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-f2dj8 e9929b94-afcf-40cb-b969-ec7bcc6fee44 33026 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc002631d27 0xc002631d28}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.620: INFO: Pod "webserver-deployment-c7997dcc8-gk8k7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gk8k7 webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-gk8k7 0b320d41-6de3-492a-af9c-9483c5346b0a 32913 0 2020-02-17 17:18:06 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e007 0xc003d1e008}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.47,StartTime:2020-02-17 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.621: INFO: Pod "webserver-deployment-c7997dcc8-hj9cq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hj9cq webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-hj9cq 7e245ce4-fa37-4120-8f43-4d9f130f22e0 32987 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e1b7 0xc003d1e1b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.621: INFO: Pod "webserver-deployment-c7997dcc8-jd676" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jd676 webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-jd676 c0a5f54e-ec1b-41f0-aada-96873581fa51 33135 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e337 0xc003d1e338}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.130,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.130,PodIP:172.30.186.181,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.186.181,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.621: INFO: Pod "webserver-deployment-c7997dcc8-msd8b" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-msd8b webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-msd8b 989aed51-c085-4378-a2c8-880b98809719 33042 0 2020-02-17 17:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e4e7 0xc003d1e4e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.50,StartTime:2020-02-17 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.50,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.621: INFO: Pod "webserver-deployment-c7997dcc8-n4gqn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-n4gqn webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-n4gqn c8352bcb-9633-4077-b2e9-fdce727ff6a3 32964 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e697 0xc003d1e698}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.621: INFO: Pod "webserver-deployment-c7997dcc8-p7cnz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-p7cnz webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-p7cnz 6415a646-3bbc-4612-a289-e78b08c40586 32922 0 2020-02-17 17:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e817 0xc003d1e818}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:172.30.104.10,StartTime:2020-02-17 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.104.10,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.622: INFO: Pod "webserver-deployment-c7997dcc8-qj9qp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-qj9qp webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-qj9qp d86047da-c6cb-40a0-be9e-ee58745cacdd 33021 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1e9c7 0xc003d1e9c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.151,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.151,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.623: INFO: Pod "webserver-deployment-c7997dcc8-vsmqb" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vsmqb webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-vsmqb a890e662-f05d-4480-8c97-eda88b04ef4a 32998 0 2020-02-17 17:18:09 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1eb47 0xc003d1eb48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:09 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 17:18:09 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:18:11.623: INFO: Pod "webserver-deployment-c7997dcc8-w6srm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w6srm webserver-deployment-c7997dcc8- deployment-2055 /api/v1/namespaces/deployment-2055/pods/webserver-deployment-c7997dcc8-w6srm 63ab7b1d-22d5-4fa9-96b4-25672570f5c2 33037 0 2020-02-17 17:18:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 d3672a0e-e8f5-4345-a24f-26e747e13fb8 0xc003d1ecc7 0xc003d1ecc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tr5l2,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tr5l2,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tr5l2,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:18:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.49,StartTime:2020-02-17 17:18:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/webserver:404": failed to resolve reference "docker.io/library/webserver:404": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:18:11.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2055" for this suite.
Feb 17 17:18:25.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:26.505: INFO: namespace deployment-2055 deletion completed in 14.860222995s

• [SLOW TEST:24.287 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:18:26.505: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1310
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:18:42.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1310" for this suite.
Feb 17 17:18:49.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:18:49.647: INFO: namespace resourcequota-1310 deletion completed in 6.661332879s

• [SLOW TEST:23.142 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:18:49.648: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4048
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 17 17:18:49.984: INFO: Waiting up to 5m0s for pod "downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d" in namespace "downward-api-4048" to be "success or failure"
Feb 17 17:18:50.007: INFO: Pod "downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d": Phase="Pending", Reason="", readiness=false. Elapsed: 22.606047ms
Feb 17 17:18:52.030: INFO: Pod "downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045696945s
STEP: Saw pod success
Feb 17 17:18:52.030: INFO: Pod "downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d" satisfied condition "success or failure"
Feb 17 17:18:52.045: INFO: Trying to get logs from node 10.241.69.147 pod downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:18:52.139: INFO: Waiting for pod downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d to disappear
Feb 17 17:18:52.152: INFO: Pod downward-api-d63c849e-61f1-44c7-9180-0ea2fa56df7d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:18:52.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4048" for this suite.
Feb 17 17:19:00.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:19:00.958: INFO: namespace downward-api-4048 deletion completed in 8.784695865s

• [SLOW TEST:11.311 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:19:00.960: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3322
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3322
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3322
STEP: Creating statefulset with conflicting port in namespace statefulset-3322
STEP: Waiting until pod test-pod will start running in namespace statefulset-3322
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3322
Feb 17 17:19:05.601: INFO: Observed stateful pod in namespace: statefulset-3322, name: ss-0, uid: 7ca48f6f-0884-478a-a5e4-56ee49413d3c, status phase: Pending. Waiting for statefulset controller to delete.
Feb 17 17:19:05.639: INFO: Observed stateful pod in namespace: statefulset-3322, name: ss-0, uid: 7ca48f6f-0884-478a-a5e4-56ee49413d3c, status phase: Failed. Waiting for statefulset controller to delete.
Feb 17 17:19:05.663: INFO: Observed stateful pod in namespace: statefulset-3322, name: ss-0, uid: 7ca48f6f-0884-478a-a5e4-56ee49413d3c, status phase: Failed. Waiting for statefulset controller to delete.
Feb 17 17:19:05.698: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3322
STEP: Removing pod with conflicting port in namespace statefulset-3322
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3322 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 17:19:09.960: INFO: Deleting all statefulset in ns statefulset-3322
Feb 17 17:19:09.979: INFO: Scaling statefulset ss to 0
Feb 17 17:19:20.096: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:19:20.122: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:19:20.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3322" for this suite.
Feb 17 17:19:28.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:19:28.966: INFO: namespace statefulset-3322 deletion completed in 8.726608827s

• [SLOW TEST:28.006 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:19:28.966: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8880
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8880
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8880
STEP: creating replication controller externalsvc in namespace services-8880
I0217 17:19:29.463469      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8880, replica count: 2
I0217 17:19:32.514091      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Feb 17 17:19:32.629: INFO: Creating new exec pod
Feb 17 17:19:34.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-8880 execpodp8vzl -- /bin/sh -x -c nslookup nodeport-service'
Feb 17 17:19:35.181: INFO: stderr: "+ nslookup nodeport-service\n"
Feb 17 17:19:35.181: INFO: stdout: "Server:\t\t172.21.0.10\nAddress:\t172.21.0.10#53\n\nnodeport-service.services-8880.svc.cluster.local\tcanonical name = externalsvc.services-8880.svc.cluster.local.\nName:\texternalsvc.services-8880.svc.cluster.local\nAddress: 172.21.131.187\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8880, will wait for the garbage collector to delete the pods
Feb 17 17:19:35.284: INFO: Deleting ReplicationController externalsvc took: 37.777806ms
Feb 17 17:19:35.484: INFO: Terminating ReplicationController externalsvc pods took: 200.266471ms
Feb 17 17:19:49.692: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:19:49.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8880" for this suite.
Feb 17 17:19:57.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:19:58.592: INFO: namespace services-8880 deletion completed in 8.796311045s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:29.626 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:19:58.593: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-976
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f4394d8e-93f5-41c1-bebd-468ab9b3d11e
STEP: Creating a pod to test consume configMaps
Feb 17 17:19:58.981: INFO: Waiting up to 5m0s for pod "pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d" in namespace "configmap-976" to be "success or failure"
Feb 17 17:19:58.994: INFO: Pod "pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d": Phase="Pending", Reason="", readiness=false. Elapsed: 12.552989ms
Feb 17 17:20:01.031: INFO: Pod "pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.049763354s
Feb 17 17:20:03.066: INFO: Pod "pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084628898s
STEP: Saw pod success
Feb 17 17:20:03.066: INFO: Pod "pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d" satisfied condition "success or failure"
Feb 17 17:20:03.091: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:20:03.235: INFO: Waiting for pod pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d to disappear
Feb 17 17:20:03.283: INFO: Pod pod-configmaps-f21342fd-fe08-4b0e-ac6b-4d988bed376d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:20:03.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-976" for this suite.
Feb 17 17:20:11.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:20:12.619: INFO: namespace configmap-976 deletion completed in 9.301428038s

• [SLOW TEST:14.026 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:20:12.619: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-fcc62f26-dd31-4d23-9333-ea3ab01118a6 in namespace container-probe-3823
Feb 17 17:20:17.019: INFO: Started pod busybox-fcc62f26-dd31-4d23-9333-ea3ab01118a6 in namespace container-probe-3823
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:20:17.044: INFO: Initial restart count of pod busybox-fcc62f26-dd31-4d23-9333-ea3ab01118a6 is 0
Feb 17 17:21:01.500: INFO: Restart count of pod container-probe-3823/busybox-fcc62f26-dd31-4d23-9333-ea3ab01118a6 is now 1 (44.456189826s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:01.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3823" for this suite.
Feb 17 17:21:09.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:21:10.555: INFO: namespace container-probe-3823 deletion completed in 8.919440575s

• [SLOW TEST:57.936 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:21:10.555: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9968
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:21:10.988: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5" in namespace "downward-api-9968" to be "success or failure"
Feb 17 17:21:11.038: INFO: Pod "downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 49.250577ms
Feb 17 17:21:13.052: INFO: Pod "downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.063492371s
Feb 17 17:21:15.075: INFO: Pod "downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.086505913s
STEP: Saw pod success
Feb 17 17:21:15.075: INFO: Pod "downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5" satisfied condition "success or failure"
Feb 17 17:21:15.088: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5 container client-container: <nil>
STEP: delete the pod
Feb 17 17:21:15.224: INFO: Waiting for pod downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5 to disappear
Feb 17 17:21:15.245: INFO: Pod downwardapi-volume-e1ef9571-cfab-469d-96e9-0c7d8478c6e5 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:15.245: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9968" for this suite.
Feb 17 17:21:23.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:21:24.005: INFO: namespace downward-api-9968 deletion completed in 8.739437543s

• [SLOW TEST:13.450 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:21:24.005: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5714
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:21:24.299: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 version'
Feb 17 17:21:24.422: INFO: stderr: ""
Feb 17 17:21:24.422: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7\", GitCommit:\"be3d344ed06bff7a4fc60656200a93c74f31f9a4\", GitTreeState:\"clean\", BuildDate:\"2020-02-11T19:34:02Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.7+IKS\", GitCommit:\"8e6ceab7b61240d0beca0e2a2d78a91f52c5df18\", GitTreeState:\"clean\", BuildDate:\"2020-02-13T08:09:12Z\", GoVersion:\"go1.13.6\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:24.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5714" for this suite.
Feb 17 17:21:30.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:21:31.111: INFO: namespace kubectl-5714 deletion completed in 6.653090483s

• [SLOW TEST:7.106 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:21:31.113: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-526
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 17 17:21:31.463: INFO: Waiting up to 5m0s for pod "downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb" in namespace "downward-api-526" to be "success or failure"
Feb 17 17:21:31.482: INFO: Pod "downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb": Phase="Pending", Reason="", readiness=false. Elapsed: 19.027997ms
Feb 17 17:21:33.516: INFO: Pod "downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052799251s
STEP: Saw pod success
Feb 17 17:21:33.516: INFO: Pod "downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb" satisfied condition "success or failure"
Feb 17 17:21:33.538: INFO: Trying to get logs from node 10.241.69.147 pod downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:21:33.653: INFO: Waiting for pod downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb to disappear
Feb 17 17:21:33.672: INFO: Pod downward-api-4466e9b8-eaf2-4c37-b347-bc9308bd5bdb no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:33.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-526" for this suite.
Feb 17 17:21:39.773: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:21:40.398: INFO: namespace downward-api-526 deletion completed in 6.693192855s

• [SLOW TEST:9.285 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:21:40.399: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8128
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 17 17:21:40.751: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:44.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8128" for this suite.
Feb 17 17:21:52.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:21:53.067: INFO: namespace init-container-8128 deletion completed in 8.686196435s

• [SLOW TEST:12.669 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:21:53.067: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1679
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1679/configmap-test-a6a5766b-2342-4e53-90f1-c8f0f1f7a0f7
STEP: Creating a pod to test consume configMaps
Feb 17 17:21:53.503: INFO: Waiting up to 5m0s for pod "pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c" in namespace "configmap-1679" to be "success or failure"
Feb 17 17:21:53.517: INFO: Pod "pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.034468ms
Feb 17 17:21:55.579: INFO: Pod "pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.076571298s
STEP: Saw pod success
Feb 17 17:21:55.580: INFO: Pod "pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c" satisfied condition "success or failure"
Feb 17 17:21:55.599: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c container env-test: <nil>
STEP: delete the pod
Feb 17 17:21:55.686: INFO: Waiting for pod pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c to disappear
Feb 17 17:21:55.708: INFO: Pod pod-configmaps-18659b2c-c967-4c59-bfed-5f1b2189db7c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:21:55.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1679" for this suite.
Feb 17 17:22:03.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:04.934: INFO: namespace configmap-1679 deletion completed in 9.194112307s

• [SLOW TEST:11.867 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:22:04.936: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8824
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:22:05.468: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7" in namespace "projected-8824" to be "success or failure"
Feb 17 17:22:05.504: INFO: Pod "downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7": Phase="Pending", Reason="", readiness=false. Elapsed: 36.196289ms
Feb 17 17:22:07.528: INFO: Pod "downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.059329561s
STEP: Saw pod success
Feb 17 17:22:07.528: INFO: Pod "downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7" satisfied condition "success or failure"
Feb 17 17:22:07.568: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7 container client-container: <nil>
STEP: delete the pod
Feb 17 17:22:07.759: INFO: Waiting for pod downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7 to disappear
Feb 17 17:22:07.985: INFO: Pod downwardapi-volume-91e658e1-0586-4c4d-8a8a-4418819c9be7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:22:07.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8824" for this suite.
Feb 17 17:22:16.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:16.903: INFO: namespace projected-8824 deletion completed in 8.884779387s

• [SLOW TEST:11.967 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:22:16.906: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:22:17.799: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:22:20.955: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:22:20.991: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3515" for this suite.
Feb 17 17:22:29.077: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:29.708: INFO: namespace webhook-3515 deletion completed in 8.693666788s
STEP: Destroying namespace "webhook-3515-markers" for this suite.
Feb 17 17:22:35.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:36.440: INFO: namespace webhook-3515-markers deletion completed in 6.731742037s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.618 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:22:36.524: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6562
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3640f6ca-c318-4715-b333-cd46cccb277b
STEP: Creating a pod to test consume secrets
Feb 17 17:22:36.880: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717" in namespace "projected-6562" to be "success or failure"
Feb 17 17:22:36.909: INFO: Pod "pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717": Phase="Pending", Reason="", readiness=false. Elapsed: 28.961412ms
Feb 17 17:22:38.925: INFO: Pod "pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.044781482s
STEP: Saw pod success
Feb 17 17:22:38.925: INFO: Pod "pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717" satisfied condition "success or failure"
Feb 17 17:22:38.952: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:22:39.036: INFO: Waiting for pod pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717 to disappear
Feb 17 17:22:39.053: INFO: Pod pod-projected-secrets-51e8041c-bb1b-4856-a7f5-f361b83f7717 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:22:39.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6562" for this suite.
Feb 17 17:22:47.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:22:47.723: INFO: namespace projected-6562 deletion completed in 8.647253117s

• [SLOW TEST:11.199 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:22:47.723: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4991
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 17 17:22:48.049: INFO: Waiting up to 5m0s for pod "pod-eceb3822-d7e4-4264-ac42-f32425c41528" in namespace "emptydir-4991" to be "success or failure"
Feb 17 17:22:48.064: INFO: Pod "pod-eceb3822-d7e4-4264-ac42-f32425c41528": Phase="Pending", Reason="", readiness=false. Elapsed: 15.692893ms
Feb 17 17:22:50.083: INFO: Pod "pod-eceb3822-d7e4-4264-ac42-f32425c41528": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034602693s
Feb 17 17:22:52.098: INFO: Pod "pod-eceb3822-d7e4-4264-ac42-f32425c41528": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049083133s
STEP: Saw pod success
Feb 17 17:22:52.098: INFO: Pod "pod-eceb3822-d7e4-4264-ac42-f32425c41528" satisfied condition "success or failure"
Feb 17 17:22:52.112: INFO: Trying to get logs from node 10.241.69.147 pod pod-eceb3822-d7e4-4264-ac42-f32425c41528 container test-container: <nil>
STEP: delete the pod
Feb 17 17:22:52.204: INFO: Waiting for pod pod-eceb3822-d7e4-4264-ac42-f32425c41528 to disappear
Feb 17 17:22:52.218: INFO: Pod pod-eceb3822-d7e4-4264-ac42-f32425c41528 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:22:52.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4991" for this suite.
Feb 17 17:23:00.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:01.031: INFO: namespace emptydir-4991 deletion completed in 8.788896181s

• [SLOW TEST:13.309 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:23:01.032: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-3437
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:23:01.587: INFO: (0) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 181.204759ms)
Feb 17 17:23:01.617: INFO: (1) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 29.169005ms)
Feb 17 17:23:01.655: INFO: (2) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 38.100505ms)
Feb 17 17:23:01.697: INFO: (3) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 42.537975ms)
Feb 17 17:23:01.731: INFO: (4) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.772889ms)
Feb 17 17:23:01.773: INFO: (5) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 41.762938ms)
Feb 17 17:23:01.819: INFO: (6) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 45.64542ms)
Feb 17 17:23:01.875: INFO: (7) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 56.44347ms)
Feb 17 17:23:01.909: INFO: (8) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.842662ms)
Feb 17 17:23:01.960: INFO: (9) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 50.332493ms)
Feb 17 17:23:02.027: INFO: (10) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 67.585039ms)
Feb 17 17:23:02.063: INFO: (11) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 35.756672ms)
Feb 17 17:23:02.103: INFO: (12) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 39.856814ms)
Feb 17 17:23:02.155: INFO: (13) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 52.208555ms)
Feb 17 17:23:02.189: INFO: (14) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 33.12664ms)
Feb 17 17:23:02.270: INFO: (15) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 80.921009ms)
Feb 17 17:23:02.307: INFO: (16) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 37.303198ms)
Feb 17 17:23:02.347: INFO: (17) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 39.508869ms)
Feb 17 17:23:02.384: INFO: (18) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 37.167824ms)
Feb 17 17:23:02.437: INFO: (19) /api/v1/nodes/10.241.69.130/proxy/logs/: <pre>
<a href="alb/">alb/</a>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/... (200; 52.586425ms)
[AfterEach] version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:23:02.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3437" for this suite.
Feb 17 17:23:10.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:11.335: INFO: namespace proxy-3437 deletion completed in 8.858219939s

• [SLOW TEST:10.303 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:23:11.335: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:23:14.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-766" for this suite.
Feb 17 17:23:45.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:23:45.620: INFO: namespace replication-controller-766 deletion completed in 30.631764564s

• [SLOW TEST:34.286 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:23:45.622: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3545
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Feb 17 17:23:45.903: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:23:51.947: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:24:19.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3545" for this suite.
Feb 17 17:24:25.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:24:26.185: INFO: namespace crd-publish-openapi-3545 deletion completed in 6.644830398s

• [SLOW TEST:40.563 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:24:26.186: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:24:27.460: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:24:29.537: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557067, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557067, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557067, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557067, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:24:32.593: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:24:32.624: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:24:33.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3936" for this suite.
Feb 17 17:24:41.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:24:42.634: INFO: namespace webhook-3936 deletion completed in 8.753551243s
STEP: Destroying namespace "webhook-3936-markers" for this suite.
Feb 17 17:24:48.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:24:49.303: INFO: namespace webhook-3936-markers deletion completed in 6.669331734s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.195 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:24:49.382: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-3053
STEP: creating replication controller nodeport-test in namespace services-3053
I0217 17:24:49.750241      25 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-3053, replica count: 2
I0217 17:24:52.800771      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 17:24:52.800: INFO: Creating new exec pod
Feb 17 17:24:55.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Feb 17 17:24:56.341: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Feb 17 17:24:56.341: INFO: stdout: ""
Feb 17 17:24:56.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 172.21.129.41 80'
Feb 17 17:24:56.681: INFO: stderr: "+ nc -zv -t -w 2 172.21.129.41 80\nConnection to 172.21.129.41 80 port [tcp/http] succeeded!\n"
Feb 17 17:24:56.681: INFO: stdout: ""
Feb 17 17:24:56.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.130 31637'
Feb 17 17:24:57.039: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.130 31637\nConnection to 10.241.69.130 31637 port [tcp/31637] succeeded!\n"
Feb 17 17:24:57.039: INFO: stdout: ""
Feb 17 17:24:57.039: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.147 31637'
Feb 17 17:24:57.384: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.147 31637\nConnection to 10.241.69.147 31637 port [tcp/31637] succeeded!\n"
Feb 17 17:24:57.384: INFO: stdout: ""
Feb 17 17:24:57.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 169.63.36.186 31637'
Feb 17 17:24:57.752: INFO: stderr: "+ nc -zv -t -w 2 169.63.36.186 31637\nConnection to 169.63.36.186 31637 port [tcp/31637] succeeded!\n"
Feb 17 17:24:57.752: INFO: stdout: ""
Feb 17 17:24:57.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-3053 execpodtf9rx -- /bin/sh -x -c nc -zv -t -w 2 169.63.36.178 31637'
Feb 17 17:24:58.124: INFO: stderr: "+ nc -zv -t -w 2 169.63.36.178 31637\nConnection to 169.63.36.178 31637 port [tcp/31637] succeeded!\n"
Feb 17 17:24:58.124: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:24:58.124: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3053" for this suite.
Feb 17 17:25:06.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:25:07.214: INFO: namespace services-3053 deletion completed in 9.06855959s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.833 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:25:07.216: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6181
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 17 17:25:07.696: INFO: Waiting up to 5m0s for pod "downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a" in namespace "downward-api-6181" to be "success or failure"
Feb 17 17:25:07.743: INFO: Pod "downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a": Phase="Pending", Reason="", readiness=false. Elapsed: 46.851692ms
Feb 17 17:25:09.778: INFO: Pod "downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.081769265s
STEP: Saw pod success
Feb 17 17:25:09.778: INFO: Pod "downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a" satisfied condition "success or failure"
Feb 17 17:25:09.796: INFO: Trying to get logs from node 10.241.69.147 pod downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:25:09.983: INFO: Waiting for pod downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a to disappear
Feb 17 17:25:10.058: INFO: Pod downward-api-1b3fa07b-986a-4251-b5ed-11a148df152a no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:25:10.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6181" for this suite.
Feb 17 17:25:18.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:25:18.823: INFO: namespace downward-api-6181 deletion completed in 8.692647891s

• [SLOW TEST:11.607 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:25:18.824: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-723
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Feb 17 17:25:19.157: INFO: Waiting up to 5m0s for pod "pod-96f64626-ca45-4ace-ad2f-22b91a306de7" in namespace "emptydir-723" to be "success or failure"
Feb 17 17:25:19.172: INFO: Pod "pod-96f64626-ca45-4ace-ad2f-22b91a306de7": Phase="Pending", Reason="", readiness=false. Elapsed: 15.048739ms
Feb 17 17:25:21.185: INFO: Pod "pod-96f64626-ca45-4ace-ad2f-22b91a306de7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028847608s
STEP: Saw pod success
Feb 17 17:25:21.185: INFO: Pod "pod-96f64626-ca45-4ace-ad2f-22b91a306de7" satisfied condition "success or failure"
Feb 17 17:25:21.206: INFO: Trying to get logs from node 10.241.69.147 pod pod-96f64626-ca45-4ace-ad2f-22b91a306de7 container test-container: <nil>
STEP: delete the pod
Feb 17 17:25:21.372: INFO: Waiting for pod pod-96f64626-ca45-4ace-ad2f-22b91a306de7 to disappear
Feb 17 17:25:21.390: INFO: Pod pod-96f64626-ca45-4ace-ad2f-22b91a306de7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:25:21.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-723" for this suite.
Feb 17 17:25:29.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:25:30.410: INFO: namespace emptydir-723 deletion completed in 9.001986042s

• [SLOW TEST:11.587 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:25:30.411: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-685
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:25:30.865: INFO: Create a RollingUpdate DaemonSet
Feb 17 17:25:30.885: INFO: Check that daemon pods launch on every node of the cluster
Feb 17 17:25:30.915: INFO: Number of nodes with available pods: 0
Feb 17 17:25:30.915: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:25:31.958: INFO: Number of nodes with available pods: 0
Feb 17 17:25:31.958: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 17:25:32.951: INFO: Number of nodes with available pods: 2
Feb 17 17:25:32.951: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 17:25:33.967: INFO: Number of nodes with available pods: 3
Feb 17 17:25:33.968: INFO: Number of running nodes: 3, number of available pods: 3
Feb 17 17:25:33.968: INFO: Update the DaemonSet to trigger a rollout
Feb 17 17:25:34.012: INFO: Updating DaemonSet daemon-set
Feb 17 17:25:40.088: INFO: Roll back the DaemonSet before rollout is complete
Feb 17 17:25:40.143: INFO: Updating DaemonSet daemon-set
Feb 17 17:25:40.143: INFO: Make sure DaemonSet rollback is complete
Feb 17 17:25:40.161: INFO: Wrong image for pod: daemon-set-42sgg. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 17 17:25:40.161: INFO: Pod daemon-set-42sgg is not available
Feb 17 17:25:41.200: INFO: Wrong image for pod: daemon-set-42sgg. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Feb 17 17:25:41.200: INFO: Pod daemon-set-42sgg is not available
Feb 17 17:25:42.199: INFO: Pod daemon-set-5t4mv is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-685, will wait for the garbage collector to delete the pods
Feb 17 17:25:42.347: INFO: Deleting DaemonSet.extensions daemon-set took: 30.557963ms
Feb 17 17:25:42.547: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.237502ms
Feb 17 17:25:44.576: INFO: Number of nodes with available pods: 0
Feb 17 17:25:44.576: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 17:25:44.590: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-685/daemonsets","resourceVersion":"35504"},"items":null}

Feb 17 17:25:44.605: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-685/pods","resourceVersion":"35504"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:25:44.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-685" for this suite.
Feb 17 17:25:52.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:25:53.274: INFO: namespace daemonsets-685 deletion completed in 8.584005386s

• [SLOW TEST:22.863 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:25:53.274: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2416
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 17 17:25:53.716: INFO: Waiting up to 5m0s for pod "downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985" in namespace "downward-api-2416" to be "success or failure"
Feb 17 17:25:53.728: INFO: Pod "downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985": Phase="Pending", Reason="", readiness=false. Elapsed: 11.733718ms
Feb 17 17:25:55.747: INFO: Pod "downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03076078s
Feb 17 17:25:57.768: INFO: Pod "downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.051282843s
STEP: Saw pod success
Feb 17 17:25:57.768: INFO: Pod "downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985" satisfied condition "success or failure"
Feb 17 17:25:57.782: INFO: Trying to get logs from node 10.241.69.147 pod downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985 container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:25:57.877: INFO: Waiting for pod downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985 to disappear
Feb 17 17:25:57.897: INFO: Pod downward-api-c69bee90-c37e-4e0e-8595-32cd9675a985 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:25:57.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2416" for this suite.
Feb 17 17:26:05.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:26:07.082: INFO: namespace downward-api-2416 deletion completed in 9.163922344s

• [SLOW TEST:13.808 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:26:07.083: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4457
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4457
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 17:26:07.449: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 17:26:27.983: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.186.131 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4457 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:26:27.983: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:26:29.268: INFO: Found all expected endpoints: [netserver-0]
Feb 17 17:26:29.283: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.84.18 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4457 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:26:29.283: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:26:30.514: INFO: Found all expected endpoints: [netserver-1]
Feb 17 17:26:30.532: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.30.104.12 8081 | grep -v '^\s*$'] Namespace:pod-network-test-4457 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:26:30.532: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:26:31.736: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:26:31.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4457" for this suite.
Feb 17 17:26:46.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:26:46.775: INFO: namespace pod-network-test-4457 deletion completed in 14.839976133s

• [SLOW TEST:39.693 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:26:46.776: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5289
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 17 17:26:49.907: INFO: Successfully updated pod "pod-update-22169681-7b54-4887-b2ba-bab4f0f5b68a"
STEP: verifying the updated pod is in kubernetes
Feb 17 17:26:49.955: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:26:49.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5289" for this suite.
Feb 17 17:27:04.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:27:05.031: INFO: namespace pods-5289 deletion completed in 15.053224053s

• [SLOW TEST:18.255 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:27:05.032: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-7180
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:27:05.397: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Feb 17 17:27:06.612: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:27:06.672: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7180" for this suite.
Feb 17 17:27:14.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:27:15.690: INFO: namespace replication-controller-7180 deletion completed in 8.992484973s

• [SLOW TEST:10.658 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:27:15.690: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:27:16.002: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:27:18.304: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9728" for this suite.
Feb 17 17:28:04.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:05.290: INFO: namespace pods-9728 deletion completed in 46.963999088s

• [SLOW TEST:49.600 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:28:05.291: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:28:06.348: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:28:08.438: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557286, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557286, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557286, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557286, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:28:11.577: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:28:11.604: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3579-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:28:14.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4956" for this suite.
Feb 17 17:28:22.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:22.961: INFO: namespace webhook-4956 deletion completed in 8.736183414s
STEP: Destroying namespace "webhook-4956-markers" for this suite.
Feb 17 17:28:31.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:31.747: INFO: namespace webhook-4956-markers deletion completed in 8.785393436s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.551 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:28:31.842: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3924.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3924.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3924.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3924.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3924.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:28:34.520: INFO: DNS probes using dns-3924/dns-test-b03ae801-068c-40d4-97fe-8c2d3f681ece succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:28:34.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3924" for this suite.
Feb 17 17:28:42.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:43.241: INFO: namespace dns-3924 deletion completed in 8.639831637s

• [SLOW TEST:11.399 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:28:43.242: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7129
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f7a8abea-4bfa-419f-aefa-4231bf1c3c93
STEP: Creating a pod to test consume configMaps
Feb 17 17:28:43.566: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7" in namespace "projected-7129" to be "success or failure"
Feb 17 17:28:43.580: INFO: Pod "pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.348932ms
Feb 17 17:28:45.595: INFO: Pod "pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.028132868s
STEP: Saw pod success
Feb 17 17:28:45.595: INFO: Pod "pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7" satisfied condition "success or failure"
Feb 17 17:28:45.610: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:28:45.745: INFO: Waiting for pod pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7 to disappear
Feb 17 17:28:45.767: INFO: Pod pod-projected-configmaps-91887031-a428-4aee-90e1-2b9b2c8c19f7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:28:45.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7129" for this suite.
Feb 17 17:28:53.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:28:54.412: INFO: namespace projected-7129 deletion completed in 8.622122537s

• [SLOW TEST:11.170 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:28:54.429: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5972
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:28:55.703: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:28:57.745: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557335, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557335, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557335, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717557335, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:29:00.792: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:29:11.544: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5972" for this suite.
Feb 17 17:29:19.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:29:20.243: INFO: namespace webhook-5972 deletion completed in 8.665170625s
STEP: Destroying namespace "webhook-5972-markers" for this suite.
Feb 17 17:29:26.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:29:26.986: INFO: namespace webhook-5972-markers deletion completed in 6.742383609s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.677 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:29:27.106: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-b6930c7c-bf71-47d8-8a72-47769a10e00c
STEP: Creating a pod to test consume secrets
Feb 17 17:29:27.512: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7" in namespace "projected-5113" to be "success or failure"
Feb 17 17:29:27.527: INFO: Pod "pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.842291ms
Feb 17 17:29:29.545: INFO: Pod "pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032198921s
STEP: Saw pod success
Feb 17 17:29:29.545: INFO: Pod "pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7" satisfied condition "success or failure"
Feb 17 17:29:29.584: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:29:29.687: INFO: Waiting for pod pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7 to disappear
Feb 17 17:29:29.703: INFO: Pod pod-projected-secrets-e9905d33-8c6b-40c5-88d0-a64f87c796b7 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:29:29.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5113" for this suite.
Feb 17 17:29:37.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:29:38.352: INFO: namespace projected-5113 deletion completed in 8.628872905s

• [SLOW TEST:11.246 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:29:38.352: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-530
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-9wbx
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 17:29:38.720: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-9wbx" in namespace "subpath-530" to be "success or failure"
Feb 17 17:29:38.737: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.221026ms
Feb 17 17:29:40.750: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 2.02940054s
Feb 17 17:29:42.766: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 4.04554716s
Feb 17 17:29:44.785: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 6.064278405s
Feb 17 17:29:46.801: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 8.080957889s
Feb 17 17:29:48.814: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 10.094060313s
Feb 17 17:29:50.835: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 12.11503697s
Feb 17 17:29:52.850: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 14.129213161s
Feb 17 17:29:54.876: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 16.155175271s
Feb 17 17:29:56.930: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 18.209496169s
Feb 17 17:29:59.250: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Running", Reason="", readiness=true. Elapsed: 20.529967265s
Feb 17 17:30:01.280: INFO: Pod "pod-subpath-test-secret-9wbx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.559181589s
STEP: Saw pod success
Feb 17 17:30:01.280: INFO: Pod "pod-subpath-test-secret-9wbx" satisfied condition "success or failure"
Feb 17 17:30:01.328: INFO: Trying to get logs from node 10.241.69.147 pod pod-subpath-test-secret-9wbx container test-container-subpath-secret-9wbx: <nil>
STEP: delete the pod
Feb 17 17:30:01.486: INFO: Waiting for pod pod-subpath-test-secret-9wbx to disappear
Feb 17 17:30:01.509: INFO: Pod pod-subpath-test-secret-9wbx no longer exists
STEP: Deleting pod pod-subpath-test-secret-9wbx
Feb 17 17:30:01.509: INFO: Deleting pod "pod-subpath-test-secret-9wbx" in namespace "subpath-530"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:30:01.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-530" for this suite.
Feb 17 17:30:09.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:30:10.473: INFO: namespace subpath-530 deletion completed in 8.880105511s

• [SLOW TEST:32.121 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:30:10.474: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-3bafadf9-9bb3-4907-b5de-643311fce9dc in namespace container-probe-6049
Feb 17 17:30:12.905: INFO: Started pod liveness-3bafadf9-9bb3-4907-b5de-643311fce9dc in namespace container-probe-6049
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:30:12.925: INFO: Initial restart count of pod liveness-3bafadf9-9bb3-4907-b5de-643311fce9dc is 0
Feb 17 17:30:33.141: INFO: Restart count of pod container-probe-6049/liveness-3bafadf9-9bb3-4907-b5de-643311fce9dc is now 1 (20.215846569s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:30:33.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6049" for this suite.
Feb 17 17:30:41.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:30:41.903: INFO: namespace container-probe-6049 deletion completed in 8.64795905s

• [SLOW TEST:31.430 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:30:41.903: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 17:30:45.284: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:30:45.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-599" for this suite.
Feb 17 17:30:53.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:30:54.068: INFO: namespace container-runtime-599 deletion completed in 8.686957268s

• [SLOW TEST:12.165 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:30:54.071: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8967
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Feb 17 17:30:54.393: INFO: Waiting up to 5m0s for pod "pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf" in namespace "emptydir-8967" to be "success or failure"
Feb 17 17:30:54.437: INFO: Pod "pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf": Phase="Pending", Reason="", readiness=false. Elapsed: 44.336985ms
Feb 17 17:30:56.454: INFO: Pod "pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.061109494s
STEP: Saw pod success
Feb 17 17:30:56.454: INFO: Pod "pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf" satisfied condition "success or failure"
Feb 17 17:30:56.472: INFO: Trying to get logs from node 10.241.69.147 pod pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf container test-container: <nil>
STEP: delete the pod
Feb 17 17:30:56.576: INFO: Waiting for pod pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf to disappear
Feb 17 17:30:56.592: INFO: Pod pod-ea6e686b-e5ae-478a-9cff-3a3befc3b6bf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:30:56.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8967" for this suite.
Feb 17 17:31:04.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:31:05.688: INFO: namespace emptydir-8967 deletion completed in 9.073943016s

• [SLOW TEST:11.617 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:31:05.689: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9619
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9619
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 17 17:31:06.173: INFO: Found 0 stateful pods, waiting for 3
Feb 17 17:31:16.190: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:31:16.190: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:31:16.190: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 17 17:31:16.282: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Feb 17 17:31:26.403: INFO: Updating stateful set ss2
Feb 17 17:31:26.443: INFO: Waiting for Pod statefulset-9619/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 17 17:31:36.488: INFO: Waiting for Pod statefulset-9619/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Feb 17 17:31:46.650: INFO: Found 2 stateful pods, waiting for 3
Feb 17 17:31:56.672: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:31:56.672: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 17:31:56.672: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Feb 17 17:31:56.749: INFO: Updating stateful set ss2
Feb 17 17:31:56.795: INFO: Waiting for Pod statefulset-9619/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 17 17:32:06.952: INFO: Updating stateful set ss2
Feb 17 17:32:07.015: INFO: Waiting for StatefulSet statefulset-9619/ss2 to complete update
Feb 17 17:32:07.015: INFO: Waiting for Pod statefulset-9619/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 17 17:32:17.060: INFO: Waiting for StatefulSet statefulset-9619/ss2 to complete update
Feb 17 17:32:17.060: INFO: Waiting for Pod statefulset-9619/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 17 17:32:27.094: INFO: Waiting for StatefulSet statefulset-9619/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 17:32:37.060: INFO: Deleting all statefulset in ns statefulset-9619
Feb 17 17:32:37.078: INFO: Scaling statefulset ss2 to 0
Feb 17 17:33:07.154: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 17:33:07.183: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:33:07.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9619" for this suite.
Feb 17 17:33:15.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:33:16.062: INFO: namespace statefulset-9619 deletion completed in 8.772967266s

• [SLOW TEST:130.373 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:33:16.062: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-518
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-518
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 17:33:16.380: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 17:33:38.872: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.39:8080/dial?request=hostName&protocol=http&host=172.30.186.140&port=8080&tries=1'] Namespace:pod-network-test-518 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:33:38.872: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:33:39.119: INFO: Waiting for endpoints: map[]
Feb 17 17:33:39.132: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.39:8080/dial?request=hostName&protocol=http&host=172.30.104.23&port=8080&tries=1'] Namespace:pod-network-test-518 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:33:39.132: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:33:39.331: INFO: Waiting for endpoints: map[]
Feb 17 17:33:39.344: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.39:8080/dial?request=hostName&protocol=http&host=172.30.84.38&port=8080&tries=1'] Namespace:pod-network-test-518 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:33:39.344: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:33:39.552: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:33:39.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-518" for this suite.
Feb 17 17:33:53.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:33:54.212: INFO: namespace pod-network-test-518 deletion completed in 14.627489514s

• [SLOW TEST:38.150 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:33:54.214: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-516
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:33:54.505: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Creating first CR 
Feb 17 17:33:54.814: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:33:54Z generation:1 name:name1 resourceVersion:37434 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cff97eff-fc76-492a-a079-ecd004fd9162] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Feb 17 17:34:04.856: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:34:04Z generation:1 name:name2 resourceVersion:37448 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:78f1e421-d26c-4612-a13e-9f08376c9837] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Feb 17 17:34:14.884: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:33:54Z generation:2 name:name1 resourceVersion:37462 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cff97eff-fc76-492a-a079-ecd004fd9162] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Feb 17 17:34:24.904: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:34:04Z generation:2 name:name2 resourceVersion:37478 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:78f1e421-d26c-4612-a13e-9f08376c9837] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Feb 17 17:34:34.949: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:33:54Z generation:2 name:name1 resourceVersion:37492 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:cff97eff-fc76-492a-a079-ecd004fd9162] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Feb 17 17:34:44.995: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-02-17T17:34:04Z generation:2 name:name2 resourceVersion:37505 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:78f1e421-d26c-4612-a13e-9f08376c9837] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:34:55.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-516" for this suite.
Feb 17 17:35:03.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:04.492: INFO: namespace crd-watch-516 deletion completed in 8.926324831s

• [SLOW TEST:70.278 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:35:04.493: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2428
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-277
STEP: Creating secret with name secret-test-0fe15ad6-603f-46f0-8ed4-21ea7bb365e3
STEP: Creating a pod to test consume secrets
Feb 17 17:35:05.357: INFO: Waiting up to 5m0s for pod "pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae" in namespace "secrets-2428" to be "success or failure"
Feb 17 17:35:05.457: INFO: Pod "pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae": Phase="Pending", Reason="", readiness=false. Elapsed: 99.544864ms
Feb 17 17:35:07.484: INFO: Pod "pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae": Phase="Running", Reason="", readiness=true. Elapsed: 2.126701405s
Feb 17 17:35:09.512: INFO: Pod "pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.154800275s
STEP: Saw pod success
Feb 17 17:35:09.512: INFO: Pod "pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae" satisfied condition "success or failure"
Feb 17 17:35:09.534: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:35:09.880: INFO: Waiting for pod pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae to disappear
Feb 17 17:35:09.915: INFO: Pod pod-secrets-36b1afbd-e002-4caf-89b0-0d6a1210fcae no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:35:09.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2428" for this suite.
Feb 17 17:35:18.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:18.710: INFO: namespace secrets-2428 deletion completed in 8.767304191s
STEP: Destroying namespace "secret-namespace-277" for this suite.
Feb 17 17:35:26.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:27.435: INFO: namespace secret-namespace-277 deletion completed in 8.724967385s

• [SLOW TEST:22.943 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:35:27.436: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5694
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Feb 17 17:35:27.793: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5694 /api/v1/namespaces/watch-5694/configmaps/e2e-watch-test-watch-closed 9ed775e8-e258-4c74-84ad-8cf591c25a5f 37638 0 2020-02-17 17:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 17:35:27.794: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5694 /api/v1/namespaces/watch-5694/configmaps/e2e-watch-test-watch-closed 9ed775e8-e258-4c74-84ad-8cf591c25a5f 37639 0 2020-02-17 17:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Feb 17 17:35:27.889: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5694 /api/v1/namespaces/watch-5694/configmaps/e2e-watch-test-watch-closed 9ed775e8-e258-4c74-84ad-8cf591c25a5f 37640 0 2020-02-17 17:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 17:35:27.889: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5694 /api/v1/namespaces/watch-5694/configmaps/e2e-watch-test-watch-closed 9ed775e8-e258-4c74-84ad-8cf591c25a5f 37641 0 2020-02-17 17:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:35:27.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5694" for this suite.
Feb 17 17:35:35.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:36.572: INFO: namespace watch-5694 deletion completed in 8.6650438s

• [SLOW TEST:9.137 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:35:36.574: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1293
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1293
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-1293
I0217 17:35:36.998463      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1293, replica count: 2
Feb 17 17:35:40.049: INFO: Creating new exec pod
I0217 17:35:40.048979      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 17:35:43.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 17 17:35:43.614: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 17 17:35:43.614: INFO: stdout: ""
Feb 17 17:35:43.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 172.21.51.251 80'
Feb 17 17:35:44.136: INFO: stderr: "+ nc -zv -t -w 2 172.21.51.251 80\nConnection to 172.21.51.251 80 port [tcp/http] succeeded!\n"
Feb 17 17:35:44.136: INFO: stdout: ""
Feb 17 17:35:44.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.130 32139'
Feb 17 17:35:44.510: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.130 32139\nConnection to 10.241.69.130 32139 port [tcp/32139] succeeded!\n"
Feb 17 17:35:44.510: INFO: stdout: ""
Feb 17 17:35:44.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 10.241.69.147 32139'
Feb 17 17:35:44.933: INFO: stderr: "+ nc -zv -t -w 2 10.241.69.147 32139\nConnection to 10.241.69.147 32139 port [tcp/32139] succeeded!\n"
Feb 17 17:35:44.933: INFO: stdout: ""
Feb 17 17:35:44.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 169.63.36.186 32139'
Feb 17 17:35:45.340: INFO: stderr: "+ nc -zv -t -w 2 169.63.36.186 32139\nConnection to 169.63.36.186 32139 port [tcp/32139] succeeded!\n"
Feb 17 17:35:45.340: INFO: stdout: ""
Feb 17 17:35:45.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1293 execpoddzmz9 -- /bin/sh -x -c nc -zv -t -w 2 169.63.36.178 32139'
Feb 17 17:35:45.709: INFO: stderr: "+ nc -zv -t -w 2 169.63.36.178 32139\nConnection to 169.63.36.178 32139 port [tcp/32139] succeeded!\n"
Feb 17 17:35:45.709: INFO: stdout: ""
Feb 17 17:35:45.709: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:35:45.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1293" for this suite.
Feb 17 17:35:53.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:35:54.532: INFO: namespace services-1293 deletion completed in 8.671748996s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.959 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:35:54.533: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:35:54.841: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Feb 17 17:35:59.855: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 17:35:59.855: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 17 17:35:59.934: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9048 /apis/apps/v1/namespaces/deployment-9048/deployments/test-cleanup-deployment 62eefa6b-d7e5-4d0c-91e6-3cd465af3be0 37813 1 2020-02-17 17:35:59 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005eb9518 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Feb 17 17:35:59.949: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-9048 /apis/apps/v1/namespaces/deployment-9048/replicasets/test-cleanup-deployment-65db99849b bfe8774f-3202-4ec2-9438-516883d9471c 37815 1 2020-02-17 17:35:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 62eefa6b-d7e5-4d0c-91e6-3cd465af3be0 0xc005eb9a67 0xc005eb9a68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005eb9ac8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 17:35:59.949: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Feb 17 17:35:59.949: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9048 /apis/apps/v1/namespaces/deployment-9048/replicasets/test-cleanup-controller d37cd9ff-3fde-4907-a8d4-769d8a6c7fba 37814 1 2020-02-17 17:35:54 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 62eefa6b-d7e5-4d0c-91e6-3cd465af3be0 0xc005eb9997 0xc005eb9998}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005eb99f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 17 17:35:59.979: INFO: Pod "test-cleanup-controller-chljb" is available:
&Pod{ObjectMeta:{test-cleanup-controller-chljb test-cleanup-controller- deployment-9048 /api/v1/namespaces/deployment-9048/pods/test-cleanup-controller-chljb 7776c1fd-3791-47c1-9d68-ce3f777e258c 37809 0 2020-02-17 17:35:54 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller d37cd9ff-3fde-4907-a8d4-769d8a6c7fba 0xc005eb9f17 0xc005eb9f18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hlghn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hlghn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hlghn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:35:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:35:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:35:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:35:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.40,StartTime:2020-02-17 17:35:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 17:35:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:containerd://143b39b1083841c08f60e19f8d84578b9f8d555a664c76b7277c124ede1a319e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Feb 17 17:35:59.979: INFO: Pod "test-cleanup-deployment-65db99849b-6fhkm" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-6fhkm test-cleanup-deployment-65db99849b- deployment-9048 /api/v1/namespaces/deployment-9048/pods/test-cleanup-deployment-65db99849b-6fhkm bd73a237-8d92-455c-9eae-6899249263b4 37819 0 2020-02-17 17:35:59 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b bfe8774f-3202-4ec2-9438-516883d9471c 0xc0026300b7 0xc0026300b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hlghn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hlghn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hlghn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 17:35:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:35:59.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9048" for this suite.
Feb 17 17:36:08.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:08.868: INFO: namespace deployment-9048 deletion completed in 8.864301229s

• [SLOW TEST:14.335 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:36:08.868: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:36:10.041: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:36:13.204: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:36:13.229: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3562-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:36:14.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7148" for this suite.
Feb 17 17:36:22.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:23.392: INFO: namespace webhook-7148 deletion completed in 8.739133142s
STEP: Destroying namespace "webhook-7148-markers" for this suite.
Feb 17 17:36:29.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:36:30.026: INFO: namespace webhook-7148-markers deletion completed in 6.633592733s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.246 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:36:30.115: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9799
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-b06644ea-976c-47c6-8140-3491fead8d65
STEP: Creating secret with name s-test-opt-upd-023af2fe-56d8-47a0-86a8-dcfe4e10ef55
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b06644ea-976c-47c6-8140-3491fead8d65
STEP: Updating secret s-test-opt-upd-023af2fe-56d8-47a0-86a8-dcfe4e10ef55
STEP: Creating secret with name s-test-opt-create-b8bbb385-c043-4dca-ba77-d91986f73e41
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:37:52.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9799" for this suite.
Feb 17 17:38:12.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:38:13.661: INFO: namespace projected-9799 deletion completed in 21.102832263s

• [SLOW TEST:103.547 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:38:13.662: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3016
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-7249
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3536
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:38:46.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3016" for this suite.
Feb 17 17:38:52.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:38:53.492: INFO: namespace namespaces-3016 deletion completed in 6.603954411s
STEP: Destroying namespace "nsdeletetest-7249" for this suite.
Feb 17 17:38:53.504: INFO: Namespace nsdeletetest-7249 was already deleted
STEP: Destroying namespace "nsdeletetest-3536" for this suite.
Feb 17 17:38:59.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:39:00.155: INFO: namespace nsdeletetest-3536 deletion completed in 6.651564769s

• [SLOW TEST:46.493 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:39:00.156: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1256
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 17 17:39:00.431: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:39:00.491: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:39:00.506: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.130 before test
Feb 17 17:39:00.742: INFO: ibm-storage-watcher-799f6c5b69-zhj9j from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb 17 17:39:00.742: INFO: calico-kube-controllers-598ddbf99d-vhtrf from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:39:00.742: INFO: olm-operator-7bf4dbc978-4rx8l from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container olm-operator ready: true, restart count 0
Feb 17 17:39:00.742: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 from kube-system started at 2020-02-17 14:49:07 +0000 UTC (4 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:39:00.742: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:39:00.742: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:39:00.742: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:39:00.742: INFO: dashboard-metrics-scraper-5cbd6549b8-r5tv4 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Feb 17 17:39:00.742: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:39:00.742: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:39:00.742: INFO: coredns-autoscaler-65c89858bf-df7mx from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:39:00.742: INFO: calico-node-nrkf6 from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:39:00.742: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 from ibm-system started at 2020-02-17 14:49:07 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:39:00.742: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:03:08 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 17:39:00.742: INFO: coredns-bc786c74-624xw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:39:00.742: INFO: ibm-master-proxy-static-10.241.69.130 from kube-system started at 2020-02-17 14:48:46 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:39:00.742: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:39:00.742: INFO: ibm-keepalived-watcher-qgfgw from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:39:00.742: INFO: coredns-bc786c74-79vl2 from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.742: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:39:00.742: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.147 before test
Feb 17 17:39:00.942: INFO: calico-node-4vlb4 from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.942: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:39:00.942: INFO: addon-catalog-source-bqjh8 from ibm-system started at 2020-02-17 14:44:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.942: INFO: 	Container configmap-registry-server ready: true, restart count 0
Feb 17 17:39:00.942: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:00.942: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:39:00.942: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:39:00.942: INFO: ibm-master-proxy-static-10.241.69.147 from kube-system started at 2020-02-17 14:40:19 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:00.942: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:39:00.942: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:39:00.942: INFO: ibm-keepalived-watcher-rh8sm from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:00.942: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:39:00.942: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.151 before test
Feb 17 17:39:01.355: INFO: ibm-master-proxy-static-10.241.69.151 from kube-system started at 2020-02-17 14:50:33 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:01.355: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:39:01.355: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:39:01.356: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-2hx9m from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.356: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:39:01.356: INFO: ibm-file-plugin-5568fbb4d7-8vzx9 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.356: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
Feb 17 17:39:01.356: INFO: calico-node-nr68s from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.356: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:39:01.356: INFO: sonobuoy-e2e-job-ae741cd10f3545c2 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:01.356: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:39:01.356: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:39:01.356: INFO: metrics-server-5bf499b69-9cwsk from kube-system started at 2020-02-17 16:20:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:01.356: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:39:01.357: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:39:01.357: INFO: vpn-79845b6f9d-zgk7f from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:39:01.357: INFO: kubernetes-dashboard-6dbd4db8bf-sjswh from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:39:01.357: INFO: coredns-bc786c74-x59lf from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:39:01.357: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:39:01.357: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:39:01.357: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-ml8mw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (4 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:39:01.357: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:39:01.357: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:39:01.357: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:39:01.357: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:52:12 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:39:01.357: INFO: ibm-keepalived-watcher-4n299 from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:39:01.357: INFO: catalog-operator-6d6c965db-dxspz from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:39:01.357: INFO: 	Container catalog-operator ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6c12a5cd-aa29-48eb-b9a0-fcc4e67bee0a 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-6c12a5cd-aa29-48eb-b9a0-fcc4e67bee0a off the node 10.241.69.147
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6c12a5cd-aa29-48eb-b9a0-fcc4e67bee0a
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:39:12.024: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1256" for this suite.
Feb 17 17:39:34.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:39:34.839: INFO: namespace sched-pred-1256 deletion completed in 22.777392979s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:34.683 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:39:34.840: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Feb 17 17:39:39.756: INFO: Successfully updated pod "pod-update-activedeadlineseconds-bf7f2af7-8f10-44af-9886-827d508f9a72"
Feb 17 17:39:39.756: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-bf7f2af7-8f10-44af-9886-827d508f9a72" in namespace "pods-7102" to be "terminated due to deadline exceeded"
Feb 17 17:39:39.782: INFO: Pod "pod-update-activedeadlineseconds-bf7f2af7-8f10-44af-9886-827d508f9a72": Phase="Running", Reason="", readiness=true. Elapsed: 26.067436ms
Feb 17 17:39:41.800: INFO: Pod "pod-update-activedeadlineseconds-bf7f2af7-8f10-44af-9886-827d508f9a72": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.044102797s
Feb 17 17:39:41.801: INFO: Pod "pod-update-activedeadlineseconds-bf7f2af7-8f10-44af-9886-827d508f9a72" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:39:41.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7102" for this suite.
Feb 17 17:39:49.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:39:50.454: INFO: namespace pods-7102 deletion completed in 8.632578258s

• [SLOW TEST:15.614 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:39:50.455: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2727
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Feb 17 17:39:50.790: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:39:59.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2727" for this suite.
Feb 17 17:40:07.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:40:08.541: INFO: namespace pods-2727 deletion completed in 9.044398728s

• [SLOW TEST:18.086 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:40:08.541: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2498
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:40:09.046: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297" in namespace "downward-api-2498" to be "success or failure"
Feb 17 17:40:09.077: INFO: Pod "downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297": Phase="Pending", Reason="", readiness=false. Elapsed: 30.846487ms
Feb 17 17:40:11.100: INFO: Pod "downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053667517s
Feb 17 17:40:13.118: INFO: Pod "downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071118324s
STEP: Saw pod success
Feb 17 17:40:13.118: INFO: Pod "downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297" satisfied condition "success or failure"
Feb 17 17:40:13.134: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297 container client-container: <nil>
STEP: delete the pod
Feb 17 17:40:13.246: INFO: Waiting for pod downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297 to disappear
Feb 17 17:40:13.278: INFO: Pod downwardapi-volume-d8c8abfc-b82d-4aac-be89-e8f0e3e83297 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:40:13.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2498" for this suite.
Feb 17 17:40:21.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:40:22.018: INFO: namespace downward-api-2498 deletion completed in 8.711909864s

• [SLOW TEST:13.478 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:40:22.020: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3538
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3538
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 17:40:22.308: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 17:40:46.727: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.186.136:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3538 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:40:46.727: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:40:46.954: INFO: Found all expected endpoints: [netserver-0]
Feb 17 17:40:46.968: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.84.48:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3538 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:40:46.968: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:40:47.199: INFO: Found all expected endpoints: [netserver-1]
Feb 17 17:40:47.211: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.30.104.25:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-3538 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:40:47.211: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:40:47.422: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:40:47.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3538" for this suite.
Feb 17 17:41:01.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:41:02.428: INFO: namespace pod-network-test-3538 deletion completed in 14.975488103s

• [SLOW TEST:40.408 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:41:02.429: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-4864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Feb 17 17:41:03.545: INFO: created pod pod-service-account-defaultsa
Feb 17 17:41:03.545: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Feb 17 17:41:03.586: INFO: created pod pod-service-account-mountsa
Feb 17 17:41:03.586: INFO: pod pod-service-account-mountsa service account token volume mount: true
Feb 17 17:41:03.625: INFO: created pod pod-service-account-nomountsa
Feb 17 17:41:03.625: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Feb 17 17:41:03.658: INFO: created pod pod-service-account-defaultsa-mountspec
Feb 17 17:41:03.658: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Feb 17 17:41:03.765: INFO: created pod pod-service-account-mountsa-mountspec
Feb 17 17:41:03.765: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Feb 17 17:41:03.838: INFO: created pod pod-service-account-nomountsa-mountspec
Feb 17 17:41:03.838: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Feb 17 17:41:03.880: INFO: created pod pod-service-account-defaultsa-nomountspec
Feb 17 17:41:03.880: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Feb 17 17:41:03.934: INFO: created pod pod-service-account-mountsa-nomountspec
Feb 17 17:41:03.934: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Feb 17 17:41:03.960: INFO: created pod pod-service-account-nomountsa-nomountspec
Feb 17 17:41:03.960: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:41:03.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4864" for this suite.
Feb 17 17:41:12.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:41:13.041: INFO: namespace svcaccounts-4864 deletion completed in 9.022423843s

• [SLOW TEST:10.613 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:41:13.042: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5253
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-25d2fd5c-439f-4449-ac09-eb1db4002c5c in namespace container-probe-5253
Feb 17 17:41:17.445: INFO: Started pod test-webserver-25d2fd5c-439f-4449-ac09-eb1db4002c5c in namespace container-probe-5253
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:41:17.460: INFO: Initial restart count of pod test-webserver-25d2fd5c-439f-4449-ac09-eb1db4002c5c is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:45:19.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5253" for this suite.
Feb 17 17:45:27.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:27.774: INFO: namespace container-probe-5253 deletion completed in 8.703206177s

• [SLOW TEST:254.733 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:45:27.774: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Feb 17 17:45:30.250: INFO: Pod pod-hostip-d4c0c1d2-4530-4338-b05a-6fc6f9ad1f5d has hostIP: 10.241.69.147
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:45:30.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9730" for this suite.
Feb 17 17:45:42.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:42.898: INFO: namespace pods-9730 deletion completed in 12.622111388s

• [SLOW TEST:15.124 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:45:42.899: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6886
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Feb 17 17:45:43.198: INFO: Waiting up to 5m0s for pod "pod-1b990300-30b3-4479-a22b-70235601f613" in namespace "emptydir-6886" to be "success or failure"
Feb 17 17:45:43.223: INFO: Pod "pod-1b990300-30b3-4479-a22b-70235601f613": Phase="Pending", Reason="", readiness=false. Elapsed: 24.148044ms
Feb 17 17:45:45.238: INFO: Pod "pod-1b990300-30b3-4479-a22b-70235601f613": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039431604s
STEP: Saw pod success
Feb 17 17:45:45.238: INFO: Pod "pod-1b990300-30b3-4479-a22b-70235601f613" satisfied condition "success or failure"
Feb 17 17:45:45.254: INFO: Trying to get logs from node 10.241.69.147 pod pod-1b990300-30b3-4479-a22b-70235601f613 container test-container: <nil>
STEP: delete the pod
Feb 17 17:45:45.406: INFO: Waiting for pod pod-1b990300-30b3-4479-a22b-70235601f613 to disappear
Feb 17 17:45:45.423: INFO: Pod pod-1b990300-30b3-4479-a22b-70235601f613 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:45:45.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6886" for this suite.
Feb 17 17:45:53.641: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:45:54.266: INFO: namespace emptydir-6886 deletion completed in 8.6961353s

• [SLOW TEST:11.368 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:45:54.267: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9315
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:45:55.102: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:45:57.147: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558355, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558355, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558355, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558355, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:46:00.193: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Feb 17 17:46:00.289: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:46:00.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9315" for this suite.
Feb 17 17:46:08.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:46:09.346: INFO: namespace webhook-9315 deletion completed in 8.984101486s
STEP: Destroying namespace "webhook-9315-markers" for this suite.
Feb 17 17:46:15.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:46:16.138: INFO: namespace webhook-9315-markers deletion completed in 6.791313017s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.936 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:46:16.203: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Feb 17 17:46:22.758: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:22.758: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:22.994: INFO: Exec stderr: ""
Feb 17 17:46:22.994: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:22.994: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:23.223: INFO: Exec stderr: ""
Feb 17 17:46:23.223: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:23.223: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:23.502: INFO: Exec stderr: ""
Feb 17 17:46:23.503: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:23.503: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:23.730: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Feb 17 17:46:23.730: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:23.730: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:23.939: INFO: Exec stderr: ""
Feb 17 17:46:23.939: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:23.939: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:24.180: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Feb 17 17:46:24.181: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:24.181: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:24.415: INFO: Exec stderr: ""
Feb 17 17:46:24.415: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:24.415: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:24.644: INFO: Exec stderr: ""
Feb 17 17:46:24.644: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:24.644: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:24.886: INFO: Exec stderr: ""
Feb 17 17:46:24.886: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-455 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 17:46:24.886: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 17:46:25.095: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:46:25.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-455" for this suite.
Feb 17 17:47:11.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:47:12.154: INFO: namespace e2e-kubelet-etc-hosts-455 deletion completed in 47.041236136s

• [SLOW TEST:55.950 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:47:12.154: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-974
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1028
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4464
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:47:20.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-974" for this suite.
Feb 17 17:47:28.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:47:29.057: INFO: namespace namespaces-974 deletion completed in 8.735337422s
STEP: Destroying namespace "nsdeletetest-1028" for this suite.
Feb 17 17:47:29.078: INFO: Namespace nsdeletetest-1028 was already deleted
STEP: Destroying namespace "nsdeletetest-4464" for this suite.
Feb 17 17:47:35.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:47:35.883: INFO: namespace nsdeletetest-4464 deletion completed in 6.80459671s

• [SLOW TEST:23.728 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:47:35.883: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6403
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 17:47:36.209: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c" in namespace "projected-6403" to be "success or failure"
Feb 17 17:47:36.234: INFO: Pod "downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.609341ms
Feb 17 17:47:38.247: INFO: Pod "downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038317517s
Feb 17 17:47:40.265: INFO: Pod "downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.055478824s
STEP: Saw pod success
Feb 17 17:47:40.265: INFO: Pod "downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c" satisfied condition "success or failure"
Feb 17 17:47:40.282: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c container client-container: <nil>
STEP: delete the pod
Feb 17 17:47:40.469: INFO: Waiting for pod downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c to disappear
Feb 17 17:47:40.487: INFO: Pod downwardapi-volume-0d9589f1-b0a5-4ceb-a5df-06dcbee5629c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:47:40.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6403" for this suite.
Feb 17 17:47:46.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:47:47.126: INFO: namespace projected-6403 deletion completed in 6.613828324s

• [SLOW TEST:11.243 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:47:47.127: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Feb 17 17:47:47.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 api-versions'
Feb 17 17:47:47.516: INFO: stderr: ""
Feb 17 17:47:47.516: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\nbatch/v2alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:47:47.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6177" for this suite.
Feb 17 17:47:55.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:47:56.160: INFO: namespace kubectl-6177 deletion completed in 8.624344259s

• [SLOW TEST:9.034 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:47:56.161: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Feb 17 17:47:56.478: INFO: Waiting up to 5m0s for pod "client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6" in namespace "containers-1797" to be "success or failure"
Feb 17 17:47:56.537: INFO: Pod "client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6": Phase="Pending", Reason="", readiness=false. Elapsed: 58.241288ms
Feb 17 17:47:58.553: INFO: Pod "client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.074693738s
STEP: Saw pod success
Feb 17 17:47:58.553: INFO: Pod "client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6" satisfied condition "success or failure"
Feb 17 17:47:58.575: INFO: Trying to get logs from node 10.241.69.147 pod client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6 container test-container: <nil>
STEP: delete the pod
Feb 17 17:47:58.689: INFO: Waiting for pod client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6 to disappear
Feb 17 17:47:58.703: INFO: Pod client-containers-e7fa067a-c845-4013-86b8-7037a95dcfa6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:47:58.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1797" for this suite.
Feb 17 17:48:06.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:07.666: INFO: namespace containers-1797 deletion completed in 8.93018458s

• [SLOW TEST:11.505 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:48:07.668: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3036
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Feb 17 17:48:08.058: INFO: Waiting up to 5m0s for pod "var-expansion-7848fd15-d6de-479c-9c54-752e83cac439" in namespace "var-expansion-3036" to be "success or failure"
Feb 17 17:48:08.085: INFO: Pod "var-expansion-7848fd15-d6de-479c-9c54-752e83cac439": Phase="Pending", Reason="", readiness=false. Elapsed: 26.966524ms
Feb 17 17:48:10.109: INFO: Pod "var-expansion-7848fd15-d6de-479c-9c54-752e83cac439": Phase="Running", Reason="", readiness=true. Elapsed: 2.051811094s
Feb 17 17:48:12.136: INFO: Pod "var-expansion-7848fd15-d6de-479c-9c54-752e83cac439": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.078157996s
STEP: Saw pod success
Feb 17 17:48:12.136: INFO: Pod "var-expansion-7848fd15-d6de-479c-9c54-752e83cac439" satisfied condition "success or failure"
Feb 17 17:48:12.155: INFO: Trying to get logs from node 10.241.69.147 pod var-expansion-7848fd15-d6de-479c-9c54-752e83cac439 container dapi-container: <nil>
STEP: delete the pod
Feb 17 17:48:12.274: INFO: Waiting for pod var-expansion-7848fd15-d6de-479c-9c54-752e83cac439 to disappear
Feb 17 17:48:12.301: INFO: Pod var-expansion-7848fd15-d6de-479c-9c54-752e83cac439 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:48:12.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3036" for this suite.
Feb 17 17:48:20.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:21.055: INFO: namespace var-expansion-3036 deletion completed in 8.713085091s

• [SLOW TEST:13.387 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:48:21.055: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-683
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 17:48:21.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-683'
Feb 17 17:48:21.579: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 17:48:21.579: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Feb 17 17:48:25.642: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete deployment e2e-test-httpd-deployment --namespace=kubectl-683'
Feb 17 17:48:25.819: INFO: stderr: ""
Feb 17 17:48:25.819: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:48:25.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-683" for this suite.
Feb 17 17:48:55.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:48:56.496: INFO: namespace kubectl-683 deletion completed in 30.647309226s

• [SLOW TEST:35.440 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:48:56.496: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a31a14cc-faf1-4d7f-8279-88d2e94ba971
STEP: Creating a pod to test consume configMaps
Feb 17 17:48:56.840: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6" in namespace "projected-3090" to be "success or failure"
Feb 17 17:48:56.856: INFO: Pod "pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6": Phase="Pending", Reason="", readiness=false. Elapsed: 15.605601ms
Feb 17 17:48:58.873: INFO: Pod "pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03299244s
STEP: Saw pod success
Feb 17 17:48:58.873: INFO: Pod "pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6" satisfied condition "success or failure"
Feb 17 17:48:58.892: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:48:58.983: INFO: Waiting for pod pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6 to disappear
Feb 17 17:48:58.997: INFO: Pod pod-projected-configmaps-37b764e9-4ad7-4179-83be-291a083410b6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:48:58.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3090" for this suite.
Feb 17 17:49:07.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:49:08.270: INFO: namespace projected-3090 deletion completed in 9.236029371s

• [SLOW TEST:11.774 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:49:08.270: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Feb 17 17:49:19.031: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0217 17:49:19.031897      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 17 17:49:19.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6901" for this suite.
Feb 17 17:49:29.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:49:29.769: INFO: namespace gc-6901 deletion completed in 10.722514746s

• [SLOW TEST:21.499 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:49:29.770: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6661
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-913af1db-89a4-4900-89a8-13057999e18b
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-913af1db-89a4-4900-89a8-13057999e18b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:49:34.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6661" for this suite.
Feb 17 17:50:04.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:50:05.746: INFO: namespace projected-6661 deletion completed in 31.423536931s

• [SLOW TEST:35.975 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:50:05.746: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8151
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Feb 17 17:50:06.113: INFO: Waiting up to 5m0s for pod "pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc" in namespace "emptydir-8151" to be "success or failure"
Feb 17 17:50:06.153: INFO: Pod "pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc": Phase="Pending", Reason="", readiness=false. Elapsed: 39.61851ms
Feb 17 17:50:08.179: INFO: Pod "pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc": Phase="Running", Reason="", readiness=true. Elapsed: 2.065740986s
Feb 17 17:50:10.211: INFO: Pod "pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.097296965s
STEP: Saw pod success
Feb 17 17:50:10.211: INFO: Pod "pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc" satisfied condition "success or failure"
Feb 17 17:50:10.242: INFO: Trying to get logs from node 10.241.69.147 pod pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc container test-container: <nil>
STEP: delete the pod
Feb 17 17:50:10.414: INFO: Waiting for pod pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc to disappear
Feb 17 17:50:10.439: INFO: Pod pod-b12fe0ca-d6a0-447b-94f2-89bf061156cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:50:10.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8151" for this suite.
Feb 17 17:50:18.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:50:19.120: INFO: namespace emptydir-8151 deletion completed in 8.655691585s

• [SLOW TEST:13.374 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:50:19.120: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 17 17:50:19.433: INFO: Waiting up to 5m0s for pod "pod-304d00ce-b644-4471-ad17-59d14074e75c" in namespace "emptydir-9954" to be "success or failure"
Feb 17 17:50:19.448: INFO: Pod "pod-304d00ce-b644-4471-ad17-59d14074e75c": Phase="Pending", Reason="", readiness=false. Elapsed: 14.840974ms
Feb 17 17:50:21.471: INFO: Pod "pod-304d00ce-b644-4471-ad17-59d14074e75c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0377967s
Feb 17 17:50:23.496: INFO: Pod "pod-304d00ce-b644-4471-ad17-59d14074e75c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.063315571s
STEP: Saw pod success
Feb 17 17:50:23.496: INFO: Pod "pod-304d00ce-b644-4471-ad17-59d14074e75c" satisfied condition "success or failure"
Feb 17 17:50:23.513: INFO: Trying to get logs from node 10.241.69.147 pod pod-304d00ce-b644-4471-ad17-59d14074e75c container test-container: <nil>
STEP: delete the pod
Feb 17 17:50:23.620: INFO: Waiting for pod pod-304d00ce-b644-4471-ad17-59d14074e75c to disappear
Feb 17 17:50:23.633: INFO: Pod pod-304d00ce-b644-4471-ad17-59d14074e75c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:50:23.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9954" for this suite.
Feb 17 17:50:31.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:50:32.348: INFO: namespace emptydir-9954 deletion completed in 8.695746022s

• [SLOW TEST:13.228 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:50:32.351: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-b4fbf5f4-55d7-4df6-a161-67310769857c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:50:32.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3521" for this suite.
Feb 17 17:50:38.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:50:39.326: INFO: namespace secrets-3521 deletion completed in 6.647787601s

• [SLOW TEST:6.975 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:50:39.326: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-624d3c41-53f4-46f6-a042-fa401f1858ae
STEP: Creating a pod to test consume configMaps
Feb 17 17:50:39.667: INFO: Waiting up to 5m0s for pod "pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355" in namespace "configmap-6233" to be "success or failure"
Feb 17 17:50:39.681: INFO: Pod "pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355": Phase="Pending", Reason="", readiness=false. Elapsed: 13.80003ms
Feb 17 17:50:41.698: INFO: Pod "pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355": Phase="Pending", Reason="", readiness=false. Elapsed: 2.030166043s
Feb 17 17:50:43.715: INFO: Pod "pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.048004567s
STEP: Saw pod success
Feb 17 17:50:43.715: INFO: Pod "pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355" satisfied condition "success or failure"
Feb 17 17:50:43.733: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:50:43.822: INFO: Waiting for pod pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355 to disappear
Feb 17 17:50:43.841: INFO: Pod pod-configmaps-5348e4cb-bd6a-4f4e-8c37-cbf621cbb355 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:50:43.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6233" for this suite.
Feb 17 17:50:51.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:50:52.516: INFO: namespace configmap-6233 deletion completed in 8.653399175s

• [SLOW TEST:13.190 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:50:52.516: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9370
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Feb 17 17:50:52.921: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-964215725 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:50:53.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9370" for this suite.
Feb 17 17:51:01.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:51:02.063: INFO: namespace kubectl-9370 deletion completed in 8.989237294s

• [SLOW TEST:9.547 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:51:02.063: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-2091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Feb 17 17:51:02.460: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Feb 17 17:51:03.026: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Feb 17 17:51:05.306: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558662, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:51:07.327: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558662, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:51:09.334: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558662, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:51:11.323: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558663, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558662, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 17:51:16.465: INFO: Waited 3.040909447s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:51:17.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-2091" for this suite.
Feb 17 17:51:25.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:51:26.142: INFO: namespace aggregator-2091 deletion completed in 8.821928564s

• [SLOW TEST:24.079 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:51:26.142: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Feb 17 17:51:26.489: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:51:26.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2573" for this suite.
Feb 17 17:51:34.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:51:35.395: INFO: namespace replication-controller-2573 deletion completed in 8.790355377s

• [SLOW TEST:9.253 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:51:35.396: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3916
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:51:35.717: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 17 17:51:40.778: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3916 create -f -'
Feb 17 17:51:41.560: INFO: stderr: ""
Feb 17 17:51:41.560: INFO: stdout: "e2e-test-crd-publish-openapi-5887-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 17 17:51:41.560: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3916 delete e2e-test-crd-publish-openapi-5887-crds test-cr'
Feb 17 17:51:41.732: INFO: stderr: ""
Feb 17 17:51:41.732: INFO: stdout: "e2e-test-crd-publish-openapi-5887-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Feb 17 17:51:41.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3916 apply -f -'
Feb 17 17:51:42.250: INFO: stderr: ""
Feb 17 17:51:42.250: INFO: stdout: "e2e-test-crd-publish-openapi-5887-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Feb 17 17:51:42.250: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3916 delete e2e-test-crd-publish-openapi-5887-crds test-cr'
Feb 17 17:51:42.507: INFO: stderr: ""
Feb 17 17:51:42.507: INFO: stdout: "e2e-test-crd-publish-openapi-5887-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 17 17:51:42.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-5887-crds'
Feb 17 17:51:42.728: INFO: stderr: ""
Feb 17 17:51:42.728: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5887-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:51:47.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3916" for this suite.
Feb 17 17:51:53.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:51:54.536: INFO: namespace crd-publish-openapi-3916 deletion completed in 6.629381285s

• [SLOW TEST:19.139 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:51:54.545: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2598
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-b3fa24bc-2c5d-4836-b45d-b6413a619066
STEP: Creating secret with name s-test-opt-upd-eb5c2c4a-1d55-46bb-a511-8442ce0dac4a
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-b3fa24bc-2c5d-4836-b45d-b6413a619066
STEP: Updating secret s-test-opt-upd-eb5c2c4a-1d55-46bb-a511-8442ce0dac4a
STEP: Creating secret with name s-test-opt-create-c32c5bac-af47-4f29-a85f-1e42bb65bbcf
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:51:59.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2598" for this suite.
Feb 17 17:52:31.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:52:32.194: INFO: namespace secrets-2598 deletion completed in 32.767050079s

• [SLOW TEST:37.650 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:52:32.195: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5327
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5327.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5327.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 157.46.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.46.157_udp@PTR;check="$$(dig +tcp +noall +answer +search 157.46.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.46.157_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5327.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5327.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5327.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5327.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5327.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 157.46.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.46.157_udp@PTR;check="$$(dig +tcp +noall +answer +search 157.46.21.172.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/172.21.46.157_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 17:52:36.681: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:36.751: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:36.814: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:37.314: INFO: Unable to read jessie_tcp@dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:37.340: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:37.366: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:37.575: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_tcp@dns-test-service.dns-5327.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:52:42.674: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:42.701: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:42.994: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:43.016: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:43.175: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:52:47.672: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:47.698: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:47.931: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:47.954: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:48.118: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:52:52.675: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:52.705: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:52.994: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:53.022: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:53.190: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:52:57.678: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:57.705: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:57.939: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:57.970: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:52:58.134: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:53:02.691: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:53:02.745: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:53:03.131: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:53:03.175: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local from pod dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073: the server could not find the requested resource (get pods dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073)
Feb 17 17:53:03.442: INFO: Lookups using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 failed for: [wheezy_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5327.svc.cluster.local]

Feb 17 17:53:08.519: INFO: DNS probes using dns-5327/dns-test-4caa08c7-3f7d-430c-9c6d-b8899492e073 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:53:08.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5327" for this suite.
Feb 17 17:53:16.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:17.587: INFO: namespace dns-5327 deletion completed in 8.726151382s

• [SLOW TEST:45.392 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:53:17.587: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6763
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:53:18.662: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:53:20.700: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558798, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558798, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558798, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558798, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:53:24.229: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 17:53:24.248: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9663-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:53:25.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6763" for this suite.
Feb 17 17:53:33.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:34.516: INFO: namespace webhook-6763 deletion completed in 8.744464298s
STEP: Destroying namespace "webhook-6763-markers" for this suite.
Feb 17 17:53:40.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:41.231: INFO: namespace webhook-6763-markers deletion completed in 6.715636156s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.739 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:53:41.327: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8136
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:53:42.087: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:53:44.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558822, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558822, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558822, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558822, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:53:47.192: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:53:47.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8136" for this suite.
Feb 17 17:53:55.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:53:56.399: INFO: namespace webhook-8136 deletion completed in 8.603646122s
STEP: Destroying namespace "webhook-8136-markers" for this suite.
Feb 17 17:54:04.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:54:05.328: INFO: namespace webhook-8136-markers deletion completed in 8.928222818s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.117 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:54:05.444: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-858
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-ttbx
STEP: Creating a pod to test atomic-volume-subpath
Feb 17 17:54:06.027: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-ttbx" in namespace "subpath-858" to be "success or failure"
Feb 17 17:54:06.070: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Pending", Reason="", readiness=false. Elapsed: 42.775901ms
Feb 17 17:54:08.095: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.068244961s
Feb 17 17:54:10.110: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 4.083555719s
Feb 17 17:54:12.134: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 6.10750657s
Feb 17 17:54:14.160: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 8.133573128s
Feb 17 17:54:16.182: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 10.154667901s
Feb 17 17:54:18.197: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 12.16978501s
Feb 17 17:54:20.214: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 14.186968485s
Feb 17 17:54:22.233: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 16.206386623s
Feb 17 17:54:24.248: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 18.220735238s
Feb 17 17:54:26.265: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Running", Reason="", readiness=true. Elapsed: 20.237998841s
Feb 17 17:54:28.286: INFO: Pod "pod-subpath-test-projected-ttbx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.258772221s
STEP: Saw pod success
Feb 17 17:54:28.286: INFO: Pod "pod-subpath-test-projected-ttbx" satisfied condition "success or failure"
Feb 17 17:54:28.302: INFO: Trying to get logs from node 10.241.69.147 pod pod-subpath-test-projected-ttbx container test-container-subpath-projected-ttbx: <nil>
STEP: delete the pod
Feb 17 17:54:28.485: INFO: Waiting for pod pod-subpath-test-projected-ttbx to disappear
Feb 17 17:54:28.511: INFO: Pod pod-subpath-test-projected-ttbx no longer exists
STEP: Deleting pod pod-subpath-test-projected-ttbx
Feb 17 17:54:28.511: INFO: Deleting pod "pod-subpath-test-projected-ttbx" in namespace "subpath-858"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:54:28.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-858" for this suite.
Feb 17 17:54:36.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:54:37.550: INFO: namespace subpath-858 deletion completed in 9.0033813s

• [SLOW TEST:32.105 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:54:37.552: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3438
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-2fd3864e-21e9-46cd-9555-46bd7f2ac5ad
STEP: Creating a pod to test consume secrets
Feb 17 17:54:37.886: INFO: Waiting up to 5m0s for pod "pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c" in namespace "secrets-3438" to be "success or failure"
Feb 17 17:54:37.911: INFO: Pod "pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c": Phase="Pending", Reason="", readiness=false. Elapsed: 24.238927ms
Feb 17 17:54:39.927: INFO: Pod "pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c": Phase="Running", Reason="", readiness=true. Elapsed: 2.040794089s
Feb 17 17:54:41.953: INFO: Pod "pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.066496603s
STEP: Saw pod success
Feb 17 17:54:41.953: INFO: Pod "pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c" satisfied condition "success or failure"
Feb 17 17:54:41.978: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 17:54:42.065: INFO: Waiting for pod pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c to disappear
Feb 17 17:54:42.086: INFO: Pod pod-secrets-97d38914-612f-448f-b987-7c2f225adf7c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:54:42.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3438" for this suite.
Feb 17 17:54:50.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:54:50.952: INFO: namespace secrets-3438 deletion completed in 8.839029931s

• [SLOW TEST:13.400 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:54:50.953: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3877
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Feb 17 17:54:51.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-3877'
Feb 17 17:54:51.702: INFO: stderr: ""
Feb 17 17:54:51.702: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Feb 17 17:54:51.702: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3877'
Feb 17 17:54:51.839: INFO: stderr: ""
Feb 17 17:54:51.839: INFO: stdout: "update-demo-nautilus-bppbj update-demo-nautilus-vtxlb "
Feb 17 17:54:51.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-bppbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Feb 17 17:54:51.983: INFO: stderr: ""
Feb 17 17:54:51.983: INFO: stdout: ""
Feb 17 17:54:51.983: INFO: update-demo-nautilus-bppbj is created but not running
Feb 17 17:54:56.983: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3877'
Feb 17 17:54:57.138: INFO: stderr: ""
Feb 17 17:54:57.139: INFO: stdout: "update-demo-nautilus-bppbj update-demo-nautilus-vtxlb "
Feb 17 17:54:57.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-bppbj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Feb 17 17:54:57.308: INFO: stderr: ""
Feb 17 17:54:57.308: INFO: stdout: "true"
Feb 17 17:54:57.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-bppbj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Feb 17 17:54:57.448: INFO: stderr: ""
Feb 17 17:54:57.448: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 17:54:57.448: INFO: validating pod update-demo-nautilus-bppbj
Feb 17 17:54:57.483: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 17:54:57.483: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 17:54:57.483: INFO: update-demo-nautilus-bppbj is verified up and running
Feb 17 17:54:57.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-vtxlb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Feb 17 17:54:57.626: INFO: stderr: ""
Feb 17 17:54:57.626: INFO: stdout: "true"
Feb 17 17:54:57.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods update-demo-nautilus-vtxlb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3877'
Feb 17 17:54:57.762: INFO: stderr: ""
Feb 17 17:54:57.762: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Feb 17 17:54:57.762: INFO: validating pod update-demo-nautilus-vtxlb
Feb 17 17:54:57.794: INFO: got data: {
  "image": "nautilus.jpg"
}

Feb 17 17:54:57.794: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Feb 17 17:54:57.794: INFO: update-demo-nautilus-vtxlb is verified up and running
STEP: using delete to clean up resources
Feb 17 17:54:57.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete --grace-period=0 --force -f - --namespace=kubectl-3877'
Feb 17 17:54:57.964: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Feb 17 17:54:57.964: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Feb 17 17:54:57.964: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3877'
Feb 17 17:54:58.135: INFO: stderr: "No resources found in kubectl-3877 namespace.\n"
Feb 17 17:54:58.135: INFO: stdout: ""
Feb 17 17:54:58.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -l name=update-demo --namespace=kubectl-3877 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Feb 17 17:54:58.266: INFO: stderr: ""
Feb 17 17:54:58.266: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:54:58.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3877" for this suite.
Feb 17 17:55:12.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:55:13.129: INFO: namespace kubectl-3877 deletion completed in 14.838411867s

• [SLOW TEST:22.175 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:55:13.129: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9157
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Feb 17 17:55:13.411: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9157'
Feb 17 17:55:13.651: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Feb 17 17:55:13.651: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Feb 17 17:55:13.671: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Feb 17 17:55:13.676: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Feb 17 17:55:13.736: INFO: scanned /root for discovery docs: <nil>
Feb 17 17:55:13.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9157'
Feb 17 17:55:29.751: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Feb 17 17:55:29.751: INFO: stdout: "Created e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403\nScaling up e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Feb 17 17:55:29.751: INFO: stdout: "Created e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403\nScaling up e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Feb 17 17:55:29.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9157'
Feb 17 17:55:29.883: INFO: stderr: ""
Feb 17 17:55:29.883: INFO: stdout: "e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403-92v4s "
Feb 17 17:55:29.883: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403-92v4s -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9157'
Feb 17 17:55:30.053: INFO: stderr: ""
Feb 17 17:55:30.053: INFO: stdout: "true"
Feb 17 17:55:30.053: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 get pods e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403-92v4s -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9157'
Feb 17 17:55:30.186: INFO: stderr: ""
Feb 17 17:55:30.187: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Feb 17 17:55:30.187: INFO: e2e-test-httpd-rc-16ff6fca229e3a13c363d8a5ecd6f403-92v4s is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Feb 17 17:55:30.187: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete rc e2e-test-httpd-rc --namespace=kubectl-9157'
Feb 17 17:55:30.335: INFO: stderr: ""
Feb 17 17:55:30.335: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:55:30.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9157" for this suite.
Feb 17 17:55:44.432: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:55:45.136: INFO: namespace kubectl-9157 deletion completed in 14.774605082s

• [SLOW TEST:32.006 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:55:45.144: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3390
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:55:45.916: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 17:55:47.960: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558945, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558945, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558945, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717558945, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:55:51.013: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Feb 17 17:55:55.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 attach --namespace=webhook-3390 to-be-attached-pod -i -c=container1'
Feb 17 17:55:55.417: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:55:55.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3390" for this suite.
Feb 17 17:56:09.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:56:10.316: INFO: namespace webhook-3390 deletion completed in 14.848277483s
STEP: Destroying namespace "webhook-3390-markers" for this suite.
Feb 17 17:56:16.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:56:17.016: INFO: namespace webhook-3390-markers deletion completed in 6.700181484s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.942 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:56:17.087: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Feb 17 17:56:17.972: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Feb 17 17:56:18.039: INFO: Waiting for terminating namespaces to be deleted...
Feb 17 17:56:18.061: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.130 before test
Feb 17 17:56:18.221: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:56:18.221: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:56:18.221: INFO: coredns-autoscaler-65c89858bf-df7mx from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container autoscaler ready: true, restart count 0
Feb 17 17:56:18.221: INFO: ibm-master-proxy-static-10.241.69.130 from kube-system started at 2020-02-17 14:48:46 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:56:18.221: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:56:18.221: INFO: ibm-keepalived-watcher-qgfgw from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:56:18.221: INFO: calico-node-nrkf6 from kube-system started at 2020-02-17 14:48:48 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:56:18.221: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 from ibm-system started at 2020-02-17 14:49:07 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:56:18.221: INFO: sonobuoy from sonobuoy started at 2020-02-17 16:03:08 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Feb 17 17:56:18.221: INFO: coredns-bc786c74-624xw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:56:18.221: INFO: coredns-bc786c74-79vl2 from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:56:18.221: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 from kube-system started at 2020-02-17 14:49:07 +0000 UTC (4 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:56:18.221: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:56:18.221: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:56:18.221: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:56:18.221: INFO: dashboard-metrics-scraper-5cbd6549b8-r5tv4 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container dashboard-metrics-scraper ready: true, restart count 0
Feb 17 17:56:18.221: INFO: ibm-storage-watcher-799f6c5b69-zhj9j from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container ibm-storage-watcher-container ready: true, restart count 0
Feb 17 17:56:18.221: INFO: calico-kube-controllers-598ddbf99d-vhtrf from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Feb 17 17:56:18.221: INFO: olm-operator-7bf4dbc978-4rx8l from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.221: INFO: 	Container olm-operator ready: true, restart count 0
Feb 17 17:56:18.221: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.147 before test
Feb 17 17:56:18.331: INFO: ibm-master-proxy-static-10.241.69.147 from kube-system started at 2020-02-17 14:40:19 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.331: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:56:18.331: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:56:18.331: INFO: ibm-keepalived-watcher-rh8sm from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.331: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:56:18.331: INFO: calico-node-4vlb4 from kube-system started at 2020-02-17 14:40:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.331: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:56:18.331: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.331: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:56:18.331: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:56:18.331: INFO: addon-catalog-source-bqjh8 from ibm-system started at 2020-02-17 14:44:25 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.331: INFO: 	Container configmap-registry-server ready: true, restart count 0
Feb 17 17:56:18.331: INFO: 
Logging pods the kubelet thinks is on node 10.241.69.151 before test
Feb 17 17:56:18.464: INFO: kubernetes-dashboard-6dbd4db8bf-sjswh from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Feb 17 17:56:18.464: INFO: calico-node-nr68s from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container calico-node ready: true, restart count 0
Feb 17 17:56:18.464: INFO: sonobuoy-e2e-job-ae741cd10f3545c2 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container e2e ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Feb 17 17:56:18.464: INFO: metrics-server-5bf499b69-9cwsk from kube-system started at 2020-02-17 16:20:10 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container metrics-server ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container metrics-server-nanny ready: true, restart count 0
Feb 17 17:56:18.464: INFO: vpn-79845b6f9d-zgk7f from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container vpn ready: true, restart count 0
Feb 17 17:56:18.464: INFO: coredns-bc786c74-x59lf from kube-system started at 2020-02-17 14:56:56 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container coredns ready: true, restart count 0
Feb 17 17:56:18.464: INFO: sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 from sonobuoy started at 2020-02-17 16:03:13 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Feb 17 17:56:18.464: INFO: 	Container systemd-logs ready: true, restart count 0
Feb 17 17:56:18.464: INFO: public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-ml8mw from kube-system started at 2020-02-17 16:20:10 +0000 UTC (4 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container ingress-auth-1 ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container ingress-auth-2 ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container ingress-auth-3 ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container nginx-ingress ready: true, restart count 0
Feb 17 17:56:18.464: INFO: test-k8s-e2e-pvg-master-verification from default started at 2020-02-17 14:52:12 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container test-k8s-e2e-pvg-master-verification ready: true, restart count 0
Feb 17 17:56:18.464: INFO: ibm-keepalived-watcher-4n299 from kube-system started at 2020-02-17 14:50:35 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container keepalived-watcher ready: true, restart count 0
Feb 17 17:56:18.464: INFO: catalog-operator-6d6c965db-dxspz from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container catalog-operator ready: true, restart count 0
Feb 17 17:56:18.464: INFO: ibm-master-proxy-static-10.241.69.151 from kube-system started at 2020-02-17 14:50:33 +0000 UTC (2 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container ibm-master-proxy-static ready: true, restart count 0
Feb 17 17:56:18.464: INFO: 	Container pause ready: true, restart count 0
Feb 17 17:56:18.464: INFO: ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-2hx9m from ibm-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container ibm-cloud-provider-ip-169-48-206-158 ready: true, restart count 0
Feb 17 17:56:18.464: INFO: ibm-file-plugin-5568fbb4d7-8vzx9 from kube-system started at 2020-02-17 16:20:10 +0000 UTC (1 container statuses recorded)
Feb 17 17:56:18.464: INFO: 	Container ibm-file-plugin-container ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.241.69.130
STEP: verifying the node has the label node 10.241.69.147
STEP: verifying the node has the label node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod test-k8s-e2e-pvg-master-verification requesting resource cpu=0m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod addon-catalog-source-bqjh8 requesting resource cpu=10m on Node 10.241.69.147
Feb 17 17:56:18.651: INFO: Pod catalog-operator-6d6c965db-dxspz requesting resource cpu=10m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-2hx9m requesting resource cpu=5m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod ibm-cloud-provider-ip-169-48-206-158-59dc5cdf9c-nzbw8 requesting resource cpu=5m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod olm-operator-7bf4dbc978-4rx8l requesting resource cpu=10m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod calico-kube-controllers-598ddbf99d-vhtrf requesting resource cpu=10m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod calico-node-4vlb4 requesting resource cpu=250m on Node 10.241.69.147
Feb 17 17:56:18.651: INFO: Pod calico-node-nr68s requesting resource cpu=250m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod calico-node-nrkf6 requesting resource cpu=250m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod coredns-autoscaler-65c89858bf-df7mx requesting resource cpu=20m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod coredns-bc786c74-624xw requesting resource cpu=100m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod coredns-bc786c74-79vl2 requesting resource cpu=100m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod coredns-bc786c74-x59lf requesting resource cpu=100m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod dashboard-metrics-scraper-5cbd6549b8-r5tv4 requesting resource cpu=1m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod ibm-file-plugin-5568fbb4d7-8vzx9 requesting resource cpu=50m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod ibm-keepalived-watcher-4n299 requesting resource cpu=5m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod ibm-keepalived-watcher-qgfgw requesting resource cpu=5m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod ibm-keepalived-watcher-rh8sm requesting resource cpu=5m on Node 10.241.69.147
Feb 17 17:56:18.651: INFO: Pod ibm-master-proxy-static-10.241.69.130 requesting resource cpu=25m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod ibm-master-proxy-static-10.241.69.147 requesting resource cpu=25m on Node 10.241.69.147
Feb 17 17:56:18.651: INFO: Pod ibm-master-proxy-static-10.241.69.151 requesting resource cpu=25m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod ibm-storage-watcher-799f6c5b69-zhj9j requesting resource cpu=50m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod kubernetes-dashboard-6dbd4db8bf-sjswh requesting resource cpu=50m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod metrics-server-5bf499b69-9cwsk requesting resource cpu=113m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-jprv6 requesting resource cpu=10m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod public-crbp5a39ad0nomcat41hp0-alb1-854cf75699-ml8mw requesting resource cpu=10m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod vpn-79845b6f9d-zgk7f requesting resource cpu=5m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod sonobuoy-e2e-job-ae741cd10f3545c2 requesting resource cpu=0m on Node 10.241.69.151
Feb 17 17:56:18.651: INFO: Pod sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-fwwxq requesting resource cpu=0m on Node 10.241.69.147
Feb 17 17:56:18.651: INFO: Pod sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-k9lrb requesting resource cpu=0m on Node 10.241.69.130
Feb 17 17:56:18.651: INFO: Pod sonobuoy-systemd-logs-daemon-set-5c94a3b880304717-vqw48 requesting resource cpu=0m on Node 10.241.69.151
STEP: Starting Pods to consume most of the cluster CPU.
Feb 17 17:56:18.651: INFO: Creating a pod which consumes cpu=2326m on Node 10.241.69.130
Feb 17 17:56:18.684: INFO: Creating a pod which consumes cpu=2534m on Node 10.241.69.147
Feb 17 17:56:18.699: INFO: Creating a pod which consumes cpu=2300m on Node 10.241.69.151
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a.15f442384ce4a538], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1820/filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a to 10.241.69.130]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a.15f442388b7e2ce2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a.15f442388f262d19], Reason = [Created], Message = [Created container filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a.15f442389892ca54], Reason = [Started], Message = [Started container filler-pod-25011ff5-ee67-4adb-90b8-d5481c153a7a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42.15f442384e359c52], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1820/filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42 to 10.241.69.147]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42.15f442388eea47bc], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42.15f4423892a7d969], Reason = [Created], Message = [Created container filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42.15f442389cf18aa7], Reason = [Started], Message = [Started container filler-pod-d3703945-3aa4-4df8-9893-405fa2dc5c42]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3.15f4423850b23da8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1820/filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3 to 10.241.69.151]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3.15f4423892f9fba2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3.15f44238966b4a71], Reason = [Created], Message = [Created container filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3.15f442389f34a47a], Reason = [Started], Message = [Started container filler-pod-e662dea0-2c3e-4a5d-ba98-709d11e5a0d3]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15f44239438e7ab3], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node 10.241.69.130
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.241.69.147
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.241.69.151
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:56:24.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1820" for this suite.
Feb 17 17:56:32.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:56:32.692: INFO: namespace sched-pred-1820 deletion completed in 8.651092478s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:15.605 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:56:32.693: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-6709
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6709 to expose endpoints map[]
Feb 17 17:56:33.039: INFO: Get endpoints failed (16.452357ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Feb 17 17:56:34.064: INFO: successfully validated that service endpoint-test2 in namespace services-6709 exposes endpoints map[] (1.041597015s elapsed)
STEP: Creating pod pod1 in namespace services-6709
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6709 to expose endpoints map[pod1:[80]]
Feb 17 17:56:37.257: INFO: successfully validated that service endpoint-test2 in namespace services-6709 exposes endpoints map[pod1:[80]] (3.15453978s elapsed)
STEP: Creating pod pod2 in namespace services-6709
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6709 to expose endpoints map[pod1:[80] pod2:[80]]
Feb 17 17:56:39.459: INFO: successfully validated that service endpoint-test2 in namespace services-6709 exposes endpoints map[pod1:[80] pod2:[80]] (2.170479586s elapsed)
STEP: Deleting pod pod1 in namespace services-6709
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6709 to expose endpoints map[pod2:[80]]
Feb 17 17:56:39.525: INFO: successfully validated that service endpoint-test2 in namespace services-6709 exposes endpoints map[pod2:[80]] (36.061831ms elapsed)
STEP: Deleting pod pod2 in namespace services-6709
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-6709 to expose endpoints map[]
Feb 17 17:56:39.570: INFO: successfully validated that service endpoint-test2 in namespace services-6709 exposes endpoints map[] (21.027699ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:56:39.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6709" for this suite.
Feb 17 17:56:47.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:56:48.350: INFO: namespace services-6709 deletion completed in 8.674761947s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.657 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:56:48.351: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1703
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-31162946-7dce-4654-b665-a95bfcf7d78e
STEP: Creating a pod to test consume configMaps
Feb 17 17:56:48.691: INFO: Waiting up to 5m0s for pod "pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7" in namespace "configmap-1703" to be "success or failure"
Feb 17 17:56:48.720: INFO: Pod "pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7": Phase="Pending", Reason="", readiness=false. Elapsed: 29.150221ms
Feb 17 17:56:50.736: INFO: Pod "pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.045409656s
STEP: Saw pod success
Feb 17 17:56:50.736: INFO: Pod "pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7" satisfied condition "success or failure"
Feb 17 17:56:50.754: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7 container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 17:56:50.883: INFO: Waiting for pod pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7 to disappear
Feb 17 17:56:50.911: INFO: Pod pod-configmaps-25aa98ff-d4c9-49ef-8363-3aae7d35dab7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:56:50.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1703" for this suite.
Feb 17 17:56:58.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:56:59.634: INFO: namespace configmap-1703 deletion completed in 8.703235655s

• [SLOW TEST:11.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:56:59.636: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6813
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 17:57:00.816: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Feb 17 17:57:02.888: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559020, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559020, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559021, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559020, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 17:57:05.987: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:57:06.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6813" for this suite.
Feb 17 17:57:14.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:57:15.096: INFO: namespace webhook-6813 deletion completed in 8.783808331s
STEP: Destroying namespace "webhook-6813-markers" for this suite.
Feb 17 17:57:21.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:57:22.143: INFO: namespace webhook-6813-markers deletion completed in 7.04694596s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.584 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:57:22.220: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2166
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Feb 17 17:57:22.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 create -f - --namespace=kubectl-2166'
Feb 17 17:57:22.941: INFO: stderr: ""
Feb 17 17:57:22.941: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Feb 17 17:57:23.961: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:57:23.961: INFO: Found 0 / 1
Feb 17 17:57:24.961: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:57:24.961: INFO: Found 1 / 1
Feb 17 17:57:24.961: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Feb 17 17:57:24.986: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:57:24.986: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Feb 17 17:57:24.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 patch pod redis-master-h8cxq --namespace=kubectl-2166 -p {"metadata":{"annotations":{"x":"y"}}}'
Feb 17 17:57:25.141: INFO: stderr: ""
Feb 17 17:57:25.141: INFO: stdout: "pod/redis-master-h8cxq patched\n"
STEP: checking annotations
Feb 17 17:57:25.161: INFO: Selector matched 1 pods for map[app:redis]
Feb 17 17:57:25.161: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:57:25.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2166" for this suite.
Feb 17 17:57:55.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:57:55.797: INFO: namespace kubectl-2166 deletion completed in 30.600130949s

• [SLOW TEST:33.577 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:57:55.797: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-6229/secret-test-a26e1134-30d5-4fb3-9cbd-71f8ef059cbb
STEP: Creating a pod to test consume secrets
Feb 17 17:57:56.114: INFO: Waiting up to 5m0s for pod "pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e" in namespace "secrets-6229" to be "success or failure"
Feb 17 17:57:56.129: INFO: Pod "pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e": Phase="Pending", Reason="", readiness=false. Elapsed: 14.800371ms
Feb 17 17:57:58.147: INFO: Pod "pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032777725s
STEP: Saw pod success
Feb 17 17:57:58.147: INFO: Pod "pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e" satisfied condition "success or failure"
Feb 17 17:57:58.160: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e container env-test: <nil>
STEP: delete the pod
Feb 17 17:57:58.265: INFO: Waiting for pod pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e to disappear
Feb 17 17:57:58.294: INFO: Pod pod-configmaps-fe3edd0f-9a47-4ca3-8cd5-fffd8482f90e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:57:58.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6229" for this suite.
Feb 17 17:58:06.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:58:07.359: INFO: namespace secrets-6229 deletion completed in 9.041741683s

• [SLOW TEST:11.563 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:58:07.360: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8271
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Feb 17 17:58:37.947: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0217 17:58:37.947901      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 17:58:37.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8271" for this suite.
Feb 17 17:58:46.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 17:58:46.598: INFO: namespace gc-8271 deletion completed in 8.625028018s

• [SLOW TEST:39.238 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 17:58:46.598: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4969
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 in namespace container-probe-4969
Feb 17 17:58:48.959: INFO: Started pod liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 in namespace container-probe-4969
STEP: checking the pod's current state and verifying that restartCount is present
Feb 17 17:58:48.972: INFO: Initial restart count of pod liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is 0
Feb 17 17:59:03.330: INFO: Restart count of pod container-probe-4969/liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is now 1 (14.357848732s elapsed)
Feb 17 17:59:23.627: INFO: Restart count of pod container-probe-4969/liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is now 2 (34.654778127s elapsed)
Feb 17 17:59:41.793: INFO: Restart count of pod container-probe-4969/liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is now 3 (52.820552635s elapsed)
Feb 17 18:00:02.060: INFO: Restart count of pod container-probe-4969/liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is now 4 (1m13.08733416s elapsed)
Feb 17 18:01:06.610: INFO: Restart count of pod container-probe-4969/liveness-8106bbf9-30a8-4230-a34b-40bb4c56e829 is now 5 (2m17.637905416s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:01:06.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4969" for this suite.
Feb 17 18:01:14.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:01:15.819: INFO: namespace container-probe-4969 deletion completed in 8.956131234s

• [SLOW TEST:149.221 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:01:15.820: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1335
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Feb 17 18:01:20.344: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:20.372: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 18:01:22.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:22.392: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 18:01:24.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:24.394: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 18:01:26.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:26.400: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 18:01:28.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:28.387: INFO: Pod pod-with-prestop-exec-hook still exists
Feb 17 18:01:30.372: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Feb 17 18:01:30.389: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:01:30.483: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1335" for this suite.
Feb 17 18:02:00.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:02:01.507: INFO: namespace container-lifecycle-hook-1335 deletion completed in 31.002393523s

• [SLOW TEST:45.688 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:02:01.508: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7165
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-2ce9a95a-c264-4b6b-a189-bba0e771761c
STEP: Creating a pod to test consume configMaps
Feb 17 18:02:01.983: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac" in namespace "projected-7165" to be "success or failure"
Feb 17 18:02:02.111: INFO: Pod "pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac": Phase="Pending", Reason="", readiness=false. Elapsed: 127.420943ms
Feb 17 18:02:04.135: INFO: Pod "pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.151888216s
STEP: Saw pod success
Feb 17 18:02:04.135: INFO: Pod "pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac" satisfied condition "success or failure"
Feb 17 18:02:04.160: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac container projected-configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 18:02:04.341: INFO: Waiting for pod pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac to disappear
Feb 17 18:02:04.395: INFO: Pod pod-projected-configmaps-63e538eb-1b58-4274-9304-bef8614964ac no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:02:04.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7165" for this suite.
Feb 17 18:02:12.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:02:13.438: INFO: namespace projected-7165 deletion completed in 8.989311045s

• [SLOW TEST:11.931 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:02:13.439: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:02:14.431: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:02:17.525: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
Feb 17 18:02:27.657: INFO: Waiting for webhook configuration to be ready...
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:02:40.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-196" for this suite.
Feb 17 18:02:48.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:02:49.179: INFO: namespace webhook-196 deletion completed in 8.619099655s
STEP: Destroying namespace "webhook-196-markers" for this suite.
Feb 17 18:02:55.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:02:55.798: INFO: namespace webhook-196-markers deletion completed in 6.618959371s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:42.441 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:02:55.883: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9852
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:02:56.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815" in namespace "downward-api-9852" to be "success or failure"
Feb 17 18:02:56.220: INFO: Pod "downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815": Phase="Pending", Reason="", readiness=false. Elapsed: 13.732928ms
Feb 17 18:02:58.239: INFO: Pod "downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032633392s
STEP: Saw pod success
Feb 17 18:02:58.239: INFO: Pod "downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815" satisfied condition "success or failure"
Feb 17 18:02:58.258: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815 container client-container: <nil>
STEP: delete the pod
Feb 17 18:02:58.362: INFO: Waiting for pod downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815 to disappear
Feb 17 18:02:58.375: INFO: Pod downwardapi-volume-13ea5f9b-d918-4d93-86a3-dd6d6f441815 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:02:58.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9852" for this suite.
Feb 17 18:03:06.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:03:07.327: INFO: namespace downward-api-9852 deletion completed in 8.925635675s

• [SLOW TEST:11.445 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:03:07.329: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1607
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1607.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1607.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 18:03:12.226: INFO: DNS probes using dns-1607/dns-test-a068ac76-d8af-424e-9508-d754521b4643 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:03:12.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1607" for this suite.
Feb 17 18:03:20.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:03:21.035: INFO: namespace dns-1607 deletion completed in 8.637653284s

• [SLOW TEST:13.707 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:03:21.036: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-7eb4f36a-0675-44d3-be4c-441bbe30f8f5
STEP: Creating secret with name secret-projected-all-test-volume-d5d8cefc-f93e-43df-abf6-265dab176248
STEP: Creating a pod to test Check all projections for projected volume plugin
Feb 17 18:03:21.427: INFO: Waiting up to 5m0s for pod "projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5" in namespace "projected-9485" to be "success or failure"
Feb 17 18:03:21.441: INFO: Pod "projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5": Phase="Pending", Reason="", readiness=false. Elapsed: 13.983931ms
Feb 17 18:03:23.457: INFO: Pod "projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.029646418s
STEP: Saw pod success
Feb 17 18:03:23.457: INFO: Pod "projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5" satisfied condition "success or failure"
Feb 17 18:03:23.476: INFO: Trying to get logs from node 10.241.69.147 pod projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5 container projected-all-volume-test: <nil>
STEP: delete the pod
Feb 17 18:03:23.606: INFO: Waiting for pod projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5 to disappear
Feb 17 18:03:23.619: INFO: Pod projected-volume-a614aa59-d078-4ec8-99b6-3ee5a7603ae5 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:03:23.619: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9485" for this suite.
Feb 17 18:03:31.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:03:32.351: INFO: namespace projected-9485 deletion completed in 8.712189738s

• [SLOW TEST:11.315 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:03:32.352: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:03:32.780: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205" in namespace "downward-api-3373" to be "success or failure"
Feb 17 18:03:32.812: INFO: Pod "downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205": Phase="Pending", Reason="", readiness=false. Elapsed: 32.006645ms
Feb 17 18:03:34.829: INFO: Pod "downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205": Phase="Running", Reason="", readiness=true. Elapsed: 2.048602287s
Feb 17 18:03:36.865: INFO: Pod "downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.084838264s
STEP: Saw pod success
Feb 17 18:03:36.865: INFO: Pod "downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205" satisfied condition "success or failure"
Feb 17 18:03:36.886: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205 container client-container: <nil>
STEP: delete the pod
Feb 17 18:03:37.054: INFO: Waiting for pod downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205 to disappear
Feb 17 18:03:37.068: INFO: Pod downwardapi-volume-dfc8c844-1ec6-4aec-960f-b5424a219205 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:03:37.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3373" for this suite.
Feb 17 18:03:45.354: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:03:45.986: INFO: namespace downward-api-3373 deletion completed in 8.894152615s

• [SLOW TEST:13.635 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:03:45.987: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-710
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Feb 17 18:03:48.383: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:03:48.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-710" for this suite.
Feb 17 18:03:54.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:03:55.082: INFO: namespace container-runtime-710 deletion completed in 6.592256556s

• [SLOW TEST:9.095 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:03:55.082: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:03:57.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3128" for this suite.
Feb 17 18:04:05.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:04:06.673: INFO: namespace emptydir-wrapper-3128 deletion completed in 9.033864358s

• [SLOW TEST:11.591 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:04:06.674: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8666
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:04:23.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8666" for this suite.
Feb 17 18:04:31.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:04:32.588: INFO: namespace resourcequota-8666 deletion completed in 8.8599489s

• [SLOW TEST:25.914 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:04:32.588: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-dc3a0c93-8a01-4832-8e1f-a99a49e64cef
STEP: Creating a pod to test consume secrets
Feb 17 18:04:32.937: INFO: Waiting up to 5m0s for pod "pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6" in namespace "secrets-9770" to be "success or failure"
Feb 17 18:04:32.954: INFO: Pod "pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6": Phase="Pending", Reason="", readiness=false. Elapsed: 16.961434ms
Feb 17 18:04:34.972: INFO: Pod "pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035254109s
STEP: Saw pod success
Feb 17 18:04:34.972: INFO: Pod "pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6" satisfied condition "success or failure"
Feb 17 18:04:34.999: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:04:35.108: INFO: Waiting for pod pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6 to disappear
Feb 17 18:04:35.126: INFO: Pod pod-secrets-0580873f-8f26-47af-8085-e2cec0dd23e6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:04:35.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9770" for this suite.
Feb 17 18:04:43.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:04:43.770: INFO: namespace secrets-9770 deletion completed in 8.617097891s

• [SLOW TEST:11.183 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:04:43.770: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1579
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-a38eb61c-74dd-4db0-a6fc-d2c176437d66
STEP: Creating configMap with name cm-test-opt-upd-1c715042-3251-4202-bea4-f28460e9bb19
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-a38eb61c-74dd-4db0-a6fc-d2c176437d66
STEP: Updating configmap cm-test-opt-upd-1c715042-3251-4202-bea4-f28460e9bb19
STEP: Creating configMap with name cm-test-opt-create-c6b8fbf9-b266-4460-9a6c-5cbc77c0312e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:04:50.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1579" for this suite.
Feb 17 18:05:20.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:05:21.259: INFO: namespace configmap-1579 deletion completed in 30.654254409s

• [SLOW TEST:37.489 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:05:21.261: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:05:21.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a" in namespace "downward-api-956" to be "success or failure"
Feb 17 18:05:21.639: INFO: Pod "downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a": Phase="Pending", Reason="", readiness=false. Elapsed: 37.522013ms
Feb 17 18:05:23.656: INFO: Pod "downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.054417699s
STEP: Saw pod success
Feb 17 18:05:23.656: INFO: Pod "downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a" satisfied condition "success or failure"
Feb 17 18:05:23.669: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a container client-container: <nil>
STEP: delete the pod
Feb 17 18:05:23.783: INFO: Waiting for pod downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a to disappear
Feb 17 18:05:23.796: INFO: Pod downwardapi-volume-cc4e01b0-f420-41ca-99c9-4f99a155f40a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:05:23.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-956" for this suite.
Feb 17 18:05:31.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:05:33.219: INFO: namespace downward-api-956 deletion completed in 9.389946331s

• [SLOW TEST:11.959 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:05:33.219: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-45da3eca-a47d-4420-8237-20b744854dce
STEP: Creating a pod to test consume configMaps
Feb 17 18:05:33.609: INFO: Waiting up to 5m0s for pod "pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d" in namespace "configmap-1401" to be "success or failure"
Feb 17 18:05:33.629: INFO: Pod "pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d": Phase="Pending", Reason="", readiness=false. Elapsed: 19.564477ms
Feb 17 18:05:35.645: INFO: Pod "pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03597117s
STEP: Saw pod success
Feb 17 18:05:35.646: INFO: Pod "pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d" satisfied condition "success or failure"
Feb 17 18:05:35.674: INFO: Trying to get logs from node 10.241.69.147 pod pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d container configmap-volume-test: <nil>
STEP: delete the pod
Feb 17 18:05:35.765: INFO: Waiting for pod pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d to disappear
Feb 17 18:05:35.783: INFO: Pod pod-configmaps-b53699b0-5811-4ffa-80e8-0294212e895d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:05:35.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1401" for this suite.
Feb 17 18:05:43.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:05:44.519: INFO: namespace configmap-1401 deletion completed in 8.710869016s

• [SLOW TEST:11.299 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:05:44.519: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4588
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Feb 17 18:05:44.841: INFO: Waiting up to 5m0s for pod "pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57" in namespace "emptydir-4588" to be "success or failure"
Feb 17 18:05:44.855: INFO: Pod "pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57": Phase="Pending", Reason="", readiness=false. Elapsed: 13.975683ms
Feb 17 18:05:46.876: INFO: Pod "pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034679888s
STEP: Saw pod success
Feb 17 18:05:46.876: INFO: Pod "pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57" satisfied condition "success or failure"
Feb 17 18:05:46.890: INFO: Trying to get logs from node 10.241.69.147 pod pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57 container test-container: <nil>
STEP: delete the pod
Feb 17 18:05:47.007: INFO: Waiting for pod pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57 to disappear
Feb 17 18:05:47.022: INFO: Pod pod-e9815ba4-39b3-4e59-b0e7-e31f3e03dc57 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:05:47.022: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4588" for this suite.
Feb 17 18:05:55.113: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:05:55.643: INFO: namespace emptydir-4588 deletion completed in 8.593975073s

• [SLOW TEST:11.124 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:05:55.643: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1789
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:05:55.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1789" for this suite.
Feb 17 18:06:04.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:06:05.011: INFO: namespace custom-resource-definition-1789 deletion completed in 9.032021631s

• [SLOW TEST:9.368 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:06:05.012: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-8730
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:06:06.321: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Feb 17 18:06:08.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559566, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559566, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559566, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559566, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:06:11.496: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:06:11.523: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:06:13.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8730" for this suite.
Feb 17 18:06:21.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:06:22.420: INFO: namespace crd-webhook-8730 deletion completed in 8.706485002s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:17.506 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:06:22.518: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1143
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:06:24.136: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:06:27.236: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:06:27.258: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 18:06:57.515: INFO: error waiting for conversion to succeed during setup: Timeout: request did not complete within requested timeout 30s
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:06:58.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1143" for this suite.
Feb 17 18:07:06.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:07:08.362: INFO: namespace crd-webhook-1143 deletion completed in 9.555825569s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:45.969 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:07:08.489: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2952
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:07:09.567: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 18:07:11.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559629, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559629, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559629, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559629, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:07:14.682: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:07:25.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2952" for this suite.
Feb 17 18:07:33.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:07:34.355: INFO: namespace webhook-2952 deletion completed in 8.64264318s
STEP: Destroying namespace "webhook-2952-markers" for this suite.
Feb 17 18:07:40.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:07:40.985: INFO: namespace webhook-2952-markers deletion completed in 6.629539433s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.563 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:07:41.054: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3260
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:07:42.293: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 18:07:44.337: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559662, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559662, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559662, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559662, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:07:47.392: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:07:47.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3260" for this suite.
Feb 17 18:08:01.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:08:02.635: INFO: namespace webhook-3260 deletion completed in 15.034140133s
STEP: Destroying namespace "webhook-3260-markers" for this suite.
Feb 17 18:08:10.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:08:11.628: INFO: namespace webhook-3260-markers deletion completed in 8.993234332s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.674 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:08:11.729: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4915
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Feb 17 18:08:12.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4915 -- logs-generator --log-lines-total 100 --run-duration 20s'
Feb 17 18:08:12.302: INFO: stderr: ""
Feb 17 18:08:12.302: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Feb 17 18:08:12.303: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Feb 17 18:08:12.303: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4915" to be "running and ready, or succeeded"
Feb 17 18:08:12.317: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 14.677175ms
Feb 17 18:08:14.335: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.032667922s
Feb 17 18:08:14.335: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Feb 17 18:08:14.335: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Feb 17 18:08:14.335: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915'
Feb 17 18:08:14.722: INFO: stderr: ""
Feb 17 18:08:14.722: INFO: stdout: "I0217 18:08:13.698223       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/2vjr 242\nI0217 18:08:13.898444       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/sfzr 202\nI0217 18:08:14.098489       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/f5bt 243\nI0217 18:08:14.298443       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/dnxf 455\nI0217 18:08:14.498465       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/v6sc 214\nI0217 18:08:14.698477       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/ftvq 430\n"
STEP: limiting log lines
Feb 17 18:08:14.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915 --tail=1'
Feb 17 18:08:14.950: INFO: stderr: ""
Feb 17 18:08:14.950: INFO: stdout: "I0217 18:08:14.898450       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/qgjr 236\n"
STEP: limiting log bytes
Feb 17 18:08:14.950: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915 --limit-bytes=1'
Feb 17 18:08:15.164: INFO: stderr: ""
Feb 17 18:08:15.164: INFO: stdout: "I"
STEP: exposing timestamps
Feb 17 18:08:15.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915 --tail=1 --timestamps'
Feb 17 18:08:15.407: INFO: stderr: ""
Feb 17 18:08:15.407: INFO: stdout: "2020-02-17T18:08:15.298648683Z I0217 18:08:15.298438       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xwns 336\n"
STEP: restricting to a time range
Feb 17 18:08:17.908: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915 --since=1s'
Feb 17 18:08:18.290: INFO: stderr: ""
Feb 17 18:08:18.290: INFO: stdout: "I0217 18:08:17.298421       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/2wm 495\nI0217 18:08:17.498424       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/hvqn 260\nI0217 18:08:17.698402       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/fxd 439\nI0217 18:08:17.898516       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/mgf 305\nI0217 18:08:18.098415       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/fcn 455\n"
Feb 17 18:08:18.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 logs logs-generator logs-generator --namespace=kubectl-4915 --since=24h'
Feb 17 18:08:18.565: INFO: stderr: ""
Feb 17 18:08:18.565: INFO: stdout: "I0217 18:08:13.698223       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/2vjr 242\nI0217 18:08:13.898444       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/sfzr 202\nI0217 18:08:14.098489       1 logs_generator.go:76] 2 POST /api/v1/namespaces/default/pods/f5bt 243\nI0217 18:08:14.298443       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/default/pods/dnxf 455\nI0217 18:08:14.498465       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/v6sc 214\nI0217 18:08:14.698477       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/ftvq 430\nI0217 18:08:14.898450       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/qgjr 236\nI0217 18:08:15.098418       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/vtd 341\nI0217 18:08:15.298438       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xwns 336\nI0217 18:08:15.498425       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/429 258\nI0217 18:08:15.698473       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/dzt 355\nI0217 18:08:15.898507       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/m8v7 479\nI0217 18:08:16.098472       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/wszw 376\nI0217 18:08:16.298454       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/sqm 431\nI0217 18:08:16.498423       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/9bj4 240\nI0217 18:08:16.698474       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/ns/pods/pjxq 589\nI0217 18:08:16.898440       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/6psl 474\nI0217 18:08:17.098468       1 logs_generator.go:76] 17 POST /api/v1/namespaces/ns/pods/mzk 545\nI0217 18:08:17.298421       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/2wm 495\nI0217 18:08:17.498424       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/hvqn 260\nI0217 18:08:17.698402       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/default/pods/fxd 439\nI0217 18:08:17.898516       1 logs_generator.go:76] 21 POST /api/v1/namespaces/kube-system/pods/mgf 305\nI0217 18:08:18.098415       1 logs_generator.go:76] 22 GET /api/v1/namespaces/kube-system/pods/fcn 455\nI0217 18:08:18.298405       1 logs_generator.go:76] 23 GET /api/v1/namespaces/default/pods/tlq6 332\nI0217 18:08:18.498410       1 logs_generator.go:76] 24 POST /api/v1/namespaces/kube-system/pods/xv4g 565\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Feb 17 18:08:18.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 delete pod logs-generator --namespace=kubectl-4915'
Feb 17 18:08:29.475: INFO: stderr: ""
Feb 17 18:08:29.475: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:08:29.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4915" for this suite.
Feb 17 18:08:37.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:08:38.206: INFO: namespace kubectl-4915 deletion completed in 8.707880563s

• [SLOW TEST:26.478 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:08:38.206: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-8383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Feb 17 18:08:46.753: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:46.774: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:48.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:48.807: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:50.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:50.790: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:52.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:52.790: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:54.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:54.790: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:56.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:56.790: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:08:58.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:08:58.788: INFO: Pod pod-with-poststart-http-hook still exists
Feb 17 18:09:00.774: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Feb 17 18:09:00.806: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:09:00.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-8383" for this suite.
Feb 17 18:09:30.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:09:32.157: INFO: namespace container-lifecycle-hook-8383 deletion completed in 31.2996061s

• [SLOW TEST:53.950 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:09:32.157: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3348
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:09:32.462: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 17 18:09:37.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3348 create -f -'
Feb 17 18:09:38.349: INFO: stderr: ""
Feb 17 18:09:38.349: INFO: stdout: "e2e-test-crd-publish-openapi-4045-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 17 18:09:38.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3348 delete e2e-test-crd-publish-openapi-4045-crds test-cr'
Feb 17 18:09:38.513: INFO: stderr: ""
Feb 17 18:09:38.513: INFO: stdout: "e2e-test-crd-publish-openapi-4045-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Feb 17 18:09:38.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3348 apply -f -'
Feb 17 18:09:38.927: INFO: stderr: ""
Feb 17 18:09:38.927: INFO: stdout: "e2e-test-crd-publish-openapi-4045-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Feb 17 18:09:38.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-3348 delete e2e-test-crd-publish-openapi-4045-crds test-cr'
Feb 17 18:09:39.111: INFO: stderr: ""
Feb 17 18:09:39.111: INFO: stdout: "e2e-test-crd-publish-openapi-4045-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Feb 17 18:09:39.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-4045-crds'
Feb 17 18:09:39.566: INFO: stderr: ""
Feb 17 18:09:39.566: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4045-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:09:44.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3348" for this suite.
Feb 17 18:09:50.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:09:51.292: INFO: namespace crd-publish-openapi-3348 deletion completed in 6.658535916s

• [SLOW TEST:19.135 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:09:51.293: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:09:51.574: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Feb 17 18:09:51.604: INFO: Pod name sample-pod: Found 0 pods out of 1
Feb 17 18:09:56.623: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 18:09:56.623: INFO: Creating deployment "test-rolling-update-deployment"
Feb 17 18:09:56.642: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Feb 17 18:09:56.675: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Feb 17 18:09:58.722: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Feb 17 18:09:58.741: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559796, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559796, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559796, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559796, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:10:00.760: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 17 18:10:00.836: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-896 /apis/apps/v1/namespaces/deployment-896/deployments/test-rolling-update-deployment 711425da-646a-4af5-8c8c-758d357cf37f 44919 1 2020-02-17 18:09:56 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005cd2ed8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-17 18:09:56 +0000 UTC,LastTransitionTime:2020-02-17 18:09:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-02-17 18:09:59 +0000 UTC,LastTransitionTime:2020-02-17 18:09:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 17 18:10:00.857: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-896 /apis/apps/v1/namespaces/deployment-896/replicasets/test-rolling-update-deployment-55d946486 29365d38-5e62-4a1f-98a7-4368c70ffb16 44907 1 2020-02-17 18:09:56 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 711425da-646a-4af5-8c8c-758d357cf37f 0xc005cd3430 0xc005cd3431}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005cd34a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:10:00.857: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Feb 17 18:10:00.858: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-896 /apis/apps/v1/namespaces/deployment-896/replicasets/test-rolling-update-controller 2bb26ac3-38b3-4e3d-adc5-b211f4bedcec 44917 2 2020-02-17 18:09:51 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 711425da-646a-4af5-8c8c-758d357cf37f 0xc005cd3347 0xc005cd3348}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005cd33b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:10:00.886: INFO: Pod "test-rolling-update-deployment-55d946486-cfqr8" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-cfqr8 test-rolling-update-deployment-55d946486- deployment-896 /api/v1/namespaces/deployment-896/pods/test-rolling-update-deployment-55d946486-cfqr8 603b7cc4-8347-44f8-87b2-9077f6a30c36 44905 0 2020-02-17 18:09:56 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 29365d38-5e62-4a1f-98a7-4368c70ffb16 0xc005d1fda0 0xc005d1fda1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hhkmt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hhkmt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hhkmt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:09:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:09:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:09:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:09:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.5,StartTime:2020-02-17 18:09:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 18:09:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://52ab3c30a14cc4cf91ce482502db83e27d9fe7c6ee0110238672f0d29ab94d08,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:10:00.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-896" for this suite.
Feb 17 18:10:09.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:10:10.016: INFO: namespace deployment-896 deletion completed in 9.096435214s

• [SLOW TEST:18.724 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:10:10.018: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 17 18:10:10.652: INFO: Waiting up to 5m0s for pod "pod-156e4da3-5681-45fb-be77-2df97b4fbec4" in namespace "emptydir-9454" to be "success or failure"
Feb 17 18:10:10.715: INFO: Pod "pod-156e4da3-5681-45fb-be77-2df97b4fbec4": Phase="Pending", Reason="", readiness=false. Elapsed: 63.707842ms
Feb 17 18:10:12.733: INFO: Pod "pod-156e4da3-5681-45fb-be77-2df97b4fbec4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.080957193s
Feb 17 18:10:14.751: INFO: Pod "pod-156e4da3-5681-45fb-be77-2df97b4fbec4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.099901078s
STEP: Saw pod success
Feb 17 18:10:14.752: INFO: Pod "pod-156e4da3-5681-45fb-be77-2df97b4fbec4" satisfied condition "success or failure"
Feb 17 18:10:14.777: INFO: Trying to get logs from node 10.241.69.147 pod pod-156e4da3-5681-45fb-be77-2df97b4fbec4 container test-container: <nil>
STEP: delete the pod
Feb 17 18:10:14.883: INFO: Waiting for pod pod-156e4da3-5681-45fb-be77-2df97b4fbec4 to disappear
Feb 17 18:10:14.905: INFO: Pod pod-156e4da3-5681-45fb-be77-2df97b4fbec4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:10:14.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9454" for this suite.
Feb 17 18:10:22.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:10:23.612: INFO: namespace emptydir-9454 deletion completed in 8.683288294s

• [SLOW TEST:13.595 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:10:23.613: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4400
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Feb 17 18:10:23.900: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45026 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 18:10:23.900: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45026 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Feb 17 18:10:33.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45041 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Feb 17 18:10:33.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45041 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Feb 17 18:10:43.978: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45054 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 18:10:43.978: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45054 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Feb 17 18:10:54.012: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45069 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 18:10:54.013: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-a 42bb91dd-ee5e-47cb-bda7-0fe215173429 45069 0 2020-02-17 18:10:23 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Feb 17 18:11:04.071: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-b 6416b65c-128f-4f68-918b-be94ae5b9773 45082 0 2020-02-17 18:11:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 18:11:04.071: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-b 6416b65c-128f-4f68-918b-be94ae5b9773 45082 0 2020-02-17 18:11:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Feb 17 18:11:14.110: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-b 6416b65c-128f-4f68-918b-be94ae5b9773 45096 0 2020-02-17 18:11:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Feb 17 18:11:14.110: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-4400 /api/v1/namespaces/watch-4400/configmaps/e2e-watch-test-configmap-b 6416b65c-128f-4f68-918b-be94ae5b9773 45096 0 2020-02-17 18:11:04 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:11:24.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4400" for this suite.
Feb 17 18:11:30.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:11:30.989: INFO: namespace watch-4400 deletion completed in 6.847355211s

• [SLOW TEST:67.377 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:11:30.991: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1188
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:11:31.319: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4" in namespace "projected-1188" to be "success or failure"
Feb 17 18:11:31.336: INFO: Pod "downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4": Phase="Pending", Reason="", readiness=false. Elapsed: 17.078597ms
Feb 17 18:11:33.354: INFO: Pod "downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034508417s
STEP: Saw pod success
Feb 17 18:11:33.354: INFO: Pod "downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4" satisfied condition "success or failure"
Feb 17 18:11:33.372: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4 container client-container: <nil>
STEP: delete the pod
Feb 17 18:11:33.501: INFO: Waiting for pod downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4 to disappear
Feb 17 18:11:33.525: INFO: Pod downwardapi-volume-b9cc02fe-bf98-4c48-8a9d-e49f5fa486c4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:11:33.525: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1188" for this suite.
Feb 17 18:11:41.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:11:42.214: INFO: namespace projected-1188 deletion completed in 8.668571672s

• [SLOW TEST:11.223 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:11:42.214: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-1974
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:11:42.486: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:11:42.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-1974" for this suite.
Feb 17 18:11:48.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:11:49.398: INFO: namespace custom-resource-definition-1974 deletion completed in 6.743416705s

• [SLOW TEST:7.184 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:11:49.398: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:11:49.691: INFO: Creating deployment "test-recreate-deployment"
Feb 17 18:11:49.710: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Feb 17 18:11:49.756: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Feb 17 18:11:51.788: INFO: Waiting deployment "test-recreate-deployment" to complete
Feb 17 18:11:51.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559909, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559909, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559909, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717559909, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:11:53.816: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Feb 17 18:11:53.845: INFO: Updating deployment test-recreate-deployment
Feb 17 18:11:53.845: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 17 18:11:54.224: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6182 /apis/apps/v1/namespaces/deployment-6182/deployments/test-recreate-deployment 92b283d4-93fd-4187-adf7-11bed036f451 45269 2 2020-02-17 18:11:49 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0061b3928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-02-17 18:11:53 +0000 UTC,LastTransitionTime:2020-02-17 18:11:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-02-17 18:11:53 +0000 UTC,LastTransitionTime:2020-02-17 18:11:49 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Feb 17 18:11:54.238: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-6182 /apis/apps/v1/namespaces/deployment-6182/replicasets/test-recreate-deployment-5f94c574ff 411edb90-39dd-4b73-ab23-ff6074db9eb6 45268 1 2020-02-17 18:11:53 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 92b283d4-93fd-4187-adf7-11bed036f451 0xc00615bb87 0xc00615bb88}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00615bbe8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:11:54.238: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Feb 17 18:11:54.238: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-6182 /apis/apps/v1/namespaces/deployment-6182/replicasets/test-recreate-deployment-68fc85c7bb 225f5323-c910-4ac8-8014-bc3c518f4542 45258 2 2020-02-17 18:11:49 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 92b283d4-93fd-4187-adf7-11bed036f451 0xc00615bc57 0xc00615bc58}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00615bcb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:11:54.255: INFO: Pod "test-recreate-deployment-5f94c574ff-s5rvn" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-s5rvn test-recreate-deployment-5f94c574ff- deployment-6182 /api/v1/namespaces/deployment-6182/pods/test-recreate-deployment-5f94c574ff-s5rvn 3d1ff4a5-1dd2-4910-8db4-f0c66f613a96 45270 0 2020-02-17 18:11:53 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 411edb90-39dd-4b73-ab23-ff6074db9eb6 0xc0060ce047 0xc0060ce048}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8sxlc,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8sxlc,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8sxlc,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:11:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:11:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:11:53 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:11:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:,StartTime:2020-02-17 18:11:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:11:54.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6182" for this suite.
Feb 17 18:12:02.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:12:03.174: INFO: namespace deployment-6182 deletion completed in 8.894688313s

• [SLOW TEST:13.776 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:12:03.175: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7711
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 17 18:12:08.520: INFO: Successfully updated pod "annotationupdate6a67059a-58fa-498f-925a-a664365b9205"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:12:10.620: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7711" for this suite.
Feb 17 18:12:40.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:12:41.321: INFO: namespace downward-api-7711 deletion completed in 30.67568928s

• [SLOW TEST:38.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:12:41.322: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-670
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:12:41.607: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Feb 17 18:12:46.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-670 create -f -'
Feb 17 18:12:46.713: INFO: stderr: ""
Feb 17 18:12:46.713: INFO: stdout: "e2e-test-crd-publish-openapi-1834-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 17 18:12:46.713: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-670 delete e2e-test-crd-publish-openapi-1834-crds test-cr'
Feb 17 18:12:46.959: INFO: stderr: ""
Feb 17 18:12:46.959: INFO: stdout: "e2e-test-crd-publish-openapi-1834-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Feb 17 18:12:46.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-670 apply -f -'
Feb 17 18:12:47.521: INFO: stderr: ""
Feb 17 18:12:47.522: INFO: stdout: "e2e-test-crd-publish-openapi-1834-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Feb 17 18:12:47.522: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=crd-publish-openapi-670 delete e2e-test-crd-publish-openapi-1834-crds test-cr'
Feb 17 18:12:47.681: INFO: stderr: ""
Feb 17 18:12:47.682: INFO: stdout: "e2e-test-crd-publish-openapi-1834-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Feb 17 18:12:47.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 explain e2e-test-crd-publish-openapi-1834-crds'
Feb 17 18:12:47.891: INFO: stderr: ""
Feb 17 18:12:47.891: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1834-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:12:52.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-670" for this suite.
Feb 17 18:12:58.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:12:59.169: INFO: namespace crd-publish-openapi-670 deletion completed in 6.700310158s

• [SLOW TEST:17.847 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:12:59.169: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6994
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-592d2505-1886-4d50-be4e-b7ed0ab72000
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:13:01.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6994" for this suite.
Feb 17 18:13:21.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:13:22.412: INFO: namespace configmap-6994 deletion completed in 20.617560023s

• [SLOW TEST:23.243 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:13:22.413: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ad4de751-51c7-457f-9611-70a3cd8458b4
STEP: Creating a pod to test consume secrets
Feb 17 18:13:22.809: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30" in namespace "projected-490" to be "success or failure"
Feb 17 18:13:22.829: INFO: Pod "pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30": Phase="Pending", Reason="", readiness=false. Elapsed: 19.849262ms
Feb 17 18:13:24.853: INFO: Pod "pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.043991752s
STEP: Saw pod success
Feb 17 18:13:24.853: INFO: Pod "pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30" satisfied condition "success or failure"
Feb 17 18:13:24.875: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:13:24.994: INFO: Waiting for pod pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30 to disappear
Feb 17 18:13:25.010: INFO: Pod pod-projected-secrets-3a3016dd-bc1f-4f09-9668-0c5857c73d30 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:13:25.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-490" for this suite.
Feb 17 18:13:31.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:13:31.866: INFO: namespace projected-490 deletion completed in 6.833584594s

• [SLOW TEST:9.453 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:13:31.867: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2972
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:13:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2972" for this suite.
Feb 17 18:13:43.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:13:44.026: INFO: namespace watch-2972 deletion completed in 6.719697176s

• [SLOW TEST:12.159 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:13:44.026: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-9433
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:13:48.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9433" for this suite.
Feb 17 18:14:00.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:14:01.337: INFO: namespace containers-9433 deletion completed in 12.86321021s

• [SLOW TEST:17.310 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:14:01.337: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3248
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Feb 17 18:14:03.958: INFO: &Pod{ObjectMeta:{send-events-11fa2acf-49c7-491f-ac61-2ae7c09b0c74  events-3248 /api/v1/namespaces/events-3248/pods/send-events-11fa2acf-49c7-491f-ac61-2ae7c09b0c74 4e78b453-4990-44ff-b578-a9086cd4027a 45802 0 2020-02-17 18:14:01 +0000 UTC <nil> <nil> map[name:foo time:746766498] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ntcfn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ntcfn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ntcfn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:14:01 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:14:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:14:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:14:01 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.62,StartTime:2020-02-17 18:14:01 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 18:14:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:containerd://8c28eaf89cb9a46bf9f981673992daf1d5672ca7850a1fc5a917cce1b3a45c1d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.62,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Feb 17 18:14:05.979: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Feb 17 18:14:07.996: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:14:08.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3248" for this suite.
Feb 17 18:14:52.334: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:14:52.916: INFO: namespace events-3248 deletion completed in 44.765725697s

• [SLOW TEST:51.579 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:14:52.916: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1518
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:15:00.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1518" for this suite.
Feb 17 18:15:08.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:15:09.275: INFO: namespace resourcequota-1518 deletion completed in 9.012308258s

• [SLOW TEST:16.359 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:15:09.276: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5318
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Feb 17 18:15:09.614: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:15:39.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5318" for this suite.
Feb 17 18:15:45.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:15:46.324: INFO: namespace crd-publish-openapi-5318 deletion completed in 6.639475616s

• [SLOW TEST:37.049 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:15:46.324: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-90a1be10-1950-4236-bdbf-e1379f5bceb3
STEP: Creating a pod to test consume secrets
Feb 17 18:15:46.640: INFO: Waiting up to 5m0s for pod "pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a" in namespace "secrets-1392" to be "success or failure"
Feb 17 18:15:46.656: INFO: Pod "pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a": Phase="Pending", Reason="", readiness=false. Elapsed: 15.772831ms
Feb 17 18:15:48.691: INFO: Pod "pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.050169224s
STEP: Saw pod success
Feb 17 18:15:48.691: INFO: Pod "pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a" satisfied condition "success or failure"
Feb 17 18:15:48.704: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:15:48.866: INFO: Waiting for pod pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a to disappear
Feb 17 18:15:48.880: INFO: Pod pod-secrets-4ca7b279-462d-4c1a-b754-6285340c046a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:15:48.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1392" for this suite.
Feb 17 18:15:54.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:15:55.483: INFO: namespace secrets-1392 deletion completed in 6.586209214s

• [SLOW TEST:9.159 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:15:55.484: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7535
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-60c5c23c-0855-422c-b1ea-d2e1d79d5497
STEP: Creating a pod to test consume secrets
Feb 17 18:15:55.788: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2" in namespace "projected-7535" to be "success or failure"
Feb 17 18:15:55.805: INFO: Pod "pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.067948ms
Feb 17 18:15:57.825: INFO: Pod "pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036500593s
STEP: Saw pod success
Feb 17 18:15:57.825: INFO: Pod "pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2" satisfied condition "success or failure"
Feb 17 18:15:57.846: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2 container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:15:57.933: INFO: Waiting for pod pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2 to disappear
Feb 17 18:15:57.949: INFO: Pod pod-projected-secrets-9c6150fd-e164-4f38-928b-9c6397922af2 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:15:57.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7535" for this suite.
Feb 17 18:16:06.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:16:07.008: INFO: namespace projected-7535 deletion completed in 9.036694046s

• [SLOW TEST:11.524 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:16:07.008: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Feb 17 18:16:07.436: INFO: Waiting up to 5m0s for pod "downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5" in namespace "downward-api-8586" to be "success or failure"
Feb 17 18:16:07.475: INFO: Pod "downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5": Phase="Pending", Reason="", readiness=false. Elapsed: 39.472113ms
Feb 17 18:16:09.490: INFO: Pod "downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.054152416s
Feb 17 18:16:11.508: INFO: Pod "downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.07218438s
STEP: Saw pod success
Feb 17 18:16:11.508: INFO: Pod "downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5" satisfied condition "success or failure"
Feb 17 18:16:11.530: INFO: Trying to get logs from node 10.241.69.147 pod downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5 container dapi-container: <nil>
STEP: delete the pod
Feb 17 18:16:11.716: INFO: Waiting for pod downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5 to disappear
Feb 17 18:16:11.730: INFO: Pod downward-api-26d7cafc-fed0-4ef6-925b-614fd34bfae5 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:16:11.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8586" for this suite.
Feb 17 18:16:17.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:16:18.381: INFO: namespace downward-api-8586 deletion completed in 6.629046608s

• [SLOW TEST:11.373 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:16:18.382: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:16:18.695: INFO: Waiting up to 5m0s for pod "downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278" in namespace "projected-2327" to be "success or failure"
Feb 17 18:16:18.710: INFO: Pod "downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278": Phase="Pending", Reason="", readiness=false. Elapsed: 15.670387ms
Feb 17 18:16:20.725: INFO: Pod "downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.030264183s
STEP: Saw pod success
Feb 17 18:16:20.725: INFO: Pod "downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278" satisfied condition "success or failure"
Feb 17 18:16:20.741: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278 container client-container: <nil>
STEP: delete the pod
Feb 17 18:16:20.821: INFO: Waiting for pod downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278 to disappear
Feb 17 18:16:20.836: INFO: Pod downwardapi-volume-31d804eb-175f-49a3-b18d-7637ddbaa278 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:16:20.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2327" for this suite.
Feb 17 18:16:28.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:16:29.502: INFO: namespace projected-2327 deletion completed in 8.645276571s

• [SLOW TEST:11.120 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:16:29.502: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6554
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6554
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Feb 17 18:16:29.832: INFO: Found 0 stateful pods, waiting for 3
Feb 17 18:16:39.850: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 18:16:39.850: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 18:16:39.850: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Feb 17 18:16:39.895: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-6554 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 18:16:40.307: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 18:16:40.307: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 18:16:40.307: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Feb 17 18:16:50.489: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Feb 17 18:17:00.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-6554 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 18:17:01.051: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 18:17:01.051: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 18:17:01.051: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 18:17:21.179: INFO: Waiting for StatefulSet statefulset-6554/ss2 to complete update
Feb 17 18:17:21.180: INFO: Waiting for Pod statefulset-6554/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Feb 17 18:17:31.219: INFO: Waiting for StatefulSet statefulset-6554/ss2 to complete update
STEP: Rolling back to a previous revision
Feb 17 18:17:41.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-6554 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Feb 17 18:17:41.613: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Feb 17 18:17:41.613: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Feb 17 18:17:41.613: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Feb 17 18:17:51.717: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Feb 17 18:18:01.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=statefulset-6554 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Feb 17 18:18:02.708: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Feb 17 18:18:02.708: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Feb 17 18:18:02.708: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Feb 17 18:18:12.849: INFO: Waiting for StatefulSet statefulset-6554/ss2 to complete update
Feb 17 18:18:12.849: INFO: Waiting for Pod statefulset-6554/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 17 18:18:12.849: INFO: Waiting for Pod statefulset-6554/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 17 18:18:12.849: INFO: Waiting for Pod statefulset-6554/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 17 18:18:22.888: INFO: Waiting for StatefulSet statefulset-6554/ss2 to complete update
Feb 17 18:18:22.888: INFO: Waiting for Pod statefulset-6554/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 17 18:18:22.888: INFO: Waiting for Pod statefulset-6554/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Feb 17 18:18:32.882: INFO: Waiting for StatefulSet statefulset-6554/ss2 to complete update
Feb 17 18:18:32.882: INFO: Waiting for Pod statefulset-6554/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Feb 17 18:18:42.898: INFO: Deleting all statefulset in ns statefulset-6554
Feb 17 18:18:42.911: INFO: Scaling statefulset ss2 to 0
Feb 17 18:19:22.969: INFO: Waiting for statefulset status.replicas updated to 0
Feb 17 18:19:23.007: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:19:23.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6554" for this suite.
Feb 17 18:19:33.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:19:33.813: INFO: namespace statefulset-6554 deletion completed in 10.707386515s

• [SLOW TEST:184.312 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:19:33.815: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:20:34.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9887" for this suite.
Feb 17 18:21:04.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:21:05.188: INFO: namespace container-probe-9887 deletion completed in 30.995641883s

• [SLOW TEST:91.373 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:21:05.193: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3052
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Feb 17 18:21:05.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 --namespace=kubectl-3052 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Feb 17 18:21:08.874: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Feb 17 18:21:08.874: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:21:10.918: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3052" for this suite.
Feb 17 18:21:19.012: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:21:19.608: INFO: namespace kubectl-3052 deletion completed in 8.666382509s

• [SLOW TEST:14.416 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:21:19.609: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Feb 17 18:21:24.602: INFO: Successfully updated pod "labelsupdateb39a8229-7eb0-405d-bc53-36c188624522"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:21:26.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5359" for this suite.
Feb 17 18:21:40.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:21:41.329: INFO: namespace downward-api-5359 deletion completed in 14.625776309s

• [SLOW TEST:21.720 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:21:41.329: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7362
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Feb 17 18:21:42.278: INFO: Number of nodes with available pods: 0
Feb 17 18:21:42.278: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 18:21:43.313: INFO: Number of nodes with available pods: 0
Feb 17 18:21:43.313: INFO: Node 10.241.69.130 is running more than one daemon pod
Feb 17 18:21:44.331: INFO: Number of nodes with available pods: 3
Feb 17 18:21:44.331: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Feb 17 18:21:44.439: INFO: Number of nodes with available pods: 2
Feb 17 18:21:44.439: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 18:21:45.473: INFO: Number of nodes with available pods: 2
Feb 17 18:21:45.473: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 18:21:46.486: INFO: Number of nodes with available pods: 2
Feb 17 18:21:46.486: INFO: Node 10.241.69.151 is running more than one daemon pod
Feb 17 18:21:47.483: INFO: Number of nodes with available pods: 3
Feb 17 18:21:47.483: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7362, will wait for the garbage collector to delete the pods
Feb 17 18:21:47.630: INFO: Deleting DaemonSet.extensions daemon-set took: 39.251526ms
Feb 17 18:21:47.830: INFO: Terminating DaemonSet.extensions daemon-set pods took: 200.28631ms
Feb 17 18:21:59.553: INFO: Number of nodes with available pods: 0
Feb 17 18:21:59.553: INFO: Number of running nodes: 0, number of available pods: 0
Feb 17 18:21:59.568: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7362/daemonsets","resourceVersion":"47299"},"items":null}

Feb 17 18:21:59.591: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7362/pods","resourceVersion":"47299"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:21:59.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7362" for this suite.
Feb 17 18:22:07.793: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:22:08.632: INFO: namespace daemonsets-7362 deletion completed in 8.897507167s

• [SLOW TEST:27.303 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:22:08.632: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7455
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Feb 17 18:22:08.959: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Feb 17 18:22:33.514: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.27:8080/dial?request=hostName&protocol=udp&host=172.30.84.22&port=8081&tries=1'] Namespace:pod-network-test-7455 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 18:22:33.514: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 18:22:33.866: INFO: Waiting for endpoints: map[]
Feb 17 18:22:33.884: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.27:8080/dial?request=hostName&protocol=udp&host=172.30.104.32&port=8081&tries=1'] Namespace:pod-network-test-7455 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 18:22:33.884: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 18:22:34.174: INFO: Waiting for endpoints: map[]
Feb 17 18:22:34.193: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.30.84.27:8080/dial?request=hostName&protocol=udp&host=172.30.186.160&port=8081&tries=1'] Namespace:pod-network-test-7455 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Feb 17 18:22:34.193: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
Feb 17 18:22:34.422: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:22:34.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7455" for this suite.
Feb 17 18:22:48.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:22:49.136: INFO: namespace pod-network-test-7455 deletion completed in 14.689815008s

• [SLOW TEST:40.504 seconds]
[sig-network] Networking
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:22:49.136: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9775
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Feb 17 18:22:49.430: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:22:53.411: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9775" for this suite.
Feb 17 18:23:23.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:23:24.143: INFO: namespace init-container-9775 deletion completed in 30.707074955s

• [SLOW TEST:35.007 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:23:24.143: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8622
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:23:25.148: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 18:23:27.205: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560605, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560605, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560605, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560605, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:23:30.271: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:23:30.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8622" for this suite.
Feb 17 18:23:38.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:23:39.607: INFO: namespace webhook-8622 deletion completed in 8.895493684s
STEP: Destroying namespace "webhook-8622-markers" for this suite.
Feb 17 18:23:46.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:23:46.783: INFO: namespace webhook-8622-markers deletion completed in 7.175939565s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.724 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:23:46.868: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0217 18:23:53.301745      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Feb 17 18:23:53.301: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:23:53.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6653" for this suite.
Feb 17 18:24:03.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:24:04.282: INFO: namespace gc-6653 deletion completed in 10.929995463s

• [SLOW TEST:17.414 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:24:04.283: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9613
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Feb 17 18:24:04.727: INFO: Waiting up to 5m0s for pod "pod-0e9685a5-2d95-4b11-be42-db23792222e3" in namespace "emptydir-9613" to be "success or failure"
Feb 17 18:24:04.763: INFO: Pod "pod-0e9685a5-2d95-4b11-be42-db23792222e3": Phase="Pending", Reason="", readiness=false. Elapsed: 36.24233ms
Feb 17 18:24:06.780: INFO: Pod "pod-0e9685a5-2d95-4b11-be42-db23792222e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.052831986s
STEP: Saw pod success
Feb 17 18:24:06.780: INFO: Pod "pod-0e9685a5-2d95-4b11-be42-db23792222e3" satisfied condition "success or failure"
Feb 17 18:24:06.798: INFO: Trying to get logs from node 10.241.69.147 pod pod-0e9685a5-2d95-4b11-be42-db23792222e3 container test-container: <nil>
STEP: delete the pod
Feb 17 18:24:07.045: INFO: Waiting for pod pod-0e9685a5-2d95-4b11-be42-db23792222e3 to disappear
Feb 17 18:24:07.067: INFO: Pod pod-0e9685a5-2d95-4b11-be42-db23792222e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:24:07.067: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9613" for this suite.
Feb 17 18:24:15.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:24:15.799: INFO: namespace emptydir-9613 deletion completed in 8.694136959s

• [SLOW TEST:11.516 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:24:15.799: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2798
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:24:16.132: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-448bafdf-f2cb-4787-8575-93e98c5c7d70" in namespace "security-context-test-2798" to be "success or failure"
Feb 17 18:24:16.152: INFO: Pod "alpine-nnp-false-448bafdf-f2cb-4787-8575-93e98c5c7d70": Phase="Pending", Reason="", readiness=false. Elapsed: 20.801793ms
Feb 17 18:24:18.167: INFO: Pod "alpine-nnp-false-448bafdf-f2cb-4787-8575-93e98c5c7d70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034947464s
Feb 17 18:24:20.181: INFO: Pod "alpine-nnp-false-448bafdf-f2cb-4787-8575-93e98c5c7d70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049567107s
Feb 17 18:24:20.181: INFO: Pod "alpine-nnp-false-448bafdf-f2cb-4787-8575-93e98c5c7d70" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:24:20.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2798" for this suite.
Feb 17 18:24:28.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:24:28.932: INFO: namespace security-context-test-2798 deletion completed in 8.69050641s

• [SLOW TEST:13.133 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:24:28.932: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6215
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6215.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-6215.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6215.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-6215.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-6215.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6215.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Feb 17 18:24:33.607: INFO: DNS probes using dns-6215/dns-test-13def73a-77bf-406e-aaf3-7f47de5c9861 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:24:33.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6215" for this suite.
Feb 17 18:24:41.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:24:42.396: INFO: namespace dns-6215 deletion completed in 8.643348146s

• [SLOW TEST:13.464 seconds]
[sig-network] DNS
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:24:42.396: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Feb 17 18:24:42.699: INFO: Waiting up to 5m0s for pod "pod-c5b05031-b877-4776-b557-100fb3abfbff" in namespace "emptydir-5047" to be "success or failure"
Feb 17 18:24:42.714: INFO: Pod "pod-c5b05031-b877-4776-b557-100fb3abfbff": Phase="Pending", Reason="", readiness=false. Elapsed: 14.308409ms
Feb 17 18:24:44.731: INFO: Pod "pod-c5b05031-b877-4776-b557-100fb3abfbff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.031557149s
STEP: Saw pod success
Feb 17 18:24:44.731: INFO: Pod "pod-c5b05031-b877-4776-b557-100fb3abfbff" satisfied condition "success or failure"
Feb 17 18:24:44.745: INFO: Trying to get logs from node 10.241.69.147 pod pod-c5b05031-b877-4776-b557-100fb3abfbff container test-container: <nil>
STEP: delete the pod
Feb 17 18:24:44.829: INFO: Waiting for pod pod-c5b05031-b877-4776-b557-100fb3abfbff to disappear
Feb 17 18:24:44.846: INFO: Pod pod-c5b05031-b877-4776-b557-100fb3abfbff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:24:44.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5047" for this suite.
Feb 17 18:24:52.937: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:24:53.732: INFO: namespace emptydir-5047 deletion completed in 8.860154743s

• [SLOW TEST:11.335 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:24:53.733: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3937
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Feb 17 18:24:54.120: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3937 /api/v1/namespaces/watch-3937/configmaps/e2e-watch-test-resource-version c15024a2-8f51-4a69-b787-cc0c54fd5648 48288 0 2020-02-17 18:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Feb 17 18:24:54.121: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-3937 /api/v1/namespaces/watch-3937/configmaps/e2e-watch-test-resource-version c15024a2-8f51-4a69-b787-cc0c54fd5648 48289 0 2020-02-17 18:24:53 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:24:54.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3937" for this suite.
Feb 17 18:25:00.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:25:00.891: INFO: namespace watch-3937 deletion completed in 6.749232094s

• [SLOW TEST:7.158 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:25:00.891: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1287
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-1287
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-1287
I0217 18:25:01.474109      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-1287, replica count: 2
I0217 18:25:04.524989      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Feb 17 18:25:04.525: INFO: Creating new exec pod
Feb 17 18:25:09.726: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1287 execpodwrqtb -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Feb 17 18:25:10.569: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Feb 17 18:25:10.569: INFO: stdout: ""
Feb 17 18:25:10.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-964215725 exec --namespace=services-1287 execpodwrqtb -- /bin/sh -x -c nc -zv -t -w 2 172.21.222.161 80'
Feb 17 18:25:11.239: INFO: stderr: "+ nc -zv -t -w 2 172.21.222.161 80\nConnection to 172.21.222.161 80 port [tcp/http] succeeded!\n"
Feb 17 18:25:11.239: INFO: stdout: ""
Feb 17 18:25:11.239: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:25:11.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1287" for this suite.
Feb 17 18:25:19.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:25:20.138: INFO: namespace services-1287 deletion completed in 8.753537146s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.247 seconds]
[sig-network] Services
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:25:20.141: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8523
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b6100e7b-8376-41ce-8db2-d95b39815d75
STEP: Creating a pod to test consume secrets
Feb 17 18:25:20.495: INFO: Waiting up to 5m0s for pod "pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1" in namespace "secrets-8523" to be "success or failure"
Feb 17 18:25:20.521: INFO: Pod "pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1": Phase="Pending", Reason="", readiness=false. Elapsed: 25.369372ms
Feb 17 18:25:22.543: INFO: Pod "pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047506477s
Feb 17 18:25:24.564: INFO: Pod "pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.068953191s
STEP: Saw pod success
Feb 17 18:25:24.564: INFO: Pod "pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1" satisfied condition "success or failure"
Feb 17 18:25:24.578: INFO: Trying to get logs from node 10.241.69.147 pod pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1 container secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:25:24.666: INFO: Waiting for pod pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1 to disappear
Feb 17 18:25:24.691: INFO: Pod pod-secrets-383328d0-2a22-4e7c-9128-08b07af684e1 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:25:24.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8523" for this suite.
Feb 17 18:25:32.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:25:33.370: INFO: namespace secrets-8523 deletion completed in 8.654156958s

• [SLOW TEST:13.230 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:25:33.370: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5420
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Feb 17 18:25:34.515: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Feb 17 18:25:36.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560734, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560734, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560734, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560734, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Feb 17 18:25:39.629: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:25:39.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5420" for this suite.
Feb 17 18:25:48.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:25:48.595: INFO: namespace webhook-5420 deletion completed in 8.643631711s
STEP: Destroying namespace "webhook-5420-markers" for this suite.
Feb 17 18:25:54.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:25:55.275: INFO: namespace webhook-5420-markers deletion completed in 6.680361246s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.970 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:25:55.341: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6008
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:26:06.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6008" for this suite.
Feb 17 18:26:15.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:26:15.690: INFO: namespace resourcequota-6008 deletion completed in 8.686639307s

• [SLOW TEST:20.349 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:26:15.691: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Feb 17 18:26:16.105: INFO: Waiting up to 5m0s for pod "pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef" in namespace "emptydir-5648" to be "success or failure"
Feb 17 18:26:16.125: INFO: Pod "pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef": Phase="Pending", Reason="", readiness=false. Elapsed: 19.834121ms
Feb 17 18:26:18.145: INFO: Pod "pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039281579s
STEP: Saw pod success
Feb 17 18:26:18.145: INFO: Pod "pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef" satisfied condition "success or failure"
Feb 17 18:26:18.161: INFO: Trying to get logs from node 10.241.69.147 pod pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef container test-container: <nil>
STEP: delete the pod
Feb 17 18:26:18.265: INFO: Waiting for pod pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef to disappear
Feb 17 18:26:18.281: INFO: Pod pod-c5979b0e-d9ef-4d32-9e77-6420c29c36ef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:26:18.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5648" for this suite.
Feb 17 18:26:26.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:26:26.903: INFO: namespace emptydir-5648 deletion completed in 8.59430242s

• [SLOW TEST:11.212 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:26:26.903: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5545
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:26:38.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5545" for this suite.
Feb 17 18:26:44.414: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:26:45.189: INFO: namespace resourcequota-5545 deletion completed in 6.830826731s

• [SLOW TEST:18.286 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:26:45.190: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-bc6dd375-5fce-43d8-9b12-dd94d963b8ce
STEP: Creating a pod to test consume secrets
Feb 17 18:26:45.506: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef" in namespace "projected-7052" to be "success or failure"
Feb 17 18:26:45.521: INFO: Pod "pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.863392ms
Feb 17 18:26:47.538: INFO: Pod "pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.031567308s
Feb 17 18:26:49.554: INFO: Pod "pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.047749903s
STEP: Saw pod success
Feb 17 18:26:49.554: INFO: Pod "pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef" satisfied condition "success or failure"
Feb 17 18:26:49.569: INFO: Trying to get logs from node 10.241.69.147 pod pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef container projected-secret-volume-test: <nil>
STEP: delete the pod
Feb 17 18:26:49.685: INFO: Waiting for pod pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef to disappear
Feb 17 18:26:49.705: INFO: Pod pod-projected-secrets-1efc8385-170f-4eea-893b-0a273cca4fef no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:26:49.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7052" for this suite.
Feb 17 18:26:55.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:26:56.342: INFO: namespace projected-7052 deletion completed in 6.61703782s

• [SLOW TEST:11.152 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:26:56.343: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2575
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Feb 17 18:26:56.658: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2575" to be "success or failure"
Feb 17 18:26:56.677: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 18.980483ms
Feb 17 18:26:58.715: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.056890224s
Feb 17 18:27:00.733: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.074967922s
STEP: Saw pod success
Feb 17 18:27:00.733: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Feb 17 18:27:00.765: INFO: Trying to get logs from node 10.241.69.147 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Feb 17 18:27:00.937: INFO: Waiting for pod pod-host-path-test to disappear
Feb 17 18:27:00.967: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:27:00.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2575" for this suite.
Feb 17 18:27:09.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:27:09.802: INFO: namespace hostpath-2575 deletion completed in 8.795000216s

• [SLOW TEST:13.459 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:27:09.804: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4355
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Feb 17 18:27:10.126: INFO: Pod name rollover-pod: Found 0 pods out of 1
Feb 17 18:27:15.143: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Feb 17 18:27:15.143: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Feb 17 18:27:17.159: INFO: Creating deployment "test-rollover-deployment"
Feb 17 18:27:17.212: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Feb 17 18:27:19.239: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Feb 17 18:27:19.268: INFO: Ensure that both replica sets have 1 created replica
Feb 17 18:27:19.302: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Feb 17 18:27:19.342: INFO: Updating deployment test-rollover-deployment
Feb 17 18:27:19.342: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Feb 17 18:27:21.378: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Feb 17 18:27:21.417: INFO: Make sure deployment "test-rollover-deployment" is complete
Feb 17 18:27:21.459: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 18:27:21.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560841, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:27:23.494: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 18:27:23.494: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560841, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:27:25.490: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 18:27:25.490: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560841, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:27:27.487: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 18:27:27.488: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560841, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:27:29.493: INFO: all replica sets need to contain the pod-template-hash label
Feb 17 18:27:29.493: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560841, loc:(*time.Location)(0x788c6e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63717560837, loc:(*time.Location)(0x788c6e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Feb 17 18:27:31.497: INFO: 
Feb 17 18:27:31.497: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Feb 17 18:27:31.548: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4355 /apis/apps/v1/namespaces/deployment-4355/deployments/test-rollover-deployment bfef3a88-b71f-42cb-8853-6fef26af96f3 48983 2 2020-02-17 18:27:17 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f3b4a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-02-17 18:27:17 +0000 UTC,LastTransitionTime:2020-02-17 18:27:17 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-02-17 18:27:31 +0000 UTC,LastTransitionTime:2020-02-17 18:27:17 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Feb 17 18:27:31.566: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-4355 /apis/apps/v1/namespaces/deployment-4355/replicasets/test-rollover-deployment-7d7dc6548c 028de519-b4af-490e-9377-5bfbdeecda51 48973 2 2020-02-17 18:27:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment bfef3a88-b71f-42cb-8853-6fef26af96f3 0xc000f3b9b7 0xc000f3b9b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f3ba18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:27:31.566: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Feb 17 18:27:31.567: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4355 /apis/apps/v1/namespaces/deployment-4355/replicasets/test-rollover-controller ab5b480b-555d-49ef-95cc-7bfce5a8fcea 48982 2 2020-02-17 18:27:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment bfef3a88-b71f-42cb-8853-6fef26af96f3 0xc000f3b897 0xc000f3b898}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000f3b908 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:27:31.567: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4355 /apis/apps/v1/namespaces/deployment-4355/replicasets/test-rollover-deployment-f6c94f66c a95d403b-8ac5-42bf-8511-80c24a27505a 48942 2 2020-02-17 18:27:17 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment bfef3a88-b71f-42cb-8853-6fef26af96f3 0xc000f3ba80 0xc000f3ba81}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f3baf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Feb 17 18:27:31.598: INFO: Pod "test-rollover-deployment-7d7dc6548c-dgssc" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-dgssc test-rollover-deployment-7d7dc6548c- deployment-4355 /api/v1/namespaces/deployment-4355/pods/test-rollover-deployment-7d7dc6548c-dgssc fa5cc418-e13c-4c41-9776-0d0fd5e7d630 48956 0 2020-02-17 18:27:19 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 028de519-b4af-490e-9377-5bfbdeecda51 0xc00399e077 0xc00399e078}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-n4257,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-n4257,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-n4257,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.241.69.147,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*600,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:27:19 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:27:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:27:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-02-17 18:27:19 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.241.69.147,PodIP:172.30.84.46,StartTime:2020-02-17 18:27:19 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-02-17 18:27:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:containerd://eb6eb6687accaa497c8ff45634f758ee05af872e754a52e13fe444a62689c47f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.30.84.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:27:31.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4355" for this suite.
Feb 17 18:27:39.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:27:40.422: INFO: namespace deployment-4355 deletion completed in 8.799197188s

• [SLOW TEST:30.617 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Feb 17 18:27:40.422: INFO: >>> kubeConfig: /tmp/kubeconfig-964215725
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8865
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Feb 17 18:27:40.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47" in namespace "projected-8865" to be "success or failure"
Feb 17 18:27:40.750: INFO: Pod "downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47": Phase="Pending", Reason="", readiness=false. Elapsed: 13.623503ms
Feb 17 18:27:42.766: INFO: Pod "downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02900519s
Feb 17 18:27:44.786: INFO: Pod "downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049227433s
STEP: Saw pod success
Feb 17 18:27:44.786: INFO: Pod "downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47" satisfied condition "success or failure"
Feb 17 18:27:44.813: INFO: Trying to get logs from node 10.241.69.147 pod downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47 container client-container: <nil>
STEP: delete the pod
Feb 17 18:27:44.894: INFO: Waiting for pod downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47 to disappear
Feb 17 18:27:44.914: INFO: Pod downwardapi-volume-3d49f9d8-6d35-47bc-a7b0-e4ac558d0f47 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Feb 17 18:27:44.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8865" for this suite.
Feb 17 18:27:51.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Feb 17 18:27:51.666: INFO: namespace projected-8865 deletion completed in 6.730557715s

• [SLOW TEST:11.244 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.7-beta.0.33+fd5f0b8795e3d6/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSFeb 17 18:27:51.668: INFO: Running AfterSuite actions on all nodes
Feb 17 18:27:51.668: INFO: Running AfterSuite actions on node 1
Feb 17 18:27:51.668: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 8653.547 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 2h24m15.280726257s
Test Suite Passed
