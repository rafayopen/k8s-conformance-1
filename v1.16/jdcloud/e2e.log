I1217 12:49:01.568741      25 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-005828023
I1217 12:49:01.568873      25 e2e.go:92] Starting e2e run "ab33bf15-3dae-48bf-a828-50302edc50e4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576586940 - Will randomize all specs
Will run 276 of 4731 specs

Dec 17 12:49:01.578: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:49:01.580: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 17 12:49:01.611: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 17 12:49:01.648: INFO: 9 / 9 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 17 12:49:01.648: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Dec 17 12:49:01.648: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 17 12:49:01.656: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'jdcloud-k8s-ipamd' (0 seconds elapsed)
Dec 17 12:49:01.656: INFO: 3 / 3 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 17 12:49:01.656: INFO: e2e test version: v1.16.4
Dec 17 12:49:01.658: INFO: kube-apiserver version: v1.16.4-12.8d683d98-dirty
Dec 17 12:49:01.658: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:49:01.667: INFO: Cluster IP family: ipv4
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:49:01.667: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
Dec 17 12:49:01.723: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-beb4fe58-2c49-4ca5-ae52-8eb50387c906
STEP: Creating a pod to test consume secrets
Dec 17 12:49:01.749: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d" in namespace "projected-3416" to be "success or failure"
Dec 17 12:49:01.758: INFO: Pod "pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.718717ms
Dec 17 12:49:03.767: INFO: Pod "pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01783906s
STEP: Saw pod success
Dec 17 12:49:03.767: INFO: Pod "pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d" satisfied condition "success or failure"
Dec 17 12:49:03.776: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 12:49:03.833: INFO: Waiting for pod pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d to disappear
Dec 17 12:49:03.838: INFO: Pod pod-projected-secrets-bade87a6-f6dd-407e-8419-ef56f877811d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:49:03.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3416" for this suite.
Dec 17 12:49:09.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:49:10.072: INFO: namespace projected-3416 deletion completed in 6.226352s

• [SLOW TEST:8.405 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:49:10.073: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-48
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 12:49:10.124: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 12:49:32.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.19:8080/dial?request=hostName&protocol=udp&host=10.0.0.40&port=8081&tries=1'] Namespace:pod-network-test-48 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:49:32.275: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:49:32.359: INFO: Waiting for endpoints: map[]
Dec 17 12:49:32.367: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.19:8080/dial?request=hostName&protocol=udp&host=10.0.0.29&port=8081&tries=1'] Namespace:pod-network-test-48 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:49:32.367: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:49:32.457: INFO: Waiting for endpoints: map[]
Dec 17 12:49:32.465: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.19:8080/dial?request=hostName&protocol=udp&host=10.0.0.36&port=8081&tries=1'] Namespace:pod-network-test-48 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:49:32.465: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:49:32.539: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:49:32.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-48" for this suite.
Dec 17 12:49:44.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:49:44.775: INFO: namespace pod-network-test-48 deletion completed in 12.221623957s

• [SLOW TEST:34.703 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:49:44.775: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 12:49:44.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4584'
Dec 17 12:49:45.014: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 12:49:45.014: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 17 12:49:47.031: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete deployment e2e-test-httpd-deployment --namespace=kubectl-4584'
Dec 17 12:49:47.113: INFO: stderr: ""
Dec 17 12:49:47.113: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:49:47.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4584" for this suite.
Dec 17 12:50:15.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:50:15.356: INFO: namespace kubectl-4584 deletion completed in 28.234987522s

• [SLOW TEST:30.580 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:50:15.356: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 12:50:15.850: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 12:50:18.892: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:50:18.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9489" for this suite.
Dec 17 12:50:24.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:50:25.158: INFO: namespace webhook-9489 deletion completed in 6.233542482s
STEP: Destroying namespace "webhook-9489-markers" for this suite.
Dec 17 12:50:31.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:50:31.388: INFO: namespace webhook-9489-markers deletion completed in 6.230215027s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.070 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:50:31.426: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 12:50:31.487: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276" in namespace "downward-api-1749" to be "success or failure"
Dec 17 12:50:31.494: INFO: Pod "downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276": Phase="Pending", Reason="", readiness=false. Elapsed: 7.776056ms
Dec 17 12:50:33.503: INFO: Pod "downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016543494s
STEP: Saw pod success
Dec 17 12:50:33.503: INFO: Pod "downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276" satisfied condition "success or failure"
Dec 17 12:50:33.508: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276 container client-container: <nil>
STEP: delete the pod
Dec 17 12:50:33.561: INFO: Waiting for pod downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276 to disappear
Dec 17 12:50:33.568: INFO: Pod downwardapi-volume-0a955df7-6992-4183-be5e-03c3dc27f276 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:50:33.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1749" for this suite.
Dec 17 12:50:39.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:50:39.829: INFO: namespace downward-api-1749 deletion completed in 6.245121553s

• [SLOW TEST:8.403 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:50:39.829: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 17 12:50:42.449: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6781 pod-service-account-f9e7ac44-9ee3-4131-a511-cc9bd3ad4494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 17 12:50:42.607: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6781 pod-service-account-f9e7ac44-9ee3-4131-a511-cc9bd3ad4494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 17 12:50:42.767: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-6781 pod-service-account-f9e7ac44-9ee3-4131-a511-cc9bd3ad4494 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:50:42.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6781" for this suite.
Dec 17 12:50:48.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:50:49.180: INFO: namespace svcaccounts-6781 deletion completed in 6.235873077s

• [SLOW TEST:9.352 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:50:49.180: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 17 12:50:49.245: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 17 12:50:59.031: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:51:00.752: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:51:10.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8417" for this suite.
Dec 17 12:51:16.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:51:17.074: INFO: namespace crd-publish-openapi-8417 deletion completed in 6.212571484s

• [SLOW TEST:27.894 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:51:17.074: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-7583c0b3-bf9b-45eb-8662-48bfaf530b27
STEP: Creating a pod to test consume secrets
Dec 17 12:51:17.143: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c" in namespace "projected-6139" to be "success or failure"
Dec 17 12:51:17.151: INFO: Pod "pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.082551ms
Dec 17 12:51:19.160: INFO: Pod "pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017186526s
STEP: Saw pod success
Dec 17 12:51:19.161: INFO: Pod "pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c" satisfied condition "success or failure"
Dec 17 12:51:19.165: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 12:51:19.220: INFO: Waiting for pod pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c to disappear
Dec 17 12:51:19.228: INFO: Pod pod-projected-secrets-a977656f-2952-4e78-999a-a88b2004ef0c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:51:19.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6139" for this suite.
Dec 17 12:51:25.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:51:25.470: INFO: namespace projected-6139 deletion completed in 6.23441185s

• [SLOW TEST:8.395 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:51:25.470: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 12:51:25.534: INFO: Waiting up to 5m0s for pod "pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1" in namespace "emptydir-3735" to be "success or failure"
Dec 17 12:51:25.542: INFO: Pod "pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1": Phase="Pending", Reason="", readiness=false. Elapsed: 7.831542ms
Dec 17 12:51:27.551: INFO: Pod "pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016990016s
STEP: Saw pod success
Dec 17 12:51:27.551: INFO: Pod "pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1" satisfied condition "success or failure"
Dec 17 12:51:27.559: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1 container test-container: <nil>
STEP: delete the pod
Dec 17 12:51:27.602: INFO: Waiting for pod pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1 to disappear
Dec 17 12:51:27.606: INFO: Pod pod-90476bc5-07e2-4e99-b055-93b1fcc5e6c1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:51:27.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3735" for this suite.
Dec 17 12:51:33.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:51:33.944: INFO: namespace emptydir-3735 deletion completed in 6.32411676s

• [SLOW TEST:8.475 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:51:33.945: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-e1269334-f51a-4ef4-bb0e-39906d9fb210
STEP: Creating a pod to test consume configMaps
Dec 17 12:51:34.085: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a" in namespace "projected-8318" to be "success or failure"
Dec 17 12:51:34.089: INFO: Pod "pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.272604ms
Dec 17 12:51:36.095: INFO: Pod "pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009574905s
STEP: Saw pod success
Dec 17 12:51:36.095: INFO: Pod "pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a" satisfied condition "success or failure"
Dec 17 12:51:36.103: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 12:51:36.180: INFO: Waiting for pod pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a to disappear
Dec 17 12:51:36.188: INFO: Pod pod-projected-configmaps-62eb0623-cf88-4d33-97e2-cf5d3c62911a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:51:36.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8318" for this suite.
Dec 17 12:51:42.250: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:51:42.441: INFO: namespace projected-8318 deletion completed in 6.219012886s

• [SLOW TEST:8.496 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:51:42.441: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-0864417f-fa4d-48ea-94a7-0efaa50bf930
STEP: Creating a pod to test consume configMaps
Dec 17 12:51:42.510: INFO: Waiting up to 5m0s for pod "pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7" in namespace "configmap-7050" to be "success or failure"
Dec 17 12:51:42.519: INFO: Pod "pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.195747ms
Dec 17 12:51:44.528: INFO: Pod "pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017807774s
STEP: Saw pod success
Dec 17 12:51:44.528: INFO: Pod "pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7" satisfied condition "success or failure"
Dec 17 12:51:44.533: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 12:51:44.570: INFO: Waiting for pod pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7 to disappear
Dec 17 12:51:44.578: INFO: Pod pod-configmaps-68902525-a3b2-419c-a890-370379ccdac7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:51:44.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7050" for this suite.
Dec 17 12:51:50.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:51:50.799: INFO: namespace configmap-7050 deletion completed in 6.207622713s

• [SLOW TEST:8.358 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:51:50.800: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3031
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 17 12:51:50.878: INFO: Found 0 stateful pods, waiting for 3
Dec 17 12:52:00.887: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:52:00.887: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:52:00.887: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:52:00.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-3031 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 12:52:01.062: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 12:52:01.062: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 12:52:01.062: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 17 12:52:11.118: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 17 12:52:21.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-3031 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 12:52:21.326: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 12:52:21.326: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 12:52:21.326: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 12:52:31.370: INFO: Waiting for StatefulSet statefulset-3031/ss2 to complete update
Dec 17 12:52:31.370: INFO: Waiting for Pod statefulset-3031/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 12:52:31.370: INFO: Waiting for Pod statefulset-3031/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 12:52:31.370: INFO: Waiting for Pod statefulset-3031/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 12:52:41.397: INFO: Waiting for StatefulSet statefulset-3031/ss2 to complete update
Dec 17 12:52:41.397: INFO: Waiting for Pod statefulset-3031/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 12:52:51.386: INFO: Waiting for StatefulSet statefulset-3031/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 17 12:53:01.386: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-3031 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 12:53:01.533: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 12:53:01.533: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 12:53:01.533: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 12:53:11.590: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 17 12:53:21.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-3031 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 12:53:21.781: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 12:53:21.781: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 12:53:21.781: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 12:53:31.832: INFO: Waiting for StatefulSet statefulset-3031/ss2 to complete update
Dec 17 12:53:31.832: INFO: Waiting for Pod statefulset-3031/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 17 12:53:31.832: INFO: Waiting for Pod statefulset-3031/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 17 12:53:31.832: INFO: Waiting for Pod statefulset-3031/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 17 12:53:41.846: INFO: Waiting for StatefulSet statefulset-3031/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 12:53:51.853: INFO: Deleting all statefulset in ns statefulset-3031
Dec 17 12:53:51.858: INFO: Scaling statefulset ss2 to 0
Dec 17 12:54:21.893: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 12:54:21.902: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:54:21.935: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3031" for this suite.
Dec 17 12:54:29.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:54:30.186: INFO: namespace statefulset-3031 deletion completed in 8.235567134s

• [SLOW TEST:159.386 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:54:30.186: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 12:54:31.283: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:54:31.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6086" for this suite.
Dec 17 12:54:37.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:54:37.573: INFO: namespace container-runtime-6086 deletion completed in 6.245657371s

• [SLOW TEST:7.387 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:54:37.574: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 12:54:37.622: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:54:39.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9027" for this suite.
Dec 17 12:54:45.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:54:45.863: INFO: namespace init-container-9027 deletion completed in 6.233593307s

• [SLOW TEST:8.289 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:54:45.863: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 17 12:54:45.928: INFO: Waiting up to 5m0s for pod "var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3" in namespace "var-expansion-2287" to be "success or failure"
Dec 17 12:54:45.936: INFO: Pod "var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3": Phase="Pending", Reason="", readiness=false. Elapsed: 8.866659ms
Dec 17 12:54:47.946: INFO: Pod "var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018053027s
STEP: Saw pod success
Dec 17 12:54:47.946: INFO: Pod "var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3" satisfied condition "success or failure"
Dec 17 12:54:47.950: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3 container dapi-container: <nil>
STEP: delete the pod
Dec 17 12:54:48.009: INFO: Waiting for pod var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3 to disappear
Dec 17 12:54:48.017: INFO: Pod var-expansion-d515d1d4-f7ef-4120-a1a7-6542388613b3 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:54:48.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2287" for this suite.
Dec 17 12:54:54.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:54:54.272: INFO: namespace var-expansion-2287 deletion completed in 6.239763334s

• [SLOW TEST:8.409 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:54:54.272: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 17 12:54:54.346: INFO: Waiting up to 5m0s for pod "pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38" in namespace "emptydir-1890" to be "success or failure"
Dec 17 12:54:54.350: INFO: Pod "pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38": Phase="Pending", Reason="", readiness=false. Elapsed: 3.999992ms
Dec 17 12:54:56.358: INFO: Pod "pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012841162s
STEP: Saw pod success
Dec 17 12:54:56.358: INFO: Pod "pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38" satisfied condition "success or failure"
Dec 17 12:54:56.363: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38 container test-container: <nil>
STEP: delete the pod
Dec 17 12:54:56.422: INFO: Waiting for pod pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38 to disappear
Dec 17 12:54:56.431: INFO: Pod pod-6f7e537b-f2d3-4481-8fa6-f3ae0f95eb38 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:54:56.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1890" for this suite.
Dec 17 12:55:02.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:55:02.660: INFO: namespace emptydir-1890 deletion completed in 6.221644486s

• [SLOW TEST:8.388 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:55:02.660: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5568
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 12:55:02.718: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 12:55:22.892: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.26:8080/dial?request=hostName&protocol=http&host=10.0.0.4&port=8080&tries=1'] Namespace:pod-network-test-5568 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:55:22.892: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:55:24.089: INFO: Waiting for endpoints: map[]
Dec 17 12:55:24.100: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.26:8080/dial?request=hostName&protocol=http&host=10.0.0.15&port=8080&tries=1'] Namespace:pod-network-test-5568 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:55:24.100: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:55:24.198: INFO: Waiting for endpoints: map[]
Dec 17 12:55:24.207: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.0.0.26:8080/dial?request=hostName&protocol=http&host=10.0.0.23&port=8080&tries=1'] Namespace:pod-network-test-5568 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 12:55:24.207: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 12:55:24.296: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:55:24.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5568" for this suite.
Dec 17 12:55:36.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:55:36.539: INFO: namespace pod-network-test-5568 deletion completed in 12.229006632s

• [SLOW TEST:33.879 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:55:36.539: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 12:55:37.031: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 12:55:40.072: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:55:40.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8765" for this suite.
Dec 17 12:55:46.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:55:46.698: INFO: namespace webhook-8765 deletion completed in 6.220463645s
STEP: Destroying namespace "webhook-8765-markers" for this suite.
Dec 17 12:55:52.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:55:52.926: INFO: namespace webhook-8765-markers deletion completed in 6.228670425s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.428 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:55:52.967: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 12:55:53.031: INFO: Waiting up to 5m0s for pod "downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c" in namespace "projected-2923" to be "success or failure"
Dec 17 12:55:53.040: INFO: Pod "downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.928788ms
Dec 17 12:55:55.050: INFO: Pod "downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018518042s
STEP: Saw pod success
Dec 17 12:55:55.050: INFO: Pod "downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c" satisfied condition "success or failure"
Dec 17 12:55:55.054: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c container client-container: <nil>
STEP: delete the pod
Dec 17 12:55:55.102: INFO: Waiting for pod downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c to disappear
Dec 17 12:55:55.111: INFO: Pod downwardapi-volume-70030af9-c241-4513-a17a-a764529cae1c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:55:55.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2923" for this suite.
Dec 17 12:56:01.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:01.364: INFO: namespace projected-2923 deletion completed in 6.244914869s

• [SLOW TEST:8.396 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:08.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1792" for this suite.
Dec 17 12:56:14.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:14.684: INFO: namespace resourcequota-1792 deletion completed in 6.217585043s

• [SLOW TEST:13.320 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:14.684: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 12:56:14.767: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 12:56:16.781: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 12:56:18.836: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-875 /apis/apps/v1/namespaces/deployment-875/deployments/test-cleanup-deployment f085f817-5348-42eb-8a62-9e74d94e2b1a 242195 1 2019-12-17 12:56:16 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025e4ba8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-17 12:56:16 +0000 UTC,LastTransitionTime:2019-12-17 12:56:16 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-12-17 12:56:17 +0000 UTC,LastTransitionTime:2019-12-17 12:56:16 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 12:56:18.844: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-875 /apis/apps/v1/namespaces/deployment-875/replicasets/test-cleanup-deployment-65db99849b 0959813d-3249-4350-924a-3effd7e9bc3f 242185 1 2019-12-17 12:56:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment f085f817-5348-42eb-8a62-9e74d94e2b1a 0xc0025e57f7 0xc0025e57f8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0025e5858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 12:56:18.852: INFO: Pod "test-cleanup-deployment-65db99849b-bq848" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-bq848 test-cleanup-deployment-65db99849b- deployment-875 /api/v1/namespaces/deployment-875/pods/test-cleanup-deployment-65db99849b-bq848 492f560f-4f17-459f-9970-11541b5585e4 242184 0 2019-12-17 12:56:16 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 0959813d-3249-4350-924a-3effd7e9bc3f 0xc0025e5c07 0xc0025e5c08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-m674d,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-m674d,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-m674d,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:56:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:56:17 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:56:16 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.28,StartTime:2019-12-17 12:56:16 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 12:56:17 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://1297830459bb7e5c83c61a2aaacf721d3dc9a2d9c5459f6a4866b591576b7d24,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.28,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:18.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-875" for this suite.
Dec 17 12:56:24.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:25.089: INFO: namespace deployment-875 deletion completed in 6.229669449s

• [SLOW TEST:10.405 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:25.089: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 12:56:25.151: INFO: Waiting up to 5m0s for pod "pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90" in namespace "emptydir-3307" to be "success or failure"
Dec 17 12:56:25.156: INFO: Pod "pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90": Phase="Pending", Reason="", readiness=false. Elapsed: 5.313594ms
Dec 17 12:56:27.166: INFO: Pod "pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014461319s
STEP: Saw pod success
Dec 17 12:56:27.166: INFO: Pod "pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90" satisfied condition "success or failure"
Dec 17 12:56:27.174: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90 container test-container: <nil>
STEP: delete the pod
Dec 17 12:56:27.210: INFO: Waiting for pod pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90 to disappear
Dec 17 12:56:27.218: INFO: Pod pod-9ecd7cb1-7e78-48dc-9e90-0ec329656a90 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:27.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3307" for this suite.
Dec 17 12:56:33.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:33.462: INFO: namespace emptydir-3307 deletion completed in 6.229816826s

• [SLOW TEST:8.373 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:33.462: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-3b3f6e60-55bf-40a0-9641-854f1ea5812b
STEP: Creating a pod to test consume secrets
Dec 17 12:56:33.528: INFO: Waiting up to 5m0s for pod "pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288" in namespace "secrets-6569" to be "success or failure"
Dec 17 12:56:33.537: INFO: Pod "pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288": Phase="Pending", Reason="", readiness=false. Elapsed: 9.638142ms
Dec 17 12:56:35.543: INFO: Pod "pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015125239s
STEP: Saw pod success
Dec 17 12:56:35.543: INFO: Pod "pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288" satisfied condition "success or failure"
Dec 17 12:56:35.551: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 12:56:35.611: INFO: Waiting for pod pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288 to disappear
Dec 17 12:56:35.615: INFO: Pod pod-secrets-13922d80-5afa-4277-ba8e-f20250bdf288 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:35.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6569" for this suite.
Dec 17 12:56:41.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:41.853: INFO: namespace secrets-6569 deletion completed in 6.230623743s

• [SLOW TEST:8.391 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:41.853: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:41.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1880" for this suite.
Dec 17 12:56:48.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:48.196: INFO: namespace resourcequota-1880 deletion completed in 6.214548402s

• [SLOW TEST:6.342 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:48.196: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 12:56:48.263: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea" in namespace "downward-api-3898" to be "success or failure"
Dec 17 12:56:48.272: INFO: Pod "downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea": Phase="Pending", Reason="", readiness=false. Elapsed: 8.742612ms
Dec 17 12:56:50.281: INFO: Pod "downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017906379s
STEP: Saw pod success
Dec 17 12:56:50.281: INFO: Pod "downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea" satisfied condition "success or failure"
Dec 17 12:56:50.289: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea container client-container: <nil>
STEP: delete the pod
Dec 17 12:56:50.326: INFO: Waiting for pod downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea to disappear
Dec 17 12:56:50.330: INFO: Pod downwardapi-volume-2288deb8-aca4-4754-8019-ca973daf70ea no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:50.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3898" for this suite.
Dec 17 12:56:56.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:56:56.586: INFO: namespace downward-api-3898 deletion completed in 6.241616375s

• [SLOW TEST:8.390 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:56:56.586: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 17 12:56:57.178: INFO: created pod pod-service-account-defaultsa
Dec 17 12:56:57.178: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 17 12:56:57.184: INFO: created pod pod-service-account-mountsa
Dec 17 12:56:57.184: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 17 12:56:57.195: INFO: created pod pod-service-account-nomountsa
Dec 17 12:56:57.195: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 17 12:56:57.202: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 17 12:56:57.202: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 17 12:56:57.210: INFO: created pod pod-service-account-mountsa-mountspec
Dec 17 12:56:57.210: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 17 12:56:57.233: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 17 12:56:57.233: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 17 12:56:57.239: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 17 12:56:57.239: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 17 12:56:57.244: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 17 12:56:57.244: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 17 12:56:57.267: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 17 12:56:57.267: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:56:57.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4720" for this suite.
Dec 17 12:57:03.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:57:03.521: INFO: namespace svcaccounts-4720 deletion completed in 6.224131343s

• [SLOW TEST:6.935 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:57:03.521: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 12:57:03.570: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 17 12:57:03.584: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 17 12:57:08.593: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 12:57:08.593: INFO: Creating deployment "test-rolling-update-deployment"
Dec 17 12:57:08.600: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 17 12:57:08.617: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 17 12:57:10.631: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 17 12:57:10.639: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 12:57:10.659: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-7865 /apis/apps/v1/namespaces/deployment-7865/deployments/test-rolling-update-deployment ca09b0c9-37db-461d-b95c-0fa84a42bfab 242559 1 2019-12-17 12:57:08 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007f3448 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-17 12:57:08 +0000 UTC,LastTransitionTime:2019-12-17 12:57:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-17 12:57:10 +0000 UTC,LastTransitionTime:2019-12-17 12:57:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 12:57:10.664: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-7865 /apis/apps/v1/namespaces/deployment-7865/replicasets/test-rolling-update-deployment-55d946486 ecbf222d-cd72-4de7-979d-c9bbcb1233eb 242548 1 2019-12-17 12:57:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment ca09b0c9-37db-461d-b95c-0fa84a42bfab 0xc0007f3df0 0xc0007f3df1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007f3e58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 12:57:10.664: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 17 12:57:10.665: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-7865 /apis/apps/v1/namespaces/deployment-7865/replicasets/test-rolling-update-controller 75cb098a-457b-4491-813f-c67e7c3199aa 242557 2 2019-12-17 12:57:03 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment ca09b0c9-37db-461d-b95c-0fa84a42bfab 0xc0007f3d27 0xc0007f3d28}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0007f3d88 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 12:57:10.673: INFO: Pod "test-rolling-update-deployment-55d946486-b6n5p" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-b6n5p test-rolling-update-deployment-55d946486- deployment-7865 /api/v1/namespaces/deployment-7865/pods/test-rolling-update-deployment-55d946486-b6n5p ca9978f6-8349-4b8f-8f7f-3d03f1d8f03a 242547 0 2019-12-17 12:57:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 ecbf222d-cd72-4de7-979d-c9bbcb1233eb 0xc000728760 0xc000728761}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lsdx5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lsdx5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lsdx5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:57:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:57:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 12:57:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.37,StartTime:2019-12-17 12:57:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 12:57:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://a3737b6a1a5ad211abf8eb781337d72d38848e66e91b8c22554173a305666409,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:57:10.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7865" for this suite.
Dec 17 12:57:16.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:57:16.919: INFO: namespace deployment-7865 deletion completed in 6.231535497s

• [SLOW TEST:13.398 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:57:16.919: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3849
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 17 12:57:16.990: INFO: Found 0 stateful pods, waiting for 3
Dec 17 12:57:27.010: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:57:27.010: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:57:27.010: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 17 12:57:27.058: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 17 12:57:37.114: INFO: Updating stateful set ss2
Dec 17 12:57:37.144: INFO: Waiting for Pod statefulset-3849/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 17 12:57:47.229: INFO: Found 2 stateful pods, waiting for 3
Dec 17 12:57:57.238: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:57:57.238: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 12:57:57.238: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 17 12:57:57.281: INFO: Updating stateful set ss2
Dec 17 12:57:57.298: INFO: Waiting for Pod statefulset-3849/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 17 12:58:07.340: INFO: Updating stateful set ss2
Dec 17 12:58:07.358: INFO: Waiting for StatefulSet statefulset-3849/ss2 to complete update
Dec 17 12:58:07.358: INFO: Waiting for Pod statefulset-3849/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 12:58:17.372: INFO: Deleting all statefulset in ns statefulset-3849
Dec 17 12:58:17.379: INFO: Scaling statefulset ss2 to 0
Dec 17 12:58:47.408: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 12:58:47.415: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:58:47.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3849" for this suite.
Dec 17 12:58:55.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:58:55.719: INFO: namespace statefulset-3849 deletion completed in 8.254762462s

• [SLOW TEST:98.800 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:58:55.719: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 12:58:55.779: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 12:58:55.814: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 12:58:55.818: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm2x4q-7kwnapovj8 before test
Dec 17 12:58:55.846: INFO: kube-state-metrics-f58cb6d75-fhf77 from jke-system started at 2019-12-17 10:07:27 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 17 12:58:55.846: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 17 12:58:55.846: INFO: coredns-8565b9f7f-w876f from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container coredns ready: true, restart count 0
Dec 17 12:58:55.846: INFO: prometheus-5ff89497-v69gb from jke-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container prometheus ready: true, restart count 0
Dec 17 12:58:55.846: INFO: kube-proxy-2zp6v from kube-system started at 2019-12-17 09:43:31 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 12:58:55.846: INFO: node-exporter-gv5p5 from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 12:58:55.846: INFO: fluent-bit-8f5mr from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 17 12:58:55.846: INFO: csi-jdcloudplugin-v42hq from jke-system started at 2019-12-17 09:43:39 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 12:58:55.846: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 12:58:55.846: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 from sonobuoy started at 2019-12-17 12:47:40 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 12:58:55.846: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 12:58:55.846: INFO: jdcloud-k8s-ipamd-g4vm6 from kube-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.846: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 12:58:55.846: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm4x4d-7kwnapovj8 before test
Dec 17 12:58:55.866: INFO: fluent-bit-5w4zl from jke-system started at 2019-12-16 10:57:14 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 12:58:55.866: INFO: kube-proxy-4bjhm from kube-system started at 2019-12-16 11:03:02 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 12:58:55.866: INFO: prometheus-jdmon-756f6977d7-g2jqg from jke-system started at 2019-12-16 14:30:05 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Dec 17 12:58:55.866: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-12-17 07:43:48 +0000 UTC (4 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 17 12:58:55.866: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 17 12:58:55.866: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 12:58:55.866: INFO: 	Container liveness-probe ready: true, restart count 0
Dec 17 12:58:55.866: INFO: node-exporter-bxz78 from jke-system started at 2019-12-16 11:12:13 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 12:58:55.866: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf from sonobuoy started at 2019-12-17 12:47:31 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.866: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 12:58:55.867: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 12:58:55.867: INFO: csi-jdcloudplugin-cgvgf from jke-system started at 2019-12-17 07:43:48 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.867: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 12:58:55.867: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 12:58:55.867: INFO: jdcloud-k8s-ipamd-n8jwz from kube-system started at 2019-12-16 10:13:39 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.867: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 12:58:55.867: INFO: coredns-8565b9f7f-sll5x from kube-system started at 2019-12-17 08:47:51 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.867: INFO: 	Container coredns ready: true, restart count 0
Dec 17 12:58:55.867: INFO: kubernetes-dashboard-6c9b78cc5c-kh2f5 from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.867: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 12:58:55.867: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm923c-7kwnapovj8 before test
Dec 17 12:58:55.896: INFO: fluent-bit-wlpbj from jke-system started at 2019-12-17 12:01:30 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.896: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 12:58:55.896: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv from sonobuoy started at 2019-12-17 12:47:35 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.896: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 12:58:55.896: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 12:58:55.896: INFO: kube-proxy-qlpgh from kube-system started at 2019-12-17 12:01:30 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.896: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 12:58:55.896: INFO: node-exporter-z2hdq from jke-system started at 2019-12-17 12:01:30 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.896: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 12:58:55.896: INFO: csi-jdcloudplugin-wkgxm from jke-system started at 2019-12-17 12:01:30 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.897: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 12:58:55.897: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 12:58:55.897: INFO: sonobuoy-e2e-job-f5193f6f15e64a7e from sonobuoy started at 2019-12-17 12:48:59 +0000 UTC (2 container statuses recorded)
Dec 17 12:58:55.897: INFO: 	Container e2e ready: true, restart count 0
Dec 17 12:58:55.897: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 12:58:55.897: INFO: jdcloud-k8s-ipamd-b4x9c from kube-system started at 2019-12-17 12:01:30 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.897: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 12:58:55.897: INFO: sonobuoy from sonobuoy started at 2019-12-17 12:46:46 +0000 UTC (1 container statuses recorded)
Dec 17 12:58:55.897: INFO: 	Container kube-sonobuoy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node k8s-node-vm2x4q-7kwnapovj8
STEP: verifying the node has the label node k8s-node-vm4x4d-7kwnapovj8
STEP: verifying the node has the label node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod csi-jdcloudplugin-cgvgf requesting resource cpu=0m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod csi-jdcloudplugin-controller-0 requesting resource cpu=0m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod csi-jdcloudplugin-v42hq requesting resource cpu=0m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod csi-jdcloudplugin-wkgxm requesting resource cpu=0m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod fluent-bit-5w4zl requesting resource cpu=200m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod fluent-bit-8f5mr requesting resource cpu=200m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod fluent-bit-wlpbj requesting resource cpu=200m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod kube-state-metrics-f58cb6d75-fhf77 requesting resource cpu=100m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod node-exporter-bxz78 requesting resource cpu=200m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod node-exporter-gv5p5 requesting resource cpu=200m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod node-exporter-z2hdq requesting resource cpu=200m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod prometheus-5ff89497-v69gb requesting resource cpu=0m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod prometheus-jdmon-756f6977d7-g2jqg requesting resource cpu=0m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod coredns-8565b9f7f-sll5x requesting resource cpu=100m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod coredns-8565b9f7f-w876f requesting resource cpu=100m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod jdcloud-k8s-ipamd-b4x9c requesting resource cpu=200m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod jdcloud-k8s-ipamd-g4vm6 requesting resource cpu=200m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod jdcloud-k8s-ipamd-n8jwz requesting resource cpu=200m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod kube-proxy-2zp6v requesting resource cpu=200m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod kube-proxy-4bjhm requesting resource cpu=200m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod kube-proxy-qlpgh requesting resource cpu=200m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod kubernetes-dashboard-6c9b78cc5c-kh2f5 requesting resource cpu=0m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod sonobuoy requesting resource cpu=0m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod sonobuoy-e2e-job-f5193f6f15e64a7e requesting resource cpu=0m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 requesting resource cpu=0m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv requesting resource cpu=0m on Node k8s-node-vm923c-7kwnapovj8
Dec 17 12:58:56.028: INFO: Pod sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf requesting resource cpu=0m on Node k8s-node-vm4x4d-7kwnapovj8
STEP: Starting Pods to consume most of the cluster CPU.
Dec 17 12:58:56.028: INFO: Creating a pod which consumes cpu=2044m on Node k8s-node-vm2x4q-7kwnapovj8
Dec 17 12:58:56.049: INFO: Creating a pod which consumes cpu=2114m on Node k8s-node-vm4x4d-7kwnapovj8
Dec 17 12:58:56.060: INFO: Creating a pod which consumes cpu=2184m on Node k8s-node-vm923c-7kwnapovj8
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42.15e12a02ca4af43b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6035/filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42 to k8s-node-vm2x4q-7kwnapovj8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42.15e12a02e82aa12f], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42.15e12a02ea90f33f], Reason = [Created], Message = [Created container filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42.15e12a02ee91cd66], Reason = [Started], Message = [Started container filler-pod-52d42922-60a7-4296-b110-1b1715cb5a42]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828.15e12a02ca8c6c7c], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6035/filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828 to k8s-node-vm4x4d-7kwnapovj8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828.15e12a02e5c2bfcf], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828.15e12a02e76792be], Reason = [Created], Message = [Created container filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828.15e12a02eb26d39f], Reason = [Started], Message = [Started container filler-pod-6a982b5d-c306-41d3-8e64-2098d3ba7828]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3.15e12a02cb606b4e], Reason = [Scheduled], Message = [Successfully assigned sched-pred-6035/filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3 to k8s-node-vm923c-7kwnapovj8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3.15e12a02e8b9292e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3.15e12a02ea36a53d], Reason = [Created], Message = [Created container filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3.15e12a02ee1a7b26], Reason = [Started], Message = [Started container filler-pod-c840175b-9459-4e12-acf1-1a13693c60c3]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e12a0344b67e3f], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e12a0345bbad02], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 Insufficient cpu.]
STEP: removing the label node off the node k8s-node-vm2x4q-7kwnapovj8
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-vm4x4d-7kwnapovj8
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node k8s-node-vm923c-7kwnapovj8
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:58:59.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6035" for this suite.
Dec 17 12:59:05.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:59:05.485: INFO: namespace sched-pred-6035 deletion completed in 6.26174284s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.766 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:59:05.486: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 12:59:09.621: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:09.629: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:11.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:11.635: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:13.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:13.647: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:15.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:15.634: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:17.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:17.647: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:19.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:19.639: INFO: Pod pod-with-prestop-http-hook still exists
Dec 17 12:59:21.629: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 17 12:59:21.638: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 12:59:21.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3410" for this suite.
Dec 17 12:59:33.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 12:59:33.902: INFO: namespace container-lifecycle-hook-3410 deletion completed in 12.23134584s

• [SLOW TEST:28.417 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 12:59:33.903: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-0b74ef8c-5bf9-4b1d-a8f7-2664578bbd0d
STEP: Creating configMap with name cm-test-opt-upd-04e51d2d-1f22-413c-8461-111452a344bb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0b74ef8c-5bf9-4b1d-a8f7-2664578bbd0d
STEP: Updating configmap cm-test-opt-upd-04e51d2d-1f22-413c-8461-111452a344bb
STEP: Creating configMap with name cm-test-opt-create-1eaf7b56-f277-4452-902f-6fa626dd8ab7
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:00:52.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-468" for this suite.
Dec 17 13:01:12.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:01:13.127: INFO: namespace projected-468 deletion completed in 20.228872809s

• [SLOW TEST:99.224 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:01:13.127: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 17 13:01:13.176: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 13:01:15.884: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:01:23.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3035" for this suite.
Dec 17 13:01:29.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:01:30.159: INFO: namespace crd-publish-openapi-3035 deletion completed in 6.234254952s

• [SLOW TEST:17.032 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:01:30.159: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-61d7ebf2-b895-457e-a88a-9bdc01e8b2d8
STEP: Creating secret with name s-test-opt-upd-b0d5da06-fbba-4b9a-9940-7bb8605796f6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-61d7ebf2-b895-457e-a88a-9bdc01e8b2d8
STEP: Updating secret s-test-opt-upd-b0d5da06-fbba-4b9a-9940-7bb8605796f6
STEP: Creating secret with name s-test-opt-create-f9810cee-258c-4394-aaf0-553778547db9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:01:34.458: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2614" for this suite.
Dec 17 13:01:52.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:01:52.701: INFO: namespace projected-2614 deletion completed in 18.22515389s

• [SLOW TEST:22.542 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:01:52.701: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 13:01:53.790: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:01:53.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3416" for this suite.
Dec 17 13:01:59.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:02:00.037: INFO: namespace container-runtime-3416 deletion completed in 6.207204123s

• [SLOW TEST:7.336 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:02:00.038: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9227
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 13:02:00.085: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 13:02:18.275: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.0.0.36:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9227 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 13:02:18.275: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 13:02:18.373: INFO: Found all expected endpoints: [netserver-0]
Dec 17 13:02:18.378: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.0.0.6:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9227 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 13:02:18.378: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 13:02:18.506: INFO: Found all expected endpoints: [netserver-1]
Dec 17 13:02:18.514: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.0.0.47:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9227 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 13:02:18.514: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 13:02:18.608: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:02:18.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9227" for this suite.
Dec 17 13:02:30.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:02:30.908: INFO: namespace pod-network-test-9227 deletion completed in 12.285192245s

• [SLOW TEST:30.871 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:02:30.909: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:02:31.045: INFO: Create a RollingUpdate DaemonSet
Dec 17 13:02:31.054: INFO: Check that daemon pods launch on every node of the cluster
Dec 17 13:02:31.073: INFO: Number of nodes with available pods: 0
Dec 17 13:02:31.073: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:02:32.095: INFO: Number of nodes with available pods: 3
Dec 17 13:02:32.096: INFO: Number of running nodes: 3, number of available pods: 3
Dec 17 13:02:32.096: INFO: Update the DaemonSet to trigger a rollout
Dec 17 13:02:32.109: INFO: Updating DaemonSet daemon-set
Dec 17 13:02:41.139: INFO: Roll back the DaemonSet before rollout is complete
Dec 17 13:02:41.153: INFO: Updating DaemonSet daemon-set
Dec 17 13:02:41.153: INFO: Make sure DaemonSet rollback is complete
Dec 17 13:02:41.162: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:41.162: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:42.187: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:42.187: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:43.184: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:43.184: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:44.184: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:44.184: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:45.184: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:45.184: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:46.188: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:46.188: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:47.187: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:47.187: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:48.184: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:48.184: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:49.183: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:49.183: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:50.187: INFO: Wrong image for pod: daemon-set-trvkd. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 17 13:02:50.187: INFO: Pod daemon-set-trvkd is not available
Dec 17 13:02:51.188: INFO: Pod daemon-set-8k2tl is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9710, will wait for the garbage collector to delete the pods
Dec 17 13:02:51.284: INFO: Deleting DaemonSet.extensions daemon-set took: 17.940463ms
Dec 17 13:02:51.584: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.19791ms
Dec 17 13:03:01.993: INFO: Number of nodes with available pods: 0
Dec 17 13:03:01.993: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 13:03:02.002: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9710/daemonsets","resourceVersion":"244052"},"items":null}

Dec 17 13:03:02.007: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9710/pods","resourceVersion":"244052"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:03:02.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9710" for this suite.
Dec 17 13:03:08.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:03:08.289: INFO: namespace daemonsets-9710 deletion completed in 6.231666009s

• [SLOW TEST:37.381 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:03:08.290: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 13:03:08.354: INFO: Waiting up to 5m0s for pod "downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936" in namespace "downward-api-5169" to be "success or failure"
Dec 17 13:03:08.359: INFO: Pod "downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936": Phase="Pending", Reason="", readiness=false. Elapsed: 5.768713ms
Dec 17 13:03:10.368: INFO: Pod "downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014763003s
STEP: Saw pod success
Dec 17 13:03:10.368: INFO: Pod "downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936" satisfied condition "success or failure"
Dec 17 13:03:10.373: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936 container dapi-container: <nil>
STEP: delete the pod
Dec 17 13:03:10.436: INFO: Waiting for pod downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936 to disappear
Dec 17 13:03:10.446: INFO: Pod downward-api-b773bfaf-a8dc-440f-b935-b1ec2ccf4936 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:03:10.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5169" for this suite.
Dec 17 13:03:16.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:03:16.714: INFO: namespace downward-api-5169 deletion completed in 6.253544691s

• [SLOW TEST:8.424 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:03:16.714: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:03:17.460: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:03:20.504: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:03:21.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7079" for this suite.
Dec 17 13:03:27.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:03:27.344: INFO: namespace webhook-7079 deletion completed in 6.22905899s
STEP: Destroying namespace "webhook-7079-markers" for this suite.
Dec 17 13:03:33.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:03:33.637: INFO: namespace webhook-7079-markers deletion completed in 6.293236295s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.963 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:03:33.677: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-cjf4
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 13:03:33.798: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cjf4" in namespace "subpath-4762" to be "success or failure"
Dec 17 13:03:33.806: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.085403ms
Dec 17 13:03:35.811: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 2.013608257s
Dec 17 13:03:37.820: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 4.022484898s
Dec 17 13:03:39.829: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 6.031416096s
Dec 17 13:03:41.838: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 8.040113335s
Dec 17 13:03:43.843: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 10.045441706s
Dec 17 13:03:45.848: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 12.050391599s
Dec 17 13:03:47.857: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 14.059247526s
Dec 17 13:03:49.862: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 16.064232321s
Dec 17 13:03:51.873: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 18.07501909s
Dec 17 13:03:53.883: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Running", Reason="", readiness=true. Elapsed: 20.085503796s
Dec 17 13:03:55.892: INFO: Pod "pod-subpath-test-configmap-cjf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.094648029s
STEP: Saw pod success
Dec 17 13:03:55.892: INFO: Pod "pod-subpath-test-configmap-cjf4" satisfied condition "success or failure"
Dec 17 13:03:55.900: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-subpath-test-configmap-cjf4 container test-container-subpath-configmap-cjf4: <nil>
STEP: delete the pod
Dec 17 13:03:55.939: INFO: Waiting for pod pod-subpath-test-configmap-cjf4 to disappear
Dec 17 13:03:55.943: INFO: Pod pod-subpath-test-configmap-cjf4 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cjf4
Dec 17 13:03:55.943: INFO: Deleting pod "pod-subpath-test-configmap-cjf4" in namespace "subpath-4762"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:03:55.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4762" for this suite.
Dec 17 13:04:01.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:04:02.186: INFO: namespace subpath-4762 deletion completed in 6.220869351s

• [SLOW TEST:28.509 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:04:02.186: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:04:02.899: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:04:05.944: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:04:06.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-771" for this suite.
Dec 17 13:04:18.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:04:18.257: INFO: namespace webhook-771 deletion completed in 12.232942996s
STEP: Destroying namespace "webhook-771-markers" for this suite.
Dec 17 13:04:24.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:04:24.564: INFO: namespace webhook-771-markers deletion completed in 6.307157411s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.416 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:04:24.602: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 13:04:24.671: INFO: Waiting up to 5m0s for pod "downward-api-82e74b60-a69a-470a-858a-3b6efe55831e" in namespace "downward-api-9853" to be "success or failure"
Dec 17 13:04:24.676: INFO: Pod "downward-api-82e74b60-a69a-470a-858a-3b6efe55831e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.413722ms
Dec 17 13:04:26.681: INFO: Pod "downward-api-82e74b60-a69a-470a-858a-3b6efe55831e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009671808s
STEP: Saw pod success
Dec 17 13:04:26.681: INFO: Pod "downward-api-82e74b60-a69a-470a-858a-3b6efe55831e" satisfied condition "success or failure"
Dec 17 13:04:26.689: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downward-api-82e74b60-a69a-470a-858a-3b6efe55831e container dapi-container: <nil>
STEP: delete the pod
Dec 17 13:04:26.740: INFO: Waiting for pod downward-api-82e74b60-a69a-470a-858a-3b6efe55831e to disappear
Dec 17 13:04:26.744: INFO: Pod downward-api-82e74b60-a69a-470a-858a-3b6efe55831e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:04:26.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9853" for this suite.
Dec 17 13:04:32.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:04:32.987: INFO: namespace downward-api-9853 deletion completed in 6.236362098s

• [SLOW TEST:8.385 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:04:32.987: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:04:49.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9605" for this suite.
Dec 17 13:04:55.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:04:55.459: INFO: namespace resourcequota-9605 deletion completed in 6.235476476s

• [SLOW TEST:22.472 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:04:55.459: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 17 13:04:55.531: INFO: Waiting up to 5m0s for pod "client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b" in namespace "containers-2843" to be "success or failure"
Dec 17 13:04:55.541: INFO: Pod "client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.271542ms
Dec 17 13:04:57.550: INFO: Pod "client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018372267s
STEP: Saw pod success
Dec 17 13:04:57.550: INFO: Pod "client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b" satisfied condition "success or failure"
Dec 17 13:04:57.558: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b container test-container: <nil>
STEP: delete the pod
Dec 17 13:04:57.601: INFO: Waiting for pod client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b to disappear
Dec 17 13:04:57.606: INFO: Pod client-containers-c34cf9c1-5488-4158-9f01-194e98d4537b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:04:57.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2843" for this suite.
Dec 17 13:05:03.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:05:03.856: INFO: namespace containers-2843 deletion completed in 6.235712004s

• [SLOW TEST:8.397 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:05:03.856: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-22c4f761-1f0a-4397-b6db-2869d2b2d162
STEP: Creating a pod to test consume secrets
Dec 17 13:05:03.929: INFO: Waiting up to 5m0s for pod "pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934" in namespace "secrets-2639" to be "success or failure"
Dec 17 13:05:03.934: INFO: Pod "pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934": Phase="Pending", Reason="", readiness=false. Elapsed: 4.721446ms
Dec 17 13:05:05.943: INFO: Pod "pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013792631s
STEP: Saw pod success
Dec 17 13:05:05.943: INFO: Pod "pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934" satisfied condition "success or failure"
Dec 17 13:05:05.947: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:05:05.984: INFO: Waiting for pod pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934 to disappear
Dec 17 13:05:05.993: INFO: Pod pod-secrets-abd91d77-ccdf-4a06-9d6c-683b61de9934 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:05:05.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2639" for this suite.
Dec 17 13:05:12.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:05:12.249: INFO: namespace secrets-2639 deletion completed in 6.242185695s

• [SLOW TEST:8.393 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:05:12.250: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:05:12.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6996'
Dec 17 13:05:12.598: INFO: stderr: ""
Dec 17 13:05:12.598: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 17 13:05:12.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6996'
Dec 17 13:05:12.754: INFO: stderr: ""
Dec 17 13:05:12.754: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 13:05:13.763: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 13:05:13.763: INFO: Found 1 / 1
Dec 17 13:05:13.763: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 13:05:13.768: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 13:05:13.768: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 13:05:13.768: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 describe pod redis-master-zv729 --namespace=kubectl-6996'
Dec 17 13:05:13.855: INFO: stderr: ""
Dec 17 13:05:13.855: INFO: stdout: "Name:         redis-master-zv729\nNamespace:    kubectl-6996\nPriority:     0\nNode:         k8s-node-vm923c-7kwnapovj8/10.0.32.5\nStart Time:   Tue, 17 Dec 2019 13:05:12 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.0.0.26\nIPs:\n  IP:           10.0.0.26\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://ba5d04fc6d44a32c49483a20c4d36221a7a809b9ecf0d3510611fc643cee8465\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 17 Dec 2019 13:05:13 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-qb2qt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-qb2qt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-qb2qt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                 Message\n  ----    ------     ----       ----                                 -------\n  Normal  Scheduled  <unknown>  default-scheduler                    Successfully assigned kubectl-6996/redis-master-zv729 to k8s-node-vm923c-7kwnapovj8\n  Normal  Pulled     0s         kubelet, k8s-node-vm923c-7kwnapovj8  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    0s         kubelet, k8s-node-vm923c-7kwnapovj8  Created container redis-master\n  Normal  Started    0s         kubelet, k8s-node-vm923c-7kwnapovj8  Started container redis-master\n"
Dec 17 13:05:13.855: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 describe rc redis-master --namespace=kubectl-6996'
Dec 17 13:05:13.942: INFO: stderr: ""
Dec 17 13:05:13.942: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-6996\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-zv729\n"
Dec 17 13:05:13.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 describe service redis-master --namespace=kubectl-6996'
Dec 17 13:05:14.025: INFO: stderr: ""
Dec 17 13:05:14.025: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-6996\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.0.56.106\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.0.0.26:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 17 13:05:14.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 describe node k8s-node-vm2x4q-7kwnapovj8'
Dec 17 13:05:14.161: INFO: stderr: ""
Dec 17 13:05:14.161: INFO: stdout: "Name:               k8s-node-vm2x4q-7kwnapovj8\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=g.n2.xlarge\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/jke-fd=1\n                    failure-domain.beta.kubernetes.io/jke-nodegroup=ng-7kwnapovj8\n                    failure-domain.beta.kubernetes.io/region=cn-east-2\n                    failure-domain.beta.kubernetes.io/zone=cn-east-2b\n                    group=default\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=k8s-node-vm2x4q-7kwnapovj8\n                    kubernetes.io/os=linux\n                    topology.zbs.csi.jdcloud.com/zone=cn-east-2b\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"zbs.csi.jdcloud.com\":\"i-6sybs7bbb6\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 17 Dec 2019 09:43:31 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Tue, 17 Dec 2019 13:05:07 +0000   Tue, 17 Dec 2019 09:43:31 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Tue, 17 Dec 2019 13:05:07 +0000   Tue, 17 Dec 2019 09:43:31 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Tue, 17 Dec 2019 13:05:07 +0000   Tue, 17 Dec 2019 09:43:31 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Tue, 17 Dec 2019 13:05:07 +0000   Tue, 17 Dec 2019 09:43:31 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.32.4\n  Hostname:    k8s-node-vm2x4q-7kwnapovj8\nCapacity:\n cpu:                4\n ephemeral-storage:  103079844Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16267708Ki\n pods:               110\nAllocatable:\n cpu:                3920m\n ephemeral-storage:  94998384074\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             13541820Ki\n pods:               110\nSystem Info:\n Machine ID:                 14a3101311244529baf9bae25e18d934\n System UUID:                D59C88F7-BE42-4BB2-881E-7A06439EA7E9\n Boot ID:                    a75caf79-6a25-42ea-ba6f-6018825fdb37\n Kernel Version:             3.10.0-693.el7.x86_64\n OS Image:                   CentOS Linux 7 (Core)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.6.2\n Kubelet Version:            v1.16.4-12.8d683d98-dirty\n Kube-Proxy Version:         v1.16.4-12.8d683d98-dirty\nProviderID:                  jdcloud:///cn-east-2b/i-6sybs7bbb6\nNon-terminated Pods:         (9 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  jke-system                 csi-jdcloudplugin-v42hq                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         3h21m\n  jke-system                 fluent-bit-8f5mr                                           200m (5%)     1 (25%)     300Mi (2%)       450Mi (3%)     3h21m\n  jke-system                 kube-state-metrics-f58cb6d75-fhf77                         100m (2%)     100m (2%)   30Mi (0%)        30Mi (0%)      177m\n  jke-system                 node-exporter-gv5p5                                        200m (5%)     200m (5%)   256Mi (1%)       256Mi (1%)     3h21m\n  jke-system                 prometheus-5ff89497-v69gb                                  0 (0%)        0 (0%)      0 (0%)           0 (0%)         177m\n  kube-system                coredns-8565b9f7f-w876f                                    100m (2%)     0 (0%)      70Mi (0%)        170Mi (1%)     177m\n  kube-system                jdcloud-k8s-ipamd-g4vm6                                    200m (5%)     200m (5%)   256Mi (1%)       256Mi (1%)     3h21m\n  kube-system                kube-proxy-2zp6v                                           200m (5%)     200m (5%)   256Mi (1%)       256Mi (1%)     3h21m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6    0 (0%)        0 (0%)      0 (0%)           0 (0%)         17m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests     Limits\n  --------           --------     ------\n  cpu                1 (25%)      1700m (43%)\n  memory             1168Mi (8%)  1418Mi (10%)\n  ephemeral-storage  0 (0%)       0 (0%)\nEvents:              <none>\n"
Dec 17 13:05:14.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 describe namespace kubectl-6996'
Dec 17 13:05:14.248: INFO: stderr: ""
Dec 17 13:05:14.248: INFO: stdout: "Name:         kubectl-6996\nLabels:       e2e-framework=kubectl\n              e2e-run=ab33bf15-3dae-48bf-a828-50302edc50e4\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:05:14.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6996" for this suite.
Dec 17 13:05:42.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:05:42.484: INFO: namespace kubectl-6996 deletion completed in 28.228527253s

• [SLOW TEST:30.235 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:05:42.484: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 13:05:42.558: INFO: Waiting up to 5m0s for pod "pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a" in namespace "emptydir-124" to be "success or failure"
Dec 17 13:05:42.566: INFO: Pod "pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 8.28135ms
Dec 17 13:05:44.571: INFO: Pod "pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013560545s
STEP: Saw pod success
Dec 17 13:05:44.571: INFO: Pod "pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a" satisfied condition "success or failure"
Dec 17 13:05:44.580: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a container test-container: <nil>
STEP: delete the pod
Dec 17 13:05:44.624: INFO: Waiting for pod pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a to disappear
Dec 17 13:05:44.628: INFO: Pod pod-47cc5f7d-9250-445a-bdfd-86b52b3f3f9a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:05:44.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-124" for this suite.
Dec 17 13:05:50.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:05:50.873: INFO: namespace emptydir-124 deletion completed in 6.231010219s

• [SLOW TEST:8.389 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:05:50.873: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 17 13:05:50.921: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 13:05:53.140: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:06:02.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8814" for this suite.
Dec 17 13:06:08.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:06:08.870: INFO: namespace crd-publish-openapi-8814 deletion completed in 6.218914382s

• [SLOW TEST:17.997 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:06:08.871: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-zzbz
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 13:06:08.956: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-zzbz" in namespace "subpath-8145" to be "success or failure"
Dec 17 13:06:08.966: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Pending", Reason="", readiness=false. Elapsed: 10.003901ms
Dec 17 13:06:10.971: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 2.015536063s
Dec 17 13:06:12.980: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 4.024525029s
Dec 17 13:06:14.989: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 6.033512494s
Dec 17 13:06:16.994: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 8.038325062s
Dec 17 13:06:19.003: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 10.047295765s
Dec 17 13:06:21.008: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 12.05216404s
Dec 17 13:06:23.013: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 14.057166241s
Dec 17 13:06:25.018: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 16.062334018s
Dec 17 13:06:27.023: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 18.067131403s
Dec 17 13:06:29.031: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Running", Reason="", readiness=true. Elapsed: 20.075298756s
Dec 17 13:06:31.039: INFO: Pod "pod-subpath-test-configmap-zzbz": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.083796413s
STEP: Saw pod success
Dec 17 13:06:31.039: INFO: Pod "pod-subpath-test-configmap-zzbz" satisfied condition "success or failure"
Dec 17 13:06:31.044: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-subpath-test-configmap-zzbz container test-container-subpath-configmap-zzbz: <nil>
STEP: delete the pod
Dec 17 13:06:31.089: INFO: Waiting for pod pod-subpath-test-configmap-zzbz to disappear
Dec 17 13:06:31.096: INFO: Pod pod-subpath-test-configmap-zzbz no longer exists
STEP: Deleting pod pod-subpath-test-configmap-zzbz
Dec 17 13:06:31.096: INFO: Deleting pod "pod-subpath-test-configmap-zzbz" in namespace "subpath-8145"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:06:31.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8145" for this suite.
Dec 17 13:06:37.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:06:37.353: INFO: namespace subpath-8145 deletion completed in 6.244106324s

• [SLOW TEST:28.483 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:06:37.354: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:06:56.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6393" for this suite.
Dec 17 13:07:02.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:07:03.015: INFO: namespace container-runtime-6393 deletion completed in 6.231906641s

• [SLOW TEST:25.661 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:07:03.015: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1217 13:07:13.125675      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 17 13:07:13.125: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:07:13.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5320" for this suite.
Dec 17 13:07:19.166: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:07:19.390: INFO: namespace gc-5320 deletion completed in 6.250533252s

• [SLOW TEST:16.375 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:07:19.390: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-90cc891d-babe-437c-b162-f84b99a3eca7
STEP: Creating a pod to test consume secrets
Dec 17 13:07:19.513: INFO: Waiting up to 5m0s for pod "pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab" in namespace "secrets-5117" to be "success or failure"
Dec 17 13:07:19.517: INFO: Pod "pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.341672ms
Dec 17 13:07:21.527: INFO: Pod "pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013785978s
STEP: Saw pod success
Dec 17 13:07:21.527: INFO: Pod "pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab" satisfied condition "success or failure"
Dec 17 13:07:21.532: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:07:21.571: INFO: Waiting for pod pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab to disappear
Dec 17 13:07:21.579: INFO: Pod pod-secrets-ee312dd6-38f3-4925-bb1a-b5ad7151e8ab no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:07:21.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5117" for this suite.
Dec 17 13:07:27.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:07:27.809: INFO: namespace secrets-5117 deletion completed in 6.216658036s

• [SLOW TEST:8.419 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:07:27.810: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 13:07:27.871: INFO: Waiting up to 5m0s for pod "downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3" in namespace "downward-api-414" to be "success or failure"
Dec 17 13:07:27.877: INFO: Pod "downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3": Phase="Pending", Reason="", readiness=false. Elapsed: 6.197643ms
Dec 17 13:07:29.886: INFO: Pod "downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014832697s
STEP: Saw pod success
Dec 17 13:07:29.886: INFO: Pod "downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3" satisfied condition "success or failure"
Dec 17 13:07:29.890: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3 container dapi-container: <nil>
STEP: delete the pod
Dec 17 13:07:29.941: INFO: Waiting for pod downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3 to disappear
Dec 17 13:07:29.948: INFO: Pod downward-api-ec0e11af-33ee-46bb-ad3f-a8157600f0a3 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:07:29.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-414" for this suite.
Dec 17 13:07:35.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:07:36.181: INFO: namespace downward-api-414 deletion completed in 6.218620488s

• [SLOW TEST:8.371 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:07:36.181: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-d22234a3-87c2-4968-bb04-506f70ab9d47
STEP: Creating a pod to test consume secrets
Dec 17 13:07:36.261: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36" in namespace "projected-4623" to be "success or failure"
Dec 17 13:07:36.266: INFO: Pod "pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36": Phase="Pending", Reason="", readiness=false. Elapsed: 5.066674ms
Dec 17 13:07:38.270: INFO: Pod "pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009824383s
STEP: Saw pod success
Dec 17 13:07:38.270: INFO: Pod "pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36" satisfied condition "success or failure"
Dec 17 13:07:38.280: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:07:38.325: INFO: Waiting for pod pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36 to disappear
Dec 17 13:07:38.330: INFO: Pod pod-projected-secrets-f4cf01d3-cdff-4fb7-ad27-71f10a4a4e36 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:07:38.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4623" for this suite.
Dec 17 13:07:44.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:07:44.609: INFO: namespace projected-4623 deletion completed in 6.264797316s

• [SLOW TEST:8.428 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:07:44.609: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:07:57.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1088" for this suite.
Dec 17 13:08:03.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:08:04.036: INFO: namespace resourcequota-1088 deletion completed in 6.227309209s

• [SLOW TEST:19.427 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:08:04.036: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-6912
STEP: creating replication controller nodeport-test in namespace services-6912
I1217 13:08:04.129007      25 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-6912, replica count: 2
Dec 17 13:08:07.179: INFO: Creating new exec pod
I1217 13:08:07.179515      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 13:08:10.214: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6912 execpod4674x -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 17 13:08:10.372: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 17 13:08:10.372: INFO: stdout: ""
Dec 17 13:08:10.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6912 execpod4674x -- /bin/sh -x -c nc -zv -t -w 2 10.0.63.94 80'
Dec 17 13:08:10.519: INFO: stderr: "+ nc -zv -t -w 2 10.0.63.94 80\nConnection to 10.0.63.94 80 port [tcp/http] succeeded!\n"
Dec 17 13:08:10.519: INFO: stdout: ""
Dec 17 13:08:10.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6912 execpod4674x -- /bin/sh -x -c nc -zv -t -w 2 10.0.32.4 30421'
Dec 17 13:08:10.673: INFO: stderr: "+ nc -zv -t -w 2 10.0.32.4 30421\nConnection to 10.0.32.4 30421 port [tcp/30421] succeeded!\n"
Dec 17 13:08:10.673: INFO: stdout: ""
Dec 17 13:08:10.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6912 execpod4674x -- /bin/sh -x -c nc -zv -t -w 2 10.0.32.3 30421'
Dec 17 13:08:10.861: INFO: stderr: "+ nc -zv -t -w 2 10.0.32.3 30421\nConnection to 10.0.32.3 30421 port [tcp/30421] succeeded!\n"
Dec 17 13:08:10.861: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:08:10.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6912" for this suite.
Dec 17 13:08:16.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:08:17.088: INFO: namespace services-6912 deletion completed in 6.216737347s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.052 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:08:17.088: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-9956
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-9956
STEP: Deleting pre-stop pod
Dec 17 13:08:26.232: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:08:26.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-9956" for this suite.
Dec 17 13:09:10.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:09:10.491: INFO: namespace prestop-9956 deletion completed in 44.23125898s

• [SLOW TEST:53.403 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:09:10.492: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 13:09:13.106: INFO: Successfully updated pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835"
Dec 17 13:09:13.106: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835" in namespace "pods-9275" to be "terminated due to deadline exceeded"
Dec 17 13:09:13.110: INFO: Pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835": Phase="Running", Reason="", readiness=true. Elapsed: 4.353009ms
Dec 17 13:09:15.115: INFO: Pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835": Phase="Running", Reason="", readiness=true. Elapsed: 2.009529159s
Dec 17 13:09:17.125: INFO: Pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.018725183s
Dec 17 13:09:17.125: INFO: Pod "pod-update-activedeadlineseconds-545a1328-efbb-4bf0-a703-c4d6cf40c835" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:09:17.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9275" for this suite.
Dec 17 13:09:23.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:09:23.369: INFO: namespace pods-9275 deletion completed in 6.230272405s

• [SLOW TEST:12.877 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:09:23.369: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 17 13:09:23.443: INFO: Waiting up to 5m0s for pod "client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee" in namespace "containers-5583" to be "success or failure"
Dec 17 13:09:23.452: INFO: Pod "client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.417584ms
Dec 17 13:09:25.461: INFO: Pod "client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018582329s
STEP: Saw pod success
Dec 17 13:09:25.461: INFO: Pod "client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee" satisfied condition "success or failure"
Dec 17 13:09:25.466: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee container test-container: <nil>
STEP: delete the pod
Dec 17 13:09:25.521: INFO: Waiting for pod client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee to disappear
Dec 17 13:09:25.529: INFO: Pod client-containers-e20592e6-7316-4cd4-bace-cea75d2e55ee no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:09:25.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5583" for this suite.
Dec 17 13:09:31.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:09:31.778: INFO: namespace containers-5583 deletion completed in 6.234117972s

• [SLOW TEST:8.409 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:09:31.778: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5212
I1217 13:09:31.837650      25 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5212, replica count: 1
I1217 13:09:32.888385      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 13:09:33.888780      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 13:09:34.006: INFO: Created: latency-svc-x8zxf
Dec 17 13:09:34.013: INFO: Got endpoints: latency-svc-x8zxf [23.158324ms]
Dec 17 13:09:34.048: INFO: Created: latency-svc-nvxqv
Dec 17 13:09:34.052: INFO: Got endpoints: latency-svc-nvxqv [38.569918ms]
Dec 17 13:09:34.073: INFO: Created: latency-svc-9jxqx
Dec 17 13:09:34.078: INFO: Got endpoints: latency-svc-9jxqx [65.161738ms]
Dec 17 13:09:34.082: INFO: Created: latency-svc-kggh8
Dec 17 13:09:34.087: INFO: Got endpoints: latency-svc-kggh8 [73.951025ms]
Dec 17 13:09:34.099: INFO: Created: latency-svc-ttgqt
Dec 17 13:09:34.102: INFO: Got endpoints: latency-svc-ttgqt [88.550675ms]
Dec 17 13:09:34.110: INFO: Created: latency-svc-nr2n7
Dec 17 13:09:34.118: INFO: Got endpoints: latency-svc-nr2n7 [104.895533ms]
Dec 17 13:09:34.119: INFO: Created: latency-svc-7rdfs
Dec 17 13:09:34.127: INFO: Got endpoints: latency-svc-7rdfs [113.175495ms]
Dec 17 13:09:34.136: INFO: Created: latency-svc-dphht
Dec 17 13:09:34.138: INFO: Got endpoints: latency-svc-dphht [124.660842ms]
Dec 17 13:09:34.148: INFO: Created: latency-svc-zkbmg
Dec 17 13:09:34.159: INFO: Got endpoints: latency-svc-zkbmg [145.389008ms]
Dec 17 13:09:34.161: INFO: Created: latency-svc-ck6zt
Dec 17 13:09:34.167: INFO: Got endpoints: latency-svc-ck6zt [153.538833ms]
Dec 17 13:09:34.177: INFO: Created: latency-svc-gtbj2
Dec 17 13:09:34.179: INFO: Got endpoints: latency-svc-gtbj2 [165.677504ms]
Dec 17 13:09:34.187: INFO: Created: latency-svc-fsz8b
Dec 17 13:09:34.193: INFO: Got endpoints: latency-svc-fsz8b [179.285612ms]
Dec 17 13:09:34.200: INFO: Created: latency-svc-wrhnp
Dec 17 13:09:34.206: INFO: Got endpoints: latency-svc-wrhnp [191.745545ms]
Dec 17 13:09:34.215: INFO: Created: latency-svc-6cb4l
Dec 17 13:09:34.218: INFO: Got endpoints: latency-svc-6cb4l [203.805302ms]
Dec 17 13:09:34.230: INFO: Created: latency-svc-fcl7d
Dec 17 13:09:34.236: INFO: Got endpoints: latency-svc-fcl7d [221.865225ms]
Dec 17 13:09:34.238: INFO: Created: latency-svc-4p6qd
Dec 17 13:09:34.245: INFO: Got endpoints: latency-svc-4p6qd [231.079857ms]
Dec 17 13:09:34.255: INFO: Created: latency-svc-dtww7
Dec 17 13:09:34.259: INFO: Got endpoints: latency-svc-dtww7 [206.705307ms]
Dec 17 13:09:34.268: INFO: Created: latency-svc-5dpxc
Dec 17 13:09:34.273: INFO: Got endpoints: latency-svc-5dpxc [194.812365ms]
Dec 17 13:09:34.276: INFO: Created: latency-svc-bn9ng
Dec 17 13:09:34.283: INFO: Got endpoints: latency-svc-bn9ng [195.458954ms]
Dec 17 13:09:34.295: INFO: Created: latency-svc-mth9j
Dec 17 13:09:34.298: INFO: Got endpoints: latency-svc-mth9j [196.125931ms]
Dec 17 13:09:34.305: INFO: Created: latency-svc-m2hbr
Dec 17 13:09:34.313: INFO: Created: latency-svc-vngtp
Dec 17 13:09:34.313: INFO: Got endpoints: latency-svc-m2hbr [194.381841ms]
Dec 17 13:09:34.329: INFO: Got endpoints: latency-svc-vngtp [202.61584ms]
Dec 17 13:09:34.338: INFO: Created: latency-svc-fld5t
Dec 17 13:09:34.341: INFO: Got endpoints: latency-svc-fld5t [202.716979ms]
Dec 17 13:09:34.350: INFO: Created: latency-svc-ftcfl
Dec 17 13:09:34.356: INFO: Got endpoints: latency-svc-ftcfl [196.64306ms]
Dec 17 13:09:34.362: INFO: Created: latency-svc-snlx6
Dec 17 13:09:34.369: INFO: Got endpoints: latency-svc-snlx6 [201.484966ms]
Dec 17 13:09:34.426: INFO: Created: latency-svc-t5pzm
Dec 17 13:09:34.430: INFO: Got endpoints: latency-svc-t5pzm [250.867377ms]
Dec 17 13:09:34.436: INFO: Created: latency-svc-9gsb6
Dec 17 13:09:34.443: INFO: Got endpoints: latency-svc-9gsb6 [250.281558ms]
Dec 17 13:09:34.447: INFO: Created: latency-svc-7sbmg
Dec 17 13:09:34.451: INFO: Got endpoints: latency-svc-7sbmg [245.047291ms]
Dec 17 13:09:34.462: INFO: Created: latency-svc-jjh9f
Dec 17 13:09:34.467: INFO: Got endpoints: latency-svc-jjh9f [249.145516ms]
Dec 17 13:09:34.474: INFO: Created: latency-svc-q7vkz
Dec 17 13:09:34.480: INFO: Got endpoints: latency-svc-q7vkz [244.514125ms]
Dec 17 13:09:34.484: INFO: Created: latency-svc-hj6md
Dec 17 13:09:34.488: INFO: Got endpoints: latency-svc-hj6md [243.369259ms]
Dec 17 13:09:34.502: INFO: Created: latency-svc-qq4rd
Dec 17 13:09:34.509: INFO: Got endpoints: latency-svc-qq4rd [250.533779ms]
Dec 17 13:09:34.514: INFO: Created: latency-svc-4kv8b
Dec 17 13:09:34.516: INFO: Got endpoints: latency-svc-4kv8b [242.775217ms]
Dec 17 13:09:34.520: INFO: Created: latency-svc-ddg6p
Dec 17 13:09:34.525: INFO: Got endpoints: latency-svc-ddg6p [242.237192ms]
Dec 17 13:09:34.540: INFO: Created: latency-svc-c5xps
Dec 17 13:09:34.545: INFO: Got endpoints: latency-svc-c5xps [247.089816ms]
Dec 17 13:09:34.549: INFO: Created: latency-svc-kgwb9
Dec 17 13:09:34.555: INFO: Got endpoints: latency-svc-kgwb9 [241.840935ms]
Dec 17 13:09:34.557: INFO: Created: latency-svc-7srlv
Dec 17 13:09:34.563: INFO: Got endpoints: latency-svc-7srlv [233.240795ms]
Dec 17 13:09:34.576: INFO: Created: latency-svc-jh2gg
Dec 17 13:09:34.580: INFO: Got endpoints: latency-svc-jh2gg [239.035083ms]
Dec 17 13:09:34.588: INFO: Created: latency-svc-rwvm5
Dec 17 13:09:34.594: INFO: Got endpoints: latency-svc-rwvm5 [237.925693ms]
Dec 17 13:09:34.598: INFO: Created: latency-svc-6tw27
Dec 17 13:09:34.602: INFO: Got endpoints: latency-svc-6tw27 [233.192724ms]
Dec 17 13:09:34.627: INFO: Created: latency-svc-2hqxn
Dec 17 13:09:34.630: INFO: Got endpoints: latency-svc-2hqxn [200.205842ms]
Dec 17 13:09:34.637: INFO: Created: latency-svc-nhp6c
Dec 17 13:09:34.644: INFO: Got endpoints: latency-svc-nhp6c [201.232655ms]
Dec 17 13:09:34.645: INFO: Created: latency-svc-56sjs
Dec 17 13:09:34.660: INFO: Got endpoints: latency-svc-56sjs [209.772249ms]
Dec 17 13:09:34.661: INFO: Created: latency-svc-rw89v
Dec 17 13:09:34.672: INFO: Created: latency-svc-jf29g
Dec 17 13:09:34.679: INFO: Created: latency-svc-q9mcz
Dec 17 13:09:34.695: INFO: Created: latency-svc-vlr67
Dec 17 13:09:34.705: INFO: Created: latency-svc-pd4qm
Dec 17 13:09:34.711: INFO: Got endpoints: latency-svc-rw89v [244.364255ms]
Dec 17 13:09:34.714: INFO: Created: latency-svc-9g75l
Dec 17 13:09:34.735: INFO: Created: latency-svc-x8hvp
Dec 17 13:09:34.749: INFO: Created: latency-svc-wscrb
Dec 17 13:09:34.755: INFO: Created: latency-svc-k8585
Dec 17 13:09:34.762: INFO: Got endpoints: latency-svc-jf29g [281.6367ms]
Dec 17 13:09:34.773: INFO: Created: latency-svc-9j5lp
Dec 17 13:09:34.787: INFO: Created: latency-svc-5zwrd
Dec 17 13:09:34.794: INFO: Created: latency-svc-z252s
Dec 17 13:09:34.814: INFO: Created: latency-svc-twszq
Dec 17 13:09:34.814: INFO: Got endpoints: latency-svc-q9mcz [325.807093ms]
Dec 17 13:09:34.826: INFO: Created: latency-svc-sxp9t
Dec 17 13:09:34.833: INFO: Created: latency-svc-w8svj
Dec 17 13:09:34.849: INFO: Created: latency-svc-z4q56
Dec 17 13:09:34.859: INFO: Created: latency-svc-dtlhh
Dec 17 13:09:34.865: INFO: Got endpoints: latency-svc-vlr67 [355.487249ms]
Dec 17 13:09:34.866: INFO: Created: latency-svc-4mfpm
Dec 17 13:09:34.887: INFO: Created: latency-svc-trp6g
Dec 17 13:09:34.913: INFO: Got endpoints: latency-svc-pd4qm [397.308719ms]
Dec 17 13:09:34.932: INFO: Created: latency-svc-6bbbn
Dec 17 13:09:34.965: INFO: Got endpoints: latency-svc-9g75l [439.869038ms]
Dec 17 13:09:34.984: INFO: Created: latency-svc-tcz8j
Dec 17 13:09:35.010: INFO: Got endpoints: latency-svc-x8hvp [465.086574ms]
Dec 17 13:09:35.034: INFO: Created: latency-svc-525dq
Dec 17 13:09:35.064: INFO: Got endpoints: latency-svc-wscrb [509.016606ms]
Dec 17 13:09:35.083: INFO: Created: latency-svc-x2kd8
Dec 17 13:09:35.112: INFO: Got endpoints: latency-svc-k8585 [549.675744ms]
Dec 17 13:09:35.128: INFO: Created: latency-svc-w475g
Dec 17 13:09:35.161: INFO: Got endpoints: latency-svc-9j5lp [580.545396ms]
Dec 17 13:09:35.184: INFO: Created: latency-svc-2q4dk
Dec 17 13:09:35.213: INFO: Got endpoints: latency-svc-5zwrd [619.580004ms]
Dec 17 13:09:35.255: INFO: Created: latency-svc-rb9pk
Dec 17 13:09:35.262: INFO: Got endpoints: latency-svc-z252s [660.057863ms]
Dec 17 13:09:35.279: INFO: Created: latency-svc-k95vv
Dec 17 13:09:35.312: INFO: Got endpoints: latency-svc-twszq [681.663873ms]
Dec 17 13:09:35.335: INFO: Created: latency-svc-2chmr
Dec 17 13:09:35.365: INFO: Got endpoints: latency-svc-sxp9t [720.829591ms]
Dec 17 13:09:35.389: INFO: Created: latency-svc-gvgjw
Dec 17 13:09:35.411: INFO: Got endpoints: latency-svc-w8svj [750.159177ms]
Dec 17 13:09:35.428: INFO: Created: latency-svc-4qq7s
Dec 17 13:09:35.462: INFO: Got endpoints: latency-svc-z4q56 [750.689887ms]
Dec 17 13:09:35.487: INFO: Created: latency-svc-z8jsm
Dec 17 13:09:35.513: INFO: Got endpoints: latency-svc-dtlhh [751.209261ms]
Dec 17 13:09:35.533: INFO: Created: latency-svc-x92zn
Dec 17 13:09:35.561: INFO: Got endpoints: latency-svc-4mfpm [747.185619ms]
Dec 17 13:09:35.577: INFO: Created: latency-svc-k29xg
Dec 17 13:09:35.613: INFO: Got endpoints: latency-svc-trp6g [747.987205ms]
Dec 17 13:09:35.635: INFO: Created: latency-svc-4vn2m
Dec 17 13:09:35.664: INFO: Got endpoints: latency-svc-6bbbn [750.804101ms]
Dec 17 13:09:35.684: INFO: Created: latency-svc-wnhpd
Dec 17 13:09:35.712: INFO: Got endpoints: latency-svc-tcz8j [747.480592ms]
Dec 17 13:09:35.729: INFO: Created: latency-svc-qmgdc
Dec 17 13:09:35.762: INFO: Got endpoints: latency-svc-525dq [752.049077ms]
Dec 17 13:09:35.786: INFO: Created: latency-svc-llkwt
Dec 17 13:09:35.814: INFO: Got endpoints: latency-svc-x2kd8 [750.016465ms]
Dec 17 13:09:35.833: INFO: Created: latency-svc-nj5m8
Dec 17 13:09:35.862: INFO: Got endpoints: latency-svc-w475g [749.62866ms]
Dec 17 13:09:35.878: INFO: Created: latency-svc-fssqk
Dec 17 13:09:35.914: INFO: Got endpoints: latency-svc-2q4dk [753.521972ms]
Dec 17 13:09:35.939: INFO: Created: latency-svc-jrp7c
Dec 17 13:09:35.964: INFO: Got endpoints: latency-svc-rb9pk [750.334258ms]
Dec 17 13:09:35.983: INFO: Created: latency-svc-fxxc4
Dec 17 13:09:36.012: INFO: Got endpoints: latency-svc-k95vv [750.235404ms]
Dec 17 13:09:36.042: INFO: Created: latency-svc-4bzvx
Dec 17 13:09:36.063: INFO: Got endpoints: latency-svc-2chmr [750.631099ms]
Dec 17 13:09:36.084: INFO: Created: latency-svc-45br2
Dec 17 13:09:36.115: INFO: Got endpoints: latency-svc-gvgjw [750.217938ms]
Dec 17 13:09:36.134: INFO: Created: latency-svc-dxsns
Dec 17 13:09:36.162: INFO: Got endpoints: latency-svc-4qq7s [750.920473ms]
Dec 17 13:09:36.179: INFO: Created: latency-svc-9lps5
Dec 17 13:09:36.212: INFO: Got endpoints: latency-svc-z8jsm [749.92322ms]
Dec 17 13:09:36.234: INFO: Created: latency-svc-m6288
Dec 17 13:09:36.262: INFO: Got endpoints: latency-svc-x92zn [749.339977ms]
Dec 17 13:09:36.282: INFO: Created: latency-svc-9t2xm
Dec 17 13:09:36.310: INFO: Got endpoints: latency-svc-k29xg [748.706213ms]
Dec 17 13:09:36.325: INFO: Created: latency-svc-67gsf
Dec 17 13:09:36.362: INFO: Got endpoints: latency-svc-4vn2m [749.167633ms]
Dec 17 13:09:36.392: INFO: Created: latency-svc-bq66n
Dec 17 13:09:36.412: INFO: Got endpoints: latency-svc-wnhpd [747.624398ms]
Dec 17 13:09:36.433: INFO: Created: latency-svc-7v9md
Dec 17 13:09:36.463: INFO: Got endpoints: latency-svc-qmgdc [750.569505ms]
Dec 17 13:09:36.481: INFO: Created: latency-svc-qftzh
Dec 17 13:09:36.513: INFO: Got endpoints: latency-svc-llkwt [750.772581ms]
Dec 17 13:09:36.535: INFO: Created: latency-svc-b2scw
Dec 17 13:09:36.560: INFO: Got endpoints: latency-svc-nj5m8 [746.666757ms]
Dec 17 13:09:36.579: INFO: Created: latency-svc-fthhw
Dec 17 13:09:36.612: INFO: Got endpoints: latency-svc-fssqk [750.588605ms]
Dec 17 13:09:36.629: INFO: Created: latency-svc-n8cgk
Dec 17 13:09:36.662: INFO: Got endpoints: latency-svc-jrp7c [747.827002ms]
Dec 17 13:09:36.685: INFO: Created: latency-svc-h29dl
Dec 17 13:09:36.711: INFO: Got endpoints: latency-svc-fxxc4 [747.31155ms]
Dec 17 13:09:36.729: INFO: Created: latency-svc-bbmvk
Dec 17 13:09:36.762: INFO: Got endpoints: latency-svc-4bzvx [749.493059ms]
Dec 17 13:09:36.777: INFO: Created: latency-svc-4rngg
Dec 17 13:09:36.819: INFO: Got endpoints: latency-svc-45br2 [756.072801ms]
Dec 17 13:09:36.849: INFO: Created: latency-svc-m5wjl
Dec 17 13:09:36.861: INFO: Got endpoints: latency-svc-dxsns [745.228362ms]
Dec 17 13:09:36.886: INFO: Created: latency-svc-f27qp
Dec 17 13:09:36.912: INFO: Got endpoints: latency-svc-9lps5 [750.206605ms]
Dec 17 13:09:36.928: INFO: Created: latency-svc-8zfc4
Dec 17 13:09:36.963: INFO: Got endpoints: latency-svc-m6288 [750.936692ms]
Dec 17 13:09:36.989: INFO: Created: latency-svc-9gfnt
Dec 17 13:09:37.011: INFO: Got endpoints: latency-svc-9t2xm [748.210716ms]
Dec 17 13:09:37.026: INFO: Created: latency-svc-xg6f4
Dec 17 13:09:37.063: INFO: Got endpoints: latency-svc-67gsf [752.539883ms]
Dec 17 13:09:37.082: INFO: Created: latency-svc-hs52g
Dec 17 13:09:37.112: INFO: Got endpoints: latency-svc-bq66n [749.963774ms]
Dec 17 13:09:37.136: INFO: Created: latency-svc-2sghx
Dec 17 13:09:37.161: INFO: Got endpoints: latency-svc-7v9md [749.577515ms]
Dec 17 13:09:37.177: INFO: Created: latency-svc-x5vww
Dec 17 13:09:37.212: INFO: Got endpoints: latency-svc-qftzh [749.03302ms]
Dec 17 13:09:37.233: INFO: Created: latency-svc-lq45l
Dec 17 13:09:37.263: INFO: Got endpoints: latency-svc-b2scw [749.906859ms]
Dec 17 13:09:37.286: INFO: Created: latency-svc-dnpxd
Dec 17 13:09:37.310: INFO: Got endpoints: latency-svc-fthhw [749.752384ms]
Dec 17 13:09:37.340: INFO: Created: latency-svc-l4pnh
Dec 17 13:09:37.362: INFO: Got endpoints: latency-svc-n8cgk [749.396684ms]
Dec 17 13:09:37.380: INFO: Created: latency-svc-gbljp
Dec 17 13:09:37.413: INFO: Got endpoints: latency-svc-h29dl [750.967927ms]
Dec 17 13:09:37.436: INFO: Created: latency-svc-7rlj9
Dec 17 13:09:37.464: INFO: Got endpoints: latency-svc-bbmvk [753.18044ms]
Dec 17 13:09:37.481: INFO: Created: latency-svc-hnchw
Dec 17 13:09:37.512: INFO: Got endpoints: latency-svc-4rngg [750.191869ms]
Dec 17 13:09:37.531: INFO: Created: latency-svc-8nnzn
Dec 17 13:09:37.562: INFO: Got endpoints: latency-svc-m5wjl [743.413311ms]
Dec 17 13:09:37.584: INFO: Created: latency-svc-kclgp
Dec 17 13:09:37.611: INFO: Got endpoints: latency-svc-f27qp [750.113955ms]
Dec 17 13:09:37.627: INFO: Created: latency-svc-qswrl
Dec 17 13:09:37.662: INFO: Got endpoints: latency-svc-8zfc4 [750.427208ms]
Dec 17 13:09:37.681: INFO: Created: latency-svc-qz8jn
Dec 17 13:09:37.712: INFO: Got endpoints: latency-svc-9gfnt [749.601391ms]
Dec 17 13:09:37.735: INFO: Created: latency-svc-9shrs
Dec 17 13:09:37.762: INFO: Got endpoints: latency-svc-xg6f4 [751.867896ms]
Dec 17 13:09:37.778: INFO: Created: latency-svc-sxdsr
Dec 17 13:09:37.813: INFO: Got endpoints: latency-svc-hs52g [750.15991ms]
Dec 17 13:09:37.834: INFO: Created: latency-svc-n9tjc
Dec 17 13:09:37.867: INFO: Got endpoints: latency-svc-2sghx [755.108229ms]
Dec 17 13:09:37.890: INFO: Created: latency-svc-kwhbs
Dec 17 13:09:37.911: INFO: Got endpoints: latency-svc-x5vww [749.223797ms]
Dec 17 13:09:37.926: INFO: Created: latency-svc-vbpwv
Dec 17 13:09:37.962: INFO: Got endpoints: latency-svc-lq45l [749.751874ms]
Dec 17 13:09:37.981: INFO: Created: latency-svc-2d2gh
Dec 17 13:09:38.012: INFO: Got endpoints: latency-svc-dnpxd [749.03666ms]
Dec 17 13:09:38.044: INFO: Created: latency-svc-k5m4l
Dec 17 13:09:38.062: INFO: Got endpoints: latency-svc-l4pnh [751.390348ms]
Dec 17 13:09:38.076: INFO: Created: latency-svc-467j5
Dec 17 13:09:38.112: INFO: Got endpoints: latency-svc-gbljp [749.990731ms]
Dec 17 13:09:38.131: INFO: Created: latency-svc-jhjjj
Dec 17 13:09:38.167: INFO: Got endpoints: latency-svc-7rlj9 [753.971919ms]
Dec 17 13:09:38.188: INFO: Created: latency-svc-7m4zd
Dec 17 13:09:38.210: INFO: Got endpoints: latency-svc-hnchw [746.259758ms]
Dec 17 13:09:38.226: INFO: Created: latency-svc-t2lrp
Dec 17 13:09:38.262: INFO: Got endpoints: latency-svc-8nnzn [750.156335ms]
Dec 17 13:09:38.281: INFO: Created: latency-svc-wxlm9
Dec 17 13:09:38.312: INFO: Got endpoints: latency-svc-kclgp [750.224396ms]
Dec 17 13:09:38.334: INFO: Created: latency-svc-gvjjk
Dec 17 13:09:38.361: INFO: Got endpoints: latency-svc-qswrl [750.000105ms]
Dec 17 13:09:38.376: INFO: Created: latency-svc-xfrqv
Dec 17 13:09:38.411: INFO: Got endpoints: latency-svc-qz8jn [748.568042ms]
Dec 17 13:09:38.430: INFO: Created: latency-svc-q9tzb
Dec 17 13:09:38.461: INFO: Got endpoints: latency-svc-9shrs [748.925744ms]
Dec 17 13:09:38.485: INFO: Created: latency-svc-hvzx4
Dec 17 13:09:38.512: INFO: Got endpoints: latency-svc-sxdsr [749.325357ms]
Dec 17 13:09:38.528: INFO: Created: latency-svc-czbn9
Dec 17 13:09:38.564: INFO: Got endpoints: latency-svc-n9tjc [751.255345ms]
Dec 17 13:09:38.604: INFO: Created: latency-svc-6p7gk
Dec 17 13:09:38.610: INFO: Got endpoints: latency-svc-kwhbs [743.070135ms]
Dec 17 13:09:38.632: INFO: Created: latency-svc-mh29h
Dec 17 13:09:38.662: INFO: Got endpoints: latency-svc-vbpwv [751.344488ms]
Dec 17 13:09:38.679: INFO: Created: latency-svc-bfx2d
Dec 17 13:09:38.713: INFO: Got endpoints: latency-svc-2d2gh [750.891063ms]
Dec 17 13:09:38.732: INFO: Created: latency-svc-zspmk
Dec 17 13:09:38.760: INFO: Got endpoints: latency-svc-k5m4l [748.034129ms]
Dec 17 13:09:38.782: INFO: Created: latency-svc-djgzn
Dec 17 13:09:38.815: INFO: Got endpoints: latency-svc-467j5 [753.126232ms]
Dec 17 13:09:38.832: INFO: Created: latency-svc-wvgzz
Dec 17 13:09:38.863: INFO: Got endpoints: latency-svc-jhjjj [750.782404ms]
Dec 17 13:09:38.881: INFO: Created: latency-svc-ngg8n
Dec 17 13:09:38.911: INFO: Got endpoints: latency-svc-7m4zd [743.847346ms]
Dec 17 13:09:38.936: INFO: Created: latency-svc-w5dzt
Dec 17 13:09:38.963: INFO: Got endpoints: latency-svc-t2lrp [752.188862ms]
Dec 17 13:09:38.978: INFO: Created: latency-svc-46drx
Dec 17 13:09:39.014: INFO: Got endpoints: latency-svc-wxlm9 [751.570891ms]
Dec 17 13:09:39.036: INFO: Created: latency-svc-9j65s
Dec 17 13:09:39.062: INFO: Got endpoints: latency-svc-gvjjk [749.775575ms]
Dec 17 13:09:39.085: INFO: Created: latency-svc-jxm4x
Dec 17 13:09:39.111: INFO: Got endpoints: latency-svc-xfrqv [750.096417ms]
Dec 17 13:09:39.130: INFO: Created: latency-svc-wwdxt
Dec 17 13:09:39.162: INFO: Got endpoints: latency-svc-q9tzb [751.113523ms]
Dec 17 13:09:39.183: INFO: Created: latency-svc-srbcl
Dec 17 13:09:39.214: INFO: Got endpoints: latency-svc-hvzx4 [752.16781ms]
Dec 17 13:09:39.248: INFO: Created: latency-svc-pmjp2
Dec 17 13:09:39.262: INFO: Got endpoints: latency-svc-czbn9 [750.173742ms]
Dec 17 13:09:39.282: INFO: Created: latency-svc-j7x96
Dec 17 13:09:39.318: INFO: Got endpoints: latency-svc-6p7gk [753.784308ms]
Dec 17 13:09:39.346: INFO: Created: latency-svc-jw2vh
Dec 17 13:09:39.363: INFO: Got endpoints: latency-svc-mh29h [753.409576ms]
Dec 17 13:09:39.402: INFO: Created: latency-svc-m7r9g
Dec 17 13:09:39.411: INFO: Got endpoints: latency-svc-bfx2d [748.696963ms]
Dec 17 13:09:39.429: INFO: Created: latency-svc-nplqv
Dec 17 13:09:39.468: INFO: Got endpoints: latency-svc-zspmk [754.894568ms]
Dec 17 13:09:39.486: INFO: Created: latency-svc-9xcqs
Dec 17 13:09:39.513: INFO: Got endpoints: latency-svc-djgzn [752.523579ms]
Dec 17 13:09:39.539: INFO: Created: latency-svc-c5gwr
Dec 17 13:09:39.565: INFO: Got endpoints: latency-svc-wvgzz [750.490535ms]
Dec 17 13:09:39.585: INFO: Created: latency-svc-99gql
Dec 17 13:09:39.612: INFO: Got endpoints: latency-svc-ngg8n [749.675527ms]
Dec 17 13:09:39.631: INFO: Created: latency-svc-mxnxb
Dec 17 13:09:39.662: INFO: Got endpoints: latency-svc-w5dzt [751.406998ms]
Dec 17 13:09:39.684: INFO: Created: latency-svc-hkjrk
Dec 17 13:09:39.710: INFO: Got endpoints: latency-svc-46drx [747.659424ms]
Dec 17 13:09:39.726: INFO: Created: latency-svc-nt2g7
Dec 17 13:09:39.763: INFO: Got endpoints: latency-svc-9j65s [749.270711ms]
Dec 17 13:09:39.781: INFO: Created: latency-svc-j25ml
Dec 17 13:09:39.813: INFO: Got endpoints: latency-svc-jxm4x [750.534611ms]
Dec 17 13:09:39.836: INFO: Created: latency-svc-rpwxz
Dec 17 13:09:39.861: INFO: Got endpoints: latency-svc-wwdxt [749.886874ms]
Dec 17 13:09:39.876: INFO: Created: latency-svc-7xqzm
Dec 17 13:09:39.912: INFO: Got endpoints: latency-svc-srbcl [750.259314ms]
Dec 17 13:09:39.932: INFO: Created: latency-svc-nvjpz
Dec 17 13:09:39.964: INFO: Got endpoints: latency-svc-pmjp2 [750.543123ms]
Dec 17 13:09:39.991: INFO: Created: latency-svc-88b76
Dec 17 13:09:40.011: INFO: Got endpoints: latency-svc-j7x96 [749.116081ms]
Dec 17 13:09:40.029: INFO: Created: latency-svc-569q7
Dec 17 13:09:40.066: INFO: Got endpoints: latency-svc-jw2vh [748.136109ms]
Dec 17 13:09:40.085: INFO: Created: latency-svc-wqxpj
Dec 17 13:09:40.112: INFO: Got endpoints: latency-svc-m7r9g [748.481526ms]
Dec 17 13:09:40.136: INFO: Created: latency-svc-sjh6j
Dec 17 13:09:40.162: INFO: Got endpoints: latency-svc-nplqv [750.806187ms]
Dec 17 13:09:40.180: INFO: Created: latency-svc-wb9nc
Dec 17 13:09:40.212: INFO: Got endpoints: latency-svc-9xcqs [744.527344ms]
Dec 17 13:09:40.231: INFO: Created: latency-svc-pk7pn
Dec 17 13:09:40.263: INFO: Got endpoints: latency-svc-c5gwr [749.876957ms]
Dec 17 13:09:40.285: INFO: Created: latency-svc-9mnps
Dec 17 13:09:40.312: INFO: Got endpoints: latency-svc-99gql [746.633393ms]
Dec 17 13:09:40.328: INFO: Created: latency-svc-kr2gz
Dec 17 13:09:40.362: INFO: Got endpoints: latency-svc-mxnxb [749.358098ms]
Dec 17 13:09:40.392: INFO: Created: latency-svc-g78vd
Dec 17 13:09:40.417: INFO: Got endpoints: latency-svc-hkjrk [754.798162ms]
Dec 17 13:09:40.465: INFO: Created: latency-svc-4pgl9
Dec 17 13:09:40.467: INFO: Got endpoints: latency-svc-nt2g7 [757.021516ms]
Dec 17 13:09:40.492: INFO: Created: latency-svc-x67bt
Dec 17 13:09:40.513: INFO: Got endpoints: latency-svc-j25ml [750.268614ms]
Dec 17 13:09:40.533: INFO: Created: latency-svc-vl2p4
Dec 17 13:09:40.562: INFO: Got endpoints: latency-svc-rpwxz [748.940847ms]
Dec 17 13:09:40.584: INFO: Created: latency-svc-n2l6n
Dec 17 13:09:40.613: INFO: Got endpoints: latency-svc-7xqzm [752.29217ms]
Dec 17 13:09:40.633: INFO: Created: latency-svc-w59mn
Dec 17 13:09:40.664: INFO: Got endpoints: latency-svc-nvjpz [751.440828ms]
Dec 17 13:09:40.683: INFO: Created: latency-svc-8g7tm
Dec 17 13:09:40.711: INFO: Got endpoints: latency-svc-88b76 [746.97164ms]
Dec 17 13:09:40.734: INFO: Created: latency-svc-fdgnl
Dec 17 13:09:40.763: INFO: Got endpoints: latency-svc-569q7 [751.617268ms]
Dec 17 13:09:40.778: INFO: Created: latency-svc-5ltwg
Dec 17 13:09:40.812: INFO: Got endpoints: latency-svc-wqxpj [745.614525ms]
Dec 17 13:09:40.835: INFO: Created: latency-svc-c49d6
Dec 17 13:09:40.861: INFO: Got endpoints: latency-svc-sjh6j [748.816512ms]
Dec 17 13:09:40.902: INFO: Created: latency-svc-6wjh6
Dec 17 13:09:40.912: INFO: Got endpoints: latency-svc-wb9nc [750.430253ms]
Dec 17 13:09:40.930: INFO: Created: latency-svc-52q8t
Dec 17 13:09:40.964: INFO: Got endpoints: latency-svc-pk7pn [751.903268ms]
Dec 17 13:09:40.986: INFO: Created: latency-svc-29lwx
Dec 17 13:09:41.012: INFO: Got endpoints: latency-svc-9mnps [749.109347ms]
Dec 17 13:09:41.035: INFO: Created: latency-svc-j4vzk
Dec 17 13:09:41.061: INFO: Got endpoints: latency-svc-kr2gz [748.599428ms]
Dec 17 13:09:41.076: INFO: Created: latency-svc-hxj5v
Dec 17 13:09:41.113: INFO: Got endpoints: latency-svc-g78vd [750.926566ms]
Dec 17 13:09:41.132: INFO: Created: latency-svc-pvs72
Dec 17 13:09:41.164: INFO: Got endpoints: latency-svc-4pgl9 [746.94049ms]
Dec 17 13:09:41.189: INFO: Created: latency-svc-sgx4b
Dec 17 13:09:41.211: INFO: Got endpoints: latency-svc-x67bt [743.30904ms]
Dec 17 13:09:41.239: INFO: Created: latency-svc-6nwnb
Dec 17 13:09:41.262: INFO: Got endpoints: latency-svc-vl2p4 [748.488998ms]
Dec 17 13:09:41.283: INFO: Created: latency-svc-42hv2
Dec 17 13:09:41.335: INFO: Got endpoints: latency-svc-n2l6n [773.486952ms]
Dec 17 13:09:41.389: INFO: Got endpoints: latency-svc-w59mn [776.148744ms]
Dec 17 13:09:41.465: INFO: Got endpoints: latency-svc-8g7tm [801.330737ms]
Dec 17 13:09:41.472: INFO: Created: latency-svc-675zn
Dec 17 13:09:41.473: INFO: Got endpoints: latency-svc-fdgnl [761.444953ms]
Dec 17 13:09:41.481: INFO: Created: latency-svc-66br2
Dec 17 13:09:41.495: INFO: Created: latency-svc-gb2wr
Dec 17 13:09:41.509: INFO: Created: latency-svc-qtlpk
Dec 17 13:09:41.512: INFO: Got endpoints: latency-svc-5ltwg [748.897072ms]
Dec 17 13:09:41.528: INFO: Created: latency-svc-2ztjr
Dec 17 13:09:41.562: INFO: Got endpoints: latency-svc-c49d6 [750.628272ms]
Dec 17 13:09:41.581: INFO: Created: latency-svc-wtk2d
Dec 17 13:09:41.612: INFO: Got endpoints: latency-svc-6wjh6 [750.784649ms]
Dec 17 13:09:41.634: INFO: Created: latency-svc-x5qxw
Dec 17 13:09:41.662: INFO: Got endpoints: latency-svc-52q8t [749.798007ms]
Dec 17 13:09:41.677: INFO: Created: latency-svc-7pgzh
Dec 17 13:09:41.712: INFO: Got endpoints: latency-svc-29lwx [747.595868ms]
Dec 17 13:09:41.731: INFO: Created: latency-svc-qkwk9
Dec 17 13:09:41.767: INFO: Got endpoints: latency-svc-j4vzk [755.403966ms]
Dec 17 13:09:41.789: INFO: Created: latency-svc-fmpf7
Dec 17 13:09:41.811: INFO: Got endpoints: latency-svc-hxj5v [750.853481ms]
Dec 17 13:09:41.827: INFO: Created: latency-svc-rjqxt
Dec 17 13:09:41.866: INFO: Got endpoints: latency-svc-pvs72 [753.214638ms]
Dec 17 13:09:41.911: INFO: Got endpoints: latency-svc-sgx4b [746.84578ms]
Dec 17 13:09:41.963: INFO: Got endpoints: latency-svc-6nwnb [751.816693ms]
Dec 17 13:09:42.013: INFO: Got endpoints: latency-svc-42hv2 [750.903441ms]
Dec 17 13:09:42.061: INFO: Got endpoints: latency-svc-675zn [725.980987ms]
Dec 17 13:09:42.114: INFO: Got endpoints: latency-svc-66br2 [724.072182ms]
Dec 17 13:09:42.164: INFO: Got endpoints: latency-svc-gb2wr [698.643632ms]
Dec 17 13:09:42.211: INFO: Got endpoints: latency-svc-qtlpk [737.962095ms]
Dec 17 13:09:42.262: INFO: Got endpoints: latency-svc-2ztjr [750.598751ms]
Dec 17 13:09:42.313: INFO: Got endpoints: latency-svc-wtk2d [750.647235ms]
Dec 17 13:09:42.361: INFO: Got endpoints: latency-svc-x5qxw [749.538715ms]
Dec 17 13:09:42.412: INFO: Got endpoints: latency-svc-7pgzh [749.993198ms]
Dec 17 13:09:42.462: INFO: Got endpoints: latency-svc-qkwk9 [750.000838ms]
Dec 17 13:09:42.512: INFO: Got endpoints: latency-svc-fmpf7 [744.320831ms]
Dec 17 13:09:42.562: INFO: Got endpoints: latency-svc-rjqxt [750.574376ms]
Dec 17 13:09:42.562: INFO: Latencies: [38.569918ms 65.161738ms 73.951025ms 88.550675ms 104.895533ms 113.175495ms 124.660842ms 145.389008ms 153.538833ms 165.677504ms 179.285612ms 191.745545ms 194.381841ms 194.812365ms 195.458954ms 196.125931ms 196.64306ms 200.205842ms 201.232655ms 201.484966ms 202.61584ms 202.716979ms 203.805302ms 206.705307ms 209.772249ms 221.865225ms 231.079857ms 233.192724ms 233.240795ms 237.925693ms 239.035083ms 241.840935ms 242.237192ms 242.775217ms 243.369259ms 244.364255ms 244.514125ms 245.047291ms 247.089816ms 249.145516ms 250.281558ms 250.533779ms 250.867377ms 281.6367ms 325.807093ms 355.487249ms 397.308719ms 439.869038ms 465.086574ms 509.016606ms 549.675744ms 580.545396ms 619.580004ms 660.057863ms 681.663873ms 698.643632ms 720.829591ms 724.072182ms 725.980987ms 737.962095ms 743.070135ms 743.30904ms 743.413311ms 743.847346ms 744.320831ms 744.527344ms 745.228362ms 745.614525ms 746.259758ms 746.633393ms 746.666757ms 746.84578ms 746.94049ms 746.97164ms 747.185619ms 747.31155ms 747.480592ms 747.595868ms 747.624398ms 747.659424ms 747.827002ms 747.987205ms 748.034129ms 748.136109ms 748.210716ms 748.481526ms 748.488998ms 748.568042ms 748.599428ms 748.696963ms 748.706213ms 748.816512ms 748.897072ms 748.925744ms 748.940847ms 749.03302ms 749.03666ms 749.109347ms 749.116081ms 749.167633ms 749.223797ms 749.270711ms 749.325357ms 749.339977ms 749.358098ms 749.396684ms 749.493059ms 749.538715ms 749.577515ms 749.601391ms 749.62866ms 749.675527ms 749.751874ms 749.752384ms 749.775575ms 749.798007ms 749.876957ms 749.886874ms 749.906859ms 749.92322ms 749.963774ms 749.990731ms 749.993198ms 750.000105ms 750.000838ms 750.016465ms 750.096417ms 750.113955ms 750.156335ms 750.159177ms 750.15991ms 750.173742ms 750.191869ms 750.206605ms 750.217938ms 750.224396ms 750.235404ms 750.259314ms 750.268614ms 750.334258ms 750.427208ms 750.430253ms 750.490535ms 750.534611ms 750.543123ms 750.569505ms 750.574376ms 750.588605ms 750.598751ms 750.628272ms 750.631099ms 750.647235ms 750.689887ms 750.772581ms 750.782404ms 750.784649ms 750.804101ms 750.806187ms 750.853481ms 750.891063ms 750.903441ms 750.920473ms 750.926566ms 750.936692ms 750.967927ms 751.113523ms 751.209261ms 751.255345ms 751.344488ms 751.390348ms 751.406998ms 751.440828ms 751.570891ms 751.617268ms 751.816693ms 751.867896ms 751.903268ms 752.049077ms 752.16781ms 752.188862ms 752.29217ms 752.523579ms 752.539883ms 753.126232ms 753.18044ms 753.214638ms 753.409576ms 753.521972ms 753.784308ms 753.971919ms 754.798162ms 754.894568ms 755.108229ms 755.403966ms 756.072801ms 757.021516ms 761.444953ms 773.486952ms 776.148744ms 801.330737ms]
Dec 17 13:09:42.562: INFO: 50 %ile: 749.223797ms
Dec 17 13:09:42.562: INFO: 90 %ile: 752.29217ms
Dec 17 13:09:42.562: INFO: 99 %ile: 776.148744ms
Dec 17 13:09:42.562: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:09:42.562: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5212" for this suite.
Dec 17 13:10:00.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:00.790: INFO: namespace svc-latency-5212 deletion completed in 18.212809645s

• [SLOW TEST:29.012 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:10:00.790: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6811
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6811
I1217 13:10:00.903023      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6811, replica count: 2
Dec 17 13:10:03.953: INFO: Creating new exec pod
I1217 13:10:03.953600      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 13:10:07.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6811 execpodwhvjw -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 17 13:10:08.135: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 17 13:10:08.135: INFO: stdout: ""
Dec 17 13:10:08.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6811 execpodwhvjw -- /bin/sh -x -c nc -zv -t -w 2 10.0.56.50 80'
Dec 17 13:10:08.283: INFO: stderr: "+ nc -zv -t -w 2 10.0.56.50 80\nConnection to 10.0.56.50 80 port [tcp/http] succeeded!\n"
Dec 17 13:10:08.283: INFO: stdout: ""
Dec 17 13:10:08.283: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:10:08.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6811" for this suite.
Dec 17 13:10:14.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:14.574: INFO: namespace services-6811 deletion completed in 6.231548814s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.783 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:10:14.574: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:10:15.044: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:10:18.082: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:10:18.093: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-871-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:10:19.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1850" for this suite.
Dec 17 13:10:25.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:25.761: INFO: namespace webhook-1850 deletion completed in 6.215706182s
STEP: Destroying namespace "webhook-1850-markers" for this suite.
Dec 17 13:10:31.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:31.964: INFO: namespace webhook-1850-markers deletion completed in 6.203425282s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.429 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:10:32.003: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 17 13:10:32.057: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-005828023 proxy --unix-socket=/tmp/kubectl-proxy-unix597936206/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:10:32.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8205" for this suite.
Dec 17 13:10:38.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:38.351: INFO: namespace kubectl-8205 deletion completed in 6.245057438s

• [SLOW TEST:6.348 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:10:38.352: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:10:38.442: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 17 13:10:38.461: INFO: Number of nodes with available pods: 0
Dec 17 13:10:38.461: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 17 13:10:38.503: INFO: Number of nodes with available pods: 0
Dec 17 13:10:38.503: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:10:39.508: INFO: Number of nodes with available pods: 1
Dec 17 13:10:39.508: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 17 13:10:39.550: INFO: Number of nodes with available pods: 1
Dec 17 13:10:39.550: INFO: Number of running nodes: 0, number of available pods: 1
Dec 17 13:10:40.559: INFO: Number of nodes with available pods: 0
Dec 17 13:10:40.559: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 17 13:10:40.580: INFO: Number of nodes with available pods: 0
Dec 17 13:10:40.580: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:10:41.589: INFO: Number of nodes with available pods: 0
Dec 17 13:10:41.589: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:10:42.585: INFO: Number of nodes with available pods: 0
Dec 17 13:10:42.585: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:10:43.586: INFO: Number of nodes with available pods: 0
Dec 17 13:10:43.586: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:10:44.589: INFO: Number of nodes with available pods: 1
Dec 17 13:10:44.589: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8907, will wait for the garbage collector to delete the pods
Dec 17 13:10:44.677: INFO: Deleting DaemonSet.extensions daemon-set took: 17.607994ms
Dec 17 13:10:44.977: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.14448ms
Dec 17 13:10:50.985: INFO: Number of nodes with available pods: 0
Dec 17 13:10:50.985: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 13:10:50.993: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8907/daemonsets","resourceVersion":"247582"},"items":null}

Dec 17 13:10:51.000: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8907/pods","resourceVersion":"247582"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:10:51.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8907" for this suite.
Dec 17 13:10:57.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:10:57.289: INFO: namespace daemonsets-8907 deletion completed in 6.228211687s

• [SLOW TEST:18.937 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:10:57.289: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 13:10:57.348: INFO: Waiting up to 5m0s for pod "pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c" in namespace "emptydir-4324" to be "success or failure"
Dec 17 13:10:57.367: INFO: Pod "pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.228811ms
Dec 17 13:10:59.376: INFO: Pod "pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027308276s
STEP: Saw pod success
Dec 17 13:10:59.376: INFO: Pod "pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c" satisfied condition "success or failure"
Dec 17 13:10:59.409: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c container test-container: <nil>
STEP: delete the pod
Dec 17 13:10:59.481: INFO: Waiting for pod pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c to disappear
Dec 17 13:10:59.490: INFO: Pod pod-3b8566bf-db6c-4e92-a45a-9ef8bb3fc94c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:10:59.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4324" for this suite.
Dec 17 13:11:05.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:05.810: INFO: namespace emptydir-4324 deletion completed in 6.288452913s

• [SLOW TEST:8.521 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:11:05.810: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 17 13:11:05.876: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 17 13:11:10.886: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:11:10.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2139" for this suite.
Dec 17 13:11:16.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:17.195: INFO: namespace replication-controller-2139 deletion completed in 6.281431833s

• [SLOW TEST:11.385 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:11:17.196: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ba8b3832-efec-452e-b454-8670a14072ed
STEP: Creating a pod to test consume secrets
Dec 17 13:11:17.306: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583" in namespace "projected-791" to be "success or failure"
Dec 17 13:11:17.330: INFO: Pod "pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583": Phase="Pending", Reason="", readiness=false. Elapsed: 24.092987ms
Dec 17 13:11:19.339: INFO: Pod "pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.032823556s
STEP: Saw pod success
Dec 17 13:11:19.339: INFO: Pod "pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583" satisfied condition "success or failure"
Dec 17 13:11:19.347: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:11:19.401: INFO: Waiting for pod pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583 to disappear
Dec 17 13:11:19.405: INFO: Pod pod-projected-secrets-7c38ccda-f253-43d7-98d3-262331995583 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:11:19.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-791" for this suite.
Dec 17 13:11:25.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:25.666: INFO: namespace projected-791 deletion completed in 6.244887667s

• [SLOW TEST:8.470 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:11:25.666: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:11:25.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5474" for this suite.
Dec 17 13:11:31.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:32.093: INFO: namespace tables-5474 deletion completed in 6.360232822s

• [SLOW TEST:6.427 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:11:32.093: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:11:38.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-81" for this suite.
Dec 17 13:11:44.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:44.634: INFO: namespace namespaces-81 deletion completed in 6.266806504s
STEP: Destroying namespace "nsdeletetest-6165" for this suite.
Dec 17 13:11:44.642: INFO: Namespace nsdeletetest-6165 was already deleted
STEP: Destroying namespace "nsdeletetest-9943" for this suite.
Dec 17 13:11:50.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:11:50.866: INFO: namespace nsdeletetest-9943 deletion completed in 6.224070673s

• [SLOW TEST:18.773 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:11:50.866: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:12:01.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6133" for this suite.
Dec 17 13:12:08.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:12:08.214: INFO: namespace resourcequota-6133 deletion completed in 6.214117302s

• [SLOW TEST:17.348 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:12:08.215: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 17 13:12:08.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-665'
Dec 17 13:12:08.440: INFO: stderr: ""
Dec 17 13:12:08.440: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 13:12:08.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-665'
Dec 17 13:12:08.503: INFO: stderr: ""
Dec 17 13:12:08.503: INFO: stdout: "update-demo-nautilus-6qv56 update-demo-nautilus-zddmk "
Dec 17 13:12:08.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-6qv56 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:08.568: INFO: stderr: ""
Dec 17 13:12:08.568: INFO: stdout: ""
Dec 17 13:12:08.568: INFO: update-demo-nautilus-6qv56 is created but not running
Dec 17 13:12:13.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-665'
Dec 17 13:12:13.633: INFO: stderr: ""
Dec 17 13:12:13.633: INFO: stdout: "update-demo-nautilus-6qv56 update-demo-nautilus-zddmk "
Dec 17 13:12:13.633: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-6qv56 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:13.694: INFO: stderr: ""
Dec 17 13:12:13.694: INFO: stdout: "true"
Dec 17 13:12:13.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-6qv56 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:13.752: INFO: stderr: ""
Dec 17 13:12:13.752: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:12:13.752: INFO: validating pod update-demo-nautilus-6qv56
Dec 17 13:12:13.765: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:12:13.765: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:12:13.765: INFO: update-demo-nautilus-6qv56 is verified up and running
Dec 17 13:12:13.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-zddmk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:13.826: INFO: stderr: ""
Dec 17 13:12:13.826: INFO: stdout: "true"
Dec 17 13:12:13.826: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-zddmk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:13.885: INFO: stderr: ""
Dec 17 13:12:13.885: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:12:13.885: INFO: validating pod update-demo-nautilus-zddmk
Dec 17 13:12:13.898: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:12:13.898: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:12:13.898: INFO: update-demo-nautilus-zddmk is verified up and running
STEP: rolling-update to new replication controller
Dec 17 13:12:13.899: INFO: scanned /root for discovery docs: <nil>
Dec 17 13:12:13.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-665'
Dec 17 13:12:36.435: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 13:12:36.435: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 13:12:36.435: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-665'
Dec 17 13:12:36.503: INFO: stderr: ""
Dec 17 13:12:36.503: INFO: stdout: "update-demo-kitten-fpkcl update-demo-kitten-mgzbg "
Dec 17 13:12:36.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-kitten-fpkcl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:36.559: INFO: stderr: ""
Dec 17 13:12:36.559: INFO: stdout: "true"
Dec 17 13:12:36.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-kitten-fpkcl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:36.618: INFO: stderr: ""
Dec 17 13:12:36.618: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 13:12:36.618: INFO: validating pod update-demo-kitten-fpkcl
Dec 17 13:12:36.632: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 13:12:36.632: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 13:12:36.632: INFO: update-demo-kitten-fpkcl is verified up and running
Dec 17 13:12:36.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-kitten-mgzbg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:36.704: INFO: stderr: ""
Dec 17 13:12:36.704: INFO: stdout: "true"
Dec 17 13:12:36.704: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-kitten-mgzbg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-665'
Dec 17 13:12:36.763: INFO: stderr: ""
Dec 17 13:12:36.763: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 17 13:12:36.763: INFO: validating pod update-demo-kitten-mgzbg
Dec 17 13:12:36.776: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 17 13:12:36.776: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 17 13:12:36.776: INFO: update-demo-kitten-mgzbg is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:12:36.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-665" for this suite.
Dec 17 13:12:48.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:12:49.025: INFO: namespace kubectl-665 deletion completed in 12.234394912s

• [SLOW TEST:40.810 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:12:49.026: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:12:49.095: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 17 13:12:54.101: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 17 13:12:54.101: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 17 13:12:56.106: INFO: Creating deployment "test-rollover-deployment"
Dec 17 13:12:56.120: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 17 13:12:58.133: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 17 13:12:58.146: INFO: Ensure that both replica sets have 1 created replica
Dec 17 13:12:58.159: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 17 13:12:58.176: INFO: Updating deployment test-rollover-deployment
Dec 17 13:12:58.176: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 17 13:13:00.190: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 17 13:13:00.203: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 17 13:13:00.216: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 13:13:00.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185179, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:13:02.233: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 13:13:02.233: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185179, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:13:04.229: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 13:13:04.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185179, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:13:06.229: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 13:13:06.230: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185179, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:13:08.248: INFO: all replica sets need to contain the pod-template-hash label
Dec 17 13:13:08.248: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185179, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185176, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:13:10.231: INFO: 
Dec 17 13:13:10.231: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 13:13:10.253: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-18 /apis/apps/v1/namespaces/deployment-18/deployments/test-rollover-deployment 126bcbe7-bd68-4e75-b1eb-ad87634d4b85 248260 2 2019-12-17 13:12:56 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029c73b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-17 13:12:56 +0000 UTC,LastTransitionTime:2019-12-17 13:12:56 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-17 13:13:09 +0000 UTC,LastTransitionTime:2019-12-17 13:12:56 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 17 13:13:10.258: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-18 /apis/apps/v1/namespaces/deployment-18/replicasets/test-rollover-deployment-7d7dc6548c e8f399a9-fceb-4a87-a6a0-62c855e35108 248249 2 2019-12-17 13:12:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 126bcbe7-bd68-4e75-b1eb-ad87634d4b85 0xc0029c7887 0xc0029c7888}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029c78e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 17 13:13:10.258: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 17 13:13:10.258: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-18 /apis/apps/v1/namespaces/deployment-18/replicasets/test-rollover-controller 68096c20-b920-48f2-ba34-7540f304551a 248259 2 2019-12-17 13:12:49 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 126bcbe7-bd68-4e75-b1eb-ad87634d4b85 0xc0029c77b7 0xc0029c77b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0029c7818 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 13:13:10.259: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-18 /apis/apps/v1/namespaces/deployment-18/replicasets/test-rollover-deployment-f6c94f66c 9ca53d00-f704-4866-a117-5feea2487df9 248214 2 2019-12-17 13:12:56 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 126bcbe7-bd68-4e75-b1eb-ad87634d4b85 0xc0029c7950 0xc0029c7951}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0029c79c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 13:13:10.263: INFO: Pod "test-rollover-deployment-7d7dc6548c-7tgtd" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-7tgtd test-rollover-deployment-7d7dc6548c- deployment-18 /api/v1/namespaces/deployment-18/pods/test-rollover-deployment-7d7dc6548c-7tgtd 1faa5b09-13a3-43b7-aff1-d924f0fe090c 248224 0 2019-12-17 13:12:58 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c e8f399a9-fceb-4a87-a6a0-62c855e35108 0xc0029c7f17 0xc0029c7f18}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bnh4z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bnh4z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bnh4z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:12:58 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:12:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:12:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:12:58 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.41,StartTime:2019-12-17 13:12:58 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 13:12:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://b2cf901dd686e23ee562a461b854b24e681904ad778159292b0b751ec964d05e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:13:10.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-18" for this suite.
Dec 17 13:13:16.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:13:16.492: INFO: namespace deployment-18 deletion completed in 6.220202548s

• [SLOW TEST:27.466 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:13:16.492: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-920953dd-4340-40d7-9182-3dd228329433
STEP: Creating a pod to test consume configMaps
Dec 17 13:13:16.564: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340" in namespace "projected-1619" to be "success or failure"
Dec 17 13:13:16.569: INFO: Pod "pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340": Phase="Pending", Reason="", readiness=false. Elapsed: 4.79927ms
Dec 17 13:13:18.578: INFO: Pod "pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013251214s
STEP: Saw pod success
Dec 17 13:13:18.578: INFO: Pod "pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340" satisfied condition "success or failure"
Dec 17 13:13:18.582: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 13:13:18.640: INFO: Waiting for pod pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340 to disappear
Dec 17 13:13:18.648: INFO: Pod pod-projected-configmaps-322e38b5-7840-426d-87d9-262f31cc6340 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:13:18.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1619" for this suite.
Dec 17 13:13:24.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:13:24.873: INFO: namespace projected-1619 deletion completed in 6.216908584s

• [SLOW TEST:8.381 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:13:24.873: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:13:24.946: INFO: Waiting up to 5m0s for pod "downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009" in namespace "projected-5473" to be "success or failure"
Dec 17 13:13:24.955: INFO: Pod "downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009": Phase="Pending", Reason="", readiness=false. Elapsed: 8.610517ms
Dec 17 13:13:26.964: INFO: Pod "downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017307783s
STEP: Saw pod success
Dec 17 13:13:26.964: INFO: Pod "downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009" satisfied condition "success or failure"
Dec 17 13:13:26.971: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009 container client-container: <nil>
STEP: delete the pod
Dec 17 13:13:27.027: INFO: Waiting for pod downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009 to disappear
Dec 17 13:13:27.031: INFO: Pod downwardapi-volume-81522c8c-50d3-4ed1-ad9b-dce6e60c1009 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:13:27.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5473" for this suite.
Dec 17 13:13:33.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:13:33.267: INFO: namespace projected-5473 deletion completed in 6.220123636s

• [SLOW TEST:8.393 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:13:33.267: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec 17 13:13:33.311: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 17 13:14:33.345: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:14:33.350: INFO: Starting informer...
STEP: Starting pods...
Dec 17 13:14:33.385: INFO: Pod1 is running on k8s-node-vm923c-7kwnapovj8. Tainting Node
Dec 17 13:14:35.619: INFO: Pod2 is running on k8s-node-vm923c-7kwnapovj8. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 17 13:14:50.750: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 17 13:15:10.709: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:15:10.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9418" for this suite.
Dec 17 13:15:16.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:15:17.021: INFO: namespace taint-multiple-pods-9418 deletion completed in 6.272238038s

• [SLOW TEST:103.754 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:15:17.021: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7688a8ba-5578-4582-b5c3-38507dd2ba56
STEP: Creating a pod to test consume configMaps
Dec 17 13:15:17.093: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01" in namespace "projected-9394" to be "success or failure"
Dec 17 13:15:17.098: INFO: Pod "pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01": Phase="Pending", Reason="", readiness=false. Elapsed: 5.051182ms
Dec 17 13:15:19.103: INFO: Pod "pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010099138s
Dec 17 13:15:21.108: INFO: Pod "pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015030069s
STEP: Saw pod success
Dec 17 13:15:21.108: INFO: Pod "pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01" satisfied condition "success or failure"
Dec 17 13:15:21.117: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 13:15:21.170: INFO: Waiting for pod pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01 to disappear
Dec 17 13:15:21.177: INFO: Pod pod-projected-configmaps-5e722e7f-8851-4215-b81b-2e245dbf0a01 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:15:21.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9394" for this suite.
Dec 17 13:15:27.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:15:27.415: INFO: namespace projected-9394 deletion completed in 6.230839479s

• [SLOW TEST:10.394 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:15:27.416: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9433.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9433.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9433.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9433.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9433.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9433.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 13:15:29.535: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.545: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.555: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.562: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.589: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.599: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.609: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.615: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9433.svc.cluster.local from pod dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf: the server could not find the requested resource (get pods dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf)
Dec 17 13:15:29.635: INFO: Lookups using dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9433.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9433.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9433.svc.cluster.local jessie_udp@dns-test-service-2.dns-9433.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9433.svc.cluster.local]

Dec 17 13:15:34.745: INFO: DNS probes using dns-9433/dns-test-9c5d96b1-011a-4b54-aa1c-f36d366c4cbf succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:15:34.827: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9433" for this suite.
Dec 17 13:15:40.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:15:41.067: INFO: namespace dns-9433 deletion completed in 6.227561028s

• [SLOW TEST:13.651 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:15:41.067: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:15:43.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-913" for this suite.
Dec 17 13:15:49.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:15:49.489: INFO: namespace emptydir-wrapper-913 deletion completed in 6.224546553s

• [SLOW TEST:8.422 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:15:49.489: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-9923
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9923 to expose endpoints map[]
Dec 17 13:15:49.564: INFO: successfully validated that service endpoint-test2 in namespace services-9923 exposes endpoints map[] (8.69354ms elapsed)
STEP: Creating pod pod1 in namespace services-9923
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9923 to expose endpoints map[pod1:[80]]
Dec 17 13:15:50.620: INFO: successfully validated that service endpoint-test2 in namespace services-9923 exposes endpoints map[pod1:[80]] (1.043135921s elapsed)
STEP: Creating pod pod2 in namespace services-9923
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9923 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 17 13:15:51.674: INFO: successfully validated that service endpoint-test2 in namespace services-9923 exposes endpoints map[pod1:[80] pod2:[80]] (1.044485842s elapsed)
STEP: Deleting pod pod1 in namespace services-9923
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9923 to expose endpoints map[pod2:[80]]
Dec 17 13:15:51.701: INFO: successfully validated that service endpoint-test2 in namespace services-9923 exposes endpoints map[pod2:[80]] (15.815874ms elapsed)
STEP: Deleting pod pod2 in namespace services-9923
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9923 to expose endpoints map[]
Dec 17 13:15:51.723: INFO: successfully validated that service endpoint-test2 in namespace services-9923 exposes endpoints map[] (9.686612ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:15:51.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9923" for this suite.
Dec 17 13:16:03.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:16:04.017: INFO: namespace services-9923 deletion completed in 12.240043217s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.528 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:16:04.017: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 17 13:16:06.115: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-005828023 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 17 13:16:11.214: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:16:11.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4586" for this suite.
Dec 17 13:16:17.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:16:17.491: INFO: namespace pods-4586 deletion completed in 6.257352519s

• [SLOW TEST:13.474 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:16:17.491: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 17 13:16:17.539: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-005828023 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:16:17.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9322" for this suite.
Dec 17 13:16:23.626: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:16:23.840: INFO: namespace kubectl-9322 deletion completed in 6.242511325s

• [SLOW TEST:6.349 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:16:23.840: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 17 13:16:23.899: INFO: Waiting up to 5m0s for pod "pod-511daf45-ee30-4d82-bb8b-c3aa90788777" in namespace "emptydir-7363" to be "success or failure"
Dec 17 13:16:23.908: INFO: Pod "pod-511daf45-ee30-4d82-bb8b-c3aa90788777": Phase="Pending", Reason="", readiness=false. Elapsed: 9.004606ms
Dec 17 13:16:25.917: INFO: Pod "pod-511daf45-ee30-4d82-bb8b-c3aa90788777": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017946917s
STEP: Saw pod success
Dec 17 13:16:25.917: INFO: Pod "pod-511daf45-ee30-4d82-bb8b-c3aa90788777" satisfied condition "success or failure"
Dec 17 13:16:25.925: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-511daf45-ee30-4d82-bb8b-c3aa90788777 container test-container: <nil>
STEP: delete the pod
Dec 17 13:16:25.966: INFO: Waiting for pod pod-511daf45-ee30-4d82-bb8b-c3aa90788777 to disappear
Dec 17 13:16:25.974: INFO: Pod pod-511daf45-ee30-4d82-bb8b-c3aa90788777 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:16:25.974: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7363" for this suite.
Dec 17 13:16:32.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:16:32.219: INFO: namespace emptydir-7363 deletion completed in 6.238481487s

• [SLOW TEST:8.379 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:16:32.220: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-70bd7c4f-4003-4224-8d27-5e47fbb475b1
STEP: Creating a pod to test consume secrets
Dec 17 13:16:32.282: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5" in namespace "projected-1157" to be "success or failure"
Dec 17 13:16:32.292: INFO: Pod "pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.327749ms
Dec 17 13:16:34.300: INFO: Pod "pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018062521s
STEP: Saw pod success
Dec 17 13:16:34.301: INFO: Pod "pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5" satisfied condition "success or failure"
Dec 17 13:16:34.307: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:16:34.356: INFO: Waiting for pod pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5 to disappear
Dec 17 13:16:34.360: INFO: Pod pod-projected-secrets-003f43e4-9c5f-48b0-afc7-d3d1b304cee5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:16:34.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1157" for this suite.
Dec 17 13:16:40.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:16:40.649: INFO: namespace projected-1157 deletion completed in 6.262169847s

• [SLOW TEST:8.429 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:16:40.649: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-6381, will wait for the garbage collector to delete the pods
Dec 17 13:16:42.794: INFO: Deleting Job.batch foo took: 18.228084ms
Dec 17 13:16:43.094: INFO: Terminating Job.batch foo pods took: 300.261879ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:17:21.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6381" for this suite.
Dec 17 13:17:27.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:17:27.335: INFO: namespace job-6381 deletion completed in 6.221258179s

• [SLOW TEST:46.686 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:17:27.335: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:17:27.430: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"7dc85525-6c7b-4407-b8fb-2cfada9df0a5", Controller:(*bool)(0xc0038a0cba), BlockOwnerDeletion:(*bool)(0xc0038a0cbb)}}
Dec 17 13:17:27.436: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"df3a87ad-bb1e-4124-becf-88fbb48c03a9", Controller:(*bool)(0xc003a7c0b2), BlockOwnerDeletion:(*bool)(0xc003a7c0b3)}}
Dec 17 13:17:27.449: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"eeaffcd7-a317-4246-9fe0-8f9c2118a235", Controller:(*bool)(0xc0060ec3aa), BlockOwnerDeletion:(*bool)(0xc0060ec3ab)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:17:32.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2139" for this suite.
Dec 17 13:17:38.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:17:38.682: INFO: namespace gc-2139 deletion completed in 6.203850746s

• [SLOW TEST:11.347 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:17:38.682: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 17 13:17:41.802: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:17:42.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-2337" for this suite.
Dec 17 13:18:10.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:11.078: INFO: namespace replicaset-2337 deletion completed in 28.234835553s

• [SLOW TEST:32.396 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:11.078: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d1398bb5-8c39-407f-8553-2c1f1cef42b4
STEP: Creating a pod to test consume configMaps
Dec 17 13:18:11.139: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8" in namespace "projected-7094" to be "success or failure"
Dec 17 13:18:11.144: INFO: Pod "pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.250381ms
Dec 17 13:18:13.152: INFO: Pod "pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013123887s
STEP: Saw pod success
Dec 17 13:18:13.152: INFO: Pod "pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8" satisfied condition "success or failure"
Dec 17 13:18:13.161: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 13:18:13.216: INFO: Waiting for pod pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8 to disappear
Dec 17 13:18:13.223: INFO: Pod pod-projected-configmaps-d970ffdc-8c2c-4984-87ba-b0129695cdd8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:18:13.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7094" for this suite.
Dec 17 13:18:19.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:19.478: INFO: namespace projected-7094 deletion completed in 6.237852171s

• [SLOW TEST:8.400 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:19.478: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 13:18:19.535: INFO: Waiting up to 5m0s for pod "pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160" in namespace "emptydir-9228" to be "success or failure"
Dec 17 13:18:19.544: INFO: Pod "pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160": Phase="Pending", Reason="", readiness=false. Elapsed: 9.02104ms
Dec 17 13:18:21.553: INFO: Pod "pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017891058s
STEP: Saw pod success
Dec 17 13:18:21.553: INFO: Pod "pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160" satisfied condition "success or failure"
Dec 17 13:18:21.558: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160 container test-container: <nil>
STEP: delete the pod
Dec 17 13:18:21.620: INFO: Waiting for pod pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160 to disappear
Dec 17 13:18:21.628: INFO: Pod pod-1fab1922-c0e9-4f7c-993a-cc662a4bc160 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:18:21.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9228" for this suite.
Dec 17 13:18:27.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:27.894: INFO: namespace emptydir-9228 deletion completed in 6.258465802s

• [SLOW TEST:8.416 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:27.894: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 17 13:18:27.950: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 17 13:18:35.018: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:18:35.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4665" for this suite.
Dec 17 13:18:41.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:41.279: INFO: namespace pods-4665 deletion completed in 6.243075505s

• [SLOW TEST:13.385 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:41.279: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:18:41.333: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 17 13:18:42.402: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:18:43.415: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-520" for this suite.
Dec 17 13:18:49.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:49.670: INFO: namespace replication-controller-520 deletion completed in 6.241761596s

• [SLOW TEST:8.391 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:49.671: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:18:49.738: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d" in namespace "downward-api-9507" to be "success or failure"
Dec 17 13:18:49.746: INFO: Pod "downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011103ms
Dec 17 13:18:51.752: INFO: Pod "downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01328179s
STEP: Saw pod success
Dec 17 13:18:51.752: INFO: Pod "downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d" satisfied condition "success or failure"
Dec 17 13:18:51.760: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d container client-container: <nil>
STEP: delete the pod
Dec 17 13:18:51.801: INFO: Waiting for pod downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d to disappear
Dec 17 13:18:51.805: INFO: Pod downwardapi-volume-cc4e16c3-582e-4565-bbe3-f1148eb8864d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:18:51.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9507" for this suite.
Dec 17 13:18:57.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:18:58.056: INFO: namespace downward-api-9507 deletion completed in 6.237092107s

• [SLOW TEST:8.385 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:18:58.056: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 13:19:00.157: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:19:00.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1009" for this suite.
Dec 17 13:19:06.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:19:06.458: INFO: namespace container-runtime-1009 deletion completed in 6.256753477s

• [SLOW TEST:8.402 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:19:06.458: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 17 13:19:06.561: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6826 /api/v1/namespaces/watch-6826/configmaps/e2e-watch-test-resource-version f95567b6-e8b2-4344-8d38-f883242c9718 249893 0 2019-12-17 13:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 13:19:06.561: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6826 /api/v1/namespaces/watch-6826/configmaps/e2e-watch-test-resource-version f95567b6-e8b2-4344-8d38-f883242c9718 249894 0 2019-12-17 13:19:06 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:19:06.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6826" for this suite.
Dec 17 13:19:12.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:19:12.844: INFO: namespace watch-6826 deletion completed in 6.240578404s

• [SLOW TEST:6.385 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:19:12.844: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 17 13:19:15.431: INFO: Successfully updated pod "adopt-release-bdqxd"
STEP: Checking that the Job readopts the Pod
Dec 17 13:19:15.431: INFO: Waiting up to 15m0s for pod "adopt-release-bdqxd" in namespace "job-1839" to be "adopted"
Dec 17 13:19:15.435: INFO: Pod "adopt-release-bdqxd": Phase="Running", Reason="", readiness=true. Elapsed: 4.249234ms
Dec 17 13:19:17.440: INFO: Pod "adopt-release-bdqxd": Phase="Running", Reason="", readiness=true. Elapsed: 2.009632633s
Dec 17 13:19:17.440: INFO: Pod "adopt-release-bdqxd" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 17 13:19:17.956: INFO: Successfully updated pod "adopt-release-bdqxd"
STEP: Checking that the Job releases the Pod
Dec 17 13:19:17.956: INFO: Waiting up to 15m0s for pod "adopt-release-bdqxd" in namespace "job-1839" to be "released"
Dec 17 13:19:17.960: INFO: Pod "adopt-release-bdqxd": Phase="Running", Reason="", readiness=true. Elapsed: 4.229689ms
Dec 17 13:19:19.969: INFO: Pod "adopt-release-bdqxd": Phase="Running", Reason="", readiness=true. Elapsed: 2.013130687s
Dec 17 13:19:19.969: INFO: Pod "adopt-release-bdqxd" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:19:19.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1839" for this suite.
Dec 17 13:20:04.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:20:04.213: INFO: namespace job-1839 deletion completed in 44.229324681s

• [SLOW TEST:51.369 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:20:04.213: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa
Dec 17 13:20:04.270: INFO: Pod name my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa: Found 0 pods out of 1
Dec 17 13:20:09.275: INFO: Pod name my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa: Found 1 pods out of 1
Dec 17 13:20:09.275: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa" are running
Dec 17 13:20:09.284: INFO: Pod "my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa-cdpmk" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:20:04 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:20:05 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:20:05 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:20:04 +0000 UTC Reason: Message:}])
Dec 17 13:20:09.284: INFO: Trying to dial the pod
Dec 17 13:20:14.314: INFO: Controller my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa: Got expected result from replica 1 [my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa-cdpmk]: "my-hostname-basic-e2c7f446-adc5-48b9-91ec-7acc5978d7aa-cdpmk", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:20:14.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9865" for this suite.
Dec 17 13:20:20.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:20:20.599: INFO: namespace replication-controller-9865 deletion completed in 6.268547169s

• [SLOW TEST:16.386 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:20:20.600: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4915.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4915.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4915.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4915.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 186.61.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.61.186_udp@PTR;check="$$(dig +tcp +noall +answer +search 186.61.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.61.186_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4915.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4915.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4915.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4915.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4915.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4915.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 186.61.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.61.186_udp@PTR;check="$$(dig +tcp +noall +answer +search 186.61.0.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.0.61.186_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 13:20:22.717: INFO: Unable to read wheezy_udp@dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.723: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.733: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.743: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.802: INFO: Unable to read jessie_udp@dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.812: INFO: Unable to read jessie_tcp@dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.823: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.830: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local from pod dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32: the server could not find the requested resource (get pods dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32)
Dec 17 13:20:22.884: INFO: Lookups using dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32 failed for: [wheezy_udp@dns-test-service.dns-4915.svc.cluster.local wheezy_tcp@dns-test-service.dns-4915.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local jessie_udp@dns-test-service.dns-4915.svc.cluster.local jessie_tcp@dns-test-service.dns-4915.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4915.svc.cluster.local]

Dec 17 13:20:28.064: INFO: DNS probes using dns-4915/dns-test-d6e6b3d2-35e5-4c7b-aada-9daaac7b3e32 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:20:28.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4915" for this suite.
Dec 17 13:20:34.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:20:34.453: INFO: namespace dns-4915 deletion completed in 6.231102146s

• [SLOW TEST:13.853 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:20:34.453: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a58b858c-ebea-46a9-99a6-1a6ef227892a in namespace container-probe-8945
Dec 17 13:20:36.534: INFO: Started pod liveness-a58b858c-ebea-46a9-99a6-1a6ef227892a in namespace container-probe-8945
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 13:20:36.542: INFO: Initial restart count of pod liveness-a58b858c-ebea-46a9-99a6-1a6ef227892a is 0
Dec 17 13:21:00.644: INFO: Restart count of pod container-probe-8945/liveness-a58b858c-ebea-46a9-99a6-1a6ef227892a is now 1 (24.102084798s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:21:00.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8945" for this suite.
Dec 17 13:21:06.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:21:06.929: INFO: namespace container-probe-8945 deletion completed in 6.24372044s

• [SLOW TEST:32.476 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:21:06.929: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 13:21:06.993: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5387'
Dec 17 13:21:07.207: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 13:21:07.207: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 17 13:21:07.218: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete jobs e2e-test-httpd-job --namespace=kubectl-5387'
Dec 17 13:21:07.301: INFO: stderr: ""
Dec 17 13:21:07.301: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:21:07.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5387" for this suite.
Dec 17 13:21:13.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:21:13.542: INFO: namespace kubectl-5387 deletion completed in 6.233602858s

• [SLOW TEST:6.613 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:21:13.542: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:21:14.300: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:21:17.337: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:21:17.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7050" for this suite.
Dec 17 13:21:23.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:21:23.728: INFO: namespace webhook-7050 deletion completed in 6.218344836s
STEP: Destroying namespace "webhook-7050-markers" for this suite.
Dec 17 13:21:29.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:21:29.962: INFO: namespace webhook-7050-markers deletion completed in 6.234249368s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.457 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:21:30.000: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 17 13:21:30.066: INFO: Waiting up to 5m0s for pod "var-expansion-4197ca34-156c-46dd-8470-06a51f902b95" in namespace "var-expansion-4922" to be "success or failure"
Dec 17 13:21:30.070: INFO: Pod "var-expansion-4197ca34-156c-46dd-8470-06a51f902b95": Phase="Pending", Reason="", readiness=false. Elapsed: 4.381252ms
Dec 17 13:21:32.076: INFO: Pod "var-expansion-4197ca34-156c-46dd-8470-06a51f902b95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009744565s
STEP: Saw pod success
Dec 17 13:21:32.076: INFO: Pod "var-expansion-4197ca34-156c-46dd-8470-06a51f902b95" satisfied condition "success or failure"
Dec 17 13:21:32.086: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod var-expansion-4197ca34-156c-46dd-8470-06a51f902b95 container dapi-container: <nil>
STEP: delete the pod
Dec 17 13:21:32.148: INFO: Waiting for pod var-expansion-4197ca34-156c-46dd-8470-06a51f902b95 to disappear
Dec 17 13:21:32.153: INFO: Pod var-expansion-4197ca34-156c-46dd-8470-06a51f902b95 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:21:32.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4922" for this suite.
Dec 17 13:21:38.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:21:38.370: INFO: namespace var-expansion-4922 deletion completed in 6.209928115s

• [SLOW TEST:8.371 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:21:38.371: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6693
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6693
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6693
Dec 17 13:21:38.449: INFO: Found 0 stateful pods, waiting for 1
Dec 17 13:21:48.458: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 17 13:21:48.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:21:48.621: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:21:48.621: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:21:48.621: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:21:48.630: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 13:21:58.636: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:21:58.636: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:21:58.668: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999671s
Dec 17 13:21:59.674: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.990594902s
Dec 17 13:22:00.683: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.984890599s
Dec 17 13:22:01.692: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.975561214s
Dec 17 13:22:02.703: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.965630279s
Dec 17 13:22:03.712: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.955538686s
Dec 17 13:22:04.722: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.946590459s
Dec 17 13:22:05.727: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.936988214s
Dec 17 13:22:06.737: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.931394103s
Dec 17 13:22:07.746: INFO: Verifying statefulset ss doesn't scale past 1 for another 922.026646ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6693
Dec 17 13:22:08.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:22:08.923: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 13:22:08.923: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:22:08.923: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:22:08.932: INFO: Found 1 stateful pods, waiting for 3
Dec 17 13:22:18.941: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 13:22:18.941: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 13:22:18.941: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 17 13:22:18.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:22:19.112: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:22:19.112: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:22:19.112: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:22:19.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:22:19.259: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:22:19.259: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:22:19.259: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:22:19.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:22:19.394: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:22:19.394: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:22:19.394: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:22:19.394: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:22:19.412: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 17 13:22:29.426: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:22:29.426: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:22:29.426: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:22:29.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999198s
Dec 17 13:22:30.460: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.991143189s
Dec 17 13:22:31.480: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.982148247s
Dec 17 13:22:32.485: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.962760345s
Dec 17 13:22:33.497: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.956867897s
Dec 17 13:22:34.502: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.94565779s
Dec 17 13:22:35.511: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.940480097s
Dec 17 13:22:36.516: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.931530112s
Dec 17 13:22:37.525: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.92637968s
Dec 17 13:22:38.535: INFO: Verifying statefulset ss doesn't scale past 3 for another 917.234123ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6693
Dec 17 13:22:39.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:22:39.700: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 13:22:39.700: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:22:39.700: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:22:39.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:22:39.847: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 13:22:39.847: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:22:39.847: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:22:39.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-6693 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:22:39.992: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 13:22:39.992: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:22:39.992: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:22:39.992: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 13:23:20.024: INFO: Deleting all statefulset in ns statefulset-6693
Dec 17 13:23:20.028: INFO: Scaling statefulset ss to 0
Dec 17 13:23:20.052: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:23:20.057: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:23:20.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6693" for this suite.
Dec 17 13:23:26.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:23:26.344: INFO: namespace statefulset-6693 deletion completed in 6.248081326s

• [SLOW TEST:107.973 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:23:26.344: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7b2ae7c5-cca3-41f8-a7f6-15a7626292ee
STEP: Creating a pod to test consume secrets
Dec 17 13:23:26.416: INFO: Waiting up to 5m0s for pod "pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907" in namespace "secrets-5129" to be "success or failure"
Dec 17 13:23:26.423: INFO: Pod "pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907": Phase="Pending", Reason="", readiness=false. Elapsed: 7.023468ms
Dec 17 13:23:28.432: INFO: Pod "pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01605292s
STEP: Saw pod success
Dec 17 13:23:28.432: INFO: Pod "pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907" satisfied condition "success or failure"
Dec 17 13:23:28.440: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:23:28.490: INFO: Waiting for pod pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907 to disappear
Dec 17 13:23:28.497: INFO: Pod pod-secrets-de42d3f4-26fe-4400-9dad-357d3d77e907 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:23:28.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5129" for this suite.
Dec 17 13:23:34.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:23:34.757: INFO: namespace secrets-5129 deletion completed in 6.244765753s

• [SLOW TEST:8.412 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:23:34.757: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:23:34.804: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:23:35.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8087" for this suite.
Dec 17 13:23:41.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:23:41.601: INFO: namespace custom-resource-definition-8087 deletion completed in 6.235795798s

• [SLOW TEST:6.844 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:23:41.601: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 17 13:23:41.669: INFO: Waiting up to 5m0s for pod "var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f" in namespace "var-expansion-8371" to be "success or failure"
Dec 17 13:23:41.678: INFO: Pod "var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.031676ms
Dec 17 13:23:43.688: INFO: Pod "var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018045712s
STEP: Saw pod success
Dec 17 13:23:43.688: INFO: Pod "var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f" satisfied condition "success or failure"
Dec 17 13:23:43.692: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f container dapi-container: <nil>
STEP: delete the pod
Dec 17 13:23:43.750: INFO: Waiting for pod var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f to disappear
Dec 17 13:23:43.758: INFO: Pod var-expansion-3315de85-cf33-43f5-84d6-053a9e01df2f no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:23:43.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8371" for this suite.
Dec 17 13:23:49.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:23:49.992: INFO: namespace var-expansion-8371 deletion completed in 6.227044173s

• [SLOW TEST:8.391 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:23:49.993: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:23:50.043: INFO: Creating deployment "test-recreate-deployment"
Dec 17 13:23:50.054: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 17 13:23:50.079: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 17 13:23:50.088: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185830, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185830, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"test-recreate-deployment-68fc85c7bb\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185830, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712185830, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Dec 17 13:23:52.097: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 17 13:23:52.111: INFO: Updating deployment test-recreate-deployment
Dec 17 13:23:52.111: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 13:23:52.196: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-9436 /apis/apps/v1/namespaces/deployment-9436/deployments/test-recreate-deployment 4258ed49-3c8f-4418-9b99-3a34e1dc9668 251162 2 2019-12-17 13:23:50 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003207208 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-17 13:23:52 +0000 UTC,LastTransitionTime:2019-12-17 13:23:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-17 13:23:52 +0000 UTC,LastTransitionTime:2019-12-17 13:23:50 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 17 13:23:52.201: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-9436 /apis/apps/v1/namespaces/deployment-9436/replicasets/test-recreate-deployment-5f94c574ff d96e56d7-e4c2-4142-b43d-aa0eeccf763b 251160 1 2019-12-17 13:23:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 4258ed49-3c8f-4418-9b99-3a34e1dc9668 0xc003207607 0xc003207608}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003207668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 13:23:52.201: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 17 13:23:52.201: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-9436 /apis/apps/v1/namespaces/deployment-9436/replicasets/test-recreate-deployment-68fc85c7bb f3421723-5e24-4144-b69c-e7600fa7eec6 251151 2 2019-12-17 13:23:50 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 4258ed49-3c8f-4418-9b99-3a34e1dc9668 0xc0032076d7 0xc0032076d8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003207748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 13:23:52.210: INFO: Pod "test-recreate-deployment-5f94c574ff-thsv9" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-thsv9 test-recreate-deployment-5f94c574ff- deployment-9436 /api/v1/namespaces/deployment-9436/pods/test-recreate-deployment-5f94c574ff-thsv9 74bad6a5-4ac8-4fc8-a87b-2bc858e36c2f 251163 0 2019-12-17 13:23:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff d96e56d7-e4c2-4142-b43d-aa0eeccf763b 0xc003b15de7 0xc003b15de8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bbggp,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bbggp,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bbggp,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:23:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:23:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:23:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 13:23:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 13:23:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:23:52.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9436" for this suite.
Dec 17 13:23:58.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:23:58.444: INFO: namespace deployment-9436 deletion completed in 6.227052227s

• [SLOW TEST:8.451 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:23:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec 17 13:23:58.505: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 17 13:24:58.537: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:24:58.545: INFO: Starting informer...
STEP: Starting pod...
Dec 17 13:24:58.772: INFO: Pod is running on k8s-node-vm923c-7kwnapovj8. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 17 13:24:58.799: INFO: Pod wasn't evicted. Proceeding
Dec 17 13:24:58.799: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 17 13:26:13.845: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:26:13.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5787" for this suite.
Dec 17 13:26:25.884: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:26:26.095: INFO: namespace taint-single-pod-5787 deletion completed in 12.235935776s

• [SLOW TEST:147.652 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:26:26.096: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 13:26:30.263: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 13:26:30.282: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 13:26:32.282: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 13:26:32.291: INFO: Pod pod-with-poststart-http-hook still exists
Dec 17 13:26:34.282: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 17 13:26:34.290: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:26:34.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-5349" for this suite.
Dec 17 13:26:46.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:26:46.508: INFO: namespace container-lifecycle-hook-5349 deletion completed in 12.203651028s

• [SLOW TEST:20.412 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:26:46.508: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-5340
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5340
STEP: creating replication controller externalsvc in namespace services-5340
I1217 13:26:46.611667      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5340, replica count: 2
I1217 13:26:49.661969      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 17 13:26:49.711: INFO: Creating new exec pod
Dec 17 13:26:51.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-5340 execpodpkbsn -- /bin/sh -x -c nslookup nodeport-service'
Dec 17 13:26:51.882: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 17 13:26:51.882: INFO: stdout: "Server:\t\t10.0.56.10\nAddress:\t10.0.56.10#53\n\nnodeport-service.services-5340.svc.cluster.local\tcanonical name = externalsvc.services-5340.svc.cluster.local.\nName:\texternalsvc.services-5340.svc.cluster.local\nAddress: 10.0.61.135\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5340, will wait for the garbage collector to delete the pods
Dec 17 13:26:51.954: INFO: Deleting ReplicationController externalsvc took: 17.073145ms
Dec 17 13:26:52.254: INFO: Terminating ReplicationController externalsvc pods took: 300.153264ms
Dec 17 13:27:00.800: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:27:00.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5340" for this suite.
Dec 17 13:27:06.878: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:27:07.074: INFO: namespace services-5340 deletion completed in 6.221196342s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.566 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:27:07.074: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 17 13:27:47.189: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 13:27:47.189386      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:27:47.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5636" for this suite.
Dec 17 13:27:55.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:27:55.448: INFO: namespace gc-5636 deletion completed in 8.253096919s

• [SLOW TEST:48.374 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:27:55.449: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 17 13:27:57.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec pod-sharedvolume-c81efcdf-d7f7-4d96-94f5-6f0004d70669 -c busybox-main-container --namespace=emptydir-3433 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 17 13:27:57.712: INFO: stderr: ""
Dec 17 13:27:57.712: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:27:57.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3433" for this suite.
Dec 17 13:28:03.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:28:03.937: INFO: namespace emptydir-3433 deletion completed in 6.217677331s

• [SLOW TEST:8.488 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:28:03.937: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:28:04.260: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:28:07.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:28:07.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1023" for this suite.
Dec 17 13:28:13.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:28:13.579: INFO: namespace webhook-1023 deletion completed in 6.198575093s
STEP: Destroying namespace "webhook-1023-markers" for this suite.
Dec 17 13:28:19.607: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:28:19.799: INFO: namespace webhook-1023-markers deletion completed in 6.220749262s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.905 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:28:19.842: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:28:19.902: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Creating first CR 
Dec 17 13:28:20.500: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:20Z generation:1 name:name1 resourceVersion:252353 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8a5a444-6b1d-4fec-a7f6-98a44bf08839] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 17 13:28:30.524: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:30Z generation:1 name:name2 resourceVersion:252376 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:71f6b25c-aa5c-4b6a-8ca4-9bf8cf0fb79b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 17 13:28:40.531: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:20Z generation:2 name:name1 resourceVersion:252399 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8a5a444-6b1d-4fec-a7f6-98a44bf08839] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 17 13:28:50.541: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:30Z generation:2 name:name2 resourceVersion:252423 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:71f6b25c-aa5c-4b6a-8ca4-9bf8cf0fb79b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 17 13:29:00.559: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:20Z generation:2 name:name1 resourceVersion:252446 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:a8a5a444-6b1d-4fec-a7f6-98a44bf08839] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 17 13:29:10.578: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-17T13:28:30Z generation:2 name:name2 resourceVersion:252469 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:71f6b25c-aa5c-4b6a-8ca4-9bf8cf0fb79b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:29:21.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7739" for this suite.
Dec 17 13:29:27.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:29:27.344: INFO: namespace crd-watch-7739 deletion completed in 6.230892008s

• [SLOW TEST:67.502 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:29:27.344: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 17 13:29:27.409: INFO: Waiting up to 5m0s for pod "pod-1866d609-13a2-4a58-aada-0212175af6e0" in namespace "emptydir-9470" to be "success or failure"
Dec 17 13:29:27.419: INFO: Pod "pod-1866d609-13a2-4a58-aada-0212175af6e0": Phase="Pending", Reason="", readiness=false. Elapsed: 9.589626ms
Dec 17 13:29:29.424: INFO: Pod "pod-1866d609-13a2-4a58-aada-0212175af6e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014859638s
STEP: Saw pod success
Dec 17 13:29:29.424: INFO: Pod "pod-1866d609-13a2-4a58-aada-0212175af6e0" satisfied condition "success or failure"
Dec 17 13:29:29.433: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-1866d609-13a2-4a58-aada-0212175af6e0 container test-container: <nil>
STEP: delete the pod
Dec 17 13:29:29.513: INFO: Waiting for pod pod-1866d609-13a2-4a58-aada-0212175af6e0 to disappear
Dec 17 13:29:29.521: INFO: Pod pod-1866d609-13a2-4a58-aada-0212175af6e0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:29:29.521: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9470" for this suite.
Dec 17 13:29:35.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:29:35.774: INFO: namespace emptydir-9470 deletion completed in 6.245149814s

• [SLOW TEST:8.430 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:29:35.774: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-3433
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3433 to expose endpoints map[]
Dec 17 13:29:35.857: INFO: successfully validated that service multi-endpoint-test in namespace services-3433 exposes endpoints map[] (9.746802ms elapsed)
STEP: Creating pod pod1 in namespace services-3433
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3433 to expose endpoints map[pod1:[100]]
Dec 17 13:29:36.901: INFO: successfully validated that service multi-endpoint-test in namespace services-3433 exposes endpoints map[pod1:[100]] (1.034037501s elapsed)
STEP: Creating pod pod2 in namespace services-3433
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3433 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 17 13:29:37.953: INFO: successfully validated that service multi-endpoint-test in namespace services-3433 exposes endpoints map[pod1:[100] pod2:[101]] (1.041858382s elapsed)
STEP: Deleting pod pod1 in namespace services-3433
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3433 to expose endpoints map[pod2:[101]]
Dec 17 13:29:37.984: INFO: successfully validated that service multi-endpoint-test in namespace services-3433 exposes endpoints map[pod2:[101]] (18.171185ms elapsed)
STEP: Deleting pod pod2 in namespace services-3433
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3433 to expose endpoints map[]
Dec 17 13:29:38.002: INFO: successfully validated that service multi-endpoint-test in namespace services-3433 exposes endpoints map[] (4.217391ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:29:38.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3433" for this suite.
Dec 17 13:30:06.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:30:06.263: INFO: namespace services-3433 deletion completed in 28.208741281s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:30.489 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:30:06.263: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:30:08.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4982" for this suite.
Dec 17 13:30:52.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:30:52.618: INFO: namespace kubelet-test-4982 deletion completed in 44.227393997s

• [SLOW TEST:46.355 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:30:52.618: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:30:53.372: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:30:56.416: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:30:56.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1278" for this suite.
Dec 17 13:31:02.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:31:02.756: INFO: namespace webhook-1278 deletion completed in 6.213154755s
STEP: Destroying namespace "webhook-1278-markers" for this suite.
Dec 17 13:31:08.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:31:08.986: INFO: namespace webhook-1278-markers deletion completed in 6.229640177s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.404 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:31:09.022: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:31:27.115: INFO: Container started at 2019-12-17 13:31:09 +0000 UTC, pod became ready at 2019-12-17 13:31:25 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:31:27.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-553" for this suite.
Dec 17 13:31:39.150: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:31:39.320: INFO: namespace container-probe-553 deletion completed in 12.198174084s

• [SLOW TEST:30.298 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:31:39.321: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:32:39.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2358" for this suite.
Dec 17 13:32:51.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:32:51.627: INFO: namespace container-probe-2358 deletion completed in 12.206825246s

• [SLOW TEST:72.307 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:32:51.627: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:32:51.679: INFO: Waiting up to 5m0s for pod "downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7" in namespace "projected-5302" to be "success or failure"
Dec 17 13:32:51.687: INFO: Pod "downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763099ms
Dec 17 13:32:53.696: INFO: Pod "downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01658897s
STEP: Saw pod success
Dec 17 13:32:53.696: INFO: Pod "downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7" satisfied condition "success or failure"
Dec 17 13:32:53.701: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7 container client-container: <nil>
STEP: delete the pod
Dec 17 13:32:53.759: INFO: Waiting for pod downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7 to disappear
Dec 17 13:32:53.767: INFO: Pod downwardapi-volume-eb56708c-ead4-4bda-a508-7f18806f92d7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:32:53.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5302" for this suite.
Dec 17 13:32:59.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:32:59.965: INFO: namespace projected-5302 deletion completed in 6.190538414s

• [SLOW TEST:8.338 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:32:59.965: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 17 13:33:00.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-1881'
Dec 17 13:33:00.339: INFO: stderr: ""
Dec 17 13:33:00.339: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 13:33:00.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1881'
Dec 17 13:33:00.425: INFO: stderr: ""
Dec 17 13:33:00.425: INFO: stdout: "update-demo-nautilus-kzn7j update-demo-nautilus-mjct6 "
Dec 17 13:33:00.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-kzn7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:00.486: INFO: stderr: ""
Dec 17 13:33:00.486: INFO: stdout: ""
Dec 17 13:33:00.486: INFO: update-demo-nautilus-kzn7j is created but not running
Dec 17 13:33:05.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1881'
Dec 17 13:33:05.550: INFO: stderr: ""
Dec 17 13:33:05.550: INFO: stdout: "update-demo-nautilus-kzn7j update-demo-nautilus-mjct6 "
Dec 17 13:33:05.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-kzn7j -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:05.610: INFO: stderr: ""
Dec 17 13:33:05.610: INFO: stdout: "true"
Dec 17 13:33:05.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-kzn7j -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:05.668: INFO: stderr: ""
Dec 17 13:33:05.668: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:33:05.668: INFO: validating pod update-demo-nautilus-kzn7j
Dec 17 13:33:05.681: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:33:05.681: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:33:05.681: INFO: update-demo-nautilus-kzn7j is verified up and running
Dec 17 13:33:05.681: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:05.742: INFO: stderr: ""
Dec 17 13:33:05.742: INFO: stdout: "true"
Dec 17 13:33:05.742: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:05.801: INFO: stderr: ""
Dec 17 13:33:05.801: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:33:05.801: INFO: validating pod update-demo-nautilus-mjct6
Dec 17 13:33:05.814: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:33:05.814: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:33:05.814: INFO: update-demo-nautilus-mjct6 is verified up and running
STEP: scaling down the replication controller
Dec 17 13:33:05.815: INFO: scanned /root for discovery docs: <nil>
Dec 17 13:33:05.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1881'
Dec 17 13:33:06.901: INFO: stderr: ""
Dec 17 13:33:06.901: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 13:33:06.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1881'
Dec 17 13:33:06.965: INFO: stderr: ""
Dec 17 13:33:06.965: INFO: stdout: "update-demo-nautilus-kzn7j update-demo-nautilus-mjct6 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 17 13:33:11.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1881'
Dec 17 13:33:12.040: INFO: stderr: ""
Dec 17 13:33:12.040: INFO: stdout: "update-demo-nautilus-mjct6 "
Dec 17 13:33:12.040: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:12.103: INFO: stderr: ""
Dec 17 13:33:12.103: INFO: stdout: "true"
Dec 17 13:33:12.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:12.167: INFO: stderr: ""
Dec 17 13:33:12.167: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:33:12.167: INFO: validating pod update-demo-nautilus-mjct6
Dec 17 13:33:12.174: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:33:12.174: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:33:12.174: INFO: update-demo-nautilus-mjct6 is verified up and running
STEP: scaling up the replication controller
Dec 17 13:33:12.175: INFO: scanned /root for discovery docs: <nil>
Dec 17 13:33:12.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1881'
Dec 17 13:33:13.270: INFO: stderr: ""
Dec 17 13:33:13.270: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 13:33:13.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1881'
Dec 17 13:33:13.332: INFO: stderr: ""
Dec 17 13:33:13.332: INFO: stdout: "update-demo-nautilus-j42gb update-demo-nautilus-mjct6 "
Dec 17 13:33:13.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-j42gb -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:13.394: INFO: stderr: ""
Dec 17 13:33:13.394: INFO: stdout: "true"
Dec 17 13:33:13.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-j42gb -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:13.465: INFO: stderr: ""
Dec 17 13:33:13.465: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:33:13.465: INFO: validating pod update-demo-nautilus-j42gb
Dec 17 13:33:13.478: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:33:13.478: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:33:13.478: INFO: update-demo-nautilus-j42gb is verified up and running
Dec 17 13:33:13.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:13.542: INFO: stderr: ""
Dec 17 13:33:13.542: INFO: stdout: "true"
Dec 17 13:33:13.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-mjct6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1881'
Dec 17 13:33:13.599: INFO: stderr: ""
Dec 17 13:33:13.599: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 13:33:13.599: INFO: validating pod update-demo-nautilus-mjct6
Dec 17 13:33:13.610: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 13:33:13.610: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 13:33:13.610: INFO: update-demo-nautilus-mjct6 is verified up and running
STEP: using delete to clean up resources
Dec 17 13:33:13.610: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-1881'
Dec 17 13:33:13.688: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 13:33:13.688: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 13:33:13.688: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1881'
Dec 17 13:33:13.756: INFO: stderr: "No resources found in kubectl-1881 namespace.\n"
Dec 17 13:33:13.756: INFO: stdout: ""
Dec 17 13:33:13.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -l name=update-demo --namespace=kubectl-1881 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 13:33:13.818: INFO: stderr: ""
Dec 17 13:33:13.818: INFO: stdout: "update-demo-nautilus-j42gb\nupdate-demo-nautilus-mjct6\n"
Dec 17 13:33:14.318: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1881'
Dec 17 13:33:14.398: INFO: stderr: "No resources found in kubectl-1881 namespace.\n"
Dec 17 13:33:14.398: INFO: stdout: ""
Dec 17 13:33:14.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -l name=update-demo --namespace=kubectl-1881 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 13:33:14.455: INFO: stderr: ""
Dec 17 13:33:14.455: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:33:14.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1881" for this suite.
Dec 17 13:33:26.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:33:26.716: INFO: namespace kubectl-1881 deletion completed in 12.252928616s

• [SLOW TEST:26.751 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:33:26.716: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-837287ac-bd08-41e4-99bd-814c58ffa799 in namespace container-probe-7178
Dec 17 13:33:28.798: INFO: Started pod busybox-837287ac-bd08-41e4-99bd-814c58ffa799 in namespace container-probe-7178
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 13:33:28.806: INFO: Initial restart count of pod busybox-837287ac-bd08-41e4-99bd-814c58ffa799 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:37:29.843: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7178" for this suite.
Dec 17 13:37:35.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:37:36.093: INFO: namespace container-probe-7178 deletion completed in 6.236272122s

• [SLOW TEST:249.377 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:37:36.093: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 17 13:37:36.607: INFO: Pod name wrapped-volume-race-5f9d6e69-ed72-4f5b-9223-171fefea89a1: Found 0 pods out of 5
Dec 17 13:37:41.622: INFO: Pod name wrapped-volume-race-5f9d6e69-ed72-4f5b-9223-171fefea89a1: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5f9d6e69-ed72-4f5b-9223-171fefea89a1 in namespace emptydir-wrapper-6828, will wait for the garbage collector to delete the pods
Dec 17 13:37:51.757: INFO: Deleting ReplicationController wrapped-volume-race-5f9d6e69-ed72-4f5b-9223-171fefea89a1 took: 18.342229ms
Dec 17 13:37:52.057: INFO: Terminating ReplicationController wrapped-volume-race-5f9d6e69-ed72-4f5b-9223-171fefea89a1 pods took: 300.158453ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 13:38:31.496: INFO: Pod name wrapped-volume-race-1164ffe9-f5b4-486f-8c20-843c955f7722: Found 0 pods out of 5
Dec 17 13:38:36.525: INFO: Pod name wrapped-volume-race-1164ffe9-f5b4-486f-8c20-843c955f7722: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-1164ffe9-f5b4-486f-8c20-843c955f7722 in namespace emptydir-wrapper-6828, will wait for the garbage collector to delete the pods
Dec 17 13:38:46.666: INFO: Deleting ReplicationController wrapped-volume-race-1164ffe9-f5b4-486f-8c20-843c955f7722 took: 34.837014ms
Dec 17 13:38:46.966: INFO: Terminating ReplicationController wrapped-volume-race-1164ffe9-f5b4-486f-8c20-843c955f7722 pods took: 300.208419ms
STEP: Creating RC which spawns configmap-volume pods
Dec 17 13:39:23.505: INFO: Pod name wrapped-volume-race-24619afd-d296-4981-bd02-4717a314a675: Found 0 pods out of 5
Dec 17 13:39:28.512: INFO: Pod name wrapped-volume-race-24619afd-d296-4981-bd02-4717a314a675: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-24619afd-d296-4981-bd02-4717a314a675 in namespace emptydir-wrapper-6828, will wait for the garbage collector to delete the pods
Dec 17 13:39:40.636: INFO: Deleting ReplicationController wrapped-volume-race-24619afd-d296-4981-bd02-4717a314a675 took: 17.93459ms
Dec 17 13:39:40.936: INFO: Terminating ReplicationController wrapped-volume-race-24619afd-d296-4981-bd02-4717a314a675 pods took: 300.34016ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:40:22.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6828" for this suite.
Dec 17 13:40:32.155: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:40:32.361: INFO: namespace emptydir-wrapper-6828 deletion completed in 10.233747102s

• [SLOW TEST:176.268 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:40:32.361: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:40:32.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3830" for this suite.
Dec 17 13:40:38.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:40:38.649: INFO: namespace services-3830 deletion completed in 6.216023257s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.288 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:40:38.649: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:40:39.253: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 13:40:41.272: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712186839, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712186839, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712186839, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712186839, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:40:44.301: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:40:56.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7637" for this suite.
Dec 17 13:41:02.614: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:41:02.832: INFO: namespace webhook-7637 deletion completed in 6.245746243s
STEP: Destroying namespace "webhook-7637-markers" for this suite.
Dec 17 13:41:08.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:41:09.058: INFO: namespace webhook-7637-markers deletion completed in 6.225900068s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.443 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:41:09.092: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:41:09.450: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:41:12.492: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:41:22.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8524" for this suite.
Dec 17 13:41:28.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:41:28.897: INFO: namespace webhook-8524 deletion completed in 6.229563472s
STEP: Destroying namespace "webhook-8524-markers" for this suite.
Dec 17 13:41:34.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:41:35.120: INFO: namespace webhook-8524-markers deletion completed in 6.222746596s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.065 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:41:35.158: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-bfb42b45-eb89-40b6-8c80-44c83a27147b
STEP: Creating configMap with name cm-test-opt-upd-051a794f-5523-4104-ad58-a1c85e6d698c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-bfb42b45-eb89-40b6-8c80-44c83a27147b
STEP: Updating configmap cm-test-opt-upd-051a794f-5523-4104-ad58-a1c85e6d698c
STEP: Creating configMap with name cm-test-opt-create-d0855ddd-f284-46bd-be3c-79ac13fdecf3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:41:41.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7187" for this suite.
Dec 17 13:41:53.509: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:41:53.703: INFO: namespace configmap-7187 deletion completed in 12.222461562s

• [SLOW TEST:18.546 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:41:53.703: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-4e4e4d2d-f443-4fa7-92bb-337ccfe8838a
STEP: Creating a pod to test consume configMaps
Dec 17 13:41:53.776: INFO: Waiting up to 5m0s for pod "pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d" in namespace "configmap-9872" to be "success or failure"
Dec 17 13:41:53.786: INFO: Pod "pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.833904ms
Dec 17 13:41:55.791: INFO: Pod "pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015187421s
STEP: Saw pod success
Dec 17 13:41:55.791: INFO: Pod "pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d" satisfied condition "success or failure"
Dec 17 13:41:55.799: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 13:41:55.845: INFO: Waiting for pod pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d to disappear
Dec 17 13:41:55.849: INFO: Pod pod-configmaps-a164c9b2-8769-4e6c-8160-6191f2a2de3d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:41:55.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9872" for this suite.
Dec 17 13:42:01.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:02.105: INFO: namespace configmap-9872 deletion completed in 6.239557844s

• [SLOW TEST:8.402 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:42:02.105: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-615b8430-09a4-451c-84fb-e4810ebc4d7f
STEP: Creating a pod to test consume secrets
Dec 17 13:42:02.183: INFO: Waiting up to 5m0s for pod "pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b" in namespace "secrets-6430" to be "success or failure"
Dec 17 13:42:02.191: INFO: Pod "pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.93281ms
Dec 17 13:42:04.200: INFO: Pod "pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017057169s
STEP: Saw pod success
Dec 17 13:42:04.200: INFO: Pod "pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b" satisfied condition "success or failure"
Dec 17 13:42:04.208: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:42:04.284: INFO: Waiting for pod pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b to disappear
Dec 17 13:42:04.289: INFO: Pod pod-secrets-6ae71182-786d-4fdc-8d4f-3e5fcb6ec55b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:42:04.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6430" for this suite.
Dec 17 13:42:10.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:10.566: INFO: namespace secrets-6430 deletion completed in 6.270753687s

• [SLOW TEST:8.462 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:42:10.567: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 17 13:42:10.655: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255669 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 13:42:10.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255670 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 13:42:10.655: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255671 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 17 13:42:20.719: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255695 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 13:42:20.719: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255696 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 17 13:42:20.719: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8106 /api/v1/namespaces/watch-8106/configmaps/e2e-watch-test-label-changed 5da401c0-6df3-45de-8106-a5e8d45b2120 255697 0 2019-12-17 13:42:10 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:42:20.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8106" for this suite.
Dec 17 13:42:26.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:26.971: INFO: namespace watch-8106 deletion completed in 6.235662393s

• [SLOW TEST:16.404 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:42:26.971: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-dd80d134-6eac-4117-888a-31e895ab1608
STEP: Creating a pod to test consume secrets
Dec 17 13:42:27.039: INFO: Waiting up to 5m0s for pod "pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb" in namespace "secrets-2465" to be "success or failure"
Dec 17 13:42:27.047: INFO: Pod "pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.232727ms
Dec 17 13:42:29.081: INFO: Pod "pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.041787753s
STEP: Saw pod success
Dec 17 13:42:29.081: INFO: Pod "pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb" satisfied condition "success or failure"
Dec 17 13:42:29.086: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb container secret-env-test: <nil>
STEP: delete the pod
Dec 17 13:42:29.124: INFO: Waiting for pod pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb to disappear
Dec 17 13:42:29.132: INFO: Pod pod-secrets-005d6ffe-c947-4959-9d1d-0486627ec9eb no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:42:29.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2465" for this suite.
Dec 17 13:42:35.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:35.371: INFO: namespace secrets-2465 deletion completed in 6.225708275s

• [SLOW TEST:8.400 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:42:35.371: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-c56ac647-4713-4a1b-bb19-af38df23208e
STEP: Creating a pod to test consume secrets
Dec 17 13:42:35.507: INFO: Waiting up to 5m0s for pod "pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708" in namespace "secrets-1321" to be "success or failure"
Dec 17 13:42:35.517: INFO: Pod "pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708": Phase="Pending", Reason="", readiness=false. Elapsed: 9.692089ms
Dec 17 13:42:37.526: INFO: Pod "pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019264871s
STEP: Saw pod success
Dec 17 13:42:37.526: INFO: Pod "pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708" satisfied condition "success or failure"
Dec 17 13:42:37.532: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 13:42:37.574: INFO: Waiting for pod pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708 to disappear
Dec 17 13:42:37.582: INFO: Pod pod-secrets-11f386f7-a904-4b07-9258-6729da6d6708 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:42:37.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1321" for this suite.
Dec 17 13:42:43.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:43.818: INFO: namespace secrets-1321 deletion completed in 6.228580295s
STEP: Destroying namespace "secret-namespace-4636" for this suite.
Dec 17 13:42:49.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:42:50.056: INFO: namespace secret-namespace-4636 deletion completed in 6.237691136s

• [SLOW TEST:14.685 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:42:50.056: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:42:50.610: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:42:53.653: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:42:53.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5749" for this suite.
Dec 17 13:42:59.826: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:00.040: INFO: namespace webhook-5749 deletion completed in 6.242088254s
STEP: Destroying namespace "webhook-5749-markers" for this suite.
Dec 17 13:43:06.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:06.295: INFO: namespace webhook-5749-markers deletion completed in 6.255497068s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.284 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:06.341: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:43:06.421: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-8c6a322f-7f09-4640-98a2-da5638da1459" in namespace "security-context-test-8958" to be "success or failure"
Dec 17 13:43:06.425: INFO: Pod "busybox-privileged-false-8c6a322f-7f09-4640-98a2-da5638da1459": Phase="Pending", Reason="", readiness=false. Elapsed: 4.551954ms
Dec 17 13:43:08.431: INFO: Pod "busybox-privileged-false-8c6a322f-7f09-4640-98a2-da5638da1459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010090182s
Dec 17 13:43:08.431: INFO: Pod "busybox-privileged-false-8c6a322f-7f09-4640-98a2-da5638da1459" satisfied condition "success or failure"
Dec 17 13:43:08.445: INFO: Got logs for pod "busybox-privileged-false-8c6a322f-7f09-4640-98a2-da5638da1459": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:43:08.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8958" for this suite.
Dec 17 13:43:14.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:14.693: INFO: namespace security-context-test-8958 deletion completed in 6.233448683s

• [SLOW TEST:8.352 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:14.693: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:43:14.762: INFO: Waiting up to 5m0s for pod "downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389" in namespace "downward-api-9056" to be "success or failure"
Dec 17 13:43:14.771: INFO: Pod "downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389": Phase="Pending", Reason="", readiness=false. Elapsed: 8.547114ms
Dec 17 13:43:16.780: INFO: Pod "downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017762288s
STEP: Saw pod success
Dec 17 13:43:16.780: INFO: Pod "downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389" satisfied condition "success or failure"
Dec 17 13:43:16.788: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389 container client-container: <nil>
STEP: delete the pod
Dec 17 13:43:16.826: INFO: Waiting for pod downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389 to disappear
Dec 17 13:43:16.835: INFO: Pod downwardapi-volume-82cc25a4-3726-4394-bf6f-35039905b389 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:43:16.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9056" for this suite.
Dec 17 13:43:22.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:23.069: INFO: namespace downward-api-9056 deletion completed in 6.22109505s

• [SLOW TEST:8.377 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:23.070: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:43:23.129: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200" in namespace "projected-453" to be "success or failure"
Dec 17 13:43:23.139: INFO: Pod "downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200": Phase="Pending", Reason="", readiness=false. Elapsed: 9.593569ms
Dec 17 13:43:25.148: INFO: Pod "downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018466354s
STEP: Saw pod success
Dec 17 13:43:25.148: INFO: Pod "downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200" satisfied condition "success or failure"
Dec 17 13:43:25.152: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200 container client-container: <nil>
STEP: delete the pod
Dec 17 13:43:25.250: INFO: Waiting for pod downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200 to disappear
Dec 17 13:43:25.258: INFO: Pod downwardapi-volume-6b6f9936-1a34-4c31-9f58-8bb8e646a200 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:43:25.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-453" for this suite.
Dec 17 13:43:31.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:31.513: INFO: namespace projected-453 deletion completed in 6.238362112s

• [SLOW TEST:8.443 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:31.513: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5040.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5040.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 13:43:33.683: INFO: DNS probes using dns-5040/dns-test-6f948d95-71bb-424b-940a-3ecfbf4fcbfc succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:43:33.709: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5040" for this suite.
Dec 17 13:43:39.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:39.954: INFO: namespace dns-5040 deletion completed in 6.231475202s

• [SLOW TEST:8.441 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:39.954: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:43:40.021: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e" in namespace "projected-7432" to be "success or failure"
Dec 17 13:43:40.029: INFO: Pod "downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.241397ms
Dec 17 13:43:42.038: INFO: Pod "downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016824169s
STEP: Saw pod success
Dec 17 13:43:42.038: INFO: Pod "downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e" satisfied condition "success or failure"
Dec 17 13:43:42.046: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e container client-container: <nil>
STEP: delete the pod
Dec 17 13:43:42.091: INFO: Waiting for pod downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e to disappear
Dec 17 13:43:42.095: INFO: Pod downwardapi-volume-3d4e1c76-ec0c-4c65-80fb-bd510eef0d9e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:43:42.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7432" for this suite.
Dec 17 13:43:48.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:43:48.340: INFO: namespace projected-7432 deletion completed in 6.228612625s

• [SLOW TEST:8.386 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:43:48.340: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2290
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2290
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2290
Dec 17 13:43:48.413: INFO: Found 0 stateful pods, waiting for 1
Dec 17 13:43:58.418: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 17 13:43:58.427: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:43:58.709: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:43:58.709: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:43:58.709: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:43:58.717: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 17 13:44:08.723: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:44:08.723: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:44:08.754: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:08.754: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:08.754: INFO: ss-1                              Pending         []
Dec 17 13:44:08.754: INFO: 
Dec 17 13:44:08.754: INFO: StatefulSet ss has not reached scale 3, at 2
Dec 17 13:44:09.759: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.990629903s
Dec 17 13:44:10.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985620665s
Dec 17 13:44:11.770: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.980184471s
Dec 17 13:44:12.779: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.974624988s
Dec 17 13:44:13.785: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.965234434s
Dec 17 13:44:14.794: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.959648469s
Dec 17 13:44:15.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.949883764s
Dec 17 13:44:16.809: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.944204995s
Dec 17 13:44:17.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 935.000015ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2290
Dec 17 13:44:18.824: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:44:18.977: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 17 13:44:18.977: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:44:18.977: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:44:18.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:44:19.151: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 17 13:44:19.151: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:44:19.151: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:44:19.151: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:44:19.294: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 17 13:44:19.294: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 17 13:44:19.294: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 17 13:44:19.299: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 13:44:19.299: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 17 13:44:19.299: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 17 13:44:19.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:44:19.473: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:44:19.473: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:44:19.473: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:44:19.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:44:19.628: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:44:19.628: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:44:19.628: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:44:19.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 17 13:44:19.769: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 17 13:44:19.769: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 17 13:44:19.769: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 17 13:44:19.769: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:44:19.773: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 17 13:44:29.790: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:44:29.790: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:44:29.790: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 17 13:44:29.832: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:29.832: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:29.832: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:29.832: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:29.832: INFO: 
Dec 17 13:44:29.832: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:30.841: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:30.841: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:30.841: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:30.841: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:30.841: INFO: 
Dec 17 13:44:30.841: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:31.850: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:31.850: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:31.850: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:31.850: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:31.850: INFO: 
Dec 17 13:44:31.850: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:32.856: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:32.856: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:32.856: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:32.856: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:32.856: INFO: 
Dec 17 13:44:32.856: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:33.866: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:33.866: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:33.866: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:33.866: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:33.866: INFO: 
Dec 17 13:44:33.866: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:34.871: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:34.871: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:34.871: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:34.871: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:34.872: INFO: 
Dec 17 13:44:34.872: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:35.878: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:35.878: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:35.878: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:35.878: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:35.878: INFO: 
Dec 17 13:44:35.878: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:36.894: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:36.894: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:36.894: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:36.894: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:36.894: INFO: 
Dec 17 13:44:36.894: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:37.903: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:37.903: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:37.903: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:37.903: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:37.903: INFO: 
Dec 17 13:44:37.903: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 17 13:44:38.912: INFO: POD   NODE                        PHASE    GRACE  CONDITIONS
Dec 17 13:44:38.912: INFO: ss-0  k8s-node-vm923c-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:43:48 +0000 UTC  }]
Dec 17 13:44:38.912: INFO: ss-1  k8s-node-vm2x4q-7kwnapovj8  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:38.912: INFO: ss-2  k8s-node-vm4x4d-7kwnapovj8  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:20 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-17 13:44:08 +0000 UTC  }]
Dec 17 13:44:38.912: INFO: 
Dec 17 13:44:38.912: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2290
Dec 17 13:44:39.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:44:40.029: INFO: rc: 1
Dec 17 13:44:40.029: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc002f05200 exit status 1 <nil> <nil> true [0xc004c66130 0xc004c66148 0xc004c66168] [0xc004c66130 0xc004c66148 0xc004c66168] [0xc004c66140 0xc004c66158] [0x10efe30 0x10efe30] 0xc003a79e60 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec 17 13:44:50.030: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:44:50.105: INFO: rc: 1
Dec 17 13:44:50.105: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002f05590 exit status 1 <nil> <nil> true [0xc004c66178 0xc004c66190 0xc004c661a8] [0xc004c66178 0xc004c66190 0xc004c661a8] [0xc004c66188 0xc004c661a0] [0x10efe30 0x10efe30] 0xc0032aa1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:00.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:00.172: INFO: rc: 1
Dec 17 13:45:00.172: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86360 exit status 1 <nil> <nil> true [0xc0055da000 0xc0055da018 0xc0055da030] [0xc0055da000 0xc0055da018 0xc0055da030] [0xc0055da010 0xc0055da028] [0x10efe30 0x10efe30] 0xc003a782a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:10.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:10.254: INFO: rc: 1
Dec 17 13:45:10.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a866c0 exit status 1 <nil> <nil> true [0xc0055da038 0xc0055da050 0xc0055da068] [0xc0055da038 0xc0055da050 0xc0055da068] [0xc0055da048 0xc0055da060] [0x10efe30 0x10efe30] 0xc003a78660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:20.255: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:20.324: INFO: rc: 1
Dec 17 13:45:20.324: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf2360 exit status 1 <nil> <nil> true [0xc00190e020 0xc00190e148 0xc00190e330] [0xc00190e020 0xc00190e148 0xc00190e330] [0xc00190e128 0xc00190e2d0] [0x10efe30 0x10efe30] 0xc003402420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:30.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:30.423: INFO: rc: 1
Dec 17 13:45:30.423: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf26f0 exit status 1 <nil> <nil> true [0xc00190e3b0 0xc00190e570 0xc00190e6f8] [0xc00190e3b0 0xc00190e570 0xc00190e6f8] [0xc00190e558 0xc00190e5b8] [0x10efe30 0x10efe30] 0xc003402960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:40.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:40.493: INFO: rc: 1
Dec 17 13:45:40.493: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf2a50 exit status 1 <nil> <nil> true [0xc00190e730 0xc00190e888 0xc00190e958] [0xc00190e730 0xc00190e888 0xc00190e958] [0xc00190e850 0xc00190e8d0] [0x10efe30 0x10efe30] 0xc003402e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:45:50.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:45:50.566: INFO: rc: 1
Dec 17 13:45:50.566: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0510 exit status 1 <nil> <nil> true [0xc00249a030 0xc00249a048 0xc00249a060] [0xc00249a030 0xc00249a048 0xc00249a060] [0xc00249a040 0xc00249a058] [0x10efe30 0x10efe30] 0xc001214cc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:00.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:00.636: INFO: rc: 1
Dec 17 13:46:00.636: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf2db0 exit status 1 <nil> <nil> true [0xc00190e9e8 0xc00190eb38 0xc00190ecb0] [0xc00190e9e8 0xc00190eb38 0xc00190ecb0] [0xc00190eae0 0xc00190ec68] [0x10efe30 0x10efe30] 0xc003403320 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:10.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:10.714: INFO: rc: 1
Dec 17 13:46:10.714: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf3110 exit status 1 <nil> <nil> true [0xc00190ecc8 0xc00190ee88 0xc00190efa8] [0xc00190ecc8 0xc00190ee88 0xc00190efa8] [0xc00190ee38 0xc00190ef28] [0x10efe30 0x10efe30] 0xc0034037a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:20.714: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:20.784: INFO: rc: 1
Dec 17 13:46:20.784: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86b10 exit status 1 <nil> <nil> true [0xc0055da070 0xc0055da088 0xc0055da0a0] [0xc0055da070 0xc0055da088 0xc0055da0a0] [0xc0055da080 0xc0055da098] [0x10efe30 0x10efe30] 0xc003a789c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:30.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:30.851: INFO: rc: 1
Dec 17 13:46:30.851: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86e70 exit status 1 <nil> <nil> true [0xc0055da0a8 0xc0055da0c0 0xc0055da0d8] [0xc0055da0a8 0xc0055da0c0 0xc0055da0d8] [0xc0055da0b8 0xc0055da0d0] [0x10efe30 0x10efe30] 0xc003a78d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:40.851: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:40.924: INFO: rc: 1
Dec 17 13:46:40.924: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0930 exit status 1 <nil> <nil> true [0xc00249a068 0xc00249a080 0xc00249a098] [0xc00249a068 0xc00249a080 0xc00249a098] [0xc00249a078 0xc00249a090] [0x10efe30 0x10efe30] 0xc001215140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:46:50.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:46:50.988: INFO: rc: 1
Dec 17 13:46:50.988: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc006cf2330 exit status 1 <nil> <nil> true [0xc00190e060 0xc00190e240 0xc00190e3b0] [0xc00190e060 0xc00190e240 0xc00190e3b0] [0xc00190e148 0xc00190e330] [0x10efe30 0x10efe30] 0xc003402420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:00.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:01.061: INFO: rc: 1
Dec 17 13:47:01.061: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86330 exit status 1 <nil> <nil> true [0xc00249a000 0xc00249a018 0xc00249a030] [0xc00249a000 0xc00249a018 0xc00249a030] [0xc00249a010 0xc00249a028] [0x10efe30 0x10efe30] 0xc001214ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:11.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:11.126: INFO: rc: 1
Dec 17 13:47:11.126: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d36330 exit status 1 <nil> <nil> true [0xc0055da000 0xc0055da018 0xc0055da030] [0xc0055da000 0xc0055da018 0xc0055da030] [0xc0055da010 0xc0055da028] [0x10efe30 0x10efe30] 0xc003a782a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:21.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:21.194: INFO: rc: 1
Dec 17 13:47:21.194: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d366c0 exit status 1 <nil> <nil> true [0xc0055da038 0xc0055da050 0xc0055da068] [0xc0055da038 0xc0055da050 0xc0055da068] [0xc0055da048 0xc0055da060] [0x10efe30 0x10efe30] 0xc003a78660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:31.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:31.260: INFO: rc: 1
Dec 17 13:47:31.260: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0450 exit status 1 <nil> <nil> true [0xc000166000 0xc0000104b8 0xc000010e70] [0xc000166000 0xc0000104b8 0xc000010e70] [0xc000167fc0 0xc000010e48] [0x10efe30 0x10efe30] 0xc0033f02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:41.260: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:41.331: INFO: rc: 1
Dec 17 13:47:41.331: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d36a50 exit status 1 <nil> <nil> true [0xc0055da070 0xc0055da088 0xc0055da0a0] [0xc0055da070 0xc0055da088 0xc0055da0a0] [0xc0055da080 0xc0055da098] [0x10efe30 0x10efe30] 0xc003a789c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:47:51.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:47:51.401: INFO: rc: 1
Dec 17 13:47:51.401: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d36de0 exit status 1 <nil> <nil> true [0xc0055da0a8 0xc0055da0c0 0xc0055da0d8] [0xc0055da0a8 0xc0055da0c0 0xc0055da0d8] [0xc0055da0b8 0xc0055da0d0] [0x10efe30 0x10efe30] 0xc003a78d20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:01.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:01.470: INFO: rc: 1
Dec 17 13:48:01.470: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d37140 exit status 1 <nil> <nil> true [0xc0055da0e0 0xc0055da0f8 0xc0055da110] [0xc0055da0e0 0xc0055da0f8 0xc0055da110] [0xc0055da0f0 0xc0055da108] [0x10efe30 0x10efe30] 0xc003a79080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:11.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:11.539: INFO: rc: 1
Dec 17 13:48:11.539: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86780 exit status 1 <nil> <nil> true [0xc00249a038 0xc00249a050 0xc00249a068] [0xc00249a038 0xc00249a050 0xc00249a068] [0xc00249a048 0xc00249a060] [0x10efe30 0x10efe30] 0xc001214fc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:21.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:21.607: INFO: rc: 1
Dec 17 13:48:21.607: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0810 exit status 1 <nil> <nil> true [0xc000010f68 0xc000011638 0xc000011800] [0xc000010f68 0xc000011638 0xc000011800] [0xc0000114c0 0xc0000117f0] [0x10efe30 0x10efe30] 0xc0033f0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:31.608: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:31.676: INFO: rc: 1
Dec 17 13:48:31.676: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d37500 exit status 1 <nil> <nil> true [0xc0055da118 0xc0055da130 0xc0055da148] [0xc0055da118 0xc0055da130 0xc0055da148] [0xc0055da128 0xc0055da140] [0x10efe30 0x10efe30] 0xc003a793e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:41.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:41.739: INFO: rc: 1
Dec 17 13:48:41.739: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86b40 exit status 1 <nil> <nil> true [0xc00249a070 0xc00249a088 0xc00249a0a0] [0xc00249a070 0xc00249a088 0xc00249a0a0] [0xc00249a080 0xc00249a098] [0x10efe30 0x10efe30] 0xc0012154a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:48:51.739: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:48:51.809: INFO: rc: 1
Dec 17 13:48:51.809: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d36360 exit status 1 <nil> <nil> true [0xc000167e48 0xc0055da008 0xc0055da020] [0xc000167e48 0xc0055da008 0xc0055da020] [0xc0055da000 0xc0055da018] [0x10efe30 0x10efe30] 0xc003a782a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:49:01.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:49:01.877: INFO: rc: 1
Dec 17 13:49:01.877: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003a86390 exit status 1 <nil> <nil> true [0xc00249a000 0xc00249a018 0xc00249a030] [0xc00249a000 0xc00249a018 0xc00249a030] [0xc00249a010 0xc00249a028] [0x10efe30 0x10efe30] 0xc001214ae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:49:11.877: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:49:11.944: INFO: rc: 1
Dec 17 13:49:11.944: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0480 exit status 1 <nil> <nil> true [0xc0000104b8 0xc000010e70 0xc0000114c0] [0xc0000104b8 0xc000010e70 0xc0000114c0] [0xc000010e48 0xc0000112f0] [0x10efe30 0x10efe30] 0xc0033f02a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:49:21.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:49:22.014: INFO: rc: 1
Dec 17 13:49:22.014: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc003d36720 exit status 1 <nil> <nil> true [0xc0055da028 0xc0055da040 0xc0055da058] [0xc0055da028 0xc0055da040 0xc0055da058] [0xc0055da038 0xc0055da050] [0x10efe30 0x10efe30] 0xc003a78660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:49:32.015: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:49:32.084: INFO: rc: 1
Dec 17 13:49:32.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0046e0840 exit status 1 <nil> <nil> true [0xc000011638 0xc000011800 0xc000011ab8] [0xc000011638 0xc000011800 0xc000011ab8] [0xc0000117f0 0xc000011a20] [0x10efe30 0x10efe30] 0xc0033f0600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 17 13:49:42.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=statefulset-2290 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 17 13:49:42.151: INFO: rc: 1
Dec 17 13:49:42.151: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Dec 17 13:49:42.151: INFO: Scaling statefulset ss to 0
Dec 17 13:49:42.168: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 13:49:42.176: INFO: Deleting all statefulset in ns statefulset-2290
Dec 17 13:49:42.184: INFO: Scaling statefulset ss to 0
Dec 17 13:49:42.204: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 13:49:42.212: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:49:42.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2290" for this suite.
Dec 17 13:49:48.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:49:48.501: INFO: namespace statefulset-2290 deletion completed in 6.234292457s

• [SLOW TEST:360.161 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:49:48.501: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 13:49:48.551: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 13:49:48.585: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 13:49:48.590: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm2x4q-7kwnapovj8 before test
Dec 17 13:49:48.616: INFO: jdcloud-k8s-ipamd-g4vm6 from kube-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:49:48.616: INFO: kube-state-metrics-f58cb6d75-fhf77 from jke-system started at 2019-12-17 10:07:27 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 17 13:49:48.616: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 17 13:49:48.616: INFO: coredns-8565b9f7f-w876f from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container coredns ready: true, restart count 0
Dec 17 13:49:48.616: INFO: prometheus-5ff89497-v69gb from jke-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container prometheus ready: true, restart count 0
Dec 17 13:49:48.616: INFO: kube-proxy-2zp6v from kube-system started at 2019-12-17 09:43:31 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:49:48.616: INFO: node-exporter-gv5p5 from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 13:49:48.616: INFO: fluent-bit-8f5mr from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container fluent-bit ready: true, restart count 2
Dec 17 13:49:48.616: INFO: csi-jdcloudplugin-v42hq from jke-system started at 2019-12-17 09:43:39 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:49:48.616: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:49:48.616: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 from sonobuoy started at 2019-12-17 12:47:40 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.616: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:49:48.616: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:49:48.616: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm4x4d-7kwnapovj8 before test
Dec 17 13:49:48.636: INFO: prometheus-jdmon-756f6977d7-g2jqg from jke-system started at 2019-12-16 14:30:05 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Dec 17 13:49:48.636: INFO: fluent-bit-5w4zl from jke-system started at 2019-12-16 10:57:14 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 13:49:48.636: INFO: kube-proxy-4bjhm from kube-system started at 2019-12-16 11:03:02 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:49:48.636: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf from sonobuoy started at 2019-12-17 12:47:31 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:49:48.636: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:49:48.636: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-12-17 07:43:48 +0000 UTC (4 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 17 13:49:48.636: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 17 13:49:48.636: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:49:48.636: INFO: 	Container liveness-probe ready: true, restart count 0
Dec 17 13:49:48.636: INFO: node-exporter-bxz78 from jke-system started at 2019-12-16 11:12:13 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 13:49:48.636: INFO: csi-jdcloudplugin-cgvgf from jke-system started at 2019-12-17 07:43:48 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:49:48.636: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:49:48.636: INFO: kubernetes-dashboard-6c9b78cc5c-kh2f5 from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 13:49:48.636: INFO: jdcloud-k8s-ipamd-n8jwz from kube-system started at 2019-12-16 10:13:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:49:48.636: INFO: coredns-8565b9f7f-sll5x from kube-system started at 2019-12-17 08:47:51 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.636: INFO: 	Container coredns ready: true, restart count 0
Dec 17 13:49:48.636: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm923c-7kwnapovj8 before test
Dec 17 13:49:48.656: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv from sonobuoy started at 2019-12-17 12:47:35 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:49:48.656: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:49:48.656: INFO: kube-proxy-glbxd from kube-system started at 2019-12-17 13:25:02 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:49:48.656: INFO: jdcloud-k8s-ipamd-tbkt8 from kube-system started at 2019-12-17 13:25:40 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:49:48.656: INFO: fluent-bit-zwfxl from jke-system started at 2019-12-17 13:25:08 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 17 13:49:48.656: INFO: sonobuoy-e2e-job-f5193f6f15e64a7e from sonobuoy started at 2019-12-17 12:48:59 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container e2e ready: true, restart count 0
Dec 17 13:49:48.656: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 13:49:48.656: INFO: sonobuoy from sonobuoy started at 2019-12-17 12:46:46 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 13:49:48.656: INFO: csi-jdcloudplugin-cmtmd from jke-system started at 2019-12-17 13:25:01 +0000 UTC (2 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:49:48.656: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:49:48.656: INFO: node-exporter-jl6n7 from jke-system started at 2019-12-17 13:25:03 +0000 UTC (1 container statuses recorded)
Dec 17 13:49:48.656: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e12cc98963168a], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e12cc98a302955], Reason = [FailedScheduling], Message = [0/3 nodes are available: 3 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:49:49.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3298" for this suite.
Dec 17 13:49:55.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:49:55.948: INFO: namespace sched-pred-3298 deletion completed in 6.224807091s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.447 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:49:55.948: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:49:58.065: INFO: Waiting up to 5m0s for pod "client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc" in namespace "pods-1848" to be "success or failure"
Dec 17 13:49:58.074: INFO: Pod "client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc": Phase="Pending", Reason="", readiness=false. Elapsed: 8.71181ms
Dec 17 13:50:00.083: INFO: Pod "client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018099533s
STEP: Saw pod success
Dec 17 13:50:00.083: INFO: Pod "client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc" satisfied condition "success or failure"
Dec 17 13:50:00.088: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc container env3cont: <nil>
STEP: delete the pod
Dec 17 13:50:00.133: INFO: Waiting for pod client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc to disappear
Dec 17 13:50:00.137: INFO: Pod client-envvars-5466faf8-7492-41b3-8273-d3ad3b8053bc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:50:00.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1848" for this suite.
Dec 17 13:50:12.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:50:12.362: INFO: namespace pods-1848 deletion completed in 12.217394532s

• [SLOW TEST:16.414 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:50:12.362: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1143.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1143.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1143.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1143.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1143.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1143.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 13:50:14.525: INFO: DNS probes using dns-1143/dns-test-71616465-03ae-4637-83c5-f6301e7ec6f0 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:50:14.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1143" for this suite.
Dec 17 13:50:20.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:50:20.799: INFO: namespace dns-1143 deletion completed in 6.232619111s

• [SLOW TEST:8.437 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:50:20.800: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 13:50:20.873: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 13:50:20.909: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 13:50:20.919: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm2x4q-7kwnapovj8 before test
Dec 17 13:50:20.935: INFO: coredns-8565b9f7f-w876f from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container coredns ready: true, restart count 0
Dec 17 13:50:20.935: INFO: prometheus-5ff89497-v69gb from jke-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container prometheus ready: true, restart count 0
Dec 17 13:50:20.935: INFO: kube-state-metrics-f58cb6d75-fhf77 from jke-system started at 2019-12-17 10:07:27 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 17 13:50:20.935: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 17 13:50:20.935: INFO: csi-jdcloudplugin-v42hq from jke-system started at 2019-12-17 09:43:39 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:50:20.935: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:50:20.935: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 from sonobuoy started at 2019-12-17 12:47:40 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:50:20.935: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:50:20.935: INFO: kube-proxy-2zp6v from kube-system started at 2019-12-17 09:43:31 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:50:20.935: INFO: node-exporter-gv5p5 from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 13:50:20.935: INFO: fluent-bit-8f5mr from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container fluent-bit ready: true, restart count 2
Dec 17 13:50:20.935: INFO: jdcloud-k8s-ipamd-g4vm6 from kube-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.935: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:50:20.935: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm4x4d-7kwnapovj8 before test
Dec 17 13:50:20.949: INFO: csi-jdcloudplugin-cgvgf from jke-system started at 2019-12-17 07:43:48 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.949: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:50:20.949: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:50:20.949: INFO: jdcloud-k8s-ipamd-n8jwz from kube-system started at 2019-12-16 10:13:39 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.949: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:50:20.949: INFO: coredns-8565b9f7f-sll5x from kube-system started at 2019-12-17 08:47:51 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.949: INFO: 	Container coredns ready: true, restart count 0
Dec 17 13:50:20.949: INFO: kubernetes-dashboard-6c9b78cc5c-kh2f5 from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.949: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 13:50:20.949: INFO: fluent-bit-5w4zl from jke-system started at 2019-12-16 10:57:14 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 13:50:20.950: INFO: kube-proxy-4bjhm from kube-system started at 2019-12-16 11:03:02 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:50:20.950: INFO: prometheus-jdmon-756f6977d7-g2jqg from jke-system started at 2019-12-16 14:30:05 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Dec 17 13:50:20.950: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-12-17 07:43:48 +0000 UTC (4 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 17 13:50:20.950: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 17 13:50:20.950: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:50:20.950: INFO: 	Container liveness-probe ready: true, restart count 0
Dec 17 13:50:20.950: INFO: node-exporter-bxz78 from jke-system started at 2019-12-16 11:12:13 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 13:50:20.950: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf from sonobuoy started at 2019-12-17 12:47:31 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.950: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:50:20.950: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:50:20.950: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm923c-7kwnapovj8 before test
Dec 17 13:50:20.960: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv from sonobuoy started at 2019-12-17 12:47:35 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 13:50:20.960: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 13:50:20.960: INFO: kube-proxy-glbxd from kube-system started at 2019-12-17 13:25:02 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 13:50:20.960: INFO: jdcloud-k8s-ipamd-tbkt8 from kube-system started at 2019-12-17 13:25:40 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 13:50:20.960: INFO: fluent-bit-zwfxl from jke-system started at 2019-12-17 13:25:08 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 17 13:50:20.960: INFO: sonobuoy-e2e-job-f5193f6f15e64a7e from sonobuoy started at 2019-12-17 12:48:59 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container e2e ready: true, restart count 0
Dec 17 13:50:20.960: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 13:50:20.960: INFO: sonobuoy from sonobuoy started at 2019-12-17 12:46:46 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 13:50:20.960: INFO: csi-jdcloudplugin-cmtmd from jke-system started at 2019-12-17 13:25:01 +0000 UTC (2 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 13:50:20.960: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 13:50:20.960: INFO: node-exporter-jl6n7 from jke-system started at 2019-12-17 13:25:03 +0000 UTC (1 container statuses recorded)
Dec 17 13:50:20.960: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-acd42bdc-c299-4d68-89d4-33eb2c7a19a4 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-acd42bdc-c299-4d68-89d4-33eb2c7a19a4 off the node k8s-node-vm2x4q-7kwnapovj8
STEP: verifying the node doesn't have the label kubernetes.io/e2e-acd42bdc-c299-4d68-89d4-33eb2c7a19a4
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:55:25.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9173" for this suite.
Dec 17 13:55:45.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:55:45.381: INFO: namespace sched-pred-9173 deletion completed in 20.242269361s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:324.581 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:55:45.381: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:55:45.447: INFO: Creating ReplicaSet my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c
Dec 17 13:55:45.467: INFO: Pod name my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c: Found 0 pods out of 1
Dec 17 13:55:50.477: INFO: Pod name my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c: Found 1 pods out of 1
Dec 17 13:55:50.477: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c" is running
Dec 17 13:55:50.481: INFO: Pod "my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c-cgdsv" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:55:45 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:55:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:55:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-17 13:55:45 +0000 UTC Reason: Message:}])
Dec 17 13:55:50.481: INFO: Trying to dial the pod
Dec 17 13:55:55.508: INFO: Controller my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c: Got expected result from replica 1 [my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c-cgdsv]: "my-hostname-basic-8a6aefc4-481a-42fa-9603-923dd020028c-cgdsv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:55:55.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-329" for this suite.
Dec 17 13:56:01.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:56:01.728: INFO: namespace replicaset-329 deletion completed in 6.212658969s

• [SLOW TEST:16.347 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:56:01.728: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:56:01.786: INFO: Waiting up to 5m0s for pod "busybox-user-65534-e274a2ab-425d-4f87-beb6-84bcddddd753" in namespace "security-context-test-9232" to be "success or failure"
Dec 17 13:56:01.794: INFO: Pod "busybox-user-65534-e274a2ab-425d-4f87-beb6-84bcddddd753": Phase="Pending", Reason="", readiness=false. Elapsed: 8.782997ms
Dec 17 13:56:03.803: INFO: Pod "busybox-user-65534-e274a2ab-425d-4f87-beb6-84bcddddd753": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017426767s
Dec 17 13:56:03.803: INFO: Pod "busybox-user-65534-e274a2ab-425d-4f87-beb6-84bcddddd753" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:56:03.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9232" for this suite.
Dec 17 13:56:09.840: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:56:10.026: INFO: namespace security-context-test-9232 deletion completed in 6.215109958s

• [SLOW TEST:8.297 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:56:10.026: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:56:10.470: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:56:13.509: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:56:13.518: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:56:14.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-164" for this suite.
Dec 17 13:56:20.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:56:20.907: INFO: namespace crd-webhook-164 deletion completed in 6.216331654s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.915 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:56:20.942: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 13:56:21.003: INFO: Waiting up to 5m0s for pod "pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01" in namespace "emptydir-5742" to be "success or failure"
Dec 17 13:56:21.012: INFO: Pod "pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01": Phase="Pending", Reason="", readiness=false. Elapsed: 8.386981ms
Dec 17 13:56:23.017: INFO: Pod "pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01343408s
STEP: Saw pod success
Dec 17 13:56:23.017: INFO: Pod "pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01" satisfied condition "success or failure"
Dec 17 13:56:23.025: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01 container test-container: <nil>
STEP: delete the pod
Dec 17 13:56:23.092: INFO: Waiting for pod pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01 to disappear
Dec 17 13:56:23.097: INFO: Pod pod-1d2bfe1f-a676-4aaa-8874-8ae485737c01 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:56:23.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5742" for this suite.
Dec 17 13:56:29.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:56:29.340: INFO: namespace emptydir-5742 deletion completed in 6.236376513s

• [SLOW TEST:8.399 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:56:29.341: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 13:56:39.542: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 13:56:39.542259      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:56:39.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-35" for this suite.
Dec 17 13:56:47.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:56:47.776: INFO: namespace gc-35 deletion completed in 8.218713234s

• [SLOW TEST:18.436 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:56:47.776: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:56:47.820: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 13:56:50.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-2963 create -f -'
Dec 17 13:56:50.891: INFO: stderr: ""
Dec 17 13:56:50.891: INFO: stdout: "e2e-test-crd-publish-openapi-8615-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 17 13:56:50.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-2963 delete e2e-test-crd-publish-openapi-8615-crds test-cr'
Dec 17 13:56:50.969: INFO: stderr: ""
Dec 17 13:56:50.969: INFO: stdout: "e2e-test-crd-publish-openapi-8615-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 17 13:56:50.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-2963 apply -f -'
Dec 17 13:56:51.129: INFO: stderr: ""
Dec 17 13:56:51.129: INFO: stdout: "e2e-test-crd-publish-openapi-8615-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 17 13:56:51.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-2963 delete e2e-test-crd-publish-openapi-8615-crds test-cr'
Dec 17 13:56:51.208: INFO: stderr: ""
Dec 17 13:56:51.208: INFO: stdout: "e2e-test-crd-publish-openapi-8615-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 17 13:56:51.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-8615-crds'
Dec 17 13:56:51.332: INFO: stderr: ""
Dec 17 13:56:51.332: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8615-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:56:54.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2963" for this suite.
Dec 17 13:57:00.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:57:00.273: INFO: namespace crd-publish-openapi-2963 deletion completed in 6.214622255s

• [SLOW TEST:12.497 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:57:00.273: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 17 13:57:00.592: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 13:57:03.634: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:57:03.639: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:57:04.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7082" for this suite.
Dec 17 13:57:10.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:57:11.113: INFO: namespace crd-webhook-7082 deletion completed in 6.220712188s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.882 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:57:11.156: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 17 13:57:11.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-9546'
Dec 17 13:57:11.382: INFO: stderr: ""
Dec 17 13:57:11.382: INFO: stdout: "pod/pause created\n"
Dec 17 13:57:11.382: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 17 13:57:11.382: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9546" to be "running and ready"
Dec 17 13:57:11.390: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 8.083403ms
Dec 17 13:57:13.399: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.017088377s
Dec 17 13:57:13.399: INFO: Pod "pause" satisfied condition "running and ready"
Dec 17 13:57:13.399: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 17 13:57:13.399: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 label pods pause testing-label=testing-label-value --namespace=kubectl-9546'
Dec 17 13:57:13.471: INFO: stderr: ""
Dec 17 13:57:13.471: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 17 13:57:13.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pod pause -L testing-label --namespace=kubectl-9546'
Dec 17 13:57:13.533: INFO: stderr: ""
Dec 17 13:57:13.533: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 17 13:57:13.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 label pods pause testing-label- --namespace=kubectl-9546'
Dec 17 13:57:13.604: INFO: stderr: ""
Dec 17 13:57:13.604: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 17 13:57:13.604: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pod pause -L testing-label --namespace=kubectl-9546'
Dec 17 13:57:13.676: INFO: stderr: ""
Dec 17 13:57:13.676: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 17 13:57:13.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-9546'
Dec 17 13:57:13.756: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 13:57:13.756: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 17 13:57:13.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get rc,svc -l name=pause --no-headers --namespace=kubectl-9546'
Dec 17 13:57:13.847: INFO: stderr: "No resources found in kubectl-9546 namespace.\n"
Dec 17 13:57:13.847: INFO: stdout: ""
Dec 17 13:57:13.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -l name=pause --namespace=kubectl-9546 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 13:57:13.909: INFO: stderr: ""
Dec 17 13:57:13.909: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:57:13.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9546" for this suite.
Dec 17 13:57:19.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:57:20.130: INFO: namespace kubectl-9546 deletion completed in 6.207162002s

• [SLOW TEST:8.975 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:57:20.130: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 13:57:20.229: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 13:57:20.254: INFO: Number of nodes with available pods: 0
Dec 17 13:57:20.254: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 13:57:21.281: INFO: Number of nodes with available pods: 1
Dec 17 13:57:21.281: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 13:57:22.272: INFO: Number of nodes with available pods: 3
Dec 17 13:57:22.272: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 17 13:57:22.331: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:22.331: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:22.331: INFO: Wrong image for pod: daemon-set-wk8l5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:23.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:23.356: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:23.356: INFO: Wrong image for pod: daemon-set-wk8l5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:24.353: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:24.353: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:24.353: INFO: Wrong image for pod: daemon-set-wk8l5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:25.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:25.356: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:25.356: INFO: Wrong image for pod: daemon-set-wk8l5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:25.356: INFO: Pod daemon-set-wk8l5 is not available
Dec 17 13:57:26.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:26.355: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:26.355: INFO: Pod daemon-set-szrcj is not available
Dec 17 13:57:27.352: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:27.352: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:27.352: INFO: Pod daemon-set-q2xwj is not available
Dec 17 13:57:28.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:28.356: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:28.356: INFO: Pod daemon-set-q2xwj is not available
Dec 17 13:57:29.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:29.355: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:29.355: INFO: Pod daemon-set-q2xwj is not available
Dec 17 13:57:30.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:30.355: INFO: Wrong image for pod: daemon-set-q2xwj. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:30.355: INFO: Pod daemon-set-q2xwj is not available
Dec 17 13:57:31.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:31.355: INFO: Pod daemon-set-fjxt4 is not available
Dec 17 13:57:32.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:33.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:33.356: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:34.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:34.356: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:35.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:35.355: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:36.357: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:36.357: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:37.355: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:37.355: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:38.353: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:38.353: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:39.352: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:39.352: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:40.356: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:40.356: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:41.352: INFO: Wrong image for pod: daemon-set-7h6mb. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 17 13:57:41.352: INFO: Pod daemon-set-7h6mb is not available
Dec 17 13:57:42.355: INFO: Pod daemon-set-8q78x is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 17 13:57:42.392: INFO: Number of nodes with available pods: 2
Dec 17 13:57:42.392: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 13:57:43.409: INFO: Number of nodes with available pods: 2
Dec 17 13:57:43.409: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 13:57:44.409: INFO: Number of nodes with available pods: 3
Dec 17 13:57:44.409: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3673, will wait for the garbage collector to delete the pods
Dec 17 13:57:44.517: INFO: Deleting DaemonSet.extensions daemon-set took: 17.789799ms
Dec 17 13:57:44.817: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.203941ms
Dec 17 13:57:52.022: INFO: Number of nodes with available pods: 0
Dec 17 13:57:52.022: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 13:57:52.030: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3673/daemonsets","resourceVersion":"258976"},"items":null}

Dec 17 13:57:52.038: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3673/pods","resourceVersion":"258976"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:57:52.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3673" for this suite.
Dec 17 13:58:00.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:58:00.335: INFO: namespace daemonsets-3673 deletion completed in 8.246900735s

• [SLOW TEST:40.205 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:58:00.336: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-9cb08163-156c-47bb-a4ff-bb8a02d27a09
STEP: Creating secret with name s-test-opt-upd-5ed344a3-5511-4cfe-8eed-ea2682f1a3ae
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9cb08163-156c-47bb-a4ff-bb8a02d27a09
STEP: Updating secret s-test-opt-upd-5ed344a3-5511-4cfe-8eed-ea2682f1a3ae
STEP: Creating secret with name s-test-opt-create-2f525e84-9914-4509-9796-8504c5d6836e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:59:11.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5575" for this suite.
Dec 17 13:59:23.359: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:59:23.552: INFO: namespace secrets-5575 deletion completed in 12.220641755s

• [SLOW TEST:83.216 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:59:23.552: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 13:59:23.617: INFO: Waiting up to 5m0s for pod "downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26" in namespace "projected-6873" to be "success or failure"
Dec 17 13:59:23.624: INFO: Pod "downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26": Phase="Pending", Reason="", readiness=false. Elapsed: 7.740862ms
Dec 17 13:59:25.630: INFO: Pod "downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013187127s
STEP: Saw pod success
Dec 17 13:59:25.630: INFO: Pod "downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26" satisfied condition "success or failure"
Dec 17 13:59:25.638: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26 container client-container: <nil>
STEP: delete the pod
Dec 17 13:59:25.686: INFO: Waiting for pod downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26 to disappear
Dec 17 13:59:25.690: INFO: Pod downwardapi-volume-10ae1b3b-a17c-426f-bfe1-9856dadf0c26 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:59:25.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6873" for this suite.
Dec 17 13:59:31.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 13:59:31.917: INFO: namespace projected-6873 deletion completed in 6.219550858s

• [SLOW TEST:8.365 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 13:59:31.917: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-rwqj
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 13:59:32.001: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-rwqj" in namespace "subpath-6403" to be "success or failure"
Dec 17 13:59:32.020: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Pending", Reason="", readiness=false. Elapsed: 18.552023ms
Dec 17 13:59:34.025: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 2.02397116s
Dec 17 13:59:36.034: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 4.032808824s
Dec 17 13:59:38.044: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 6.042499294s
Dec 17 13:59:40.053: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 8.051178524s
Dec 17 13:59:42.061: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 10.059984669s
Dec 17 13:59:44.066: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 12.064947316s
Dec 17 13:59:46.075: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 14.073971142s
Dec 17 13:59:48.084: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 16.082946457s
Dec 17 13:59:50.093: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 18.092090926s
Dec 17 13:59:52.102: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Running", Reason="", readiness=true. Elapsed: 20.101068186s
Dec 17 13:59:54.111: INFO: Pod "pod-subpath-test-secret-rwqj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.109578592s
STEP: Saw pod success
Dec 17 13:59:54.111: INFO: Pod "pod-subpath-test-secret-rwqj" satisfied condition "success or failure"
Dec 17 13:59:54.115: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-subpath-test-secret-rwqj container test-container-subpath-secret-rwqj: <nil>
STEP: delete the pod
Dec 17 13:59:54.166: INFO: Waiting for pod pod-subpath-test-secret-rwqj to disappear
Dec 17 13:59:54.174: INFO: Pod pod-subpath-test-secret-rwqj no longer exists
STEP: Deleting pod pod-subpath-test-secret-rwqj
Dec 17 13:59:54.174: INFO: Deleting pod "pod-subpath-test-secret-rwqj" in namespace "subpath-6403"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 13:59:54.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6403" for this suite.
Dec 17 14:00:00.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:00:00.412: INFO: namespace subpath-6403 deletion completed in 6.220659931s

• [SLOW TEST:28.495 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:00:00.412: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 17 14:00:02.507: INFO: Pod pod-hostip-0d5d379e-4afd-4079-b2f4-7e1edf1830fc has hostIP: 10.0.32.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:00:02.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1145" for this suite.
Dec 17 14:00:14.551: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:00:14.761: INFO: namespace pods-1145 deletion completed in 12.23845239s

• [SLOW TEST:14.349 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:00:14.762: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:00:14.842: INFO: (0) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 15.917925ms)
Dec 17 14:00:14.850: INFO: (1) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.093758ms)
Dec 17 14:00:14.861: INFO: (2) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.473056ms)
Dec 17 14:00:14.873: INFO: (3) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.550671ms)
Dec 17 14:00:14.880: INFO: (4) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.940583ms)
Dec 17 14:00:14.891: INFO: (5) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.331856ms)
Dec 17 14:00:14.903: INFO: (6) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.28833ms)
Dec 17 14:00:14.910: INFO: (7) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.826233ms)
Dec 17 14:00:14.920: INFO: (8) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.268255ms)
Dec 17 14:00:14.933: INFO: (9) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.652154ms)
Dec 17 14:00:14.940: INFO: (10) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.879688ms)
Dec 17 14:00:14.950: INFO: (11) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.452479ms)
Dec 17 14:00:14.962: INFO: (12) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.12643ms)
Dec 17 14:00:14.969: INFO: (13) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.940108ms)
Dec 17 14:00:14.980: INFO: (14) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.307118ms)
Dec 17 14:00:14.992: INFO: (15) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.622595ms)
Dec 17 14:00:14.999: INFO: (16) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 6.894722ms)
Dec 17 14:00:15.009: INFO: (17) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.283486ms)
Dec 17 14:00:15.022: INFO: (18) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 12.329069ms)
Dec 17 14:00:15.030: INFO: (19) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8:10250/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 8.046297ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:00:15.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7958" for this suite.
Dec 17 14:00:21.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:00:21.254: INFO: namespace proxy-7958 deletion completed in 6.211424071s

• [SLOW TEST:6.493 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:00:21.255: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 17 14:00:25.388: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.388: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.495: INFO: Exec stderr: ""
Dec 17 14:00:25.495: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.495: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.572: INFO: Exec stderr: ""
Dec 17 14:00:25.572: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.572: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.657: INFO: Exec stderr: ""
Dec 17 14:00:25.657: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.657: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.747: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 17 14:00:25.747: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.747: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.822: INFO: Exec stderr: ""
Dec 17 14:00:25.822: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.822: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.907: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 17 14:00:25.907: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.907: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:25.999: INFO: Exec stderr: ""
Dec 17 14:00:25.999: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:25.999: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:26.085: INFO: Exec stderr: ""
Dec 17 14:00:26.085: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:26.085: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:26.178: INFO: Exec stderr: ""
Dec 17 14:00:26.178: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-5273 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:00:26.178: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:00:26.272: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:00:26.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-5273" for this suite.
Dec 17 14:01:12.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:01:12.525: INFO: namespace e2e-kubelet-etc-hosts-5273 deletion completed in 46.245948432s

• [SLOW TEST:51.271 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:01:12.526: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:01:12.593: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611" in namespace "downward-api-7022" to be "success or failure"
Dec 17 14:01:12.603: INFO: Pod "downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611": Phase="Pending", Reason="", readiness=false. Elapsed: 10.667616ms
Dec 17 14:01:14.609: INFO: Pod "downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016295615s
STEP: Saw pod success
Dec 17 14:01:14.609: INFO: Pod "downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611" satisfied condition "success or failure"
Dec 17 14:01:14.619: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611 container client-container: <nil>
STEP: delete the pod
Dec 17 14:01:14.665: INFO: Waiting for pod downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611 to disappear
Dec 17 14:01:14.669: INFO: Pod downwardapi-volume-a37aee16-9b67-480a-b8cf-46c8580ca611 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:01:14.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7022" for this suite.
Dec 17 14:01:20.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:01:20.905: INFO: namespace downward-api-7022 deletion completed in 6.22024839s

• [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:01:20.905: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 14:01:20.950: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 14:01:20.983: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 14:01:20.991: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm2x4q-7kwnapovj8 before test
Dec 17 14:01:21.013: INFO: kube-state-metrics-f58cb6d75-fhf77 from jke-system started at 2019-12-17 10:07:27 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 17 14:01:21.013: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 17 14:01:21.013: INFO: coredns-8565b9f7f-w876f from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container coredns ready: true, restart count 0
Dec 17 14:01:21.013: INFO: prometheus-5ff89497-v69gb from jke-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container prometheus ready: true, restart count 0
Dec 17 14:01:21.013: INFO: fluent-bit-8f5mr from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container fluent-bit ready: true, restart count 2
Dec 17 14:01:21.013: INFO: csi-jdcloudplugin-v42hq from jke-system started at 2019-12-17 09:43:39 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:01:21.013: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:01:21.013: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 from sonobuoy started at 2019-12-17 12:47:40 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:01:21.013: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:01:21.013: INFO: kube-proxy-2zp6v from kube-system started at 2019-12-17 09:43:31 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:01:21.013: INFO: node-exporter-gv5p5 from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:01:21.013: INFO: jdcloud-k8s-ipamd-g4vm6 from kube-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.013: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:01:21.013: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm4x4d-7kwnapovj8 before test
Dec 17 14:01:21.035: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-12-17 07:43:48 +0000 UTC (4 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 17 14:01:21.035: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 17 14:01:21.035: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:01:21.035: INFO: 	Container liveness-probe ready: true, restart count 0
Dec 17 14:01:21.035: INFO: node-exporter-bxz78 from jke-system started at 2019-12-16 11:12:13 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:01:21.035: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf from sonobuoy started at 2019-12-17 12:47:31 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:01:21.035: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:01:21.035: INFO: csi-jdcloudplugin-cgvgf from jke-system started at 2019-12-17 07:43:48 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:01:21.035: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:01:21.035: INFO: kubernetes-dashboard-6c9b78cc5c-kh2f5 from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 14:01:21.035: INFO: jdcloud-k8s-ipamd-n8jwz from kube-system started at 2019-12-16 10:13:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:01:21.035: INFO: coredns-8565b9f7f-sll5x from kube-system started at 2019-12-17 08:47:51 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container coredns ready: true, restart count 0
Dec 17 14:01:21.035: INFO: fluent-bit-5w4zl from jke-system started at 2019-12-16 10:57:14 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 14:01:21.035: INFO: kube-proxy-4bjhm from kube-system started at 2019-12-16 11:03:02 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:01:21.035: INFO: prometheus-jdmon-756f6977d7-g2jqg from jke-system started at 2019-12-16 14:30:05 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.035: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Dec 17 14:01:21.035: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm923c-7kwnapovj8 before test
Dec 17 14:01:21.046: INFO: sonobuoy-e2e-job-f5193f6f15e64a7e from sonobuoy started at 2019-12-17 12:48:59 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container e2e ready: true, restart count 0
Dec 17 14:01:21.046: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 14:01:21.046: INFO: csi-jdcloudplugin-cmtmd from jke-system started at 2019-12-17 13:25:01 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:01:21.046: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:01:21.046: INFO: node-exporter-jl6n7 from jke-system started at 2019-12-17 13:25:03 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:01:21.046: INFO: sonobuoy from sonobuoy started at 2019-12-17 12:46:46 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 14:01:21.046: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv from sonobuoy started at 2019-12-17 12:47:35 +0000 UTC (2 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:01:21.046: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:01:21.046: INFO: kube-proxy-glbxd from kube-system started at 2019-12-17 13:25:02 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:01:21.046: INFO: jdcloud-k8s-ipamd-tbkt8 from kube-system started at 2019-12-17 13:25:40 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:01:21.046: INFO: fluent-bit-zwfxl from jke-system started at 2019-12-17 13:25:08 +0000 UTC (1 container statuses recorded)
Dec 17 14:01:21.046: INFO: 	Container fluent-bit ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-da686090-0267-4241-8f5a-0015e4f0ccf1 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-da686090-0267-4241-8f5a-0015e4f0ccf1 off the node k8s-node-vm923c-7kwnapovj8
STEP: verifying the node doesn't have the label kubernetes.io/e2e-da686090-0267-4241-8f5a-0015e4f0ccf1
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:01:25.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6135" for this suite.
Dec 17 14:01:33.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:01:33.446: INFO: namespace sched-pred-6135 deletion completed in 8.231933739s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:12.541 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:01:33.447: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-34a890ff-60f0-443e-a01c-15f9f4034dda
STEP: Creating a pod to test consume secrets
Dec 17 14:01:33.519: INFO: Waiting up to 5m0s for pod "pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5" in namespace "secrets-3458" to be "success or failure"
Dec 17 14:01:33.533: INFO: Pod "pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5": Phase="Pending", Reason="", readiness=false. Elapsed: 14.581046ms
Dec 17 14:01:35.543: INFO: Pod "pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023613803s
STEP: Saw pod success
Dec 17 14:01:35.543: INFO: Pod "pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5" satisfied condition "success or failure"
Dec 17 14:01:35.547: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5 container secret-volume-test: <nil>
STEP: delete the pod
Dec 17 14:01:35.597: INFO: Waiting for pod pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5 to disappear
Dec 17 14:01:35.605: INFO: Pod pod-secrets-fc2acaa8-24f6-49bb-a040-8f207373bba5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:01:35.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3458" for this suite.
Dec 17 14:01:41.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:01:41.853: INFO: namespace secrets-3458 deletion completed in 6.231537968s

• [SLOW TEST:8.406 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:01:41.853: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:01:42.318: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:01:45.363: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 17 14:01:47.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 attach --namespace=webhook-808 to-be-attached-pod -i -c=container1'
Dec 17 14:01:47.500: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:01:47.517: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-808" for this suite.
Dec 17 14:01:59.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:01:59.737: INFO: namespace webhook-808 deletion completed in 12.213317312s
STEP: Destroying namespace "webhook-808-markers" for this suite.
Dec 17 14:02:05.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:02:05.953: INFO: namespace webhook-808-markers deletion completed in 6.215610109s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.138 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:02:05.991: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:02:06.608: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:02:09.651: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:02:09.662: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5003-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:02:10.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7663" for this suite.
Dec 17 14:02:16.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:02:16.534: INFO: namespace webhook-7663 deletion completed in 6.219281712s
STEP: Destroying namespace "webhook-7663-markers" for this suite.
Dec 17 14:02:22.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:02:22.750: INFO: namespace webhook-7663-markers deletion completed in 6.215462597s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.796 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:02:22.787: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-c2c9ffa9-08ca-4327-83a5-f89fb6906c5c
STEP: Creating a pod to test consume configMaps
Dec 17 14:02:22.863: INFO: Waiting up to 5m0s for pod "pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082" in namespace "configmap-2529" to be "success or failure"
Dec 17 14:02:22.868: INFO: Pod "pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082": Phase="Pending", Reason="", readiness=false. Elapsed: 4.253532ms
Dec 17 14:02:24.873: INFO: Pod "pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009645129s
STEP: Saw pod success
Dec 17 14:02:24.873: INFO: Pod "pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082" satisfied condition "success or failure"
Dec 17 14:02:24.881: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:02:24.958: INFO: Waiting for pod pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082 to disappear
Dec 17 14:02:24.962: INFO: Pod pod-configmaps-0d57d80f-8dbc-412b-a10b-b609c9515082 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:02:24.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2529" for this suite.
Dec 17 14:02:30.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:02:31.195: INFO: namespace configmap-2529 deletion completed in 6.225499805s

• [SLOW TEST:8.407 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:02:31.195: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:02:33.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1224" for this suite.
Dec 17 14:02:53.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:02:53.525: INFO: namespace containers-1224 deletion completed in 20.220916178s

• [SLOW TEST:22.330 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:02:53.525: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 17 14:02:53.589: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3677" to be "success or failure"
Dec 17 14:02:53.597: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 8.357914ms
Dec 17 14:02:55.607: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017618184s
STEP: Saw pod success
Dec 17 14:02:55.607: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 17 14:02:55.611: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 17 14:02:55.652: INFO: Waiting for pod pod-host-path-test to disappear
Dec 17 14:02:55.660: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:02:55.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3677" for this suite.
Dec 17 14:03:01.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:03:01.902: INFO: namespace hostpath-3677 deletion completed in 6.228990256s

• [SLOW TEST:8.377 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:03:01.903: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:03:01.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f" in namespace "downward-api-3812" to be "success or failure"
Dec 17 14:03:01.977: INFO: Pod "downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.22064ms
Dec 17 14:03:03.983: INFO: Pod "downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015592255s
STEP: Saw pod success
Dec 17 14:03:03.983: INFO: Pod "downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f" satisfied condition "success or failure"
Dec 17 14:03:03.991: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f container client-container: <nil>
STEP: delete the pod
Dec 17 14:03:04.038: INFO: Waiting for pod downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f to disappear
Dec 17 14:03:04.042: INFO: Pod downwardapi-volume-22f6fb5e-ad79-4f2a-b25b-86153225488f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:03:04.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3812" for this suite.
Dec 17 14:03:10.074: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:03:10.268: INFO: namespace downward-api-3812 deletion completed in 6.218176762s

• [SLOW TEST:8.365 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:03:10.268: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7834
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7834
STEP: Creating statefulset with conflicting port in namespace statefulset-7834
STEP: Waiting until pod test-pod will start running in namespace statefulset-7834
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7834
Dec 17 14:03:12.410: INFO: Observed stateful pod in namespace: statefulset-7834, name: ss-0, uid: 574bc3ef-cdcc-43cc-9fcc-8ead06bc03cb, status phase: Pending. Waiting for statefulset controller to delete.
Dec 17 14:03:12.983: INFO: Observed stateful pod in namespace: statefulset-7834, name: ss-0, uid: 574bc3ef-cdcc-43cc-9fcc-8ead06bc03cb, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 14:03:12.997: INFO: Observed stateful pod in namespace: statefulset-7834, name: ss-0, uid: 574bc3ef-cdcc-43cc-9fcc-8ead06bc03cb, status phase: Failed. Waiting for statefulset controller to delete.
Dec 17 14:03:13.005: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7834
STEP: Removing pod with conflicting port in namespace statefulset-7834
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7834 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 14:03:17.081: INFO: Deleting all statefulset in ns statefulset-7834
Dec 17 14:03:17.085: INFO: Scaling statefulset ss to 0
Dec 17 14:03:27.120: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 14:03:27.128: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:03:27.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7834" for this suite.
Dec 17 14:03:33.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:03:33.401: INFO: namespace statefulset-7834 deletion completed in 6.233891493s

• [SLOW TEST:23.133 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:03:33.401: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:03:33.472: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44" in namespace "downward-api-2413" to be "success or failure"
Dec 17 14:03:33.479: INFO: Pod "downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44": Phase="Pending", Reason="", readiness=false. Elapsed: 6.397457ms
Dec 17 14:03:35.484: INFO: Pod "downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011437173s
STEP: Saw pod success
Dec 17 14:03:35.484: INFO: Pod "downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44" satisfied condition "success or failure"
Dec 17 14:03:35.492: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44 container client-container: <nil>
STEP: delete the pod
Dec 17 14:03:35.539: INFO: Waiting for pod downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44 to disappear
Dec 17 14:03:35.543: INFO: Pod downwardapi-volume-fb8f9496-6427-45af-8ae0-1dcfd2d22e44 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:03:35.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2413" for this suite.
Dec 17 14:03:41.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:03:41.781: INFO: namespace downward-api-2413 deletion completed in 6.224286587s

• [SLOW TEST:8.380 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:03:41.781: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-7201/configmap-test-dce6c2ea-1d3d-4629-ac2b-75a27cfce07a
STEP: Creating a pod to test consume configMaps
Dec 17 14:03:41.852: INFO: Waiting up to 5m0s for pod "pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737" in namespace "configmap-7201" to be "success or failure"
Dec 17 14:03:41.861: INFO: Pod "pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737": Phase="Pending", Reason="", readiness=false. Elapsed: 9.14084ms
Dec 17 14:03:43.866: INFO: Pod "pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014394613s
STEP: Saw pod success
Dec 17 14:03:43.866: INFO: Pod "pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737" satisfied condition "success or failure"
Dec 17 14:03:43.874: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737 container env-test: <nil>
STEP: delete the pod
Dec 17 14:03:43.921: INFO: Waiting for pod pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737 to disappear
Dec 17 14:03:43.925: INFO: Pod pod-configmaps-ed0b5c38-92e9-4a57-9d57-6d91bed11737 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:03:43.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7201" for this suite.
Dec 17 14:03:49.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:03:50.178: INFO: namespace configmap-7201 deletion completed in 6.245208764s

• [SLOW TEST:8.397 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:03:50.178: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-a89acc89-808f-4d27-a1f9-fbcc4dd601dc in namespace container-probe-720
Dec 17 14:03:52.261: INFO: Started pod busybox-a89acc89-808f-4d27-a1f9-fbcc4dd601dc in namespace container-probe-720
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 14:03:52.266: INFO: Initial restart count of pod busybox-a89acc89-808f-4d27-a1f9-fbcc4dd601dc is 0
Dec 17 14:04:38.458: INFO: Restart count of pod container-probe-720/busybox-a89acc89-808f-4d27-a1f9-fbcc4dd601dc is now 1 (46.191308081s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:04:38.480: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-720" for this suite.
Dec 17 14:04:44.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:04:44.740: INFO: namespace container-probe-720 deletion completed in 6.245426517s

• [SLOW TEST:54.562 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:04:44.740: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:04:45.105: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:04:48.150: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:04:48.155: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:04:48.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9407" for this suite.
Dec 17 14:04:54.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:04:55.101: INFO: namespace webhook-9407 deletion completed in 6.228698728s
STEP: Destroying namespace "webhook-9407-markers" for this suite.
Dec 17 14:05:01.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:05:01.327: INFO: namespace webhook-9407-markers deletion completed in 6.226200601s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.624 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:05:01.364: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:05:01.423: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970" in namespace "downward-api-2457" to be "success or failure"
Dec 17 14:05:01.432: INFO: Pod "downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970": Phase="Pending", Reason="", readiness=false. Elapsed: 8.81278ms
Dec 17 14:05:03.441: INFO: Pod "downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017797849s
STEP: Saw pod success
Dec 17 14:05:03.441: INFO: Pod "downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970" satisfied condition "success or failure"
Dec 17 14:05:03.449: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970 container client-container: <nil>
STEP: delete the pod
Dec 17 14:05:03.493: INFO: Waiting for pod downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970 to disappear
Dec 17 14:05:03.501: INFO: Pod downwardapi-volume-2b9fb6ca-4e3c-4aff-9c5f-3c7de49a2970 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:05:03.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2457" for this suite.
Dec 17 14:05:09.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:05:09.733: INFO: namespace downward-api-2457 deletion completed in 6.224341804s

• [SLOW TEST:8.368 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:05:09.733: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2131
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-2131
Dec 17 14:05:09.810: INFO: Found 0 stateful pods, waiting for 1
Dec 17 14:05:19.815: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 17 14:05:19.861: INFO: Deleting all statefulset in ns statefulset-2131
Dec 17 14:05:19.875: INFO: Scaling statefulset ss to 0
Dec 17 14:05:49.904: INFO: Waiting for statefulset status.replicas updated to 0
Dec 17 14:05:49.911: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:05:49.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2131" for this suite.
Dec 17 14:05:55.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:05:56.187: INFO: namespace statefulset-2131 deletion completed in 6.229115256s

• [SLOW TEST:46.454 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:05:56.187: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:05:56.231: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:05:58.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8050" for this suite.
Dec 17 14:06:42.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:06:42.585: INFO: namespace pods-8050 deletion completed in 44.229399172s

• [SLOW TEST:46.398 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:06:42.585: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 17 14:06:42.634: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 17 14:06:43.136: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 17 14:06:45.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188403, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188403, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188403, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188403, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 17 14:06:47.887: INFO: Waited 637.912836ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:06:48.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7277" for this suite.
Dec 17 14:06:54.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:06:54.632: INFO: namespace aggregator-7277 deletion completed in 6.283651775s

• [SLOW TEST:12.047 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:06:54.632: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:06:54.685: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 14:06:56.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-3630 create -f -'
Dec 17 14:06:57.235: INFO: stderr: ""
Dec 17 14:06:57.235: INFO: stdout: "e2e-test-crd-publish-openapi-4280-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 17 14:06:57.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-3630 delete e2e-test-crd-publish-openapi-4280-crds test-cr'
Dec 17 14:06:57.314: INFO: stderr: ""
Dec 17 14:06:57.314: INFO: stdout: "e2e-test-crd-publish-openapi-4280-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 17 14:06:57.315: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-3630 apply -f -'
Dec 17 14:06:57.458: INFO: stderr: ""
Dec 17 14:06:57.458: INFO: stdout: "e2e-test-crd-publish-openapi-4280-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 17 14:06:57.458: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-3630 delete e2e-test-crd-publish-openapi-4280-crds test-cr'
Dec 17 14:06:57.540: INFO: stderr: ""
Dec 17 14:06:57.540: INFO: stdout: "e2e-test-crd-publish-openapi-4280-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 17 14:06:57.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-4280-crds'
Dec 17 14:06:57.660: INFO: stderr: ""
Dec 17 14:06:57.660: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4280-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:00.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3630" for this suite.
Dec 17 14:07:06.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:06.594: INFO: namespace crd-publish-openapi-3630 deletion completed in 6.224124286s

• [SLOW TEST:11.962 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:06.594: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 17 14:07:06.645: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 17 14:07:06.645: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:06.827: INFO: stderr: ""
Dec 17 14:07:06.827: INFO: stdout: "service/redis-slave created\n"
Dec 17 14:07:06.827: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 17 14:07:06.827: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:06.985: INFO: stderr: ""
Dec 17 14:07:06.985: INFO: stdout: "service/redis-master created\n"
Dec 17 14:07:06.986: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 17 14:07:06.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:07.172: INFO: stderr: ""
Dec 17 14:07:07.172: INFO: stdout: "service/frontend created\n"
Dec 17 14:07:07.172: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 17 14:07:07.172: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:07.305: INFO: stderr: ""
Dec 17 14:07:07.305: INFO: stdout: "deployment.apps/frontend created\n"
Dec 17 14:07:07.305: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 17 14:07:07.305: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:07.449: INFO: stderr: ""
Dec 17 14:07:07.449: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 17 14:07:07.449: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 17 14:07:07.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-6439'
Dec 17 14:07:07.583: INFO: stderr: ""
Dec 17 14:07:07.583: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 17 14:07:07.583: INFO: Waiting for all frontend pods to be Running.
Dec 17 14:07:12.634: INFO: Waiting for frontend to serve content.
Dec 17 14:07:12.659: INFO: Trying to add a new entry to the guestbook.
Dec 17 14:07:12.689: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 17 14:07:12.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:12.824: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:12.824: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 14:07:12.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:12.947: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:12.947: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 14:07:12.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:13.057: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:13.057: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 14:07:13.057: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:13.138: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:13.138: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 14:07:13.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:13.220: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:13.220: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 17 14:07:13.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-6439'
Dec 17 14:07:13.297: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:07:13.297: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:13.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6439" for this suite.
Dec 17 14:07:19.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:19.572: INFO: namespace kubectl-6439 deletion completed in 6.260876156s

• [SLOW TEST:12.978 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:19.572: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-50917dde-1107-41f7-b803-7d36578a1c72
STEP: Creating a pod to test consume configMaps
Dec 17 14:07:19.649: INFO: Waiting up to 5m0s for pod "pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764" in namespace "configmap-221" to be "success or failure"
Dec 17 14:07:19.656: INFO: Pod "pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764": Phase="Pending", Reason="", readiness=false. Elapsed: 7.915682ms
Dec 17 14:07:21.661: INFO: Pod "pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012880073s
STEP: Saw pod success
Dec 17 14:07:21.661: INFO: Pod "pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764" satisfied condition "success or failure"
Dec 17 14:07:21.670: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:07:21.731: INFO: Waiting for pod pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764 to disappear
Dec 17 14:07:21.736: INFO: Pod pod-configmaps-a3b7b75b-22a9-4af1-8bf3-f1bd1c264764 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:21.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-221" for this suite.
Dec 17 14:07:27.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:27.941: INFO: namespace configmap-221 deletion completed in 6.197463372s

• [SLOW TEST:8.369 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:27.941: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:27.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3391" for this suite.
Dec 17 14:07:34.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:34.228: INFO: namespace custom-resource-definition-3391 deletion completed in 6.225369958s

• [SLOW TEST:6.288 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:34.228: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 17 14:07:34.277: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-8805 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 17 14:07:34.347: INFO: stderr: ""
Dec 17 14:07:34.347: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 17 14:07:34.347: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 17 14:07:34.347: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-8805" to be "running and ready, or succeeded"
Dec 17 14:07:34.355: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 7.848634ms
Dec 17 14:07:36.364: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.016986889s
Dec 17 14:07:36.364: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 17 14:07:36.364: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 17 14:07:36.364: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805'
Dec 17 14:07:36.449: INFO: stderr: ""
Dec 17 14:07:36.449: INFO: stdout: "I1217 14:07:34.903458       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/2tkr 345\nI1217 14:07:35.103678       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/6rrf 426\nI1217 14:07:35.303663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/7s9 515\nI1217 14:07:35.503585       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jgl 222\nI1217 14:07:35.703681       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/tlvz 352\nI1217 14:07:35.903663       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/wskh 477\nI1217 14:07:36.103830       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/hd4 517\nI1217 14:07:36.303797       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/r6sr 324\n"
STEP: limiting log lines
Dec 17 14:07:36.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805 --tail=1'
Dec 17 14:07:36.532: INFO: stderr: ""
Dec 17 14:07:36.532: INFO: stdout: "I1217 14:07:36.503583       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/t6wd 446\n"
STEP: limiting log bytes
Dec 17 14:07:36.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805 --limit-bytes=1'
Dec 17 14:07:36.620: INFO: stderr: ""
Dec 17 14:07:36.620: INFO: stdout: "I"
STEP: exposing timestamps
Dec 17 14:07:36.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805 --tail=1 --timestamps'
Dec 17 14:07:36.696: INFO: stderr: ""
Dec 17 14:07:36.696: INFO: stdout: "2019-12-17T14:07:36.50377941Z I1217 14:07:36.503583       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/t6wd 446\n"
STEP: restricting to a time range
Dec 17 14:07:39.196: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805 --since=1s'
Dec 17 14:07:39.271: INFO: stderr: ""
Dec 17 14:07:39.271: INFO: stdout: "I1217 14:07:38.303834       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/zcjl 340\nI1217 14:07:38.503690       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/kvf 496\nI1217 14:07:38.703715       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/fhh 448\nI1217 14:07:38.903619       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/7cwq 334\nI1217 14:07:39.103718       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/crl 215\n"
Dec 17 14:07:39.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs logs-generator logs-generator --namespace=kubectl-8805 --since=24h'
Dec 17 14:07:39.355: INFO: stderr: ""
Dec 17 14:07:39.355: INFO: stdout: "I1217 14:07:34.903458       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/2tkr 345\nI1217 14:07:35.103678       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/ns/pods/6rrf 426\nI1217 14:07:35.303663       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/7s9 515\nI1217 14:07:35.503585       1 logs_generator.go:76] 3 GET /api/v1/namespaces/ns/pods/jgl 222\nI1217 14:07:35.703681       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/tlvz 352\nI1217 14:07:35.903663       1 logs_generator.go:76] 5 GET /api/v1/namespaces/default/pods/wskh 477\nI1217 14:07:36.103830       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/hd4 517\nI1217 14:07:36.303797       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/r6sr 324\nI1217 14:07:36.503583       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/t6wd 446\nI1217 14:07:36.703572       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/f5tp 328\nI1217 14:07:36.903625       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/fwgg 293\nI1217 14:07:37.103602       1 logs_generator.go:76] 11 GET /api/v1/namespaces/ns/pods/5ml 413\nI1217 14:07:37.303601       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/gnqs 237\nI1217 14:07:37.503620       1 logs_generator.go:76] 13 GET /api/v1/namespaces/default/pods/5gg6 488\nI1217 14:07:37.703605       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/7ksp 586\nI1217 14:07:37.903703       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/qvjw 367\nI1217 14:07:38.103746       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/nt2 230\nI1217 14:07:38.303834       1 logs_generator.go:76] 17 GET /api/v1/namespaces/kube-system/pods/zcjl 340\nI1217 14:07:38.503690       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/kvf 496\nI1217 14:07:38.703715       1 logs_generator.go:76] 19 POST /api/v1/namespaces/kube-system/pods/fhh 448\nI1217 14:07:38.903619       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/7cwq 334\nI1217 14:07:39.103718       1 logs_generator.go:76] 21 GET /api/v1/namespaces/kube-system/pods/crl 215\nI1217 14:07:39.303674       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/default/pods/nvp 386\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 17 14:07:39.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete pod logs-generator --namespace=kubectl-8805'
Dec 17 14:07:41.042: INFO: stderr: ""
Dec 17 14:07:41.042: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:41.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8805" for this suite.
Dec 17 14:07:47.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:47.273: INFO: namespace kubectl-8805 deletion completed in 6.214902089s

• [SLOW TEST:13.045 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:47.273: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-d99dc984-69b1-4f5f-ac5a-85b9815c9d4c
STEP: Creating a pod to test consume configMaps
Dec 17 14:07:47.338: INFO: Waiting up to 5m0s for pod "pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a" in namespace "configmap-408" to be "success or failure"
Dec 17 14:07:47.348: INFO: Pod "pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.530235ms
Dec 17 14:07:49.356: INFO: Pod "pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017907401s
STEP: Saw pod success
Dec 17 14:07:49.356: INFO: Pod "pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a" satisfied condition "success or failure"
Dec 17 14:07:49.361: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:07:49.409: INFO: Waiting for pod pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a to disappear
Dec 17 14:07:49.416: INFO: Pod pod-configmaps-a472d755-0a4b-4337-ae04-9b8fecc8c73a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:07:49.416: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-408" for this suite.
Dec 17 14:07:55.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:07:55.647: INFO: namespace configmap-408 deletion completed in 6.215100418s

• [SLOW TEST:8.374 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:07:55.647: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 17 14:07:59.799: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 14:07:59.807: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 14:08:01.808: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 14:08:01.816: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 17 14:08:03.808: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 17 14:08:03.816: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:08:03.816: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1766" for this suite.
Dec 17 14:08:31.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:08:32.069: INFO: namespace container-lifecycle-hook-1766 deletion completed in 28.239097423s

• [SLOW TEST:36.422 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:08:32.070: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-48e44d22-eea0-430b-a95f-6392a241590c
STEP: Creating secret with name secret-projected-all-test-volume-6f64c14a-df1d-4599-8c27-287911fde624
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 17 14:08:32.149: INFO: Waiting up to 5m0s for pod "projected-volume-156964f4-0306-416b-85c0-30ba8facdde6" in namespace "projected-3591" to be "success or failure"
Dec 17 14:08:32.159: INFO: Pod "projected-volume-156964f4-0306-416b-85c0-30ba8facdde6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.979639ms
Dec 17 14:08:34.168: INFO: Pod "projected-volume-156964f4-0306-416b-85c0-30ba8facdde6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018816982s
STEP: Saw pod success
Dec 17 14:08:34.168: INFO: Pod "projected-volume-156964f4-0306-416b-85c0-30ba8facdde6" satisfied condition "success or failure"
Dec 17 14:08:34.172: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod projected-volume-156964f4-0306-416b-85c0-30ba8facdde6 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 17 14:08:34.209: INFO: Waiting for pod projected-volume-156964f4-0306-416b-85c0-30ba8facdde6 to disappear
Dec 17 14:08:34.217: INFO: Pod projected-volume-156964f4-0306-416b-85c0-30ba8facdde6 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:08:34.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3591" for this suite.
Dec 17 14:08:40.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:08:40.491: INFO: namespace projected-3591 deletion completed in 6.26060342s

• [SLOW TEST:8.421 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:08:40.491: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 14:08:47.113: INFO: Successfully updated pod "annotationupdateacc5ebcb-ff3c-4c85-b8dc-225439807487"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:08:49.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2563" for this suite.
Dec 17 14:09:01.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:09:01.393: INFO: namespace downward-api-2563 deletion completed in 12.236220199s

• [SLOW TEST:20.902 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:09:01.393: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-f60a6810-a1a4-460a-9495-64472f17db74
STEP: Creating a pod to test consume configMaps
Dec 17 14:09:01.468: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db" in namespace "projected-6754" to be "success or failure"
Dec 17 14:09:01.481: INFO: Pod "pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db": Phase="Pending", Reason="", readiness=false. Elapsed: 12.240792ms
Dec 17 14:09:03.489: INFO: Pod "pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020708754s
STEP: Saw pod success
Dec 17 14:09:03.489: INFO: Pod "pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db" satisfied condition "success or failure"
Dec 17 14:09:03.497: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:09:03.548: INFO: Waiting for pod pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db to disappear
Dec 17 14:09:03.556: INFO: Pod pod-projected-configmaps-c91e0e05-7e30-4d6e-b15e-dad04aadb0db no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:09:03.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6754" for this suite.
Dec 17 14:09:09.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:09:09.782: INFO: namespace projected-6754 deletion completed in 6.219393218s

• [SLOW TEST:8.389 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:09:09.782: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-ec3313c0-e186-4ab5-a764-dfec13b7d75f
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-ec3313c0-e186-4ab5-a764-dfec13b7d75f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:10:42.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5634" for this suite.
Dec 17 14:11:02.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:11:03.075: INFO: namespace projected-5634 deletion completed in 20.232157762s

• [SLOW TEST:113.293 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:11:03.075: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:11:05.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3745" for this suite.
Dec 17 14:11:51.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:11:51.451: INFO: namespace kubelet-test-3745 deletion completed in 46.24127193s

• [SLOW TEST:48.376 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:11:51.452: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:11:56.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2896" for this suite.
Dec 17 14:12:03.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:12:03.294: INFO: namespace watch-2896 deletion completed in 6.335282712s

• [SLOW TEST:11.843 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:12:03.294: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:12:19.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6148" for this suite.
Dec 17 14:12:25.574: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:12:25.797: INFO: namespace resourcequota-6148 deletion completed in 6.251828335s

• [SLOW TEST:22.503 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:12:25.797: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:12:25.845: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:12:32.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4061" for this suite.
Dec 17 14:12:38.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:12:38.634: INFO: namespace custom-resource-definition-4061 deletion completed in 6.236347681s

• [SLOW TEST:12.837 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:12:38.634: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:12:38.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 version'
Dec 17 14:12:38.733: INFO: stderr: ""
Dec 17 14:12:38.733: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.4\", GitCommit:\"224be7bdce5a9dd0c2fd0d46b83865648e2fe0ba\", GitTreeState:\"clean\", BuildDate:\"2019-12-11T12:47:40Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16+\", GitVersion:\"v1.16.4-12.8d683d98-dirty\", GitCommit:\"8d683d982b20a8f28a62ad502db0f352e50f621c\", GitTreeState:\"dirty\", BuildDate:\"2019-12-16T08:31:23Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:12:38.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3331" for this suite.
Dec 17 14:12:44.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:12:44.963: INFO: namespace kubectl-3331 deletion completed in 6.215941259s

• [SLOW TEST:6.328 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:12:44.963: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:12:45.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2209" for this suite.
Dec 17 14:13:13.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:13:13.278: INFO: namespace pods-2209 deletion completed in 28.229036589s

• [SLOW TEST:28.315 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:13:13.278: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-aac44799-1be7-435f-a61a-93538aa1ab36
STEP: Creating a pod to test consume secrets
Dec 17 14:13:13.347: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242" in namespace "projected-3518" to be "success or failure"
Dec 17 14:13:13.355: INFO: Pod "pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242": Phase="Pending", Reason="", readiness=false. Elapsed: 7.688156ms
Dec 17 14:13:15.366: INFO: Pod "pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018317252s
STEP: Saw pod success
Dec 17 14:13:15.366: INFO: Pod "pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242" satisfied condition "success or failure"
Dec 17 14:13:15.374: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 17 14:13:15.430: INFO: Waiting for pod pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242 to disappear
Dec 17 14:13:15.434: INFO: Pod pod-projected-secrets-83580e8f-5a29-4b84-b21d-308493e4f242 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:13:15.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3518" for this suite.
Dec 17 14:13:21.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:13:21.692: INFO: namespace projected-3518 deletion completed in 6.244374741s

• [SLOW TEST:8.414 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:13:21.693: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-4165/secret-test-d316b34e-b1d5-4c45-b27d-50722dfa1506
STEP: Creating a pod to test consume secrets
Dec 17 14:13:21.763: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8" in namespace "secrets-4165" to be "success or failure"
Dec 17 14:13:21.774: INFO: Pod "pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8": Phase="Pending", Reason="", readiness=false. Elapsed: 11.199082ms
Dec 17 14:13:23.779: INFO: Pod "pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016430193s
STEP: Saw pod success
Dec 17 14:13:23.779: INFO: Pod "pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8" satisfied condition "success or failure"
Dec 17 14:13:23.788: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8 container env-test: <nil>
STEP: delete the pod
Dec 17 14:13:23.830: INFO: Waiting for pod pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8 to disappear
Dec 17 14:13:23.834: INFO: Pod pod-configmaps-ac6b038f-ea96-46cc-988d-d348354f3eb8 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:13:23.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4165" for this suite.
Dec 17 14:13:29.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:13:30.077: INFO: namespace secrets-4165 deletion completed in 6.229181456s

• [SLOW TEST:8.384 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:13:30.077: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 17 14:13:34.219: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 14:13:34.223: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 14:13:36.223: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 14:13:36.232: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 17 14:13:38.223: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 17 14:13:38.232: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:13:38.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-653" for this suite.
Dec 17 14:13:50.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:13:50.510: INFO: namespace container-lifecycle-hook-653 deletion completed in 12.239032987s

• [SLOW TEST:20.433 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:13:50.510: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-2f19bf1d-fdeb-4c9c-96a1-9fa038516048
STEP: Creating a pod to test consume configMaps
Dec 17 14:13:50.579: INFO: Waiting up to 5m0s for pod "pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795" in namespace "configmap-9859" to be "success or failure"
Dec 17 14:13:50.584: INFO: Pod "pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795": Phase="Pending", Reason="", readiness=false. Elapsed: 4.686318ms
Dec 17 14:13:52.593: INFO: Pod "pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013882282s
STEP: Saw pod success
Dec 17 14:13:52.593: INFO: Pod "pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795" satisfied condition "success or failure"
Dec 17 14:13:52.598: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:13:52.653: INFO: Waiting for pod pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795 to disappear
Dec 17 14:13:52.661: INFO: Pod pod-configmaps-0c3497c9-e797-4eb3-bece-82273b9ff795 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:13:52.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9859" for this suite.
Dec 17 14:13:58.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:13:58.896: INFO: namespace configmap-9859 deletion completed in 6.221088056s

• [SLOW TEST:8.386 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:13:58.896: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 17 14:13:58.955: INFO: Waiting up to 5m0s for pod "pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce" in namespace "emptydir-239" to be "success or failure"
Dec 17 14:13:58.963: INFO: Pod "pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce": Phase="Pending", Reason="", readiness=false. Elapsed: 8.099731ms
Dec 17 14:14:00.979: INFO: Pod "pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.024081668s
STEP: Saw pod success
Dec 17 14:14:00.979: INFO: Pod "pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce" satisfied condition "success or failure"
Dec 17 14:14:00.984: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce container test-container: <nil>
STEP: delete the pod
Dec 17 14:14:01.028: INFO: Waiting for pod pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce to disappear
Dec 17 14:14:01.036: INFO: Pod pod-3a5912b1-d690-47e8-a5eb-ab092d8f49ce no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:14:01.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-239" for this suite.
Dec 17 14:14:07.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:14:07.267: INFO: namespace emptydir-239 deletion completed in 6.223648038s

• [SLOW TEST:8.371 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:14:07.267: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 14:14:07.317: INFO: PodSpec: initContainers in spec.initContainers
Dec 17 14:14:53.210: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-58bf42ab-5b5d-419c-8698-ec824d15313d", GenerateName:"", Namespace:"init-container-8431", SelfLink:"/api/v1/namespaces/init-container-8431/pods/pod-init-58bf42ab-5b5d-419c-8698-ec824d15313d", UID:"56727a5a-1aa3-4a72-8a0b-a64f590f8b12", ResourceVersion:"263219", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712188847, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"317822022"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-2h7tx", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0030be080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2h7tx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2h7tx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-2h7tx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003a7dcc8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"k8s-node-vm923c-7kwnapovj8", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc001bd7260), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a7dd40)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003a7dd60)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003a7dd68), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003a7dd6c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188847, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188847, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188847, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712188847, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.32.5", PodIP:"10.0.0.32", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.0.0.32"}}, StartTime:(*v1.Time)(0xc0010bd800), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b49c00)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b49c70)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/busybox@sha256:e004c2cc521c95383aebb1fb5893719aa7a8eae2e7a71f316a4410784edb00a9", ContainerID:"docker://77ddda274f72d4660ba9c5f274ef5b6b2e56b2aa257f114e0ccd21349a735d45", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010bd840), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0010bd820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003a7ddef)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:14:53.211: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8431" for this suite.
Dec 17 14:15:05.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:15:05.452: INFO: namespace init-container-8431 deletion completed in 12.227518144s

• [SLOW TEST:58.185 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:15:05.452: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8809.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8809.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8809.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8809.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8809.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8809.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 14:15:07.630: INFO: DNS probes using dns-8809/dns-test-5c9d5111-ff4b-4c7f-8aaa-cd051ea57cdd succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:15:07.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8809" for this suite.
Dec 17 14:15:13.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:15:13.921: INFO: namespace dns-8809 deletion completed in 6.210833659s

• [SLOW TEST:8.469 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:15:13.921: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-dfccc399-368b-4754-91d9-26f4ee9af4f5
STEP: Creating a pod to test consume configMaps
Dec 17 14:15:13.992: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1" in namespace "projected-5617" to be "success or failure"
Dec 17 14:15:14.001: INFO: Pod "pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1": Phase="Pending", Reason="", readiness=false. Elapsed: 9.101111ms
Dec 17 14:15:16.010: INFO: Pod "pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017825331s
STEP: Saw pod success
Dec 17 14:15:16.010: INFO: Pod "pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1" satisfied condition "success or failure"
Dec 17 14:15:16.015: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:15:16.051: INFO: Waiting for pod pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1 to disappear
Dec 17 14:15:16.059: INFO: Pod pod-projected-configmaps-6b1e44e2-13e9-4290-beb4-ecb8e0d476d1 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:15:16.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5617" for this suite.
Dec 17 14:15:22.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:15:22.289: INFO: namespace projected-5617 deletion completed in 6.216788559s

• [SLOW TEST:8.368 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:15:22.289: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:15:39.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9115" for this suite.
Dec 17 14:15:45.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:15:45.665: INFO: namespace resourcequota-9115 deletion completed in 6.241021861s

• [SLOW TEST:23.376 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:15:45.665: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:15:56.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5803" for this suite.
Dec 17 14:16:02.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:16:03.077: INFO: namespace resourcequota-5803 deletion completed in 6.213048752s

• [SLOW TEST:17.412 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:16:03.077: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 14:16:03.205: INFO: Number of nodes with available pods: 0
Dec 17 14:16:03.205: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:04.218: INFO: Number of nodes with available pods: 1
Dec 17 14:16:04.218: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:05.225: INFO: Number of nodes with available pods: 3
Dec 17 14:16:05.225: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 17 14:16:05.276: INFO: Number of nodes with available pods: 2
Dec 17 14:16:05.276: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:06.299: INFO: Number of nodes with available pods: 2
Dec 17 14:16:06.299: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:07.298: INFO: Number of nodes with available pods: 2
Dec 17 14:16:07.298: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:08.296: INFO: Number of nodes with available pods: 2
Dec 17 14:16:08.296: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:09.303: INFO: Number of nodes with available pods: 2
Dec 17 14:16:09.303: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:10.299: INFO: Number of nodes with available pods: 2
Dec 17 14:16:10.299: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:11.299: INFO: Number of nodes with available pods: 2
Dec 17 14:16:11.299: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:16:12.292: INFO: Number of nodes with available pods: 3
Dec 17 14:16:12.292: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6481, will wait for the garbage collector to delete the pods
Dec 17 14:16:12.376: INFO: Deleting DaemonSet.extensions daemon-set took: 17.287401ms
Dec 17 14:16:12.676: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.188436ms
Dec 17 14:16:21.984: INFO: Number of nodes with available pods: 0
Dec 17 14:16:21.984: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 14:16:21.989: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6481/daemonsets","resourceVersion":"263616"},"items":null}

Dec 17 14:16:21.998: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6481/pods","resourceVersion":"263616"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:16:22.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6481" for this suite.
Dec 17 14:16:28.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:16:28.301: INFO: namespace daemonsets-6481 deletion completed in 6.234180384s

• [SLOW TEST:25.224 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:16:28.301: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:16:28.362: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-dabd0c18-71bd-47b0-b2cb-624ebd800632" in namespace "security-context-test-9918" to be "success or failure"
Dec 17 14:16:28.371: INFO: Pod "alpine-nnp-false-dabd0c18-71bd-47b0-b2cb-624ebd800632": Phase="Pending", Reason="", readiness=false. Elapsed: 8.948357ms
Dec 17 14:16:30.380: INFO: Pod "alpine-nnp-false-dabd0c18-71bd-47b0-b2cb-624ebd800632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017890955s
Dec 17 14:16:30.380: INFO: Pod "alpine-nnp-false-dabd0c18-71bd-47b0-b2cb-624ebd800632" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:16:30.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9918" for this suite.
Dec 17 14:16:36.470: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:16:36.672: INFO: namespace security-context-test-9918 deletion completed in 6.230025365s

• [SLOW TEST:8.370 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:16:36.672: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 14:16:39.288: INFO: Successfully updated pod "labelsupdate6b4067dc-f66f-46a4-b1ea-bc349311f787"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:16:41.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2057" for this suite.
Dec 17 14:16:53.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:16:53.583: INFO: namespace downward-api-2057 deletion completed in 12.235244568s

• [SLOW TEST:16.912 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:16:53.583: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:16:53.641: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7" in namespace "projected-4267" to be "success or failure"
Dec 17 14:16:53.650: INFO: Pod "downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.164171ms
Dec 17 14:16:55.659: INFO: Pod "downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018043229s
STEP: Saw pod success
Dec 17 14:16:55.659: INFO: Pod "downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7" satisfied condition "success or failure"
Dec 17 14:16:55.663: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7 container client-container: <nil>
STEP: delete the pod
Dec 17 14:16:55.702: INFO: Waiting for pod downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7 to disappear
Dec 17 14:16:55.709: INFO: Pod downwardapi-volume-d6dfd8b7-41bb-4951-9aa8-46be7150fde7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:16:55.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4267" for this suite.
Dec 17 14:17:01.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:17:01.979: INFO: namespace projected-4267 deletion completed in 6.255649281s

• [SLOW TEST:8.395 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:17:01.979: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 17 14:17:02.052: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263813 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 14:17:02.052: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263813 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 17 14:17:12.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263836 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 17 14:17:12.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263836 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 17 14:17:22.082: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263859 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 14:17:22.082: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263859 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 17 14:17:32.100: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263882 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 14:17:32.100: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-a b24d7617-9a6e-47c6-8a27-7c1db1af6496 263882 0 2019-12-17 14:17:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 17 14:17:42.117: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-b 8652fa8e-9d13-4198-9720-d4ca77105f52 263905 0 2019-12-17 14:17:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 14:17:42.117: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-b 8652fa8e-9d13-4198-9720-d4ca77105f52 263905 0 2019-12-17 14:17:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 17 14:17:52.135: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-b 8652fa8e-9d13-4198-9720-d4ca77105f52 263928 0 2019-12-17 14:17:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 14:17:52.135: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-376 /api/v1/namespaces/watch-376/configmaps/e2e-watch-test-configmap-b 8652fa8e-9d13-4198-9720-d4ca77105f52 263928 0 2019-12-17 14:17:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:18:02.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-376" for this suite.
Dec 17 14:18:08.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:18:08.372: INFO: namespace watch-376 deletion completed in 6.229838567s

• [SLOW TEST:66.394 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:18:08.372: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:18:08.444: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f" in namespace "downward-api-5906" to be "success or failure"
Dec 17 14:18:08.453: INFO: Pod "downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.773248ms
Dec 17 14:18:10.461: INFO: Pod "downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017420773s
STEP: Saw pod success
Dec 17 14:18:10.461: INFO: Pod "downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f" satisfied condition "success or failure"
Dec 17 14:18:10.473: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f container client-container: <nil>
STEP: delete the pod
Dec 17 14:18:10.518: INFO: Waiting for pod downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f to disappear
Dec 17 14:18:10.523: INFO: Pod downwardapi-volume-8e0dc9bf-01d3-4b3a-8f70-e1e40de4b60f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:18:10.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5906" for this suite.
Dec 17 14:18:16.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:18:16.817: INFO: namespace downward-api-5906 deletion completed in 6.287172818s

• [SLOW TEST:8.445 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:18:16.817: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 17 14:18:16.868: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 api-versions'
Dec 17 14:18:16.933: INFO: stderr: ""
Dec 17 14:18:16.933: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:18:16.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2082" for this suite.
Dec 17 14:18:22.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:18:23.172: INFO: namespace kubectl-2082 deletion completed in 6.231954365s

• [SLOW TEST:6.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:18:23.172: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 17 14:18:23.217: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:18:36.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3843" for this suite.
Dec 17 14:18:42.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:18:43.221: INFO: namespace crd-publish-openapi-3843 deletion completed in 6.261904002s

• [SLOW TEST:20.049 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:18:43.221: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:19:10.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7512" for this suite.
Dec 17 14:19:16.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:19:16.676: INFO: namespace namespaces-7512 deletion completed in 6.218005946s
STEP: Destroying namespace "nsdeletetest-4846" for this suite.
Dec 17 14:19:16.684: INFO: Namespace nsdeletetest-4846 was already deleted
STEP: Destroying namespace "nsdeletetest-4272" for this suite.
Dec 17 14:19:22.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:19:22.904: INFO: namespace nsdeletetest-4272 deletion completed in 6.219944885s

• [SLOW TEST:39.683 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:19:22.904: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 14:19:25.546: INFO: Successfully updated pod "annotationupdate37965c1c-f84d-4957-994b-d61cda8ec126"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:19:27.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8810" for this suite.
Dec 17 14:19:41.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:19:41.836: INFO: namespace projected-8810 deletion completed in 14.233772429s

• [SLOW TEST:18.932 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:19:41.836: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 17 14:19:44.459: INFO: Successfully updated pod "labelsupdate0f7e884a-3527-412b-9062-392fd6566e6f"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:19:46.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7145" for this suite.
Dec 17 14:20:02.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:20:02.716: INFO: namespace projected-7145 deletion completed in 16.214087452s

• [SLOW TEST:20.880 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:20:02.716: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-408a4389-4af4-401f-9c3e-58ce2bc7215c
STEP: Creating a pod to test consume configMaps
Dec 17 14:20:02.793: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd" in namespace "projected-1286" to be "success or failure"
Dec 17 14:20:02.800: INFO: Pod "pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.832215ms
Dec 17 14:20:04.809: INFO: Pod "pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016029569s
STEP: Saw pod success
Dec 17 14:20:04.809: INFO: Pod "pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd" satisfied condition "success or failure"
Dec 17 14:20:04.814: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:20:04.858: INFO: Waiting for pod pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd to disappear
Dec 17 14:20:04.866: INFO: Pod pod-projected-configmaps-2d96d331-f4e6-4f9e-abd8-8a23468e38fd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:20:04.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1286" for this suite.
Dec 17 14:20:10.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:20:11.088: INFO: namespace projected-1286 deletion completed in 6.215086714s

• [SLOW TEST:8.372 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:20:11.088: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 14:20:11.161: INFO: Waiting up to 5m0s for pod "downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1" in namespace "downward-api-949" to be "success or failure"
Dec 17 14:20:11.166: INFO: Pod "downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.331567ms
Dec 17 14:20:13.175: INFO: Pod "downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013514668s
STEP: Saw pod success
Dec 17 14:20:13.175: INFO: Pod "downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1" satisfied condition "success or failure"
Dec 17 14:20:13.179: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1 container dapi-container: <nil>
STEP: delete the pod
Dec 17 14:20:13.229: INFO: Waiting for pod downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1 to disappear
Dec 17 14:20:13.233: INFO: Pod downward-api-ea368481-d9de-4010-9c4f-2fcd22f29cc1 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:20:13.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-949" for this suite.
Dec 17 14:20:19.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:20:19.494: INFO: namespace downward-api-949 deletion completed in 6.246595562s

• [SLOW TEST:8.406 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:20:19.494: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 14:20:21.615: INFO: DNS probes using dns-test-e8daeb64-bb85-4bed-b8a8-23f60cc0af61 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 14:20:23.700: INFO: File wheezy_udp@dns-test-service-3.dns-6309.svc.cluster.local from pod  dns-6309/dns-test-8662553a-b062-4f84-b9e2-2f62f2bc1e08 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 17 14:20:23.707: INFO: File jessie_udp@dns-test-service-3.dns-6309.svc.cluster.local from pod  dns-6309/dns-test-8662553a-b062-4f84-b9e2-2f62f2bc1e08 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 17 14:20:23.707: INFO: Lookups using dns-6309/dns-test-8662553a-b062-4f84-b9e2-2f62f2bc1e08 failed for: [wheezy_udp@dns-test-service-3.dns-6309.svc.cluster.local jessie_udp@dns-test-service-3.dns-6309.svc.cluster.local]

Dec 17 14:20:28.729: INFO: DNS probes using dns-test-8662553a-b062-4f84-b9e2-2f62f2bc1e08 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-6309.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-6309.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 17 14:20:30.850: INFO: DNS probes using dns-test-5578a6b9-0dc8-4dd3-a5f5-0fcd2b7f1178 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:20:30.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6309" for this suite.
Dec 17 14:20:36.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:20:37.157: INFO: namespace dns-6309 deletion completed in 6.225860931s

• [SLOW TEST:17.663 seconds]
[sig-network] DNS
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:20:37.157: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 17 14:20:39.774: INFO: Successfully updated pod "pod-update-27487eed-c365-4f6b-86c6-5fc6e2db6705"
STEP: verifying the updated pod is in kubernetes
Dec 17 14:20:39.791: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:20:39.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2018" for this suite.
Dec 17 14:21:07.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:21:08.031: INFO: namespace pods-2018 deletion completed in 28.226254634s

• [SLOW TEST:30.874 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:21:08.031: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 17 14:21:08.098: INFO: Waiting up to 5m0s for pod "client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da" in namespace "containers-3220" to be "success or failure"
Dec 17 14:21:08.104: INFO: Pod "client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da": Phase="Pending", Reason="", readiness=false. Elapsed: 6.272381ms
Dec 17 14:21:10.109: INFO: Pod "client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01162532s
STEP: Saw pod success
Dec 17 14:21:10.109: INFO: Pod "client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da" satisfied condition "success or failure"
Dec 17 14:21:10.118: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da container test-container: <nil>
STEP: delete the pod
Dec 17 14:21:10.167: INFO: Waiting for pod client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da to disappear
Dec 17 14:21:10.171: INFO: Pod client-containers-edc11489-50c8-4c5d-94a8-dda40d58b7da no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:21:10.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3220" for this suite.
Dec 17 14:21:16.214: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:21:16.424: INFO: namespace containers-3220 deletion completed in 6.238297627s

• [SLOW TEST:8.393 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:21:16.424: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 14:21:16.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7200'
Dec 17 14:21:16.690: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 14:21:16.690: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 17 14:21:16.707: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-wndcl]
Dec 17 14:21:16.707: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-wndcl" in namespace "kubectl-7200" to be "running and ready"
Dec 17 14:21:16.713: INFO: Pod "e2e-test-httpd-rc-wndcl": Phase="Pending", Reason="", readiness=false. Elapsed: 5.502802ms
Dec 17 14:21:18.721: INFO: Pod "e2e-test-httpd-rc-wndcl": Phase="Running", Reason="", readiness=true. Elapsed: 2.014137277s
Dec 17 14:21:18.722: INFO: Pod "e2e-test-httpd-rc-wndcl" satisfied condition "running and ready"
Dec 17 14:21:18.722: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-wndcl]
Dec 17 14:21:18.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs rc/e2e-test-httpd-rc --namespace=kubectl-7200'
Dec 17 14:21:18.815: INFO: stderr: ""
Dec 17 14:21:18.815: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.0.0.52. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.0.0.52. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 17 14:21:17.298950 2019] [mpm_event:notice] [pid 1:tid 140596621802344] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 17 14:21:17.298989 2019] [core:notice] [pid 1:tid 140596621802344] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 17 14:21:18.815: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete rc e2e-test-httpd-rc --namespace=kubectl-7200'
Dec 17 14:21:18.889: INFO: stderr: ""
Dec 17 14:21:18.889: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:21:18.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7200" for this suite.
Dec 17 14:21:46.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:21:47.138: INFO: namespace kubectl-7200 deletion completed in 28.234662389s

• [SLOW TEST:30.714 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:21:47.139: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:21:47.187: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:21:49.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-203" for this suite.
Dec 17 14:22:33.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:22:33.492: INFO: namespace pods-203 deletion completed in 44.232588648s

• [SLOW TEST:46.353 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:22:33.492: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 14:22:33.537: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:22:36.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1441" for this suite.
Dec 17 14:22:48.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:22:48.664: INFO: namespace init-container-1441 deletion completed in 12.236450509s

• [SLOW TEST:15.172 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:22:48.664: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:22:59.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7292" for this suite.
Dec 17 14:23:05.820: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:23:06.033: INFO: namespace resourcequota-7292 deletion completed in 6.240466537s

• [SLOW TEST:17.369 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:23:06.033: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:23:06.083: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 17 14:23:08.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-6962 create -f -'
Dec 17 14:23:09.121: INFO: stderr: ""
Dec 17 14:23:09.121: INFO: stdout: "e2e-test-crd-publish-openapi-2014-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 17 14:23:09.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-6962 delete e2e-test-crd-publish-openapi-2014-crds test-cr'
Dec 17 14:23:09.198: INFO: stderr: ""
Dec 17 14:23:09.198: INFO: stdout: "e2e-test-crd-publish-openapi-2014-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 17 14:23:09.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-6962 apply -f -'
Dec 17 14:23:09.350: INFO: stderr: ""
Dec 17 14:23:09.350: INFO: stdout: "e2e-test-crd-publish-openapi-2014-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 17 14:23:09.350: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-6962 delete e2e-test-crd-publish-openapi-2014-crds test-cr'
Dec 17 14:23:09.424: INFO: stderr: ""
Dec 17 14:23:09.424: INFO: stdout: "e2e-test-crd-publish-openapi-2014-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 17 14:23:09.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-2014-crds'
Dec 17 14:23:09.541: INFO: stderr: ""
Dec 17 14:23:09.541: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2014-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:23:11.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6962" for this suite.
Dec 17 14:23:17.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:23:17.478: INFO: namespace crd-publish-openapi-6962 deletion completed in 6.227111754s

• [SLOW TEST:11.445 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:23:17.479: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 14:23:17.532: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6506'
Dec 17 14:23:17.602: INFO: stderr: ""
Dec 17 14:23:17.602: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 17 14:23:22.652: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pod e2e-test-httpd-pod --namespace=kubectl-6506 -o json'
Dec 17 14:23:22.715: INFO: stderr: ""
Dec 17 14:23:22.715: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-17T14:23:17Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6506\",\n        \"resourceVersion\": \"265176\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6506/pods/e2e-test-httpd-pod\",\n        \"uid\": \"703ac211-82ae-4642-9598-abbe707bf790\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-ffbnc\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"k8s-node-vm923c-7kwnapovj8\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-ffbnc\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-ffbnc\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T14:23:17Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T14:23:18Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T14:23:18Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-17T14:23:17Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://bd455fa366393f7afb970c14de550d5fa168f9cf2b7fd338b5f904e5d65dde67\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-17T14:23:18Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.32.5\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.0.0.32\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.0.0.32\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-17T14:23:17Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 17 14:23:22.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 replace -f - --namespace=kubectl-6506'
Dec 17 14:23:22.891: INFO: stderr: ""
Dec 17 14:23:22.891: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 17 14:23:22.899: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete pods e2e-test-httpd-pod --namespace=kubectl-6506'
Dec 17 14:23:24.907: INFO: stderr: ""
Dec 17 14:23:24.907: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:23:24.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6506" for this suite.
Dec 17 14:23:30.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:23:31.158: INFO: namespace kubectl-6506 deletion completed in 6.237463607s

• [SLOW TEST:13.680 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:23:31.159: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 17 14:23:31.218: INFO: Waiting up to 5m0s for pod "pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30" in namespace "emptydir-1354" to be "success or failure"
Dec 17 14:23:31.229: INFO: Pod "pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30": Phase="Pending", Reason="", readiness=false. Elapsed: 11.247943ms
Dec 17 14:23:33.238: INFO: Pod "pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020432524s
STEP: Saw pod success
Dec 17 14:23:33.238: INFO: Pod "pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30" satisfied condition "success or failure"
Dec 17 14:23:33.246: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30 container test-container: <nil>
STEP: delete the pod
Dec 17 14:23:33.294: INFO: Waiting for pod pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30 to disappear
Dec 17 14:23:33.302: INFO: Pod pod-ec0d3b89-2419-4c03-ad28-9f7332b8bd30 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:23:33.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1354" for this suite.
Dec 17 14:23:39.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:23:39.542: INFO: namespace emptydir-1354 deletion completed in 6.226348394s

• [SLOW TEST:8.383 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:23:39.542: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-n4cl
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 14:23:39.616: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-n4cl" in namespace "subpath-2642" to be "success or failure"
Dec 17 14:23:39.624: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Pending", Reason="", readiness=false. Elapsed: 8.750326ms
Dec 17 14:23:41.629: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 2.013666405s
Dec 17 14:23:43.638: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 4.022754565s
Dec 17 14:23:45.647: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 6.031387311s
Dec 17 14:23:47.656: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 8.040335012s
Dec 17 14:23:49.665: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 10.049364969s
Dec 17 14:23:51.671: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 12.054999968s
Dec 17 14:23:53.680: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 14.063861326s
Dec 17 14:23:55.689: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 16.073050097s
Dec 17 14:23:57.698: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 18.082045144s
Dec 17 14:23:59.707: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Running", Reason="", readiness=true. Elapsed: 20.091368022s
Dec 17 14:24:01.716: INFO: Pod "pod-subpath-test-downwardapi-n4cl": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.100604318s
STEP: Saw pod success
Dec 17 14:24:01.716: INFO: Pod "pod-subpath-test-downwardapi-n4cl" satisfied condition "success or failure"
Dec 17 14:24:01.725: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-subpath-test-downwardapi-n4cl container test-container-subpath-downwardapi-n4cl: <nil>
STEP: delete the pod
Dec 17 14:24:01.781: INFO: Waiting for pod pod-subpath-test-downwardapi-n4cl to disappear
Dec 17 14:24:01.786: INFO: Pod pod-subpath-test-downwardapi-n4cl no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-n4cl
Dec 17 14:24:01.786: INFO: Deleting pod "pod-subpath-test-downwardapi-n4cl" in namespace "subpath-2642"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:24:01.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2642" for this suite.
Dec 17 14:24:07.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:24:08.035: INFO: namespace subpath-2642 deletion completed in 6.22057195s

• [SLOW TEST:28.493 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:24:08.035: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:24:08.106: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4" in namespace "projected-3202" to be "success or failure"
Dec 17 14:24:08.112: INFO: Pod "downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.989469ms
Dec 17 14:24:10.121: INFO: Pod "downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015179332s
STEP: Saw pod success
Dec 17 14:24:10.121: INFO: Pod "downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4" satisfied condition "success or failure"
Dec 17 14:24:10.129: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4 container client-container: <nil>
STEP: delete the pod
Dec 17 14:24:10.167: INFO: Waiting for pod downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4 to disappear
Dec 17 14:24:10.172: INFO: Pod downwardapi-volume-d1752568-abd8-4ab1-abe7-d505bb733dd4 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:24:10.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3202" for this suite.
Dec 17 14:24:16.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:24:16.419: INFO: namespace projected-3202 deletion completed in 6.229887361s

• [SLOW TEST:8.383 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:24:16.419: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:24:20.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-247" for this suite.
Dec 17 14:24:26.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:24:26.760: INFO: namespace kubelet-test-247 deletion completed in 6.247099596s

• [SLOW TEST:10.341 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:24:26.760: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 17 14:24:26.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-9439'
Dec 17 14:24:26.948: INFO: stderr: ""
Dec 17 14:24:26.948: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 17 14:24:26.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9439'
Dec 17 14:24:27.021: INFO: stderr: ""
Dec 17 14:24:27.021: INFO: stdout: "update-demo-nautilus-2fl6l update-demo-nautilus-s9c4k "
Dec 17 14:24:27.021: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-2fl6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9439'
Dec 17 14:24:27.095: INFO: stderr: ""
Dec 17 14:24:27.095: INFO: stdout: ""
Dec 17 14:24:27.095: INFO: update-demo-nautilus-2fl6l is created but not running
Dec 17 14:24:32.095: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9439'
Dec 17 14:24:32.157: INFO: stderr: ""
Dec 17 14:24:32.157: INFO: stdout: "update-demo-nautilus-2fl6l update-demo-nautilus-s9c4k "
Dec 17 14:24:32.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-2fl6l -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9439'
Dec 17 14:24:32.220: INFO: stderr: ""
Dec 17 14:24:32.220: INFO: stdout: "true"
Dec 17 14:24:32.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-2fl6l -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9439'
Dec 17 14:24:32.282: INFO: stderr: ""
Dec 17 14:24:32.282: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 14:24:32.282: INFO: validating pod update-demo-nautilus-2fl6l
Dec 17 14:24:32.291: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 14:24:32.291: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 14:24:32.291: INFO: update-demo-nautilus-2fl6l is verified up and running
Dec 17 14:24:32.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-s9c4k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9439'
Dec 17 14:24:32.353: INFO: stderr: ""
Dec 17 14:24:32.353: INFO: stdout: "true"
Dec 17 14:24:32.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods update-demo-nautilus-s9c4k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9439'
Dec 17 14:24:32.414: INFO: stderr: ""
Dec 17 14:24:32.414: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 17 14:24:32.414: INFO: validating pod update-demo-nautilus-s9c4k
Dec 17 14:24:32.433: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 17 14:24:32.433: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 17 14:24:32.433: INFO: update-demo-nautilus-s9c4k is verified up and running
STEP: using delete to clean up resources
Dec 17 14:24:32.434: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete --grace-period=0 --force -f - --namespace=kubectl-9439'
Dec 17 14:24:32.511: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 17 14:24:32.511: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 17 14:24:32.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9439'
Dec 17 14:24:32.577: INFO: stderr: "No resources found in kubectl-9439 namespace.\n"
Dec 17 14:24:32.577: INFO: stdout: ""
Dec 17 14:24:32.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -l name=update-demo --namespace=kubectl-9439 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 14:24:32.636: INFO: stderr: ""
Dec 17 14:24:32.636: INFO: stdout: "update-demo-nautilus-2fl6l\nupdate-demo-nautilus-s9c4k\n"
Dec 17 14:24:33.137: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9439'
Dec 17 14:24:33.210: INFO: stderr: "No resources found in kubectl-9439 namespace.\n"
Dec 17 14:24:33.210: INFO: stdout: ""
Dec 17 14:24:33.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -l name=update-demo --namespace=kubectl-9439 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 17 14:24:33.276: INFO: stderr: ""
Dec 17 14:24:33.276: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:24:33.276: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9439" for this suite.
Dec 17 14:24:45.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:24:45.517: INFO: namespace kubectl-9439 deletion completed in 12.233722325s

• [SLOW TEST:18.757 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:24:45.517: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:24:45.962: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:24:49.002: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 17 14:24:49.036: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:24:49.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3979" for this suite.
Dec 17 14:24:55.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:24:55.297: INFO: namespace webhook-3979 deletion completed in 6.226805795s
STEP: Destroying namespace "webhook-3979-markers" for this suite.
Dec 17 14:25:01.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:25:01.530: INFO: namespace webhook-3979-markers deletion completed in 6.233130433s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.047 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:25:01.565: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:25:01.627: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:25:01.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6561" for this suite.
Dec 17 14:25:07.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:25:07.944: INFO: namespace custom-resource-definition-6561 deletion completed in 6.234584246s

• [SLOW TEST:6.379 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:25:07.944: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 17 14:25:10.059: INFO: &Pod{ObjectMeta:{send-events-e9defc9a-2761-4028-b6da-4d8df5ae0b06  events-8789 /api/v1/namespaces/events-8789/pods/send-events-e9defc9a-2761-4028-b6da-4d8df5ae0b06 7ae5477e-4771-425b-9a8b-6c2fe66b3272 265688 0 2019-12-17 14:25:07 +0000 UTC <nil> <nil> map[name:foo time:997244172] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tfps4,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tfps4,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tfps4,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:25:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:25:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:25:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:25:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.41,StartTime:2019-12-17 14:25:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:25:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://jdcloud-cn-east-2.jcr.service.jdcloud.com/kubernetes-e2e-test-images/agnhost@sha256:4273341f784390e3fd568bee1bf86efe6ef4ad4a7a1a75c0dcd01776683d669a,ContainerID:docker://d0c08d208e79a62faa74d47a2b2b577b7f2c21683d1454089afb8848b9296b23,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 17 14:25:12.068: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 17 14:25:14.077: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:25:14.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8789" for this suite.
Dec 17 14:25:58.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:25:58.338: INFO: namespace events-8789 deletion completed in 44.233854848s

• [SLOW TEST:50.394 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:25:58.338: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:26:04.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6119" for this suite.
Dec 17 14:26:10.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:26:10.652: INFO: namespace job-6119 deletion completed in 6.237331827s

• [SLOW TEST:12.314 seconds]
[sig-apps] Job
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:26:10.652: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 17 14:26:10.715: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 17 14:26:10.746: INFO: Waiting for terminating namespaces to be deleted...
Dec 17 14:26:10.754: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm2x4q-7kwnapovj8 before test
Dec 17 14:26:10.788: INFO: kube-state-metrics-f58cb6d75-fhf77 from jke-system started at 2019-12-17 10:07:27 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container addon-resizer ready: true, restart count 0
Dec 17 14:26:10.788: INFO: 	Container kube-state-metrics ready: true, restart count 0
Dec 17 14:26:10.788: INFO: coredns-8565b9f7f-w876f from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container coredns ready: true, restart count 0
Dec 17 14:26:10.788: INFO: prometheus-5ff89497-v69gb from jke-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container prometheus ready: true, restart count 0
Dec 17 14:26:10.788: INFO: fluent-bit-8f5mr from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container fluent-bit ready: true, restart count 2
Dec 17 14:26:10.788: INFO: csi-jdcloudplugin-v42hq from jke-system started at 2019-12-17 09:43:39 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:26:10.788: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:26:10.788: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-mqqt6 from sonobuoy started at 2019-12-17 12:47:40 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:26:10.788: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:26:10.788: INFO: kube-proxy-2zp6v from kube-system started at 2019-12-17 09:43:31 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:26:10.788: INFO: node-exporter-gv5p5 from jke-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:26:10.788: INFO: jdcloud-k8s-ipamd-g4vm6 from kube-system started at 2019-12-17 09:43:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.788: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:26:10.788: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm4x4d-7kwnapovj8 before test
Dec 17 14:26:10.808: INFO: node-exporter-bxz78 from jke-system started at 2019-12-16 11:12:13 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:26:10.808: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-wn7wf from sonobuoy started at 2019-12-17 12:47:31 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:26:10.808: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:26:10.808: INFO: csi-jdcloudplugin-controller-0 from jke-system started at 2019-12-17 07:43:48 +0000 UTC (4 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container csi-attacher ready: true, restart count 0
Dec 17 14:26:10.808: INFO: 	Container csi-provisioner ready: true, restart count 0
Dec 17 14:26:10.808: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:26:10.808: INFO: 	Container liveness-probe ready: true, restart count 0
Dec 17 14:26:10.808: INFO: csi-jdcloudplugin-cgvgf from jke-system started at 2019-12-17 07:43:48 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:26:10.808: INFO: 	Container jdcloud-csi ready: true, restart count 0
Dec 17 14:26:10.808: INFO: coredns-8565b9f7f-sll5x from kube-system started at 2019-12-17 08:47:51 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container coredns ready: true, restart count 0
Dec 17 14:26:10.808: INFO: kubernetes-dashboard-6c9b78cc5c-kh2f5 from kube-system started at 2019-12-17 10:07:27 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec 17 14:26:10.808: INFO: jdcloud-k8s-ipamd-n8jwz from kube-system started at 2019-12-16 10:13:39 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:26:10.808: INFO: kube-proxy-4bjhm from kube-system started at 2019-12-16 11:03:02 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:26:10.808: INFO: prometheus-jdmon-756f6977d7-g2jqg from jke-system started at 2019-12-16 14:30:05 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container k8s-metrics-to-jdmon ready: true, restart count 0
Dec 17 14:26:10.808: INFO: fluent-bit-5w4zl from jke-system started at 2019-12-16 10:57:14 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.808: INFO: 	Container fluent-bit ready: true, restart count 1
Dec 17 14:26:10.808: INFO: 
Logging pods the kubelet thinks is on node k8s-node-vm923c-7kwnapovj8 before test
Dec 17 14:26:10.837: INFO: jdcloud-k8s-ipamd-tbkt8 from kube-system started at 2019-12-17 13:25:40 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container jdcloud-k8s-ipamd ready: true, restart count 0
Dec 17 14:26:10.837: INFO: fluent-bit-zwfxl from jke-system started at 2019-12-17 13:25:08 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container fluent-bit ready: true, restart count 0
Dec 17 14:26:10.837: INFO: sonobuoy-systemd-logs-daemon-set-766d7fd4a6f648ae-t5ldv from sonobuoy started at 2019-12-17 12:47:35 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 17 14:26:10.837: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 17 14:26:10.837: INFO: kube-proxy-glbxd from kube-system started at 2019-12-17 13:25:02 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 17 14:26:10.837: INFO: sonobuoy-e2e-job-f5193f6f15e64a7e from sonobuoy started at 2019-12-17 12:48:59 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container e2e ready: true, restart count 0
Dec 17 14:26:10.837: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 17 14:26:10.837: INFO: node-exporter-jl6n7 from jke-system started at 2019-12-17 13:25:03 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container node-exporter ready: true, restart count 0
Dec 17 14:26:10.837: INFO: sonobuoy from sonobuoy started at 2019-12-17 12:46:46 +0000 UTC (1 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 17 14:26:10.837: INFO: csi-jdcloudplugin-cmtmd from jke-system started at 2019-12-17 13:25:01 +0000 UTC (2 container statuses recorded)
Dec 17 14:26:10.837: INFO: 	Container driver-registrar ready: true, restart count 0
Dec 17 14:26:10.837: INFO: 	Container jdcloud-csi ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0030aa50-16ed-4647-9ae1-d6a523911df3 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-0030aa50-16ed-4647-9ae1-d6a523911df3 off the node k8s-node-vm923c-7kwnapovj8
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0030aa50-16ed-4647-9ae1-d6a523911df3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:26:19.054: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-7432" for this suite.
Dec 17 14:26:35.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:26:35.357: INFO: namespace sched-pred-7432 deletion completed in 16.294262261s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:24.704 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:26:35.357: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:26:37.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6163" for this suite.
Dec 17 14:27:21.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:27:21.736: INFO: namespace kubelet-test-6163 deletion completed in 44.225778501s

• [SLOW TEST:46.379 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:27:21.736: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 14:27:21.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9002'
Dec 17 14:27:21.846: INFO: stderr: ""
Dec 17 14:27:21.846: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 17 14:27:21.854: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete pods e2e-test-httpd-pod --namespace=kubectl-9002'
Dec 17 14:27:30.985: INFO: stderr: ""
Dec 17 14:27:30.985: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:27:30.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9002" for this suite.
Dec 17 14:27:37.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:27:37.232: INFO: namespace kubectl-9002 deletion completed in 6.231673223s

• [SLOW TEST:15.496 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:27:37.232: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-d0280d4d-0bd1-4ff0-bfad-4c1decef1fb9
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:27:37.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5735" for this suite.
Dec 17 14:27:43.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:27:43.546: INFO: namespace secrets-5735 deletion completed in 6.227443142s

• [SLOW TEST:6.315 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:27:43.546: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 17 14:27:43.608: INFO: Waiting up to 5m0s for pod "downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9" in namespace "downward-api-735" to be "success or failure"
Dec 17 14:27:43.612: INFO: Pod "downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.178254ms
Dec 17 14:27:45.621: INFO: Pod "downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013042384s
STEP: Saw pod success
Dec 17 14:27:45.621: INFO: Pod "downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9" satisfied condition "success or failure"
Dec 17 14:27:45.629: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9 container dapi-container: <nil>
STEP: delete the pod
Dec 17 14:27:45.681: INFO: Waiting for pod downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9 to disappear
Dec 17 14:27:45.685: INFO: Pod downward-api-59e21943-fd88-4739-be32-edc78b6ae4a9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:27:45.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-735" for this suite.
Dec 17 14:27:51.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:27:51.914: INFO: namespace downward-api-735 deletion completed in 6.221484103s

• [SLOW TEST:8.367 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:27:51.914: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-9k5k
STEP: Creating a pod to test atomic-volume-subpath
Dec 17 14:27:51.994: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9k5k" in namespace "subpath-5647" to be "success or failure"
Dec 17 14:27:52.023: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Pending", Reason="", readiness=false. Elapsed: 28.558745ms
Dec 17 14:27:54.032: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 2.037621807s
Dec 17 14:27:56.042: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 4.047166534s
Dec 17 14:27:58.050: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 6.055807952s
Dec 17 14:28:00.059: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 8.06491645s
Dec 17 14:28:02.069: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 10.074224636s
Dec 17 14:28:04.074: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 12.079411624s
Dec 17 14:28:06.083: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 14.08848421s
Dec 17 14:28:08.092: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 16.097529497s
Dec 17 14:28:10.101: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 18.106844968s
Dec 17 14:28:12.110: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Running", Reason="", readiness=true. Elapsed: 20.116050131s
Dec 17 14:28:14.115: INFO: Pod "pod-subpath-test-projected-9k5k": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.121022608s
STEP: Saw pod success
Dec 17 14:28:14.115: INFO: Pod "pod-subpath-test-projected-9k5k" satisfied condition "success or failure"
Dec 17 14:28:14.124: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-subpath-test-projected-9k5k container test-container-subpath-projected-9k5k: <nil>
STEP: delete the pod
Dec 17 14:28:14.170: INFO: Waiting for pod pod-subpath-test-projected-9k5k to disappear
Dec 17 14:28:14.174: INFO: Pod pod-subpath-test-projected-9k5k no longer exists
STEP: Deleting pod pod-subpath-test-projected-9k5k
Dec 17 14:28:14.174: INFO: Deleting pod "pod-subpath-test-projected-9k5k" in namespace "subpath-5647"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:28:14.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5647" for this suite.
Dec 17 14:28:20.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:28:20.429: INFO: namespace subpath-5647 deletion completed in 6.240008312s

• [SLOW TEST:28.515 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:28:20.429: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 17 14:28:20.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=kubectl-845 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 17 14:28:21.841: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 17 14:28:21.841: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:28:23.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-845" for this suite.
Dec 17 14:28:29.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:28:30.113: INFO: namespace kubectl-845 deletion completed in 6.241618483s

• [SLOW TEST:9.683 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:28:30.113: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-a803385b-7c71-44ef-81a7-c10cf4908eec in namespace container-probe-893
Dec 17 14:28:32.200: INFO: Started pod test-webserver-a803385b-7c71-44ef-81a7-c10cf4908eec in namespace container-probe-893
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 14:28:32.208: INFO: Initial restart count of pod test-webserver-a803385b-7c71-44ef-81a7-c10cf4908eec is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:32:33.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-893" for this suite.
Dec 17 14:32:39.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:32:39.505: INFO: namespace container-probe-893 deletion completed in 6.233868552s

• [SLOW TEST:249.392 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:32:39.505: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 17 14:32:39.569: INFO: Waiting up to 5m0s for pod "pod-90fde427-1b32-48db-9867-600914fb13c9" in namespace "emptydir-3269" to be "success or failure"
Dec 17 14:32:39.577: INFO: Pod "pod-90fde427-1b32-48db-9867-600914fb13c9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.153145ms
Dec 17 14:32:41.586: INFO: Pod "pod-90fde427-1b32-48db-9867-600914fb13c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01733912s
STEP: Saw pod success
Dec 17 14:32:41.586: INFO: Pod "pod-90fde427-1b32-48db-9867-600914fb13c9" satisfied condition "success or failure"
Dec 17 14:32:41.591: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-90fde427-1b32-48db-9867-600914fb13c9 container test-container: <nil>
STEP: delete the pod
Dec 17 14:32:41.661: INFO: Waiting for pod pod-90fde427-1b32-48db-9867-600914fb13c9 to disappear
Dec 17 14:32:41.669: INFO: Pod pod-90fde427-1b32-48db-9867-600914fb13c9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:32:41.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3269" for this suite.
Dec 17 14:32:47.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:32:47.898: INFO: namespace emptydir-3269 deletion completed in 6.222211506s

• [SLOW TEST:8.393 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:32:47.898: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-2938
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2938
STEP: creating replication controller externalsvc in namespace services-2938
I1217 14:32:47.998520      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2938, replica count: 2
I1217 14:32:51.048872      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 17 14:32:51.086: INFO: Creating new exec pod
Dec 17 14:32:53.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-2938 execpodbmrm8 -- /bin/sh -x -c nslookup clusterip-service'
Dec 17 14:32:53.617: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 17 14:32:53.617: INFO: stdout: "Server:\t\t10.0.56.10\nAddress:\t10.0.56.10#53\n\nclusterip-service.services-2938.svc.cluster.local\tcanonical name = externalsvc.services-2938.svc.cluster.local.\nName:\texternalsvc.services-2938.svc.cluster.local\nAddress: 10.0.61.163\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2938, will wait for the garbage collector to delete the pods
Dec 17 14:32:53.691: INFO: Deleting ReplicationController externalsvc took: 17.623722ms
Dec 17 14:32:53.991: INFO: Terminating ReplicationController externalsvc pods took: 300.25643ms
Dec 17 14:33:00.840: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:33:00.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2938" for this suite.
Dec 17 14:33:06.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:33:07.129: INFO: namespace services-2938 deletion completed in 6.237303889s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.231 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:33:07.130: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 17 14:33:07.262: INFO: Number of nodes with available pods: 0
Dec 17 14:33:07.262: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:33:08.282: INFO: Number of nodes with available pods: 1
Dec 17 14:33:08.282: INFO: Node k8s-node-vm2x4q-7kwnapovj8 is running more than one daemon pod
Dec 17 14:33:09.281: INFO: Number of nodes with available pods: 3
Dec 17 14:33:09.281: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 17 14:33:09.324: INFO: Number of nodes with available pods: 2
Dec 17 14:33:09.324: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 14:33:10.350: INFO: Number of nodes with available pods: 2
Dec 17 14:33:10.350: INFO: Node k8s-node-vm4x4d-7kwnapovj8 is running more than one daemon pod
Dec 17 14:33:11.343: INFO: Number of nodes with available pods: 3
Dec 17 14:33:11.343: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1890, will wait for the garbage collector to delete the pods
Dec 17 14:33:11.436: INFO: Deleting DaemonSet.extensions daemon-set took: 18.789355ms
Dec 17 14:33:11.736: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.169275ms
Dec 17 14:33:14.441: INFO: Number of nodes with available pods: 0
Dec 17 14:33:14.441: INFO: Number of running nodes: 0, number of available pods: 0
Dec 17 14:33:14.445: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1890/daemonsets","resourceVersion":"267305"},"items":null}

Dec 17 14:33:14.453: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1890/pods","resourceVersion":"267305"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:33:14.484: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1890" for this suite.
Dec 17 14:33:20.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:33:20.734: INFO: namespace daemonsets-1890 deletion completed in 6.236885708s

• [SLOW TEST:13.604 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:33:20.734: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-5400d971-88fc-45c0-aa8d-72ee4d75acbf
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:33:22.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9585" for this suite.
Dec 17 14:33:34.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:33:35.109: INFO: namespace configmap-9585 deletion completed in 12.219886876s

• [SLOW TEST:14.375 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:33:35.109: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 17 14:33:35.178: INFO: Waiting up to 5m0s for pod "pod-c2542f95-c491-40ab-89b7-6ec5e38eedef" in namespace "emptydir-8057" to be "success or failure"
Dec 17 14:33:35.187: INFO: Pod "pod-c2542f95-c491-40ab-89b7-6ec5e38eedef": Phase="Pending", Reason="", readiness=false. Elapsed: 8.785292ms
Dec 17 14:33:37.196: INFO: Pod "pod-c2542f95-c491-40ab-89b7-6ec5e38eedef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01780075s
STEP: Saw pod success
Dec 17 14:33:37.196: INFO: Pod "pod-c2542f95-c491-40ab-89b7-6ec5e38eedef" satisfied condition "success or failure"
Dec 17 14:33:37.204: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-c2542f95-c491-40ab-89b7-6ec5e38eedef container test-container: <nil>
STEP: delete the pod
Dec 17 14:33:37.251: INFO: Waiting for pod pod-c2542f95-c491-40ab-89b7-6ec5e38eedef to disappear
Dec 17 14:33:37.259: INFO: Pod pod-c2542f95-c491-40ab-89b7-6ec5e38eedef no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:33:37.259: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8057" for this suite.
Dec 17 14:33:43.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:33:43.511: INFO: namespace emptydir-8057 deletion completed in 6.231743783s

• [SLOW TEST:8.402 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:33:43.511: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-db84106c-66ed-489c-87d8-9fb505d7fbdb
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:33:43.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2057" for this suite.
Dec 17 14:33:49.627: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:33:49.833: INFO: namespace configmap-2057 deletion completed in 6.231297457s

• [SLOW TEST:6.322 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:33:49.834: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 17 14:33:49.888: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:34:02.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3787" for this suite.
Dec 17 14:34:09.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:34:09.204: INFO: namespace crd-publish-openapi-3787 deletion completed in 6.228950164s

• [SLOW TEST:19.370 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:34:09.204: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 17 14:34:09.263: INFO: namespace kubectl-5830
Dec 17 14:34:09.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-5830'
Dec 17 14:34:09.561: INFO: stderr: ""
Dec 17 14:34:09.561: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 14:34:10.571: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:34:10.571: INFO: Found 1 / 1
Dec 17 14:34:10.571: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 17 14:34:10.580: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:34:10.580: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 14:34:10.580: INFO: wait on redis-master startup in kubectl-5830 
Dec 17 14:34:10.580: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 logs redis-master-xmr97 redis-master --namespace=kubectl-5830'
Dec 17 14:34:10.663: INFO: stderr: ""
Dec 17 14:34:10.663: INFO: stdout: "1:C 17 Dec 2019 14:34:10.160 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 17 Dec 2019 14:34:10.160 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 17 Dec 2019 14:34:10.160 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 17 Dec 2019 14:34:10.162 * Running mode=standalone, port=6379.\n1:M 17 Dec 2019 14:34:10.162 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 17 Dec 2019 14:34:10.162 # Server initialized\n1:M 17 Dec 2019 14:34:10.162 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 17 Dec 2019 14:34:10.162 * Ready to accept connections\n"
STEP: exposing RC
Dec 17 14:34:10.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5830'
Dec 17 14:34:10.771: INFO: stderr: ""
Dec 17 14:34:10.771: INFO: stdout: "service/rm2 exposed\n"
Dec 17 14:34:10.779: INFO: Service rm2 in namespace kubectl-5830 found.
STEP: exposing service
Dec 17 14:34:12.794: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5830'
Dec 17 14:34:12.881: INFO: stderr: ""
Dec 17 14:34:12.881: INFO: stdout: "service/rm3 exposed\n"
Dec 17 14:34:12.890: INFO: Service rm3 in namespace kubectl-5830 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:34:14.903: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5830" for this suite.
Dec 17 14:34:42.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:34:43.153: INFO: namespace kubectl-5830 deletion completed in 28.236575009s

• [SLOW TEST:33.949 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:34:43.154: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 17 14:34:43.196: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:34:46.541: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-3004" for this suite.
Dec 17 14:34:52.584: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:34:52.787: INFO: namespace init-container-3004 deletion completed in 6.232166179s

• [SLOW TEST:9.634 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:34:52.788: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6225
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6225
I1217 14:34:52.909948      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6225, replica count: 2
Dec 17 14:34:55.960: INFO: Creating new exec pod
I1217 14:34:55.960509      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 14:34:58.998: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6225 execpodfkg76 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 17 14:34:59.165: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 17 14:34:59.165: INFO: stdout: ""
Dec 17 14:34:59.166: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6225 execpodfkg76 -- /bin/sh -x -c nc -zv -t -w 2 10.0.57.125 80'
Dec 17 14:34:59.320: INFO: stderr: "+ nc -zv -t -w 2 10.0.57.125 80\nConnection to 10.0.57.125 80 port [tcp/http] succeeded!\n"
Dec 17 14:34:59.320: INFO: stdout: ""
Dec 17 14:34:59.321: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6225 execpodfkg76 -- /bin/sh -x -c nc -zv -t -w 2 10.0.32.4 30783'
Dec 17 14:34:59.477: INFO: stderr: "+ nc -zv -t -w 2 10.0.32.4 30783\nConnection to 10.0.32.4 30783 port [tcp/30783] succeeded!\n"
Dec 17 14:34:59.477: INFO: stdout: ""
Dec 17 14:34:59.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 exec --namespace=services-6225 execpodfkg76 -- /bin/sh -x -c nc -zv -t -w 2 10.0.32.3 30783'
Dec 17 14:34:59.638: INFO: stderr: "+ nc -zv -t -w 2 10.0.32.3 30783\nConnection to 10.0.32.3 30783 port [tcp/30783] succeeded!\n"
Dec 17 14:34:59.638: INFO: stdout: ""
Dec 17 14:34:59.638: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:34:59.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6225" for this suite.
Dec 17 14:35:05.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:05.963: INFO: namespace services-6225 deletion completed in 6.241747846s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.175 seconds]
[sig-network] Services
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:35:05.963: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:35:06.034: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-1c85f29d-de4f-4500-8d78-42d5e2a941ee" in namespace "security-context-test-3601" to be "success or failure"
Dec 17 14:35:06.044: INFO: Pod "busybox-readonly-false-1c85f29d-de4f-4500-8d78-42d5e2a941ee": Phase="Pending", Reason="", readiness=false. Elapsed: 9.392627ms
Dec 17 14:35:08.053: INFO: Pod "busybox-readonly-false-1c85f29d-de4f-4500-8d78-42d5e2a941ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018564996s
Dec 17 14:35:08.053: INFO: Pod "busybox-readonly-false-1c85f29d-de4f-4500-8d78-42d5e2a941ee" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:35:08.053: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-3601" for this suite.
Dec 17 14:35:14.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:14.289: INFO: namespace security-context-test-3601 deletion completed in 6.228282937s

• [SLOW TEST:8.326 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:35:14.289: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:35:14.916: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 14:35:16.940: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190114, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190114, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190114, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190114, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:35:19.968: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:35:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7071-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:35:21.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1350" for this suite.
Dec 17 14:35:27.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:27.398: INFO: namespace webhook-1350 deletion completed in 6.240293311s
STEP: Destroying namespace "webhook-1350-markers" for this suite.
Dec 17 14:35:33.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:33.655: INFO: namespace webhook-1350-markers deletion completed in 6.256459844s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.404 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:35:33.694: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:35:33.743: INFO: Creating deployment "webserver-deployment"
Dec 17 14:35:33.752: INFO: Waiting for observed generation 1
Dec 17 14:35:35.766: INFO: Waiting for all required pods to come up
Dec 17 14:35:35.778: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 17 14:35:35.778: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 17 14:35:35.824: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 17 14:35:35.839: INFO: Updating deployment webserver-deployment
Dec 17 14:35:35.839: INFO: Waiting for observed generation 2
Dec 17 14:35:37.876: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 17 14:35:37.885: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 17 14:35:37.905: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 17 14:35:37.926: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 17 14:35:37.926: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 17 14:35:37.930: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 17 14:35:37.946: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 17 14:35:37.946: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 17 14:35:37.959: INFO: Updating deployment webserver-deployment
Dec 17 14:35:37.960: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 17 14:35:37.974: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 17 14:35:39.992: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 17 14:35:40.040: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-8922 /apis/apps/v1/namespaces/deployment-8922/deployments/webserver-deployment 72d05183-7e22-4245-acfd-07a4fbd8ba0b 268358 3 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0050499a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:14,UnavailableReplicas:19,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-17 14:35:37 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-17 14:35:39 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,},},ReadyReplicas:14,CollisionCount:nil,},}

Dec 17 14:35:40.111: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-8922 /apis/apps/v1/namespaces/deployment-8922/replicasets/webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 268263 3 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 72d05183-7e22-4245-acfd-07a4fbd8ba0b 0xc004875667 0xc004875668}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004875758 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 17 14:35:40.111: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 17 14:35:40.111: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-8922 /apis/apps/v1/namespaces/deployment-8922/replicasets/webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 268357 3 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 72d05183-7e22-4245-acfd-07a4fbd8ba0b 0xc0048755a7 0xc0048755a8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004875608 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:14,AvailableReplicas:14,Conditions:[]ReplicaSetCondition{},},}
Dec 17 14:35:40.129: INFO: Pod "webserver-deployment-595b5b9587-2n2tf" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2n2tf webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-2n2tf ed1f0dc0-5cc2-4eb0-9a32-4825b714b428 268105 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc005049f97 0xc005049f98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.47,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2d6dfc37ce9f306aaf368c3e97cb4a0aae56a8b220679c691a44504d8f2ebc72,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.47,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.129: INFO: Pod "webserver-deployment-595b5b9587-4jnb5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4jnb5 webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-4jnb5 7655e913-b17c-4bfd-b6b6-bbd904f5547d 268257 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038ae140 0xc0038ae141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.129: INFO: Pod "webserver-deployment-595b5b9587-4w5gf" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4w5gf webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-4w5gf 3fe21b4f-9491-4ab0-9a74-db9ee55128fa 268083 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038ae320 0xc0038ae321}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.32,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://bd6f929abf7dfc6d4f042f1b40dd914b052e1c385a2c576b01e607ab161db455,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.129: INFO: Pod "webserver-deployment-595b5b9587-5q7hs" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5q7hs webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-5q7hs 3026b358-6936-43cd-b082-dcc137c161bb 268110 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038ae4c0 0xc0038ae4c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.39,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://bf77beb499d1a950b3eda48afe73c260eb5f04dfddc1a6564b46ab7bdc1b5425,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-6gz4k" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6gz4k webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-6gz4k 11a66c5a-1a86-4d5c-afb2-3f4945f312d5 268343 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038ae6e0 0xc0038ae6e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.46,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2563649de2ac247f72343aa78584716cb9881e01c517140ded8fdc5e54548d7b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-7rvln" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7rvln webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-7rvln ef82e333-9318-4958-a664-5f0e30748bbe 268200 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038ae8e0 0xc0038ae8e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-94jf5" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-94jf5 webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-94jf5 d2c5e007-8550-43c8-a419-b229fbad8c77 268089 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038aea90 0xc0038aea91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.26,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://cf39736338e1990b50511302e0629c4375fe87a15419e27e6d4e7cceb8276128,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.26,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-9wr5h" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9wr5h webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-9wr5h 43dfdb92-4429-4082-91e6-34940facc82e 268092 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038aec50 0xc0038aec51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.37,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://17d2a71ebd792070a43234ce0d956c381d94f74ae3dcf4270ba27dfb6e7e950f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-bpvhw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bpvhw webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-bpvhw 37a91e49-1ef7-494a-9c6b-1ceb6cdbf60d 268269 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038aede0 0xc0038aede1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.130: INFO: Pod "webserver-deployment-595b5b9587-clllj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-clllj webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-clllj a9663237-bd0a-4c05-aed2-937b2397e83b 268325 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038aef80 0xc0038aef81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.41,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://241b6582361e360a0b58ed3c2a048a4b84a0b96b15060e5276c1d35962722217,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-gqmpl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gqmpl webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-gqmpl eaabf39a-f28a-4c56-9cd4-27130706a626 268106 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af190 0xc0038af191}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.19,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0753a22ff748d456768d9f3e80849324f821d84091ff335bef8f24482ea77958,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.19,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-kr5qv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kr5qv webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-kr5qv 0ea70f1a-355b-4bc2-8733-5a33f4338c6c 268333 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af350 0xc0038af351}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.49,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://96ee738347e4a57588973b4f9154840d5dfbb7b58242866038cdbc8f93554f0f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.49,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-np6n8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-np6n8 webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-np6n8 6b66b383-bc64-46f3-b1f3-b589e22f57e7 268353 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af4c0 0xc0038af4c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:10.0.0.40,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://52eb082685aa9f1f1f384f373004b0263d5c56fb25a5306f82686e2f0a368459,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-qr8h9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qr8h9 webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-qr8h9 5538c4e5-c777-4454-9999-cab23622029d 268342 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af620 0xc0038af621}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:10.0.0.33,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a81d59d0c9689e587560f003ab750f1f10995e7527fe141786f7be5c54fc836e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-r2pqs" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r2pqs webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-r2pqs ce75d7c6-4a42-4977-97d8-22ed933b9cce 268086 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af7d0 0xc0038af7d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:34 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:10.0.0.36,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8bda92381d9b361cc99620266487f0105e57ce61a0f21c24494f76cb992c2442,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.131: INFO: Pod "webserver-deployment-595b5b9587-sv5gj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-sv5gj webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-sv5gj df238c70-7a20-4dcf-9a50-37569f6aec26 268271 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038af970 0xc0038af971}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-595b5b9587-vqqgp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vqqgp webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-vqqgp 9a27686d-2a35-4c6e-a30d-079a5b2b1868 268278 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038afac0 0xc0038afac1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-595b5b9587-wtphc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wtphc webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-wtphc 1947b925-d72c-45fc-abb9-46d7b99f3075 268095 0 2019-12-17 14:35:33 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038afc00 0xc0038afc01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:33 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:10.0.0.11,StartTime:2019-12-17 14:35:33 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://58ef5a41c295d3337f984c6d8c222c2ece74ccacadba6c7caaf7a08f47e36551,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.11,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-595b5b9587-xnjv5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xnjv5 webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-xnjv5 2da411a5-2793-4b32-8313-02f77573bc0f 268264 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038afd60 0xc0038afd61}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-595b5b9587-zwfnj" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zwfnj webserver-deployment-595b5b9587- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-595b5b9587-zwfnj d37867a1-a405-4c32-8737-84658a359dff 268355 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 02daddf1-1eba-4025-b95b-2546c706c4dc 0xc0038afea0 0xc0038afea1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:10.0.0.6,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-17 14:35:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://df678632757dc20216492321ba956668c49727123ed16961f95ed32cd1f56220,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.0.0.6,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-c7997dcc8-49gft" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-49gft webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-49gft c9a6037a-44fb-4b2b-a767-2d252f238f7e 268237 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492000 0xc003492001}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:,StartTime:2019-12-17 14:35:37 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-c7997dcc8-7d6zc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7d6zc webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-7d6zc 7b684984-67e6-4234-9ad2-98db7361822d 268314 0 2019-12-17 14:35:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc0034921f0 0xc0034921f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.132: INFO: Pod "webserver-deployment-c7997dcc8-7gvhw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7gvhw webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-7gvhw 58fa9e7c-2997-4c15-ad71-b5bcdf53bc6f 268158 0 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc0034923a0 0xc0034923a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:36 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-9k9v7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-9k9v7 webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-9k9v7 95b4f85d-198c-4330-9e62-3c0b29601ee4 268332 0 2019-12-17 14:35:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492560 0xc003492561}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-gjj6k" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gjj6k webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-gjj6k a34ac057-8ec2-4bc7-b2d0-0645e8b64122 268250 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492700 0xc003492701}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-hcpvj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hcpvj webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-hcpvj b28ba826-585e-49cf-a440-b64f70f907de 268273 0 2019-12-17 14:35:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492890 0xc003492891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-ktqbd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ktqbd webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-ktqbd 40a63bcb-b1dc-452a-bcf5-38197f16196f 268279 0 2019-12-17 14:35:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492a30 0xc003492a31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-lr2s6" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lr2s6 webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-lr2s6 be368982-61a5-4bfa-9855-9db27b882c37 268262 0 2019-12-17 14:35:37 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492ba0 0xc003492ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-q8ncf" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-q8ncf webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-q8ncf 50fbdfeb-376e-4ac2-98cb-ac2b060658b7 268141 0 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492de0 0xc003492de1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm923c-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.5,PodIP:,StartTime:2019-12-17 14:35:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.133: INFO: Pod "webserver-deployment-c7997dcc8-rjj6p" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rjj6p webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-rjj6p e2d4a480-cae1-4bd0-8e3a-bf62188bb9c3 268163 0 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003492fc0 0xc003492fc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.134: INFO: Pod "webserver-deployment-c7997dcc8-vkt77" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vkt77 webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-vkt77 2d4d92bd-2684-4b2c-a8b1-dba978eb82e2 268126 0 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc0034931a0 0xc0034931a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.134: INFO: Pod "webserver-deployment-c7997dcc8-zcsct" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zcsct webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-zcsct 942a744c-7673-4aa0-b328-6ce8c4afffcd 268132 0 2019-12-17 14:35:35 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003493360 0xc003493361}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm2x4q-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.4,PodIP:,StartTime:2019-12-17 14:35:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 17 14:35:40.134: INFO: Pod "webserver-deployment-c7997dcc8-znbtp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-znbtp webserver-deployment-c7997dcc8- deployment-8922 /api/v1/namespaces/deployment-8922/pods/webserver-deployment-c7997dcc8-znbtp 0d271d1b-b3e0-4d10-a2a6-6efa4dc5596e 268312 0 2019-12-17 14:35:38 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2495fc00-8a64-491a-8ebf-b9272a80ef32 0xc003493510 0xc003493511}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wdrvs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wdrvs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wdrvs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:k8s-node-vm4x4d-7kwnapovj8,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-17 14:35:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.32.3,PodIP:,StartTime:2019-12-17 14:35:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:35:40.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8922" for this suite.
Dec 17 14:35:50.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:50.444: INFO: namespace deployment-8922 deletion completed in 10.272874881s

• [SLOW TEST:16.750 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:35:50.444: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 17 14:35:51.102: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 14:35:51.102143      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:35:51.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1425" for this suite.
Dec 17 14:35:57.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:35:57.330: INFO: namespace gc-1425 deletion completed in 6.213488289s

• [SLOW TEST:6.886 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:35:57.330: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 14:35:57.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5158'
Dec 17 14:35:57.448: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 14:35:57.448: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec 17 14:35:57.460: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec 17 14:35:57.478: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 17 14:35:57.485: INFO: scanned /root for discovery docs: <nil>
Dec 17 14:35:57.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5158'
Dec 17 14:36:13.332: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 17 14:36:13.332: INFO: stdout: "Created e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7\nScaling up e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 17 14:36:13.332: INFO: stdout: "Created e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7\nScaling up e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 17 14:36:13.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5158'
Dec 17 14:36:13.398: INFO: stderr: ""
Dec 17 14:36:13.398: INFO: stdout: "e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7-hzc7k "
Dec 17 14:36:13.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7-hzc7k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5158'
Dec 17 14:36:13.459: INFO: stderr: ""
Dec 17 14:36:13.459: INFO: stdout: "true"
Dec 17 14:36:13.459: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 get pods e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7-hzc7k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5158'
Dec 17 14:36:13.515: INFO: stderr: ""
Dec 17 14:36:13.515: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 17 14:36:13.515: INFO: e2e-test-httpd-rc-6698c833043a6252e56763ce9eab30d7-hzc7k is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 17 14:36:13.515: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete rc e2e-test-httpd-rc --namespace=kubectl-5158'
Dec 17 14:36:13.589: INFO: stderr: ""
Dec 17 14:36:13.589: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:36:13.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5158" for this suite.
Dec 17 14:36:19.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:36:19.841: INFO: namespace kubectl-5158 deletion completed in 6.237256228s

• [SLOW TEST:22.511 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:36:19.841: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-754
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 17 14:36:19.898: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 17 14:36:42.084: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.0.0.13 8081 | grep -v '^\s*$'] Namespace:pod-network-test-754 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:36:42.084: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:36:43.173: INFO: Found all expected endpoints: [netserver-0]
Dec 17 14:36:43.181: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.0.0.26 8081 | grep -v '^\s*$'] Namespace:pod-network-test-754 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:36:43.182: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:36:44.259: INFO: Found all expected endpoints: [netserver-1]
Dec 17 14:36:44.263: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.0.0.27 8081 | grep -v '^\s*$'] Namespace:pod-network-test-754 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 17 14:36:44.263: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
Dec 17 14:36:45.346: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:36:45.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-754" for this suite.
Dec 17 14:36:57.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:36:57.613: INFO: namespace pod-network-test-754 deletion completed in 12.252287771s

• [SLOW TEST:37.772 seconds]
[sig-network] Networking
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:36:57.613: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:37:00.724: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6806" for this suite.
Dec 17 14:37:12.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:37:12.989: INFO: namespace replication-controller-6806 deletion completed in 12.251024299s

• [SLOW TEST:15.376 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:37:12.989: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 17 14:37:14.069: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:37:14.100: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2910" for this suite.
Dec 17 14:37:20.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:37:20.346: INFO: namespace container-runtime-2910 deletion completed in 6.236895341s

• [SLOW TEST:7.357 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:37:20.346: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 17 14:37:26.474: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1217 14:37:26.474482      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:37:26.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7022" for this suite.
Dec 17 14:37:34.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:37:34.725: INFO: namespace gc-7022 deletion completed in 8.243981836s

• [SLOW TEST:14.379 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:37:34.726: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:37:34.792: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 17 14:37:37.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 create -f -'
Dec 17 14:37:37.837: INFO: stderr: ""
Dec 17 14:37:37.837: INFO: stdout: "e2e-test-crd-publish-openapi-9287-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 17 14:37:37.837: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 delete e2e-test-crd-publish-openapi-9287-crds test-foo'
Dec 17 14:37:37.939: INFO: stderr: ""
Dec 17 14:37:37.939: INFO: stdout: "e2e-test-crd-publish-openapi-9287-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 17 14:37:37.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 apply -f -'
Dec 17 14:37:38.091: INFO: stderr: ""
Dec 17 14:37:38.091: INFO: stdout: "e2e-test-crd-publish-openapi-9287-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 17 14:37:38.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 delete e2e-test-crd-publish-openapi-9287-crds test-foo'
Dec 17 14:37:38.195: INFO: stderr: ""
Dec 17 14:37:38.195: INFO: stdout: "e2e-test-crd-publish-openapi-9287-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 17 14:37:38.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 create -f -'
Dec 17 14:37:38.310: INFO: rc: 1
Dec 17 14:37:38.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 apply -f -'
Dec 17 14:37:38.428: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 17 14:37:38.428: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 create -f -'
Dec 17 14:37:38.543: INFO: rc: 1
Dec 17 14:37:38.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 --namespace=crd-publish-openapi-1581 apply -f -'
Dec 17 14:37:38.656: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 17 14:37:38.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-9287-crds'
Dec 17 14:37:38.782: INFO: stderr: ""
Dec 17 14:37:38.782: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9287-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 17 14:37:38.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-9287-crds.metadata'
Dec 17 14:37:38.903: INFO: stderr: ""
Dec 17 14:37:38.903: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9287-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 17 14:37:38.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-9287-crds.spec'
Dec 17 14:37:39.043: INFO: stderr: ""
Dec 17 14:37:39.043: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9287-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 17 14:37:39.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-9287-crds.spec.bars'
Dec 17 14:37:39.164: INFO: stderr: ""
Dec 17 14:37:39.164: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9287-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 17 14:37:39.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 explain e2e-test-crd-publish-openapi-9287-crds.spec.bars2'
Dec 17 14:37:39.285: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:37:41.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1581" for this suite.
Dec 17 14:37:48.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:37:48.229: INFO: namespace crd-publish-openapi-1581 deletion completed in 6.240679047s

• [SLOW TEST:13.503 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:37:48.229: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 17 14:37:48.306: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1566 /api/v1/namespaces/watch-1566/configmaps/e2e-watch-test-watch-closed 6a8cfda6-b91f-4437-87ec-2ce06bfe13ff 269397 0 2019-12-17 14:37:48 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 17 14:37:48.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1566 /api/v1/namespaces/watch-1566/configmaps/e2e-watch-test-watch-closed 6a8cfda6-b91f-4437-87ec-2ce06bfe13ff 269398 0 2019-12-17 14:37:48 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 17 14:37:48.339: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1566 /api/v1/namespaces/watch-1566/configmaps/e2e-watch-test-watch-closed 6a8cfda6-b91f-4437-87ec-2ce06bfe13ff 269399 0 2019-12-17 14:37:48 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 17 14:37:48.339: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1566 /api/v1/namespaces/watch-1566/configmaps/e2e-watch-test-watch-closed 6a8cfda6-b91f-4437-87ec-2ce06bfe13ff 269400 0 2019-12-17 14:37:48 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:37:48.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1566" for this suite.
Dec 17 14:37:54.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:37:54.585: INFO: namespace watch-1566 deletion completed in 6.23201275s

• [SLOW TEST:6.356 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:37:54.585: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 17 14:37:54.978: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 17 14:37:57.001: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190274, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190274, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190274, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712190274, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 17 14:38:00.037: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:38:00.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4269" for this suite.
Dec 17 14:38:06.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:38:06.341: INFO: namespace webhook-4269 deletion completed in 6.214017725s
STEP: Destroying namespace "webhook-4269-markers" for this suite.
Dec 17 14:38:12.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:38:12.580: INFO: namespace webhook-4269-markers deletion completed in 6.238754793s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.033 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:38:12.618: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-43645013-690d-44c5-9e7f-0088c4ee5f6c
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-43645013-690d-44c5-9e7f-0088c4ee5f6c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:38:16.795: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6555" for this suite.
Dec 17 14:38:32.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:38:33.057: INFO: namespace configmap-6555 deletion completed in 16.247893705s

• [SLOW TEST:20.439 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:38:33.057: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-b8c9a481-d481-448b-ab9e-04986f2d9c67
STEP: Creating a pod to test consume configMaps
Dec 17 14:38:33.121: INFO: Waiting up to 5m0s for pod "pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f" in namespace "configmap-9394" to be "success or failure"
Dec 17 14:38:33.129: INFO: Pod "pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.330344ms
Dec 17 14:38:35.135: INFO: Pod "pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013753074s
STEP: Saw pod success
Dec 17 14:38:35.135: INFO: Pod "pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f" satisfied condition "success or failure"
Dec 17 14:38:35.143: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f container configmap-volume-test: <nil>
STEP: delete the pod
Dec 17 14:38:35.190: INFO: Waiting for pod pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f to disappear
Dec 17 14:38:35.196: INFO: Pod pod-configmaps-738ad3c9-8deb-448d-a233-ef308ad13f5f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:38:35.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9394" for this suite.
Dec 17 14:38:41.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:38:41.430: INFO: namespace configmap-9394 deletion completed in 6.218944019s

• [SLOW TEST:8.372 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:38:41.430: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 in namespace container-probe-2489
Dec 17 14:38:43.524: INFO: Started pod liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 in namespace container-probe-2489
STEP: checking the pod's current state and verifying that restartCount is present
Dec 17 14:38:43.528: INFO: Initial restart count of pod liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is 0
Dec 17 14:38:59.598: INFO: Restart count of pod container-probe-2489/liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is now 1 (16.069961136s elapsed)
Dec 17 14:39:19.686: INFO: Restart count of pod container-probe-2489/liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is now 2 (36.158056691s elapsed)
Dec 17 14:39:39.759: INFO: Restart count of pod container-probe-2489/liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is now 3 (56.230885064s elapsed)
Dec 17 14:39:59.840: INFO: Restart count of pod container-probe-2489/liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is now 4 (1m16.311444891s elapsed)
Dec 17 14:41:10.123: INFO: Restart count of pod container-probe-2489/liveness-46856c3b-6e6b-4884-bc12-f1ad6f5d2b51 is now 5 (2m26.594603164s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:10.146: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2489" for this suite.
Dec 17 14:41:16.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:41:16.384: INFO: namespace container-probe-2489 deletion completed in 6.22344736s

• [SLOW TEST:154.954 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:41:16.384: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 17 14:41:16.448: INFO: Waiting up to 5m0s for pod "downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23" in namespace "projected-3198" to be "success or failure"
Dec 17 14:41:16.457: INFO: Pod "downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23": Phase="Pending", Reason="", readiness=false. Elapsed: 9.512403ms
Dec 17 14:41:18.466: INFO: Pod "downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018473589s
STEP: Saw pod success
Dec 17 14:41:18.466: INFO: Pod "downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23" satisfied condition "success or failure"
Dec 17 14:41:18.471: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23 container client-container: <nil>
STEP: delete the pod
Dec 17 14:41:18.526: INFO: Waiting for pod downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23 to disappear
Dec 17 14:41:18.533: INFO: Pod downwardapi-volume-43f9b4f9-a24b-4613-92c7-201f6a5d0f23 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:18.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3198" for this suite.
Dec 17 14:41:24.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:41:24.808: INFO: namespace projected-3198 deletion completed in 6.262108734s

• [SLOW TEST:8.424 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:41:24.808: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5777/configmap-test-7340f78f-25ce-4aa0-94e7-5c79f5c37238
STEP: Creating a pod to test consume configMaps
Dec 17 14:41:24.878: INFO: Waiting up to 5m0s for pod "pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8" in namespace "configmap-5777" to be "success or failure"
Dec 17 14:41:24.887: INFO: Pod "pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8": Phase="Pending", Reason="", readiness=false. Elapsed: 8.578078ms
Dec 17 14:41:26.892: INFO: Pod "pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013830802s
STEP: Saw pod success
Dec 17 14:41:26.892: INFO: Pod "pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8" satisfied condition "success or failure"
Dec 17 14:41:26.901: INFO: Trying to get logs from node k8s-node-vm2x4q-7kwnapovj8 pod pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8 container env-test: <nil>
STEP: delete the pod
Dec 17 14:41:26.959: INFO: Waiting for pod pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8 to disappear
Dec 17 14:41:26.963: INFO: Pod pod-configmaps-6cc6a3bf-8544-413a-b5da-45c9f05610b8 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:26.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5777" for this suite.
Dec 17 14:41:33.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:41:33.200: INFO: namespace configmap-5777 deletion completed in 6.22261353s

• [SLOW TEST:8.391 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:41:33.200: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 17 14:41:33.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 cluster-info'
Dec 17 14:41:33.308: INFO: stderr: ""
Dec 17 14:41:33.308: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.0.56.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.0.56.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:33.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4233" for this suite.
Dec 17 14:41:39.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:41:39.559: INFO: namespace kubectl-4233 deletion completed in 6.237035191s

• [SLOW TEST:6.359 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:41:39.559: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-lkvd6 in namespace proxy-4053
I1217 14:41:39.629973      25 runners.go:184] Created replication controller with name: proxy-service-lkvd6, namespace: proxy-4053, replica count: 1
I1217 14:41:40.680288      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1217 14:41:41.680704      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:42.680879      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:43.681182      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:44.681338      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:45.681605      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:46.681775      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:47.682022      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1217 14:41:48.682344      25 runners.go:184] proxy-service-lkvd6 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 17 14:41:48.687: INFO: setup took 9.078690764s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 17 14:41:48.698: INFO: (0) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 10.655268ms)
Dec 17 14:41:48.699: INFO: (0) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 12.457357ms)
Dec 17 14:41:48.702: INFO: (0) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 15.068498ms)
Dec 17 14:41:48.702: INFO: (0) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.86563ms)
Dec 17 14:41:48.704: INFO: (0) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 16.908388ms)
Dec 17 14:41:48.704: INFO: (0) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 17.051944ms)
Dec 17 14:41:48.704: INFO: (0) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 17.37253ms)
Dec 17 14:41:48.705: INFO: (0) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 17.359377ms)
Dec 17 14:41:48.705: INFO: (0) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 17.758103ms)
Dec 17 14:41:48.705: INFO: (0) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 18.107684ms)
Dec 17 14:41:48.706: INFO: (0) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 18.955048ms)
Dec 17 14:41:48.706: INFO: (0) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 18.93911ms)
Dec 17 14:41:48.707: INFO: (0) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 19.70782ms)
Dec 17 14:41:48.707: INFO: (0) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 20.050668ms)
Dec 17 14:41:48.709: INFO: (0) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 21.717787ms)
Dec 17 14:41:48.710: INFO: (0) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 22.695989ms)
Dec 17 14:41:48.717: INFO: (1) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 6.663124ms)
Dec 17 14:41:48.720: INFO: (1) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 10.170735ms)
Dec 17 14:41:48.721: INFO: (1) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 10.643503ms)
Dec 17 14:41:48.721: INFO: (1) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 10.618343ms)
Dec 17 14:41:48.721: INFO: (1) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 10.923146ms)
Dec 17 14:41:48.722: INFO: (1) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 11.943509ms)
Dec 17 14:41:48.723: INFO: (1) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 13.36663ms)
Dec 17 14:41:48.724: INFO: (1) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 13.567159ms)
Dec 17 14:41:48.726: INFO: (1) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 16.001665ms)
Dec 17 14:41:48.726: INFO: (1) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 16.43707ms)
Dec 17 14:41:48.727: INFO: (1) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 16.564444ms)
Dec 17 14:41:48.729: INFO: (1) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 18.698604ms)
Dec 17 14:41:48.729: INFO: (1) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 19.402617ms)
Dec 17 14:41:48.730: INFO: (1) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 20.387541ms)
Dec 17 14:41:48.731: INFO: (1) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 21.160956ms)
Dec 17 14:41:48.734: INFO: (1) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 24.274368ms)
Dec 17 14:41:48.741: INFO: (2) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 6.999681ms)
Dec 17 14:41:48.744: INFO: (2) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 9.081216ms)
Dec 17 14:41:48.744: INFO: (2) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.097995ms)
Dec 17 14:41:48.745: INFO: (2) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 10.249662ms)
Dec 17 14:41:48.746: INFO: (2) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 11.128629ms)
Dec 17 14:41:48.749: INFO: (2) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 14.267967ms)
Dec 17 14:41:48.749: INFO: (2) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.406386ms)
Dec 17 14:41:48.749: INFO: (2) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.380526ms)
Dec 17 14:41:48.750: INFO: (2) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 15.700192ms)
Dec 17 14:41:48.750: INFO: (2) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 15.739975ms)
Dec 17 14:41:48.751: INFO: (2) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 16.286689ms)
Dec 17 14:41:48.752: INFO: (2) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 17.70205ms)
Dec 17 14:41:48.752: INFO: (2) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.79274ms)
Dec 17 14:41:48.753: INFO: (2) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 18.428862ms)
Dec 17 14:41:48.756: INFO: (2) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 21.921044ms)
Dec 17 14:41:48.757: INFO: (2) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 21.789075ms)
Dec 17 14:41:48.763: INFO: (3) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 6.102553ms)
Dec 17 14:41:48.765: INFO: (3) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 7.786386ms)
Dec 17 14:41:48.765: INFO: (3) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 7.845302ms)
Dec 17 14:41:48.768: INFO: (3) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 10.734842ms)
Dec 17 14:41:48.768: INFO: (3) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 11.28228ms)
Dec 17 14:41:48.770: INFO: (3) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 12.847433ms)
Dec 17 14:41:48.771: INFO: (3) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.583996ms)
Dec 17 14:41:48.772: INFO: (3) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.094963ms)
Dec 17 14:41:48.772: INFO: (3) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.307245ms)
Dec 17 14:41:48.773: INFO: (3) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.481682ms)
Dec 17 14:41:48.773: INFO: (3) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 15.489306ms)
Dec 17 14:41:48.773: INFO: (3) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.506589ms)
Dec 17 14:41:48.775: INFO: (3) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 17.318785ms)
Dec 17 14:41:48.775: INFO: (3) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 18.066286ms)
Dec 17 14:41:48.777: INFO: (3) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 20.617396ms)
Dec 17 14:41:48.779: INFO: (3) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 21.693822ms)
Dec 17 14:41:48.789: INFO: (4) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.401972ms)
Dec 17 14:41:48.789: INFO: (4) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 9.322977ms)
Dec 17 14:41:48.789: INFO: (4) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 9.594842ms)
Dec 17 14:41:48.789: INFO: (4) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 10.124277ms)
Dec 17 14:41:48.790: INFO: (4) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 10.668277ms)
Dec 17 14:41:48.792: INFO: (4) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 12.486246ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.562014ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.52292ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 15.54119ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 15.758144ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 16.014679ms)
Dec 17 14:41:48.795: INFO: (4) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.865493ms)
Dec 17 14:41:48.797: INFO: (4) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 17.889474ms)
Dec 17 14:41:48.797: INFO: (4) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 18.118309ms)
Dec 17 14:41:48.799: INFO: (4) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 19.898101ms)
Dec 17 14:41:48.801: INFO: (4) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 22.021628ms)
Dec 17 14:41:48.810: INFO: (5) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 8.314573ms)
Dec 17 14:41:48.812: INFO: (5) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.909551ms)
Dec 17 14:41:48.812: INFO: (5) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 10.139299ms)
Dec 17 14:41:48.812: INFO: (5) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 10.734752ms)
Dec 17 14:41:48.813: INFO: (5) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 12.046541ms)
Dec 17 14:41:48.814: INFO: (5) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 12.619379ms)
Dec 17 14:41:48.817: INFO: (5) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.947824ms)
Dec 17 14:41:48.817: INFO: (5) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.655569ms)
Dec 17 14:41:48.817: INFO: (5) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.485268ms)
Dec 17 14:41:48.818: INFO: (5) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.753018ms)
Dec 17 14:41:48.818: INFO: (5) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.993541ms)
Dec 17 14:41:48.819: INFO: (5) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 17.397247ms)
Dec 17 14:41:48.819: INFO: (5) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 17.48039ms)
Dec 17 14:41:48.819: INFO: (5) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 18.078144ms)
Dec 17 14:41:48.822: INFO: (5) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 20.58509ms)
Dec 17 14:41:48.823: INFO: (5) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 21.662955ms)
Dec 17 14:41:48.830: INFO: (6) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 7.057587ms)
Dec 17 14:41:48.832: INFO: (6) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 8.185688ms)
Dec 17 14:41:48.833: INFO: (6) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.767235ms)
Dec 17 14:41:48.833: INFO: (6) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.92615ms)
Dec 17 14:41:48.833: INFO: (6) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.945559ms)
Dec 17 14:41:48.835: INFO: (6) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 11.412185ms)
Dec 17 14:41:48.837: INFO: (6) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 13.439103ms)
Dec 17 14:41:48.837: INFO: (6) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 13.581939ms)
Dec 17 14:41:48.839: INFO: (6) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 16.042386ms)
Dec 17 14:41:48.839: INFO: (6) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 16.005782ms)
Dec 17 14:41:48.839: INFO: (6) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 15.763409ms)
Dec 17 14:41:48.840: INFO: (6) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 16.541345ms)
Dec 17 14:41:48.840: INFO: (6) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 16.538568ms)
Dec 17 14:41:48.844: INFO: (6) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 20.307184ms)
Dec 17 14:41:48.845: INFO: (6) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 21.798552ms)
Dec 17 14:41:48.848: INFO: (6) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 23.920313ms)
Dec 17 14:41:48.854: INFO: (7) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 6.475422ms)
Dec 17 14:41:48.856: INFO: (7) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 8.173231ms)
Dec 17 14:41:48.856: INFO: (7) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 8.457299ms)
Dec 17 14:41:48.856: INFO: (7) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 8.533654ms)
Dec 17 14:41:48.857: INFO: (7) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 9.666155ms)
Dec 17 14:41:48.858: INFO: (7) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 10.359988ms)
Dec 17 14:41:48.860: INFO: (7) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 12.84302ms)
Dec 17 14:41:48.862: INFO: (7) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 13.695275ms)
Dec 17 14:41:48.862: INFO: (7) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 13.901808ms)
Dec 17 14:41:48.862: INFO: (7) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.154782ms)
Dec 17 14:41:48.862: INFO: (7) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.434825ms)
Dec 17 14:41:48.866: INFO: (7) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.569795ms)
Dec 17 14:41:48.866: INFO: (7) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 17.922778ms)
Dec 17 14:41:48.866: INFO: (7) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 17.82321ms)
Dec 17 14:41:48.869: INFO: (7) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 21.17518ms)
Dec 17 14:41:48.870: INFO: (7) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 21.977942ms)
Dec 17 14:41:48.877: INFO: (8) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 7.308579ms)
Dec 17 14:41:48.879: INFO: (8) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.158226ms)
Dec 17 14:41:48.880: INFO: (8) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 9.528845ms)
Dec 17 14:41:48.882: INFO: (8) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 11.819258ms)
Dec 17 14:41:48.885: INFO: (8) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.262517ms)
Dec 17 14:41:48.886: INFO: (8) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.64943ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 16.798543ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 16.816666ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 16.857813ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 16.879876ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 16.800838ms)
Dec 17 14:41:48.887: INFO: (8) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 16.981468ms)
Dec 17 14:41:48.888: INFO: (8) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 17.827082ms)
Dec 17 14:41:48.888: INFO: (8) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 18.287086ms)
Dec 17 14:41:48.889: INFO: (8) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 18.449794ms)
Dec 17 14:41:48.892: INFO: (8) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 21.810028ms)
Dec 17 14:41:48.902: INFO: (9) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 9.66056ms)
Dec 17 14:41:48.902: INFO: (9) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 9.392463ms)
Dec 17 14:41:48.902: INFO: (9) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.750165ms)
Dec 17 14:41:48.903: INFO: (9) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 11.229117ms)
Dec 17 14:41:48.905: INFO: (9) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 13.387321ms)
Dec 17 14:41:48.907: INFO: (9) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.353027ms)
Dec 17 14:41:48.907: INFO: (9) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.212209ms)
Dec 17 14:41:48.907: INFO: (9) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.177387ms)
Dec 17 14:41:48.910: INFO: (9) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 17.250556ms)
Dec 17 14:41:48.911: INFO: (9) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 18.294295ms)
Dec 17 14:41:48.911: INFO: (9) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 18.555984ms)
Dec 17 14:41:48.911: INFO: (9) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 18.464783ms)
Dec 17 14:41:48.911: INFO: (9) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 18.500442ms)
Dec 17 14:41:48.911: INFO: (9) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 19.008508ms)
Dec 17 14:41:48.915: INFO: (9) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 23.104559ms)
Dec 17 14:41:48.916: INFO: (9) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 23.364642ms)
Dec 17 14:41:48.926: INFO: (10) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 10.385378ms)
Dec 17 14:41:48.926: INFO: (10) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 10.383535ms)
Dec 17 14:41:48.926: INFO: (10) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 10.535077ms)
Dec 17 14:41:48.927: INFO: (10) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 11.086646ms)
Dec 17 14:41:48.929: INFO: (10) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 13.471403ms)
Dec 17 14:41:48.931: INFO: (10) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.478564ms)
Dec 17 14:41:48.931: INFO: (10) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 15.385403ms)
Dec 17 14:41:48.931: INFO: (10) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 15.685673ms)
Dec 17 14:41:48.933: INFO: (10) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 17.164876ms)
Dec 17 14:41:48.933: INFO: (10) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 17.426508ms)
Dec 17 14:41:48.933: INFO: (10) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 17.395439ms)
Dec 17 14:41:48.934: INFO: (10) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 18.663449ms)
Dec 17 14:41:48.934: INFO: (10) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 18.620657ms)
Dec 17 14:41:48.935: INFO: (10) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 19.110847ms)
Dec 17 14:41:48.935: INFO: (10) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 19.397742ms)
Dec 17 14:41:48.939: INFO: (10) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 22.780491ms)
Dec 17 14:41:48.948: INFO: (11) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 9.246001ms)
Dec 17 14:41:48.948: INFO: (11) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 9.289499ms)
Dec 17 14:41:48.948: INFO: (11) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.169048ms)
Dec 17 14:41:48.949: INFO: (11) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 10.529249ms)
Dec 17 14:41:48.950: INFO: (11) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 11.513771ms)
Dec 17 14:41:48.953: INFO: (11) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 14.201403ms)
Dec 17 14:41:48.953: INFO: (11) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 14.259227ms)
Dec 17 14:41:48.953: INFO: (11) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.599597ms)
Dec 17 14:41:48.954: INFO: (11) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 15.143178ms)
Dec 17 14:41:48.954: INFO: (11) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.232383ms)
Dec 17 14:41:48.954: INFO: (11) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.357257ms)
Dec 17 14:41:48.956: INFO: (11) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 16.784444ms)
Dec 17 14:41:48.956: INFO: (11) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 17.313389ms)
Dec 17 14:41:48.957: INFO: (11) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 18.347116ms)
Dec 17 14:41:48.959: INFO: (11) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 20.322437ms)
Dec 17 14:41:48.960: INFO: (11) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 21.596299ms)
Dec 17 14:41:48.970: INFO: (12) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 9.043571ms)
Dec 17 14:41:48.970: INFO: (12) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 9.140384ms)
Dec 17 14:41:48.970: INFO: (12) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.414854ms)
Dec 17 14:41:48.971: INFO: (12) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 10.550497ms)
Dec 17 14:41:48.973: INFO: (12) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 12.622697ms)
Dec 17 14:41:48.974: INFO: (12) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 13.802661ms)
Dec 17 14:41:48.976: INFO: (12) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 15.332958ms)
Dec 17 14:41:48.976: INFO: (12) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.299295ms)
Dec 17 14:41:48.976: INFO: (12) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.623893ms)
Dec 17 14:41:48.976: INFO: (12) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.770756ms)
Dec 17 14:41:48.976: INFO: (12) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 16.129022ms)
Dec 17 14:41:48.977: INFO: (12) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 16.983781ms)
Dec 17 14:41:48.978: INFO: (12) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.707705ms)
Dec 17 14:41:48.979: INFO: (12) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 18.758835ms)
Dec 17 14:41:48.982: INFO: (12) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 21.247584ms)
Dec 17 14:41:48.983: INFO: (12) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 22.214862ms)
Dec 17 14:41:48.992: INFO: (13) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.469707ms)
Dec 17 14:41:48.992: INFO: (13) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 9.460461ms)
Dec 17 14:41:48.992: INFO: (13) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.608941ms)
Dec 17 14:41:48.993: INFO: (13) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.766138ms)
Dec 17 14:41:48.993: INFO: (13) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 10.120393ms)
Dec 17 14:41:48.994: INFO: (13) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 10.947658ms)
Dec 17 14:41:48.996: INFO: (13) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 13.288154ms)
Dec 17 14:41:48.998: INFO: (13) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.687619ms)
Dec 17 14:41:48.998: INFO: (13) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 14.677182ms)
Dec 17 14:41:48.998: INFO: (13) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 14.638651ms)
Dec 17 14:41:48.998: INFO: (13) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 14.841175ms)
Dec 17 14:41:48.998: INFO: (13) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 15.274823ms)
Dec 17 14:41:49.000: INFO: (13) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.416175ms)
Dec 17 14:41:49.002: INFO: (13) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 18.502421ms)
Dec 17 14:41:49.004: INFO: (13) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 20.729516ms)
Dec 17 14:41:49.007: INFO: (13) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 23.995963ms)
Dec 17 14:41:49.015: INFO: (14) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 7.652567ms)
Dec 17 14:41:49.016: INFO: (14) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.09162ms)
Dec 17 14:41:49.017: INFO: (14) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.34959ms)
Dec 17 14:41:49.019: INFO: (14) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 12.120192ms)
Dec 17 14:41:49.023: INFO: (14) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.428578ms)
Dec 17 14:41:49.023: INFO: (14) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 15.217309ms)
Dec 17 14:41:49.023: INFO: (14) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.346796ms)
Dec 17 14:41:49.023: INFO: (14) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 15.483317ms)
Dec 17 14:41:49.023: INFO: (14) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 15.623681ms)
Dec 17 14:41:49.024: INFO: (14) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 16.844121ms)
Dec 17 14:41:49.025: INFO: (14) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 17.861184ms)
Dec 17 14:41:49.025: INFO: (14) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.902245ms)
Dec 17 14:41:49.025: INFO: (14) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 18.046718ms)
Dec 17 14:41:49.025: INFO: (14) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 18.198691ms)
Dec 17 14:41:49.027: INFO: (14) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 20.046352ms)
Dec 17 14:41:49.030: INFO: (14) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 22.446131ms)
Dec 17 14:41:49.042: INFO: (15) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 11.824911ms)
Dec 17 14:41:49.042: INFO: (15) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 11.687006ms)
Dec 17 14:41:49.042: INFO: (15) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 11.62976ms)
Dec 17 14:41:49.042: INFO: (15) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 11.563817ms)
Dec 17 14:41:49.042: INFO: (15) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 12.012336ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 15.681957ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.643941ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 15.267487ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 15.561152ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 15.248528ms)
Dec 17 14:41:49.046: INFO: (15) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 15.668961ms)
Dec 17 14:41:49.047: INFO: (15) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 16.123275ms)
Dec 17 14:41:49.048: INFO: (15) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 17.737714ms)
Dec 17 14:41:49.048: INFO: (15) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 17.61801ms)
Dec 17 14:41:49.053: INFO: (15) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 23.208197ms)
Dec 17 14:41:49.053: INFO: (15) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 22.761752ms)
Dec 17 14:41:49.063: INFO: (16) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 8.793361ms)
Dec 17 14:41:49.063: INFO: (16) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.059115ms)
Dec 17 14:41:49.063: INFO: (16) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.501075ms)
Dec 17 14:41:49.063: INFO: (16) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.895091ms)
Dec 17 14:41:49.065: INFO: (16) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 12.00382ms)
Dec 17 14:41:49.068: INFO: (16) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 14.561425ms)
Dec 17 14:41:49.068: INFO: (16) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 14.400361ms)
Dec 17 14:41:49.069: INFO: (16) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 14.20119ms)
Dec 17 14:41:49.069: INFO: (16) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 14.978867ms)
Dec 17 14:41:49.069: INFO: (16) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 15.430327ms)
Dec 17 14:41:49.069: INFO: (16) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.829545ms)
Dec 17 14:41:49.069: INFO: (16) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 15.712871ms)
Dec 17 14:41:49.071: INFO: (16) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 16.934509ms)
Dec 17 14:41:49.071: INFO: (16) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 17.920441ms)
Dec 17 14:41:49.071: INFO: (16) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 17.493716ms)
Dec 17 14:41:49.075: INFO: (16) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 20.833633ms)
Dec 17 14:41:49.081: INFO: (17) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 6.353747ms)
Dec 17 14:41:49.083: INFO: (17) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 8.239667ms)
Dec 17 14:41:49.083: INFO: (17) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 8.263712ms)
Dec 17 14:41:49.085: INFO: (17) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 10.057129ms)
Dec 17 14:41:49.085: INFO: (17) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 10.270701ms)
Dec 17 14:41:49.085: INFO: (17) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 10.4791ms)
Dec 17 14:41:49.089: INFO: (17) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 14.055347ms)
Dec 17 14:41:49.089: INFO: (17) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.273083ms)
Dec 17 14:41:49.089: INFO: (17) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 14.438165ms)
Dec 17 14:41:49.091: INFO: (17) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 16.001098ms)
Dec 17 14:41:49.091: INFO: (17) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 16.113948ms)
Dec 17 14:41:49.091: INFO: (17) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 16.498539ms)
Dec 17 14:41:49.092: INFO: (17) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 17.511576ms)
Dec 17 14:41:49.095: INFO: (17) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 20.381983ms)
Dec 17 14:41:49.095: INFO: (17) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 20.48713ms)
Dec 17 14:41:49.099: INFO: (17) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 24.353037ms)
Dec 17 14:41:49.109: INFO: (18) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 9.452751ms)
Dec 17 14:41:49.109: INFO: (18) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 9.522582ms)
Dec 17 14:41:49.109: INFO: (18) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.45148ms)
Dec 17 14:41:49.109: INFO: (18) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 9.651302ms)
Dec 17 14:41:49.111: INFO: (18) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 11.017893ms)
Dec 17 14:41:49.111: INFO: (18) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 11.125656ms)
Dec 17 14:41:49.114: INFO: (18) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 14.359819ms)
Dec 17 14:41:49.114: INFO: (18) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 14.260933ms)
Dec 17 14:41:49.114: INFO: (18) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.356231ms)
Dec 17 14:41:49.114: INFO: (18) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 14.459603ms)
Dec 17 14:41:49.114: INFO: (18) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 14.739753ms)
Dec 17 14:41:49.116: INFO: (18) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 16.635206ms)
Dec 17 14:41:49.118: INFO: (18) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 18.551372ms)
Dec 17 14:41:49.118: INFO: (18) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 18.644457ms)
Dec 17 14:41:49.121: INFO: (18) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 21.814171ms)
Dec 17 14:41:49.122: INFO: (18) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 22.253461ms)
Dec 17 14:41:49.131: INFO: (19) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:462/proxy/: tls qux (200; 9.619034ms)
Dec 17 14:41:49.131: INFO: (19) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">... (200; 9.376121ms)
Dec 17 14:41:49.131: INFO: (19) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:443/proxy/tlsrewritem... (200; 9.336644ms)
Dec 17 14:41:49.131: INFO: (19) /api/v1/namespaces/proxy-4053/pods/https:proxy-service-lkvd6-dzts4:460/proxy/: tls baz (200; 9.573912ms)
Dec 17 14:41:49.132: INFO: (19) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:1080/proxy/rewriteme">test<... (200; 9.784157ms)
Dec 17 14:41:49.132: INFO: (19) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 9.9238ms)
Dec 17 14:41:49.135: INFO: (19) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname1/proxy/: tls baz (200; 12.930663ms)
Dec 17 14:41:49.136: INFO: (19) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/: <a href="/api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4/proxy/rewriteme">test</a> (200; 14.040696ms)
Dec 17 14:41:49.136: INFO: (19) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:162/proxy/: bar (200; 13.973306ms)
Dec 17 14:41:49.136: INFO: (19) /api/v1/namespaces/proxy-4053/pods/http:proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 13.913395ms)
Dec 17 14:41:49.136: INFO: (19) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname2/proxy/: bar (200; 14.34637ms)
Dec 17 14:41:49.137: INFO: (19) /api/v1/namespaces/proxy-4053/pods/proxy-service-lkvd6-dzts4:160/proxy/: foo (200; 14.600595ms)
Dec 17 14:41:49.140: INFO: (19) /api/v1/namespaces/proxy-4053/services/http:proxy-service-lkvd6:portname1/proxy/: foo (200; 18.4015ms)
Dec 17 14:41:49.150: INFO: (19) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname2/proxy/: bar (200; 27.816395ms)
Dec 17 14:41:49.150: INFO: (19) /api/v1/namespaces/proxy-4053/services/proxy-service-lkvd6:portname1/proxy/: foo (200; 28.007109ms)
Dec 17 14:41:49.150: INFO: (19) /api/v1/namespaces/proxy-4053/services/https:proxy-service-lkvd6:tlsportname2/proxy/: tls qux (200; 27.905917ms)
STEP: deleting ReplicationController proxy-service-lkvd6 in namespace proxy-4053, will wait for the garbage collector to delete the pods
Dec 17 14:41:49.226: INFO: Deleting ReplicationController proxy-service-lkvd6 took: 18.022974ms
Dec 17 14:41:49.526: INFO: Terminating ReplicationController proxy-service-lkvd6 pods took: 300.169932ms
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:51.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4053" for this suite.
Dec 17 14:41:57.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:41:57.577: INFO: namespace proxy-4053 deletion completed in 6.23572674s

• [SLOW TEST:18.018 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:41:57.577: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 17 14:41:57.637: INFO: Waiting up to 5m0s for pod "pod-21e0eee8-9b52-42ab-952f-5535ef17cd20" in namespace "emptydir-4549" to be "success or failure"
Dec 17 14:41:57.645: INFO: Pod "pod-21e0eee8-9b52-42ab-952f-5535ef17cd20": Phase="Pending", Reason="", readiness=false. Elapsed: 8.269651ms
Dec 17 14:41:59.654: INFO: Pod "pod-21e0eee8-9b52-42ab-952f-5535ef17cd20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017522941s
STEP: Saw pod success
Dec 17 14:41:59.654: INFO: Pod "pod-21e0eee8-9b52-42ab-952f-5535ef17cd20" satisfied condition "success or failure"
Dec 17 14:41:59.662: INFO: Trying to get logs from node k8s-node-vm923c-7kwnapovj8 pod pod-21e0eee8-9b52-42ab-952f-5535ef17cd20 container test-container: <nil>
STEP: delete the pod
Dec 17 14:41:59.700: INFO: Waiting for pod pod-21e0eee8-9b52-42ab-952f-5535ef17cd20 to disappear
Dec 17 14:41:59.704: INFO: Pod pod-21e0eee8-9b52-42ab-952f-5535ef17cd20 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:41:59.704: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4549" for this suite.
Dec 17 14:42:05.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:42:05.930: INFO: namespace emptydir-4549 deletion completed in 6.212024313s

• [SLOW TEST:8.353 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:42:05.930: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 17 14:42:05.980: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 create -f - --namespace=kubectl-3539'
Dec 17 14:42:06.171: INFO: stderr: ""
Dec 17 14:42:06.171: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 17 14:42:07.177: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:42:07.177: INFO: Found 0 / 1
Dec 17 14:42:08.180: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:42:08.180: INFO: Found 1 / 1
Dec 17 14:42:08.180: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 17 14:42:08.185: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:42:08.185: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 17 14:42:08.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 patch pod redis-master-8c9tj --namespace=kubectl-3539 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 17 14:42:08.256: INFO: stderr: ""
Dec 17 14:42:08.256: INFO: stdout: "pod/redis-master-8c9tj patched\n"
STEP: checking annotations
Dec 17 14:42:08.261: INFO: Selector matched 1 pods for map[app:redis]
Dec 17 14:42:08.261: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:42:08.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3539" for this suite.
Dec 17 14:42:20.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:42:20.495: INFO: namespace kubectl-3539 deletion completed in 12.226046903s

• [SLOW TEST:14.565 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:42:20.495: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W1217 14:42:51.115526      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 17 14:42:51.115: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:42:51.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1990" for this suite.
Dec 17 14:42:57.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:42:57.355: INFO: namespace gc-1990 deletion completed in 6.232932211s

• [SLOW TEST:36.860 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:42:57.355: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 17 14:42:57.405: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-8471'
Dec 17 14:42:57.474: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 17 14:42:57.475: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 17 14:42:59.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-005828023 delete deployment e2e-test-httpd-deployment --namespace=kubectl-8471'
Dec 17 14:42:59.574: INFO: stderr: ""
Dec 17 14:42:59.574: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:42:59.574: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8471" for this suite.
Dec 17 14:43:27.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:43:27.812: INFO: namespace kubectl-8471 deletion completed in 28.225041903s

• [SLOW TEST:30.457 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:43:27.813: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 17 14:43:27.917: INFO: (0) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 30.490815ms)
Dec 17 14:43:27.924: INFO: (1) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.128825ms)
Dec 17 14:43:27.935: INFO: (2) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.003319ms)
Dec 17 14:43:27.946: INFO: (3) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.056545ms)
Dec 17 14:43:27.954: INFO: (4) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.01231ms)
Dec 17 14:43:27.964: INFO: (5) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.448698ms)
Dec 17 14:43:27.975: INFO: (6) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.736121ms)
Dec 17 14:43:27.982: INFO: (7) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.10797ms)
Dec 17 14:43:27.993: INFO: (8) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.633708ms)
Dec 17 14:43:28.003: INFO: (9) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.854897ms)
Dec 17 14:43:28.011: INFO: (10) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.070194ms)
Dec 17 14:43:28.022: INFO: (11) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.340338ms)
Dec 17 14:43:28.033: INFO: (12) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.091957ms)
Dec 17 14:43:28.041: INFO: (13) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.831609ms)
Dec 17 14:43:28.052: INFO: (14) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.489853ms)
Dec 17 14:43:28.064: INFO: (15) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 11.216455ms)
Dec 17 14:43:28.071: INFO: (16) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.198746ms)
Dec 17 14:43:28.081: INFO: (17) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.595293ms)
Dec 17 14:43:28.092: INFO: (18) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 10.582497ms)
Dec 17 14:43:28.099: INFO: (19) /api/v1/nodes/k8s-node-vm2x4q-7kwnapovj8/proxy/logs/: <pre>
<a href="anaconda/">anaconda/</a>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</... (200; 7.082258ms)
[AfterEach] version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:43:28.099: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5739" for this suite.
Dec 17 14:43:34.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:43:34.354: INFO: namespace proxy-5739 deletion completed in 6.242894975s

• [SLOW TEST:6.541 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:43:34.354: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:43:50.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7311" for this suite.
Dec 17 14:43:56.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:43:56.753: INFO: namespace resourcequota-7311 deletion completed in 6.227752036s

• [SLOW TEST:22.399 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 17 14:43:56.754: INFO: >>> kubeConfig: /tmp/kubeconfig-005828023
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 17 14:43:56.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8417" for this suite.
Dec 17 14:44:24.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 17 14:44:25.066: INFO: namespace kubelet-test-8417 deletion completed in 28.234261612s

• [SLOW TEST:28.313 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.4-beta.0.50+d9a25890317058/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSDec 17 14:44:25.066: INFO: Running AfterSuite actions on all nodes
Dec 17 14:44:25.066: INFO: Running AfterSuite actions on node 1
Dec 17 14:44:25.066: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 6923.494 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 1h55m24.553781757s
Test Suite Passed
