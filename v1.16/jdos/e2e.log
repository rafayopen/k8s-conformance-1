I1205 06:50:01.481245      20 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-535733101
I1205 06:50:01.481583      20 e2e.go:92] Starting e2e run "d4184877-8724-4f35-82aa-b06f60d022e3" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575528600 - Will randomize all specs
Will run 276 of 4732 specs

Dec  5 06:50:01.490: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 06:50:01.492: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  5 06:50:01.504: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  5 06:50:01.530: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  5 06:50:01.530: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Dec  5 06:50:01.530: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  5 06:50:01.541: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  5 06:50:01.541: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  5 06:50:01.541: INFO: e2e test version: v1.16.3
Dec  5 06:50:01.542: INFO: kube-apiserver version: v1.16.3
Dec  5 06:50:01.543: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 06:50:01.547: INFO: Cluster IP family: ipv4
S
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:50:01.547: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
Dec  5 06:50:01.625: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 06:53:31.670: INFO: DNS probes using dns-test-6dd9df35-c603-4675-8670-80a83ac575cf succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 06:53:33.745: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:33.750: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:33.750: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:53:38.754: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:38.759: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:38.759: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:53:43.768: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:43.772: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:43.772: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:53:48.756: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:48.762: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:48.762: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:53:53.755: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:53.759: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains '' instead of 'bar.example.com.'
Dec  5 06:53:53.759: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:53:58.756: INFO: File wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:58.761: INFO: File jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local from pod  dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  5 06:53:58.761: INFO: Lookups using dns-9150/dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d failed for: [wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local]

Dec  5 06:54:03.757: INFO: DNS probes using dns-test-49487ee6-4e2d-4c81-94be-9dc7bbf6e00d succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-9150.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-9150.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 06:54:07.913: INFO: DNS probes using dns-test-153566df-5b1a-4751-b16d-26efe9c3a3cd succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:54:07.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9150" for this suite.
Dec  5 06:54:14.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:54:14.101: INFO: namespace dns-9150 deletion completed in 6.117434495s

â€¢ [SLOW TEST:252.554 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:54:14.101: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f3f45e68-50e6-4678-b428-5a7575d9dd71
STEP: Creating a pod to test consume configMaps
Dec  5 06:54:14.155: INFO: Waiting up to 5m0s for pod "pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df" in namespace "configmap-8303" to be "success or failure"
Dec  5 06:54:14.166: INFO: Pod "pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df": Phase="Pending", Reason="", readiness=false. Elapsed: 11.179202ms
Dec  5 06:54:16.169: INFO: Pod "pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014245545s
Dec  5 06:54:18.174: INFO: Pod "pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.019484069s
STEP: Saw pod success
Dec  5 06:54:18.174: INFO: Pod "pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df" satisfied condition "success or failure"
Dec  5 06:54:18.177: INFO: Trying to get logs from node worknode pod pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 06:54:18.215: INFO: Waiting for pod pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df to disappear
Dec  5 06:54:18.219: INFO: Pod pod-configmaps-844c5a9a-77b2-41ad-826a-e50bc81d53df no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:54:18.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8303" for this suite.
Dec  5 06:54:24.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:54:24.314: INFO: namespace configmap-8303 deletion completed in 6.090794187s

â€¢ [SLOW TEST:10.213 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:54:24.318: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 06:54:24.350: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:54:28.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2238" for this suite.
Dec  5 06:55:12.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:55:12.520: INFO: namespace pods-2238 deletion completed in 44.116814623s

â€¢ [SLOW TEST:48.203 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:55:12.521: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 06:55:13.113: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 06:55:15.122: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125713, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125713, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125713, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125713, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 06:55:18.145: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:55:18.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6010" for this suite.
Dec  5 06:55:24.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:55:24.386: INFO: namespace webhook-6010 deletion completed in 6.138165466s
STEP: Destroying namespace "webhook-6010-markers" for this suite.
Dec  5 06:55:30.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:55:30.496: INFO: namespace webhook-6010-markers deletion completed in 6.109580479s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.991 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:55:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-867e3d71-710d-49b7-b290-ae5ba55cb1cc
STEP: Creating a pod to test consume secrets
Dec  5 06:55:30.560: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae" in namespace "projected-2968" to be "success or failure"
Dec  5 06:55:30.581: INFO: Pod "pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae": Phase="Pending", Reason="", readiness=false. Elapsed: 21.325541ms
Dec  5 06:55:32.589: INFO: Pod "pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.028959864s
Dec  5 06:55:34.593: INFO: Pod "pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033056893s
STEP: Saw pod success
Dec  5 06:55:34.593: INFO: Pod "pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae" satisfied condition "success or failure"
Dec  5 06:55:34.596: INFO: Trying to get logs from node worknode pod pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 06:55:34.620: INFO: Waiting for pod pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae to disappear
Dec  5 06:55:34.626: INFO: Pod pod-projected-secrets-60c7075b-22ad-4fd4-9f85-99e6d4101eae no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:55:34.627: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2968" for this suite.
Dec  5 06:55:40.653: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:55:40.761: INFO: namespace projected-2968 deletion completed in 6.130150288s

â€¢ [SLOW TEST:10.250 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:55:40.762: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  5 06:55:40.851: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:55:45.039: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9203" for this suite.
Dec  5 06:55:51.066: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:55:51.175: INFO: namespace init-container-9203 deletion completed in 6.129476345s

â€¢ [SLOW TEST:10.413 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:55:51.176: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  5 06:55:51.224: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  5 06:55:56.229: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:55:56.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8489" for this suite.
Dec  5 06:56:02.297: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:56:02.388: INFO: namespace replication-controller-8489 deletion completed in 6.119036067s

â€¢ [SLOW TEST:11.212 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:56:02.389: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-07dedb3f-fe72-4945-8d3b-2fc79816d8a6
STEP: Creating a pod to test consume secrets
Dec  5 06:56:02.433: INFO: Waiting up to 5m0s for pod "pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0" in namespace "secrets-5142" to be "success or failure"
Dec  5 06:56:02.450: INFO: Pod "pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0": Phase="Pending", Reason="", readiness=false. Elapsed: 16.68397ms
Dec  5 06:56:04.453: INFO: Pod "pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020324952s
STEP: Saw pod success
Dec  5 06:56:04.454: INFO: Pod "pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0" satisfied condition "success or failure"
Dec  5 06:56:04.457: INFO: Trying to get logs from node worknode pod pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 06:56:04.489: INFO: Waiting for pod pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0 to disappear
Dec  5 06:56:04.492: INFO: Pod pod-secrets-f42d1479-40f2-4ee7-98f5-d0607ae78ab0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:56:04.492: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5142" for this suite.
Dec  5 06:56:10.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:56:10.607: INFO: namespace secrets-5142 deletion completed in 6.108551639s

â€¢ [SLOW TEST:8.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:56:10.607: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9692/configmap-test-562bc5c4-129e-42e7-ab6a-69bcbcce2f6d
STEP: Creating a pod to test consume configMaps
Dec  5 06:56:10.653: INFO: Waiting up to 5m0s for pod "pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63" in namespace "configmap-9692" to be "success or failure"
Dec  5 06:56:10.669: INFO: Pod "pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63": Phase="Pending", Reason="", readiness=false. Elapsed: 15.484305ms
Dec  5 06:56:12.675: INFO: Pod "pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021637082s
STEP: Saw pod success
Dec  5 06:56:12.675: INFO: Pod "pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63" satisfied condition "success or failure"
Dec  5 06:56:12.677: INFO: Trying to get logs from node worknode pod pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63 container env-test: <nil>
STEP: delete the pod
Dec  5 06:56:12.699: INFO: Waiting for pod pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63 to disappear
Dec  5 06:56:12.702: INFO: Pod pod-configmaps-709a1a1e-0bb4-4a6c-92d2-c58fd27f6d63 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:56:12.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9692" for this suite.
Dec  5 06:56:18.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:56:18.800: INFO: namespace configmap-9692 deletion completed in 6.095699336s

â€¢ [SLOW TEST:8.193 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:56:18.800: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 06:56:18.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5807'
Dec  5 06:56:19.158: INFO: stderr: ""
Dec  5 06:56:19.158: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec  5 06:56:24.213: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pod e2e-test-httpd-pod --namespace=kubectl-5807 -o json'
Dec  5 06:56:24.291: INFO: stderr: ""
Dec  5 06:56:24.291: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"192.168.233.210/32\"\n        },\n        \"creationTimestamp\": \"2019-12-05T06:56:19Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5807\",\n        \"resourceVersion\": \"3236\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5807/pods/e2e-test-httpd-pod\",\n        \"uid\": \"100d7e9c-b119-41d8-839d-28f6fe995369\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-ttjlg\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"worknode\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-ttjlg\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-ttjlg\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-05T06:56:19Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-05T06:56:20Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-05T06:56:20Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-05T06:56:19Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://fadec37010229afeafc337c8a6b122ab416e4ea643ea0d4891fcc62def264c4a\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-05T06:56:20Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.3.47\",\n        \"phase\": \"Running\",\n        \"podIP\": \"192.168.233.210\",\n        \"podIPs\": [\n            {\n                \"ip\": \"192.168.233.210\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-05T06:56:19Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  5 06:56:24.292: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 replace -f - --namespace=kubectl-5807'
Dec  5 06:56:24.486: INFO: stderr: ""
Dec  5 06:56:24.486: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec  5 06:56:24.489: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete pods e2e-test-httpd-pod --namespace=kubectl-5807'
Dec  5 06:56:26.536: INFO: stderr: ""
Dec  5 06:56:26.536: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:56:26.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5807" for this suite.
Dec  5 06:56:32.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:56:32.654: INFO: namespace kubectl-5807 deletion completed in 6.111211469s

â€¢ [SLOW TEST:13.854 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:56:32.655: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-55b143d2-e435-4bce-a60c-997a68aa0ae0
STEP: Creating a pod to test consume configMaps
Dec  5 06:56:32.695: INFO: Waiting up to 5m0s for pod "pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57" in namespace "configmap-6844" to be "success or failure"
Dec  5 06:56:32.697: INFO: Pod "pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.452038ms
Dec  5 06:56:34.702: INFO: Pod "pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006887364s
Dec  5 06:56:36.706: INFO: Pod "pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011204432s
STEP: Saw pod success
Dec  5 06:56:36.706: INFO: Pod "pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57" satisfied condition "success or failure"
Dec  5 06:56:36.709: INFO: Trying to get logs from node worknode pod pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 06:56:36.734: INFO: Waiting for pod pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57 to disappear
Dec  5 06:56:36.739: INFO: Pod pod-configmaps-f91214ea-ecbf-41c4-ab54-08ea853b8f57 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:56:36.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6844" for this suite.
Dec  5 06:56:42.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:56:42.851: INFO: namespace configmap-6844 deletion completed in 6.106073362s

â€¢ [SLOW TEST:10.197 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:56:42.854: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4223
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 06:56:42.887: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 06:57:05.009: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.228.71:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4223 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 06:57:05.009: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 06:57:05.198: INFO: Found all expected endpoints: [netserver-0]
Dec  5 06:57:05.201: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://192.168.233.212:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4223 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 06:57:05.201: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 06:57:05.363: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:57:05.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4223" for this suite.
Dec  5 06:57:17.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:57:17.477: INFO: namespace pod-network-test-4223 deletion completed in 12.107109526s

â€¢ [SLOW TEST:34.623 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:57:17.480: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  5 06:57:17.513: INFO: namespace kubectl-9102
Dec  5 06:57:17.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9102'
Dec  5 06:57:17.660: INFO: stderr: ""
Dec  5 06:57:17.660: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 06:57:18.665: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 06:57:18.665: INFO: Found 0 / 1
Dec  5 06:57:19.664: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 06:57:19.664: INFO: Found 1 / 1
Dec  5 06:57:19.664: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 06:57:19.668: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 06:57:19.668: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 06:57:19.668: INFO: wait on redis-master startup in kubectl-9102 
Dec  5 06:57:19.668: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs redis-master-rdz6h redis-master --namespace=kubectl-9102'
Dec  5 06:57:19.760: INFO: stderr: ""
Dec  5 06:57:19.761: INFO: stdout: "1:C 05 Dec 2019 06:57:18.785 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 05 Dec 2019 06:57:18.786 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 05 Dec 2019 06:57:18.786 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 05 Dec 2019 06:57:18.787 * Running mode=standalone, port=6379.\n1:M 05 Dec 2019 06:57:18.788 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 05 Dec 2019 06:57:18.788 # Server initialized\n1:M 05 Dec 2019 06:57:18.788 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 05 Dec 2019 06:57:18.788 * Ready to accept connections\n"
STEP: exposing RC
Dec  5 06:57:19.761: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-9102'
Dec  5 06:57:19.846: INFO: stderr: ""
Dec  5 06:57:19.846: INFO: stdout: "service/rm2 exposed\n"
Dec  5 06:57:19.849: INFO: Service rm2 in namespace kubectl-9102 found.
STEP: exposing service
Dec  5 06:57:21.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-9102'
Dec  5 06:57:21.955: INFO: stderr: ""
Dec  5 06:57:21.955: INFO: stdout: "service/rm3 exposed\n"
Dec  5 06:57:21.960: INFO: Service rm3 in namespace kubectl-9102 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:57:23.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9102" for this suite.
Dec  5 06:57:51.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:57:52.075: INFO: namespace kubectl-9102 deletion completed in 28.103473409s

â€¢ [SLOW TEST:34.595 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:57:52.076: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec  5 06:57:52.114: INFO: Waiting up to 5m0s for pod "var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524" in namespace "var-expansion-4544" to be "success or failure"
Dec  5 06:57:52.128: INFO: Pod "var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524": Phase="Pending", Reason="", readiness=false. Elapsed: 13.895942ms
Dec  5 06:57:54.135: INFO: Pod "var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020929478s
Dec  5 06:57:56.139: INFO: Pod "var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025289383s
STEP: Saw pod success
Dec  5 06:57:56.140: INFO: Pod "var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524" satisfied condition "success or failure"
Dec  5 06:57:56.143: INFO: Trying to get logs from node worknode pod var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524 container dapi-container: <nil>
STEP: delete the pod
Dec  5 06:57:56.170: INFO: Waiting for pod var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524 to disappear
Dec  5 06:57:56.174: INFO: Pod var-expansion-c1dc69ed-3172-46e7-bfaf-7e3bb5dc3524 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:57:56.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4544" for this suite.
Dec  5 06:58:02.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:58:02.277: INFO: namespace var-expansion-4544 deletion completed in 6.097094081s

â€¢ [SLOW TEST:10.201 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:58:02.277: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  5 06:58:02.313: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:58:17.651: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3325" for this suite.
Dec  5 06:58:23.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:58:23.775: INFO: namespace crd-publish-openapi-3325 deletion completed in 6.121825369s

â€¢ [SLOW TEST:21.498 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:58:23.776: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 06:58:24.457: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 06:58:26.468: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711125904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 06:58:29.484: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:58:29.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-330" for this suite.
Dec  5 06:58:35.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:58:35.795: INFO: namespace webhook-330 deletion completed in 6.111215251s
STEP: Destroying namespace "webhook-330-markers" for this suite.
Dec  5 06:58:41.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:58:41.902: INFO: namespace webhook-330-markers deletion completed in 6.107614745s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:18.140 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:58:41.916: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 06:58:41.956: INFO: Waiting up to 5m0s for pod "pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050" in namespace "emptydir-4850" to be "success or failure"
Dec  5 06:58:41.966: INFO: Pod "pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050": Phase="Pending", Reason="", readiness=false. Elapsed: 10.320033ms
Dec  5 06:58:43.971: INFO: Pod "pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014688335s
Dec  5 06:58:45.974: INFO: Pod "pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.017998853s
STEP: Saw pod success
Dec  5 06:58:45.974: INFO: Pod "pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050" satisfied condition "success or failure"
Dec  5 06:58:45.977: INFO: Trying to get logs from node worknode pod pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050 container test-container: <nil>
STEP: delete the pod
Dec  5 06:58:46.081: INFO: Waiting for pod pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050 to disappear
Dec  5 06:58:46.105: INFO: Pod pod-d4ca9ee9-c19b-4b72-aa8d-d7266cdec050 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 06:58:46.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4850" for this suite.
Dec  5 06:58:52.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 06:58:52.254: INFO: namespace emptydir-4850 deletion completed in 6.141211097s

â€¢ [SLOW TEST:10.338 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 06:58:52.255: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-1253815d-1d0d-4520-8c95-36fe643d2490 in namespace container-probe-9984
Dec  5 06:58:54.327: INFO: Started pod liveness-1253815d-1d0d-4520-8c95-36fe643d2490 in namespace container-probe-9984
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 06:58:54.331: INFO: Initial restart count of pod liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is 0
Dec  5 06:59:14.407: INFO: Restart count of pod container-probe-9984/liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is now 1 (20.076774773s elapsed)
Dec  5 06:59:34.452: INFO: Restart count of pod container-probe-9984/liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is now 2 (40.121040752s elapsed)
Dec  5 06:59:54.490: INFO: Restart count of pod container-probe-9984/liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is now 3 (1m0.15984241s elapsed)
Dec  5 07:00:14.526: INFO: Restart count of pod container-probe-9984/liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is now 4 (1m20.195836214s elapsed)
Dec  5 07:01:24.760: INFO: Restart count of pod container-probe-9984/liveness-1253815d-1d0d-4520-8c95-36fe643d2490 is now 5 (2m30.429710667s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:01:24.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9984" for this suite.
Dec  5 07:01:30.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:01:30.922: INFO: namespace container-probe-9984 deletion completed in 6.130854551s

â€¢ [SLOW TEST:158.667 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:01:30.923: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d0819454-ae83-4da3-a151-2a9d790509ab
STEP: Creating a pod to test consume configMaps
Dec  5 07:01:30.973: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab" in namespace "configmap-8598" to be "success or failure"
Dec  5 07:01:30.990: INFO: Pod "pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab": Phase="Pending", Reason="", readiness=false. Elapsed: 16.741867ms
Dec  5 07:01:32.993: INFO: Pod "pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.01989375s
Dec  5 07:01:34.996: INFO: Pod "pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022925011s
STEP: Saw pod success
Dec  5 07:01:34.996: INFO: Pod "pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab" satisfied condition "success or failure"
Dec  5 07:01:35.000: INFO: Trying to get logs from node worknode pod pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 07:01:35.039: INFO: Waiting for pod pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab to disappear
Dec  5 07:01:35.044: INFO: Pod pod-configmaps-8b7eb8f2-b871-48fb-89fb-f10f7e1388ab no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:01:35.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8598" for this suite.
Dec  5 07:01:41.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:01:41.168: INFO: namespace configmap-8598 deletion completed in 6.116043214s

â€¢ [SLOW TEST:10.246 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:01:41.168: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:01:41.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-2208'
Dec  5 07:01:41.377: INFO: stderr: ""
Dec  5 07:01:41.377: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  5 07:01:41.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-2208'
Dec  5 07:01:41.557: INFO: stderr: ""
Dec  5 07:01:41.557: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 07:01:42.566: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:01:42.566: INFO: Found 0 / 1
Dec  5 07:01:43.562: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:01:43.562: INFO: Found 1 / 1
Dec  5 07:01:43.562: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  5 07:01:43.565: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:01:43.565: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 07:01:43.565: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 describe pod redis-master-swvmf --namespace=kubectl-2208'
Dec  5 07:01:43.674: INFO: stderr: ""
Dec  5 07:01:43.674: INFO: stdout: "Name:         redis-master-swvmf\nNamespace:    kubectl-2208\nPriority:     0\nNode:         worknode/10.0.3.47\nStart Time:   Thu, 05 Dec 2019 07:01:41 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 192.168.233.220/32\nStatus:       Running\nIP:           192.168.233.220\nIPs:\n  IP:           192.168.233.220\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://0e9011076c6f6d515310d467219612073fb5fb885ba92210e79a3e456ae65685\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Thu, 05 Dec 2019 07:01:42 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-g54tk (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-g54tk:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-g54tk\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  2s    default-scheduler  Successfully assigned kubectl-2208/redis-master-swvmf to worknode\n  Normal  Pulled     1s    kubelet, worknode  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, worknode  Created container redis-master\n  Normal  Started    1s    kubelet, worknode  Started container redis-master\n"
Dec  5 07:01:43.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 describe rc redis-master --namespace=kubectl-2208'
Dec  5 07:01:43.785: INFO: stderr: ""
Dec  5 07:01:43.785: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-2208\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-swvmf\n"
Dec  5 07:01:43.785: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 describe service redis-master --namespace=kubectl-2208'
Dec  5 07:01:43.865: INFO: stderr: ""
Dec  5 07:01:43.865: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-2208\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.107.140.100\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         192.168.233.220:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  5 07:01:43.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 describe node allinone'
Dec  5 07:01:43.957: INFO: stderr: ""
Dec  5 07:01:43.957: INFO: stdout: "Name:               allinone\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=allinone\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.0.2.237/22\n                    projectcalico.org/IPv4IPIPTunnelAddr: 192.168.228.64\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 05 Dec 2019 06:33:53 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 05 Dec 2019 06:35:20 +0000   Thu, 05 Dec 2019 06:35:20 +0000   CalicoIsUp                   Calico is running on this node\n  MemoryPressure       False   Thu, 05 Dec 2019 07:01:25 +0000   Thu, 05 Dec 2019 06:33:50 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Thu, 05 Dec 2019 07:01:25 +0000   Thu, 05 Dec 2019 06:33:50 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Thu, 05 Dec 2019 07:01:25 +0000   Thu, 05 Dec 2019 06:33:50 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Thu, 05 Dec 2019 07:01:25 +0000   Thu, 05 Dec 2019 06:35:24 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.2.237\n  Hostname:    allinone\nCapacity:\n cpu:                2\n ephemeral-storage:  30830588Ki\n hugepages-2Mi:      0\n memory:             2048068Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  28413469854\n hugepages-2Mi:      0\n memory:             1945668Ki\n pods:               110\nSystem Info:\n Machine ID:                 a0ddf71df1831702b4275a5c5de86288\n System UUID:                A7223D56-1A35-419F-9DF5-EB00D879B121\n Boot ID:                    1c398ffa-cd81-42cf-9aa0-7477dded3683\n Kernel Version:             4.4.0-116-generic\n OS Image:                   Ubuntu 16.04.4 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.2\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nNon-terminated Pods:         (10 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-kube-controllers-55754f75c-g2l8q                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                calico-node-wt92j                                          250m (12%)    0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                coredns-5644d7b6d9-5jdzn                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (8%)     27m\n  kube-system                coredns-5644d7b6d9-8vk79                                   100m (5%)     0 (0%)      70Mi (3%)        170Mi (8%)     27m\n  kube-system                etcd-allinone                                              0 (0%)        0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                kube-apiserver-allinone                                    250m (12%)    0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                kube-controller-manager-allinone                           200m (10%)    0 (0%)      0 (0%)           0 (0%)         26m\n  kube-system                kube-proxy-4g9tm                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         27m\n  kube-system                kube-scheduler-allinone                                    100m (5%)     0 (0%)      0 (0%)           0 (0%)         26m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh    0 (0%)        0 (0%)      0 (0%)           0 (0%)         11m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                1 (50%)     0 (0%)\n  memory             140Mi (7%)  340Mi (17%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                  Message\n  ----    ------                   ----               ----                  -------\n  Normal  NodeHasSufficientMemory  27m (x8 over 27m)  kubelet, allinone     Node allinone status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    27m (x8 over 27m)  kubelet, allinone     Node allinone status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     27m (x7 over 27m)  kubelet, allinone     Node allinone status is now: NodeHasSufficientPID\n  Normal  Starting                 27m                kube-proxy, allinone  Starting kube-proxy.\n"
Dec  5 07:01:43.957: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 describe namespace kubectl-2208'
Dec  5 07:01:44.030: INFO: stderr: ""
Dec  5 07:01:44.030: INFO: stdout: "Name:         kubectl-2208\nLabels:       e2e-framework=kubectl\n              e2e-run=d4184877-8724-4f35-82aa-b06f60d022e3\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:01:44.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2208" for this suite.
Dec  5 07:01:56.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:01:56.156: INFO: namespace kubectl-2208 deletion completed in 12.122882632s

â€¢ [SLOW TEST:14.987 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:01:56.156: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f6f4c466-a08e-4ed1-b2fe-51b16ee1faf2
STEP: Creating a pod to test consume secrets
Dec  5 07:01:56.209: INFO: Waiting up to 5m0s for pod "pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22" in namespace "secrets-3006" to be "success or failure"
Dec  5 07:01:56.212: INFO: Pod "pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22": Phase="Pending", Reason="", readiness=false. Elapsed: 3.606405ms
Dec  5 07:01:58.215: INFO: Pod "pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006527558s
STEP: Saw pod success
Dec  5 07:01:58.215: INFO: Pod "pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22" satisfied condition "success or failure"
Dec  5 07:01:58.218: INFO: Trying to get logs from node worknode pod pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:01:58.249: INFO: Waiting for pod pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22 to disappear
Dec  5 07:01:58.256: INFO: Pod pod-secrets-24b59ede-6393-410a-8e57-6e62f81ced22 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:01:58.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3006" for this suite.
Dec  5 07:02:04.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:02:04.374: INFO: namespace secrets-3006 deletion completed in 6.112941472s

â€¢ [SLOW TEST:8.218 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:02:04.376: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:02:04.407: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:02:09.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2928" for this suite.
Dec  5 07:02:15.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:02:16.111: INFO: namespace custom-resource-definition-2928 deletion completed in 6.258778714s

â€¢ [SLOW TEST:11.735 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:02:16.113: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:02:16.192: INFO: Creating deployment "test-recreate-deployment"
Dec  5 07:02:16.198: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  5 07:02:16.217: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  5 07:02:18.227: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  5 07:02:18.229: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  5 07:02:18.236: INFO: Updating deployment test-recreate-deployment
Dec  5 07:02:18.236: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  5 07:02:18.355: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-1443 /apis/apps/v1/namespaces/deployment-1443/deployments/test-recreate-deployment 1df39183-6576-462b-aec5-9ff0661f23e4 4350 2 2019-12-05 07:02:16 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00340f3c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-05 07:02:18 +0000 UTC,LastTransitionTime:2019-12-05 07:02:18 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-05 07:02:18 +0000 UTC,LastTransitionTime:2019-12-05 07:02:16 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 07:02:18.358: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-1443 /apis/apps/v1/namespaces/deployment-1443/replicasets/test-recreate-deployment-5f94c574ff 06a97181-7a90-46c8-8dc9-a51b8d625f89 4349 1 2019-12-05 07:02:18 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 1df39183-6576-462b-aec5-9ff0661f23e4 0xc00340f8e7 0xc00340f8e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00340f948 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:02:18.358: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  5 07:02:18.358: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-1443 /apis/apps/v1/namespaces/deployment-1443/replicasets/test-recreate-deployment-68fc85c7bb 4f324957-6429-4068-ac21-52d626d04463 4337 2 2019-12-05 07:02:16 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 1df39183-6576-462b-aec5-9ff0661f23e4 0xc00340f9a7 0xc00340f9a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00340fa08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:02:18.363: INFO: Pod "test-recreate-deployment-5f94c574ff-96zvs" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-96zvs test-recreate-deployment-5f94c574ff- deployment-1443 /api/v1/namespaces/deployment-1443/pods/test-recreate-deployment-5f94c574ff-96zvs e55c52e4-191a-4a1b-be02-cce4bfd3655e 4348 0 2019-12-05 07:02:18 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 06a97181-7a90-46c8-8dc9-a51b8d625f89 0xc0035bf157 0xc0035bf158}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-f8zwr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-f8zwr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-f8zwr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:02:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:02:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:02:18 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:02:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:02:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:02:18.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1443" for this suite.
Dec  5 07:02:24.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:02:24.467: INFO: namespace deployment-1443 deletion completed in 6.100428057s

â€¢ [SLOW TEST:8.354 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:02:24.467: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 07:02:24.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-8755'
Dec  5 07:02:24.583: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 07:02:24.583: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec  5 07:02:26.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete deployment e2e-test-httpd-deployment --namespace=kubectl-8755'
Dec  5 07:02:26.698: INFO: stderr: ""
Dec  5 07:02:26.698: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:02:26.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8755" for this suite.
Dec  5 07:02:38.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:02:38.835: INFO: namespace kubectl-8755 deletion completed in 12.128276807s

â€¢ [SLOW TEST:14.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:02:38.839: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-0626ed8a-ca74-4154-bd27-8c167b1b7904
STEP: Creating a pod to test consume secrets
Dec  5 07:02:38.963: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14" in namespace "projected-7528" to be "success or failure"
Dec  5 07:02:38.968: INFO: Pod "pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14": Phase="Pending", Reason="", readiness=false. Elapsed: 4.714812ms
Dec  5 07:02:40.972: INFO: Pod "pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00930701s
STEP: Saw pod success
Dec  5 07:02:40.973: INFO: Pod "pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14" satisfied condition "success or failure"
Dec  5 07:02:40.976: INFO: Trying to get logs from node worknode pod pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:02:41.006: INFO: Waiting for pod pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14 to disappear
Dec  5 07:02:41.014: INFO: Pod pod-projected-secrets-93997cb5-60c9-4b88-82d8-4b589029ef14 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:02:41.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7528" for this suite.
Dec  5 07:02:47.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:02:47.120: INFO: namespace projected-7528 deletion completed in 6.101432161s

â€¢ [SLOW TEST:8.282 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:02:47.121: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:02:47.176: INFO: Create a RollingUpdate DaemonSet
Dec  5 07:02:47.184: INFO: Check that daemon pods launch on every node of the cluster
Dec  5 07:02:47.195: INFO: Number of nodes with available pods: 0
Dec  5 07:02:47.195: INFO: Node allinone is running more than one daemon pod
Dec  5 07:02:48.205: INFO: Number of nodes with available pods: 0
Dec  5 07:02:48.205: INFO: Node allinone is running more than one daemon pod
Dec  5 07:02:49.206: INFO: Number of nodes with available pods: 1
Dec  5 07:02:49.206: INFO: Node allinone is running more than one daemon pod
Dec  5 07:02:50.204: INFO: Number of nodes with available pods: 2
Dec  5 07:02:50.204: INFO: Number of running nodes: 2, number of available pods: 2
Dec  5 07:02:50.204: INFO: Update the DaemonSet to trigger a rollout
Dec  5 07:02:50.212: INFO: Updating DaemonSet daemon-set
Dec  5 07:02:54.232: INFO: Roll back the DaemonSet before rollout is complete
Dec  5 07:02:54.239: INFO: Updating DaemonSet daemon-set
Dec  5 07:02:54.239: INFO: Make sure DaemonSet rollback is complete
Dec  5 07:02:54.244: INFO: Wrong image for pod: daemon-set-xhrz8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  5 07:02:54.244: INFO: Pod daemon-set-xhrz8 is not available
Dec  5 07:02:55.256: INFO: Wrong image for pod: daemon-set-xhrz8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  5 07:02:55.256: INFO: Pod daemon-set-xhrz8 is not available
Dec  5 07:02:56.254: INFO: Wrong image for pod: daemon-set-xhrz8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  5 07:02:56.254: INFO: Pod daemon-set-xhrz8 is not available
Dec  5 07:02:57.257: INFO: Wrong image for pod: daemon-set-xhrz8. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  5 07:02:57.257: INFO: Pod daemon-set-xhrz8 is not available
Dec  5 07:02:58.253: INFO: Pod daemon-set-bvp4n is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8436, will wait for the garbage collector to delete the pods
Dec  5 07:02:58.325: INFO: Deleting DaemonSet.extensions daemon-set took: 8.062771ms
Dec  5 07:02:58.626: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.719692ms
Dec  5 07:03:07.631: INFO: Number of nodes with available pods: 0
Dec  5 07:03:07.631: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 07:03:07.636: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8436/daemonsets","resourceVersion":"4612"},"items":null}

Dec  5 07:03:07.640: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8436/pods","resourceVersion":"4612"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:03:07.649: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8436" for this suite.
Dec  5 07:03:13.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:03:13.777: INFO: namespace daemonsets-8436 deletion completed in 6.126065801s

â€¢ [SLOW TEST:26.657 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:03:13.782: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:03:14.596: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec  5 07:03:16.608: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126194, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126194, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126194, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126194, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:03:19.640: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:03:19.645: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:03:20.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8793" for this suite.
Dec  5 07:03:26.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:03:26.965: INFO: namespace crd-webhook-8793 deletion completed in 6.120321221s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:13.198 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:03:26.980: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:03:27.017: INFO: Creating ReplicaSet my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6
Dec  5 07:03:27.025: INFO: Pod name my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6: Found 0 pods out of 1
Dec  5 07:03:32.029: INFO: Pod name my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6: Found 1 pods out of 1
Dec  5 07:03:32.029: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6" is running
Dec  5 07:03:32.032: INFO: Pod "my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6-b4scc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:03:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:03:28 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:03:28 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:03:27 +0000 UTC Reason: Message:}])
Dec  5 07:03:32.032: INFO: Trying to dial the pod
Dec  5 07:03:37.043: INFO: Controller my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6: Got expected result from replica 1 [my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6-b4scc]: "my-hostname-basic-9d3d7cd3-7bc9-4478-9542-672529c249b6-b4scc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:03:37.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-589" for this suite.
Dec  5 07:03:43.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:03:43.150: INFO: namespace replicaset-589 deletion completed in 6.102884922s

â€¢ [SLOW TEST:16.170 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:03:43.151: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 07:03:45.710: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba"
Dec  5 07:03:45.711: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba" in namespace "pods-8988" to be "terminated due to deadline exceeded"
Dec  5 07:03:45.717: INFO: Pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba": Phase="Running", Reason="", readiness=true. Elapsed: 6.266337ms
Dec  5 07:03:47.719: INFO: Pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba": Phase="Running", Reason="", readiness=true. Elapsed: 2.008915533s
Dec  5 07:03:49.723: INFO: Pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.012550214s
Dec  5 07:03:49.723: INFO: Pod "pod-update-activedeadlineseconds-cc911045-9c00-4613-abb2-100d4af62fba" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:03:49.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8988" for this suite.
Dec  5 07:03:55.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:03:55.819: INFO: namespace pods-8988 deletion completed in 6.092391168s

â€¢ [SLOW TEST:12.668 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:03:55.820: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  5 07:04:00.396: INFO: Successfully updated pod "labelsupdate78a168d8-d08f-4a54-87ab-c0ef7bc1ce19"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:04:02.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6058" for this suite.
Dec  5 07:04:18.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:04:18.522: INFO: namespace downward-api-6058 deletion completed in 16.094621697s

â€¢ [SLOW TEST:22.702 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:04:18.523: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:04:18.558: INFO: Creating deployment "webserver-deployment"
Dec  5 07:04:18.562: INFO: Waiting for observed generation 1
Dec  5 07:04:20.622: INFO: Waiting for all required pods to come up
Dec  5 07:04:20.633: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  5 07:04:24.662: INFO: Waiting for deployment "webserver-deployment" to complete
Dec  5 07:04:24.667: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec  5 07:04:24.673: INFO: Updating deployment webserver-deployment
Dec  5 07:04:24.673: INFO: Waiting for observed generation 2
Dec  5 07:04:26.686: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  5 07:04:26.689: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  5 07:04:26.694: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  5 07:04:26.704: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  5 07:04:26.704: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  5 07:04:26.706: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  5 07:04:26.711: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec  5 07:04:26.711: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec  5 07:04:26.718: INFO: Updating deployment webserver-deployment
Dec  5 07:04:26.718: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec  5 07:04:26.734: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  5 07:04:28.800: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  5 07:04:28.922: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-4146 /apis/apps/v1/namespaces/deployment-4146/deployments/webserver-deployment 53f2d9f5-7045-4951-b991-00edc6c74a67 5250 3 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002602f58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-05 07:04:26 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-05 07:04:27 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec  5 07:04:28.952: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-4146 /apis/apps/v1/namespaces/deployment-4146/replicasets/webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 5243 3 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 53f2d9f5-7045-4951-b991-00edc6c74a67 0xc00327ddf7 0xc00327ddf8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00327de68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:04:28.952: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec  5 07:04:28.952: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-4146 /apis/apps/v1/namespaces/deployment-4146/replicasets/webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 5239 3 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 53f2d9f5-7045-4951-b991-00edc6c74a67 0xc00327dd37 0xc00327dd38}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00327dd98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:04:29.391: INFO: Pod "webserver-deployment-595b5b9587-4gvn7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4gvn7 webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-4gvn7 08df3edc-cf03-44a1-9d77-6c1e47a45c25 5266 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc0026033a0 0xc0026033a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.391: INFO: Pod "webserver-deployment-595b5b9587-67nbb" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-67nbb webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-67nbb dde608b6-7a59-47a1-a1e4-0118e8afb424 5249 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc0026034f0 0xc0026034f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.392: INFO: Pod "webserver-deployment-595b5b9587-6gsbt" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6gsbt webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-6gsbt 2e3bdcfc-c484-4f66-a626-3356e8d5dee5 5093 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.228.76/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603640 0xc002603641}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:192.168.228.76,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://28df6b25ce1f9655c5fc8245906fd162481ec14e39f83100acac1481d3937855,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.228.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.392: INFO: Pod "webserver-deployment-595b5b9587-bxnlc" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bxnlc webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-bxnlc d4f19cdd-2323-47ce-9d5d-203e9928b064 5233 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc0026037b0 0xc0026037b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.392: INFO: Pod "webserver-deployment-595b5b9587-c8hmh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-c8hmh webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-c8hmh ee89aad2-7c43-48be-8e4a-fb5fa37b59e9 5076 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.233.235/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603900 0xc002603901}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.235,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9dd5e872ad387fb57f46d42e2c305f76eb1a03beb67c4029dd854d738c077c28,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.235,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.392: INFO: Pod "webserver-deployment-595b5b9587-d7r6r" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-d7r6r webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-d7r6r 2e18fee2-cf8a-4348-ac2a-97adb1387410 5206 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603a70 0xc002603a71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.392: INFO: Pod "webserver-deployment-595b5b9587-gxxmw" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gxxmw webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-gxxmw 135b34b4-9d4e-4059-bb5a-6f42d9a8a6d8 5097 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.228.77/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603bc0 0xc002603bc1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:192.168.228.77,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://32132e14f71151c9fdd0a53807b45bdd79b1d8b76829ac232f027b4f7b0ccec2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.228.77,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.393: INFO: Pod "webserver-deployment-595b5b9587-hpx7j" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hpx7j webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-hpx7j 501b2ee8-59d9-4887-8d59-b167315551bf 5227 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603d40 0xc002603d41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.393: INFO: Pod "webserver-deployment-595b5b9587-jj7cq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jj7cq webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-jj7cq e21848bc-1e3b-41f6-8104-dacb649bd424 5017 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.233.231/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603e50 0xc002603e51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.231,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://240ecc459166d4aa97364b37db8259b85d764266209597afcf86996a40bed929,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.231,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.393: INFO: Pod "webserver-deployment-595b5b9587-kg8dz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kg8dz webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-kg8dz a20a0a08-b81f-4f5b-b87b-75e253985269 5082 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.233.234/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc002603fd0 0xc002603fd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.234,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://955fc39bd1662c5619c1bc4df811bbaae854f1618bfb3bb13764abb3a5c28c26,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.234,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.394: INFO: Pod "webserver-deployment-595b5b9587-kg9t2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-kg9t2 webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-kg9t2 849f7c5f-75cc-4240-a828-fa6d7ded4588 5270 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790140 0xc003790141}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.394: INFO: Pod "webserver-deployment-595b5b9587-l5vls" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-l5vls webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-l5vls b151dff8-7e85-496d-a737-9cba9adbdddc 5261 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790290 0xc003790291}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.394: INFO: Pod "webserver-deployment-595b5b9587-lmqnl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lmqnl webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-lmqnl 3dd29263-7e06-46b2-aaa9-2d942e702890 5011 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.233.232/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790510 0xc003790511}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:20 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.232,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:20 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b2e403698c11f91bc496e7be0099cf340c1e9dc92505ec5aaecbd99b63fb46d0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.232,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.395: INFO: Pod "webserver-deployment-595b5b9587-n9zzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-n9zzt webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-n9zzt 26240640-791f-4771-84d6-a5a099dfc149 5279 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc0037906d0 0xc0037906d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.395: INFO: Pod "webserver-deployment-595b5b9587-nlxlj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nlxlj webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-nlxlj bd9124f1-c6ab-4832-98d3-f64415648857 5264 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790820 0xc003790821}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.395: INFO: Pod "webserver-deployment-595b5b9587-pcscr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pcscr webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-pcscr c012599b-5685-427d-addf-eaa708007742 5234 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790970 0xc003790971}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.396: INFO: Pod "webserver-deployment-595b5b9587-rzbrh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rzbrh webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-rzbrh 5d562ce3-d04d-4855-922f-d0ef01cca5c8 5257 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790a80 0xc003790a81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.396: INFO: Pod "webserver-deployment-595b5b9587-wfnwp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wfnwp webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-wfnwp 91cb0c6c-81ec-4e20-b1dd-8faa5484dc76 5079 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.233.233/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790bd0 0xc003790bd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.233,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:21 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2c9da2c450fd560ae34993df755906f34c87b7404a984d9eb8409dcea1ddad60,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.233,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.396: INFO: Pod "webserver-deployment-595b5b9587-wmdqp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wmdqp webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-wmdqp 994a2236-c668-45aa-aa9f-b5c6461a9a21 5069 0 2019-12-05 07:04:18 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:192.168.228.73/32] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790d40 0xc003790d41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:18 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:192.168.228.73,StartTime:2019-12-05 07:04:18 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:22 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1eb43bcc19e2815d41be58177fffaec161864e2c3575f2e853609b07e1c1c90c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.228.73,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.396: INFO: Pod "webserver-deployment-595b5b9587-zxtn7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zxtn7 webserver-deployment-595b5b9587- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-595b5b9587-zxtn7 05c75bcc-42f5-4678-8286-42a7289d9a6a 5256 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cb5f304e-a5ca-48ac-8d30-e9541d944d0f 0xc003790eb0 0xc003790eb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.397: INFO: Pod "webserver-deployment-c7997dcc8-48qn2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-48qn2 webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-48qn2 7d2d5c55-e4a9-4832-8e6c-4f2603fe9ae3 5163 0 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.233.236/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791000 0xc003791001}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.397: INFO: Pod "webserver-deployment-c7997dcc8-89xds" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-89xds webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-89xds 587ad540-e2aa-40ff-aa89-28ab4048dae9 5282 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791190 0xc003791191}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.397: INFO: Pod "webserver-deployment-c7997dcc8-l6m5v" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-l6m5v webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-l6m5v 3bf22e28-422d-43d0-8473-6f4f4a4e7fcb 5247 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791300 0xc003791301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.397: INFO: Pod "webserver-deployment-c7997dcc8-lhd5q" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lhd5q webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-lhd5q 85972e1f-a570-4778-b0e2-3e565b902379 5166 0 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.233.237/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791470 0xc003791471}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.397: INFO: Pod "webserver-deployment-c7997dcc8-lkpkz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lkpkz webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-lkpkz debb9213-54fa-4a9d-a5f7-c8ec4191ae78 5287 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc0037915e0 0xc0037915e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.398: INFO: Pod "webserver-deployment-c7997dcc8-nkhn7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nkhn7 webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-nkhn7 ed9cc69f-054e-42e6-81e1-2b8b8503fa1b 5173 0 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.233.238/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791750 0xc003791751}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.398: INFO: Pod "webserver-deployment-c7997dcc8-px7mj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-px7mj webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-px7mj fe4604e9-4241-4339-8c2c-8afb7b7bace6 5252 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc0037918c0 0xc0037918c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.399: INFO: Pod "webserver-deployment-c7997dcc8-r6wvt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r6wvt webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-r6wvt 4ac6c11a-2543-4351-a034-ff1a999ad5cb 5172 0 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.228.78/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791a30 0xc003791a31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.399: INFO: Pod "webserver-deployment-c7997dcc8-s8754" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-s8754 webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-s8754 3149b18e-49ff-4280-93c2-16ea31ed6316 5276 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791ba0 0xc003791ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.399: INFO: Pod "webserver-deployment-c7997dcc8-tk46b" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tk46b webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-tk46b a58560bc-e452-48da-a2ae-9d5fb9145cfd 5275 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791d20 0xc003791d21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.399: INFO: Pod "webserver-deployment-c7997dcc8-xnhlw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xnhlw webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-xnhlw 7ff9778c-922b-46c8-bd1c-1edbc126c3a3 5235 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc003791e90 0xc003791e91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.400: INFO: Pod "webserver-deployment-c7997dcc8-z72mm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-z72mm webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-z72mm 27a2a506-9a1d-46f2-8da6-c504f7c29e0c 5178 0 2019-12-05 07:04:24 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:192.168.228.79/32] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc0033dc000 0xc0033dc001}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:24 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  5 07:04:29.400: INFO: Pod "webserver-deployment-c7997dcc8-zhskc" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zhskc webserver-deployment-c7997dcc8- deployment-4146 /api/v1/namespaces/deployment-4146/pods/webserver-deployment-c7997dcc8-zhskc 4c68adb5-5040-4e81-a270-32223d05fa30 5290 0 2019-12-05 07:04:26 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 91b34cf1-6ee7-4fa5-b3d2-964bf5ba86c7 0xc0033dc170 0xc0033dc171}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-mx7vx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-mx7vx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-mx7vx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:allinone,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:26 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.2.237,PodIP:,StartTime:2019-12-05 07:04:26 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:04:29.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4146" for this suite.
Dec  5 07:04:42.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:04:42.200: INFO: namespace deployment-4146 deletion completed in 12.636446855s

â€¢ [SLOW TEST:23.678 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:04:42.208: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-d9ad6822-40e8-4035-a91a-36e69f9a445f
STEP: Creating a pod to test consume secrets
Dec  5 07:04:42.262: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e" in namespace "projected-6543" to be "success or failure"
Dec  5 07:04:42.268: INFO: Pod "pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 5.589355ms
Dec  5 07:04:44.272: INFO: Pod "pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009571131s
Dec  5 07:04:46.275: INFO: Pod "pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013193841s
STEP: Saw pod success
Dec  5 07:04:46.275: INFO: Pod "pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e" satisfied condition "success or failure"
Dec  5 07:04:46.278: INFO: Trying to get logs from node worknode pod pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:04:46.307: INFO: Waiting for pod pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e to disappear
Dec  5 07:04:46.311: INFO: Pod pod-projected-secrets-79d1147b-8714-4993-aac7-72c869980b5e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:04:46.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6543" for this suite.
Dec  5 07:04:52.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:04:52.419: INFO: namespace projected-6543 deletion completed in 6.104856282s

â€¢ [SLOW TEST:10.211 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:04:52.419: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:04:52.465: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  5 07:04:52.473: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  5 07:04:57.487: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 07:04:57.487: INFO: Creating deployment "test-rolling-update-deployment"
Dec  5 07:04:57.494: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  5 07:04:57.504: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  5 07:04:59.518: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  5 07:04:59.521: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126297, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126297, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126297, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126297, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:05:01.533: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  5 07:05:01.542: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-1384 /apis/apps/v1/namespaces/deployment-1384/deployments/test-rolling-update-deployment 1049236c-a2c4-4a7c-a816-32541aa66b73 5881 1 2019-12-05 07:04:57 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0020a2288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-05 07:04:57 +0000 UTC,LastTransitionTime:2019-12-05 07:04:57 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-05 07:04:59 +0000 UTC,LastTransitionTime:2019-12-05 07:04:57 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 07:05:01.545: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-1384 /apis/apps/v1/namespaces/deployment-1384/replicasets/test-rolling-update-deployment-55d946486 f7c7e0ab-c7dd-4a22-9866-68c4fc47d9b7 5870 1 2019-12-05 07:04:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 1049236c-a2c4-4a7c-a816-32541aa66b73 0xc0020a2760 0xc0020a2761}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0020a27c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:05:01.545: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  5 07:05:01.545: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-1384 /apis/apps/v1/namespaces/deployment-1384/replicasets/test-rolling-update-controller 20840dca-b9f9-421e-92f8-28fa32b7c38c 5879 2 2019-12-05 07:04:52 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 1049236c-a2c4-4a7c-a816-32541aa66b73 0xc0020a266f 0xc0020a2680}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0020a26e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:05:01.548: INFO: Pod "test-rolling-update-deployment-55d946486-gjhf5" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-gjhf5 test-rolling-update-deployment-55d946486- deployment-1384 /api/v1/namespaces/deployment-1384/pods/test-rolling-update-deployment-55d946486-gjhf5 1b851e50-c38a-4220-94aa-63a8060499d5 5869 0 2019-12-05 07:04:57 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:192.168.233.249/32] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 f7c7e0ab-c7dd-4a22-9866-68c4fc47d9b7 0xc0020a2c20 0xc0020a2c21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-s9p7l,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-s9p7l,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-s9p7l,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:04:57 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.249,StartTime:2019-12-05 07:04:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:04:58 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://60b440f22da06e55f0bbf4829bb29bf41c072c4ef3e48040c283f5656583d7a7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.249,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:05:01.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1384" for this suite.
Dec  5 07:05:07.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:05:07.658: INFO: namespace deployment-1384 deletion completed in 6.106489929s

â€¢ [SLOW TEST:15.239 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:05:07.660: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:05:11.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8482" for this suite.
Dec  5 07:05:29.745: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:05:29.824: INFO: namespace containers-8482 deletion completed in 18.097404952s

â€¢ [SLOW TEST:22.164 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:05:29.825: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 07:05:29.886: INFO: Number of nodes with available pods: 0
Dec  5 07:05:29.886: INFO: Node allinone is running more than one daemon pod
Dec  5 07:05:30.896: INFO: Number of nodes with available pods: 0
Dec  5 07:05:30.896: INFO: Node allinone is running more than one daemon pod
Dec  5 07:05:31.892: INFO: Number of nodes with available pods: 2
Dec  5 07:05:31.893: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  5 07:05:31.934: INFO: Number of nodes with available pods: 1
Dec  5 07:05:31.934: INFO: Node allinone is running more than one daemon pod
Dec  5 07:05:32.949: INFO: Number of nodes with available pods: 1
Dec  5 07:05:32.949: INFO: Node allinone is running more than one daemon pod
Dec  5 07:05:33.947: INFO: Number of nodes with available pods: 2
Dec  5 07:05:33.947: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2413, will wait for the garbage collector to delete the pods
Dec  5 07:05:34.015: INFO: Deleting DaemonSet.extensions daemon-set took: 9.207264ms
Dec  5 07:05:34.316: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.784015ms
Dec  5 07:05:45.722: INFO: Number of nodes with available pods: 0
Dec  5 07:05:45.722: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 07:05:45.725: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2413/daemonsets","resourceVersion":"6084"},"items":null}

Dec  5 07:05:45.727: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2413/pods","resourceVersion":"6084"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:05:45.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2413" for this suite.
Dec  5 07:05:51.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:05:51.836: INFO: namespace daemonsets-2413 deletion completed in 6.097633031s

â€¢ [SLOW TEST:22.012 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:05:51.837: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 07:05:55.946: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:05:55.954: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 07:05:57.954: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:05:57.960: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 07:06:00.011: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:06:00.014: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 07:06:01.973: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:06:01.976: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 07:06:03.955: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:06:03.959: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  5 07:06:05.960: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  5 07:06:05.963: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:06:05.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9220" for this suite.
Dec  5 07:06:18.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:06:18.097: INFO: namespace container-lifecycle-hook-9220 deletion completed in 12.127641884s

â€¢ [SLOW TEST:26.260 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:06:18.097: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-9b9a7639-75c3-4c9e-bc61-f8bf86ab21a6
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:06:18.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1872" for this suite.
Dec  5 07:06:24.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:06:24.239: INFO: namespace secrets-1872 deletion completed in 6.099990348s

â€¢ [SLOW TEST:6.142 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:06:24.240: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  5 07:06:24.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-1220'
Dec  5 07:06:24.562: INFO: stderr: ""
Dec  5 07:06:24.562: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  5 07:06:25.573: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:06:25.573: INFO: Found 0 / 1
Dec  5 07:06:26.567: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:06:26.567: INFO: Found 1 / 1
Dec  5 07:06:26.567: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  5 07:06:26.570: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:06:26.570: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  5 07:06:26.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 patch pod redis-master-6mqrs --namespace=kubectl-1220 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  5 07:06:26.659: INFO: stderr: ""
Dec  5 07:06:26.659: INFO: stdout: "pod/redis-master-6mqrs patched\n"
STEP: checking annotations
Dec  5 07:06:26.662: INFO: Selector matched 1 pods for map[app:redis]
Dec  5 07:06:26.662: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:06:26.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1220" for this suite.
Dec  5 07:06:38.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:06:38.760: INFO: namespace kubectl-1220 deletion completed in 12.094744959s

â€¢ [SLOW TEST:14.520 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:06:38.761: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  5 07:07:08.836: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:07:08.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1205 07:07:08.836215      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-6733" for this suite.
Dec  5 07:07:14.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:07:14.939: INFO: namespace gc-6733 deletion completed in 6.099771845s

â€¢ [SLOW TEST:36.178 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:07:14.939: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7300.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7300.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7300.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7300.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 232.155.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.155.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.155.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.155.232_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7300.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7300.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7300.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7300.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7300.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7300.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 232.155.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.155.232_udp@PTR;check="$$(dig +tcp +noall +answer +search 232.155.103.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.103.155.232_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 07:07:17.042: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.045: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.048: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.051: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.073: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.077: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.080: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.083: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:17.105: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:22.112: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.117: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.121: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.124: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.151: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.155: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.159: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.163: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:22.184: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:27.110: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.115: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.119: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.123: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.149: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.153: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.156: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.160: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:27.190: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:32.116: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.120: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.124: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.128: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.153: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.156: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.160: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.164: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:32.187: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:37.109: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.113: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.117: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.122: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.155: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.160: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.164: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.168: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:37.200: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:42.109: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.114: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.117: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.121: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.154: INFO: Unable to read jessie_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.160: INFO: Unable to read jessie_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.165: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.170: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:42.200: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_udp@dns-test-service.dns-7300.svc.cluster.local jessie_tcp@dns-test-service.dns-7300.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:47.112: INFO: Unable to read wheezy_udp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:47.120: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:47.129: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:47.138: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local from pod dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539: the server could not find the requested resource (get pods dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539)
Dec  5 07:07:47.220: INFO: Lookups using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 failed for: [wheezy_udp@dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@dns-test-service.dns-7300.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7300.svc.cluster.local]

Dec  5 07:07:52.206: INFO: DNS probes using dns-7300/dns-test-e1d10cc4-df00-49f7-abb6-4c58b8099539 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:07:52.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7300" for this suite.
Dec  5 07:07:58.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:07:58.496: INFO: namespace dns-7300 deletion completed in 6.121722319s

â€¢ [SLOW TEST:43.557 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:07:58.500: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:07:58.546: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-25814405-2a79-4b5a-8e7d-12aeda8f6ba7" in namespace "security-context-test-6871" to be "success or failure"
Dec  5 07:07:58.560: INFO: Pod "busybox-readonly-false-25814405-2a79-4b5a-8e7d-12aeda8f6ba7": Phase="Pending", Reason="", readiness=false. Elapsed: 13.679571ms
Dec  5 07:08:00.563: INFO: Pod "busybox-readonly-false-25814405-2a79-4b5a-8e7d-12aeda8f6ba7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016842392s
Dec  5 07:08:00.563: INFO: Pod "busybox-readonly-false-25814405-2a79-4b5a-8e7d-12aeda8f6ba7" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:08:00.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6871" for this suite.
Dec  5 07:08:06.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:08:06.650: INFO: namespace security-context-test-6871 deletion completed in 6.083967932s

â€¢ [SLOW TEST:8.150 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:08:06.651: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6597
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-6597
STEP: Creating statefulset with conflicting port in namespace statefulset-6597
STEP: Waiting until pod test-pod will start running in namespace statefulset-6597
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-6597
Dec  5 07:08:10.745: INFO: Observed stateful pod in namespace: statefulset-6597, name: ss-0, uid: 3a990965-9c52-40db-9edc-cf2034d803d4, status phase: Pending. Waiting for statefulset controller to delete.
Dec  5 07:08:11.296: INFO: Observed stateful pod in namespace: statefulset-6597, name: ss-0, uid: 3a990965-9c52-40db-9edc-cf2034d803d4, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 07:08:11.306: INFO: Observed stateful pod in namespace: statefulset-6597, name: ss-0, uid: 3a990965-9c52-40db-9edc-cf2034d803d4, status phase: Failed. Waiting for statefulset controller to delete.
Dec  5 07:08:11.317: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-6597
STEP: Removing pod with conflicting port in namespace statefulset-6597
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-6597 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 07:08:15.421: INFO: Deleting all statefulset in ns statefulset-6597
Dec  5 07:08:15.424: INFO: Scaling statefulset ss to 0
Dec  5 07:08:35.443: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 07:08:35.445: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:08:35.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6597" for this suite.
Dec  5 07:08:41.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:08:41.615: INFO: namespace statefulset-6597 deletion completed in 6.142526637s

â€¢ [SLOW TEST:34.964 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:08:41.622: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:08:41.681: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6" in namespace "downward-api-2101" to be "success or failure"
Dec  5 07:08:41.694: INFO: Pod "downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6": Phase="Pending", Reason="", readiness=false. Elapsed: 13.14641ms
Dec  5 07:08:43.698: INFO: Pod "downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017093373s
Dec  5 07:08:45.702: INFO: Pod "downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021377202s
STEP: Saw pod success
Dec  5 07:08:45.702: INFO: Pod "downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6" satisfied condition "success or failure"
Dec  5 07:08:45.705: INFO: Trying to get logs from node worknode pod downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6 container client-container: <nil>
STEP: delete the pod
Dec  5 07:08:45.740: INFO: Waiting for pod downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6 to disappear
Dec  5 07:08:45.746: INFO: Pod downwardapi-volume-2719403e-b1ab-44f5-8adf-e6ddd9812be6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:08:45.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2101" for this suite.
Dec  5 07:08:51.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:08:51.863: INFO: namespace downward-api-2101 deletion completed in 6.112462498s

â€¢ [SLOW TEST:10.241 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:08:51.863: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec  5 07:08:51.906: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-6381'
Dec  5 07:08:52.037: INFO: stderr: ""
Dec  5 07:08:52.037: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 07:08:52.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6381'
Dec  5 07:08:52.144: INFO: stderr: ""
Dec  5 07:08:52.144: INFO: stdout: "update-demo-nautilus-27qh7 update-demo-nautilus-g7b5m "
Dec  5 07:08:52.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-27qh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:08:52.209: INFO: stderr: ""
Dec  5 07:08:52.209: INFO: stdout: ""
Dec  5 07:08:52.209: INFO: update-demo-nautilus-27qh7 is created but not running
Dec  5 07:08:57.211: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6381'
Dec  5 07:08:57.290: INFO: stderr: ""
Dec  5 07:08:57.290: INFO: stdout: "update-demo-nautilus-27qh7 update-demo-nautilus-g7b5m "
Dec  5 07:08:57.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-27qh7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:08:57.379: INFO: stderr: ""
Dec  5 07:08:57.379: INFO: stdout: "true"
Dec  5 07:08:57.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-27qh7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:08:57.451: INFO: stderr: ""
Dec  5 07:08:57.451: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:08:57.451: INFO: validating pod update-demo-nautilus-27qh7
Dec  5 07:08:57.460: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:08:57.460: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:08:57.460: INFO: update-demo-nautilus-27qh7 is verified up and running
Dec  5 07:08:57.460: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-g7b5m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:08:57.537: INFO: stderr: ""
Dec  5 07:08:57.537: INFO: stdout: "true"
Dec  5 07:08:57.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-g7b5m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:08:57.622: INFO: stderr: ""
Dec  5 07:08:57.622: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:08:57.622: INFO: validating pod update-demo-nautilus-g7b5m
Dec  5 07:08:57.626: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:08:57.626: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:08:57.626: INFO: update-demo-nautilus-g7b5m is verified up and running
STEP: rolling-update to new replication controller
Dec  5 07:08:57.628: INFO: scanned /root for discovery docs: <nil>
Dec  5 07:08:57.628: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6381'
Dec  5 07:09:20.216: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 07:09:20.216: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 07:09:20.217: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6381'
Dec  5 07:09:20.339: INFO: stderr: ""
Dec  5 07:09:20.339: INFO: stdout: "update-demo-kitten-bgwc5 update-demo-kitten-chcnt "
Dec  5 07:09:20.339: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-kitten-bgwc5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:09:20.418: INFO: stderr: ""
Dec  5 07:09:20.418: INFO: stdout: "true"
Dec  5 07:09:20.419: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-kitten-bgwc5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:09:20.503: INFO: stderr: ""
Dec  5 07:09:20.503: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 07:09:20.503: INFO: validating pod update-demo-kitten-bgwc5
Dec  5 07:09:20.510: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 07:09:20.510: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 07:09:20.510: INFO: update-demo-kitten-bgwc5 is verified up and running
Dec  5 07:09:20.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-kitten-chcnt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:09:20.600: INFO: stderr: ""
Dec  5 07:09:20.600: INFO: stdout: "true"
Dec  5 07:09:20.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-kitten-chcnt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6381'
Dec  5 07:09:20.671: INFO: stderr: ""
Dec  5 07:09:20.671: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  5 07:09:20.671: INFO: validating pod update-demo-kitten-chcnt
Dec  5 07:09:20.676: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  5 07:09:20.676: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  5 07:09:20.676: INFO: update-demo-kitten-chcnt is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:09:20.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6381" for this suite.
Dec  5 07:09:32.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:09:32.798: INFO: namespace kubectl-6381 deletion completed in 12.117721764s

â€¢ [SLOW TEST:40.935 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:09:32.800: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:09:32.833: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  5 07:09:34.878: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:09:34.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1556" for this suite.
Dec  5 07:09:40.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:09:41.092: INFO: namespace replication-controller-1556 deletion completed in 6.204455756s

â€¢ [SLOW TEST:8.292 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:09:41.093: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec  5 07:09:41.190: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4556" to be "success or failure"
Dec  5 07:09:41.196: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 5.814045ms
Dec  5 07:09:43.201: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01074265s
STEP: Saw pod success
Dec  5 07:09:43.201: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  5 07:09:43.205: INFO: Trying to get logs from node worknode pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  5 07:09:43.252: INFO: Waiting for pod pod-host-path-test to disappear
Dec  5 07:09:43.255: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:09:43.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4556" for this suite.
Dec  5 07:09:49.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:09:49.369: INFO: namespace hostpath-4556 deletion completed in 6.110157938s

â€¢ [SLOW TEST:8.276 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:09:49.370: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-86cbdf40-5434-467e-8238-df50336e041f
STEP: Creating a pod to test consume secrets
Dec  5 07:09:49.589: INFO: Waiting up to 5m0s for pod "pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514" in namespace "secrets-6528" to be "success or failure"
Dec  5 07:09:49.602: INFO: Pod "pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514": Phase="Pending", Reason="", readiness=false. Elapsed: 13.048776ms
Dec  5 07:09:51.612: INFO: Pod "pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023532116s
STEP: Saw pod success
Dec  5 07:09:51.613: INFO: Pod "pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514" satisfied condition "success or failure"
Dec  5 07:09:51.619: INFO: Trying to get logs from node worknode pod pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:09:51.680: INFO: Waiting for pod pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514 to disappear
Dec  5 07:09:51.688: INFO: Pod pod-secrets-31d6fbec-df88-4947-b37b-7506e7144514 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:09:51.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6528" for this suite.
Dec  5 07:09:57.725: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:09:57.849: INFO: namespace secrets-6528 deletion completed in 6.152884041s
STEP: Destroying namespace "secret-namespace-9822" for this suite.
Dec  5 07:10:03.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:10:03.962: INFO: namespace secret-namespace-9822 deletion completed in 6.113547382s

â€¢ [SLOW TEST:14.593 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:10:03.965: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:10:04.510: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}}, CollisionCount:(*int32)(nil)}
Dec  5 07:10:06.515: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126604, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:10:09.531: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:10:09.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-391" for this suite.
Dec  5 07:10:15.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:10:15.698: INFO: namespace webhook-391 deletion completed in 6.112019035s
STEP: Destroying namespace "webhook-391-markers" for this suite.
Dec  5 07:10:21.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:10:21.800: INFO: namespace webhook-391-markers deletion completed in 6.101506013s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.853 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:10:21.819: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-4cn4j in namespace proxy-5299
I1205 07:10:21.887588      20 runners.go:184] Created replication controller with name: proxy-service-4cn4j, namespace: proxy-5299, replica count: 1
I1205 07:10:22.946910      20 runners.go:184] proxy-service-4cn4j Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 07:10:23.952483      20 runners.go:184] proxy-service-4cn4j Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1205 07:10:24.959850      20 runners.go:184] proxy-service-4cn4j Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 07:10:24.962: INFO: setup took 3.109271224s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  5 07:10:24.982: INFO: (0) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 19.403772ms)
Dec  5 07:10:24.983: INFO: (0) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 19.573731ms)
Dec  5 07:10:24.990: INFO: (0) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 26.787658ms)
Dec  5 07:10:24.990: INFO: (0) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 27.266268ms)
Dec  5 07:10:24.993: INFO: (0) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 30.096128ms)
Dec  5 07:10:24.993: INFO: (0) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 30.122234ms)
Dec  5 07:10:24.993: INFO: (0) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 30.562438ms)
Dec  5 07:10:24.993: INFO: (0) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 30.32099ms)
Dec  5 07:10:24.999: INFO: (0) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 36.075698ms)
Dec  5 07:10:24.999: INFO: (0) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 36.061855ms)
Dec  5 07:10:25.000: INFO: (0) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 37.410824ms)
Dec  5 07:10:25.002: INFO: (0) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 39.815143ms)
Dec  5 07:10:25.003: INFO: (0) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 39.727855ms)
Dec  5 07:10:25.003: INFO: (0) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 39.980283ms)
Dec  5 07:10:25.003: INFO: (0) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 40.135988ms)
Dec  5 07:10:25.009: INFO: (0) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 45.883929ms)
Dec  5 07:10:25.020: INFO: (1) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.430269ms)
Dec  5 07:10:25.024: INFO: (1) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 13.471672ms)
Dec  5 07:10:25.024: INFO: (1) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 14.182378ms)
Dec  5 07:10:25.025: INFO: (1) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 15.032362ms)
Dec  5 07:10:25.025: INFO: (1) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 14.672043ms)
Dec  5 07:10:25.025: INFO: (1) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 16.142632ms)
Dec  5 07:10:25.026: INFO: (1) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 16.498291ms)
Dec  5 07:10:25.026: INFO: (1) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 16.695783ms)
Dec  5 07:10:25.026: INFO: (1) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 16.504092ms)
Dec  5 07:10:25.027: INFO: (1) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 17.590594ms)
Dec  5 07:10:25.032: INFO: (1) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 22.894511ms)
Dec  5 07:10:25.033: INFO: (1) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 23.698592ms)
Dec  5 07:10:25.033: INFO: (1) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 23.871222ms)
Dec  5 07:10:25.039: INFO: (1) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 29.144894ms)
Dec  5 07:10:25.039: INFO: (1) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 29.65122ms)
Dec  5 07:10:25.040: INFO: (1) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 29.457545ms)
Dec  5 07:10:25.051: INFO: (2) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 10.708096ms)
Dec  5 07:10:25.058: INFO: (2) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 17.226635ms)
Dec  5 07:10:25.061: INFO: (2) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 20.364614ms)
Dec  5 07:10:25.061: INFO: (2) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 20.916683ms)
Dec  5 07:10:25.061: INFO: (2) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 20.457645ms)
Dec  5 07:10:25.061: INFO: (2) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 21.085044ms)
Dec  5 07:10:25.061: INFO: (2) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 20.860778ms)
Dec  5 07:10:25.062: INFO: (2) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 20.507924ms)
Dec  5 07:10:25.064: INFO: (2) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 23.480805ms)
Dec  5 07:10:25.064: INFO: (2) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 23.658067ms)
Dec  5 07:10:25.066: INFO: (2) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 25.687353ms)
Dec  5 07:10:25.069: INFO: (2) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 29.31506ms)
Dec  5 07:10:25.070: INFO: (2) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 30.011717ms)
Dec  5 07:10:25.070: INFO: (2) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 29.77731ms)
Dec  5 07:10:25.072: INFO: (2) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 31.124684ms)
Dec  5 07:10:25.072: INFO: (2) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 31.377521ms)
Dec  5 07:10:25.108: INFO: (3) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 34.829489ms)
Dec  5 07:10:25.110: INFO: (3) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 37.528859ms)
Dec  5 07:10:25.113: INFO: (3) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 40.014077ms)
Dec  5 07:10:25.113: INFO: (3) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 40.1789ms)
Dec  5 07:10:25.113: INFO: (3) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 40.158488ms)
Dec  5 07:10:25.116: INFO: (3) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 42.977969ms)
Dec  5 07:10:25.119: INFO: (3) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 46.080792ms)
Dec  5 07:10:25.120: INFO: (3) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 47.771831ms)
Dec  5 07:10:25.120: INFO: (3) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 46.93277ms)
Dec  5 07:10:25.120: INFO: (3) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 47.303639ms)
Dec  5 07:10:25.122: INFO: (3) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 49.15465ms)
Dec  5 07:10:25.123: INFO: (3) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 50.356291ms)
Dec  5 07:10:25.123: INFO: (3) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 50.525013ms)
Dec  5 07:10:25.126: INFO: (3) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 53.606888ms)
Dec  5 07:10:25.128: INFO: (3) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 54.988706ms)
Dec  5 07:10:25.128: INFO: (3) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 55.609797ms)
Dec  5 07:10:25.145: INFO: (4) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 16.795239ms)
Dec  5 07:10:25.145: INFO: (4) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 16.120705ms)
Dec  5 07:10:25.145: INFO: (4) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 16.414374ms)
Dec  5 07:10:25.146: INFO: (4) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 16.887406ms)
Dec  5 07:10:25.152: INFO: (4) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 23.323233ms)
Dec  5 07:10:25.157: INFO: (4) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 27.938323ms)
Dec  5 07:10:25.158: INFO: (4) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 29.468496ms)
Dec  5 07:10:25.162: INFO: (4) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 32.948506ms)
Dec  5 07:10:25.162: INFO: (4) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 33.632556ms)
Dec  5 07:10:25.163: INFO: (4) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 33.651458ms)
Dec  5 07:10:25.163: INFO: (4) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 33.46962ms)
Dec  5 07:10:25.163: INFO: (4) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 34.123952ms)
Dec  5 07:10:25.164: INFO: (4) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 34.262447ms)
Dec  5 07:10:25.164: INFO: (4) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 35.691443ms)
Dec  5 07:10:25.165: INFO: (4) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 36.251882ms)
Dec  5 07:10:25.166: INFO: (4) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 37.709869ms)
Dec  5 07:10:25.183: INFO: (5) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 16.516188ms)
Dec  5 07:10:25.183: INFO: (5) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 16.56016ms)
Dec  5 07:10:25.183: INFO: (5) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 16.865672ms)
Dec  5 07:10:25.185: INFO: (5) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 18.294484ms)
Dec  5 07:10:25.185: INFO: (5) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 18.282864ms)
Dec  5 07:10:25.186: INFO: (5) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 18.696558ms)
Dec  5 07:10:25.187: INFO: (5) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 19.664077ms)
Dec  5 07:10:25.189: INFO: (5) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 22.314307ms)
Dec  5 07:10:25.189: INFO: (5) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 22.370281ms)
Dec  5 07:10:25.189: INFO: (5) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 23.011134ms)
Dec  5 07:10:25.201: INFO: (5) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 34.954754ms)
Dec  5 07:10:25.203: INFO: (5) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 36.352552ms)
Dec  5 07:10:25.206: INFO: (5) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 39.836741ms)
Dec  5 07:10:25.210: INFO: (5) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 43.358104ms)
Dec  5 07:10:25.211: INFO: (5) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 44.837974ms)
Dec  5 07:10:25.212: INFO: (5) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 45.412439ms)
Dec  5 07:10:25.227: INFO: (6) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 12.104887ms)
Dec  5 07:10:25.228: INFO: (6) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 14.238056ms)
Dec  5 07:10:25.230: INFO: (6) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 14.666842ms)
Dec  5 07:10:25.230: INFO: (6) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 15.72449ms)
Dec  5 07:10:25.233: INFO: (6) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 19.017902ms)
Dec  5 07:10:25.241: INFO: (6) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 27.318211ms)
Dec  5 07:10:25.241: INFO: (6) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 27.445911ms)
Dec  5 07:10:25.241: INFO: (6) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 26.556289ms)
Dec  5 07:10:25.242: INFO: (6) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 28.632652ms)
Dec  5 07:10:25.243: INFO: (6) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 28.596007ms)
Dec  5 07:10:25.246: INFO: (6) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 33.71041ms)
Dec  5 07:10:25.247: INFO: (6) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 32.350353ms)
Dec  5 07:10:25.247: INFO: (6) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 34.25596ms)
Dec  5 07:10:25.248: INFO: (6) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 34.711556ms)
Dec  5 07:10:25.249: INFO: (6) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 34.094076ms)
Dec  5 07:10:25.250: INFO: (6) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 37.071058ms)
Dec  5 07:10:25.266: INFO: (7) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 15.786251ms)
Dec  5 07:10:25.268: INFO: (7) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 17.937544ms)
Dec  5 07:10:25.270: INFO: (7) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 19.072455ms)
Dec  5 07:10:25.270: INFO: (7) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 19.249681ms)
Dec  5 07:10:25.272: INFO: (7) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 21.293273ms)
Dec  5 07:10:25.272: INFO: (7) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 21.618229ms)
Dec  5 07:10:25.272: INFO: (7) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 21.771447ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 23.340665ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 23.311143ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 23.718101ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 23.317497ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 23.532543ms)
Dec  5 07:10:25.274: INFO: (7) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 23.319518ms)
Dec  5 07:10:25.275: INFO: (7) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 24.483466ms)
Dec  5 07:10:25.276: INFO: (7) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 26.146974ms)
Dec  5 07:10:25.278: INFO: (7) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 27.334937ms)
Dec  5 07:10:25.285: INFO: (8) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 5.658785ms)
Dec  5 07:10:25.285: INFO: (8) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 7.025073ms)
Dec  5 07:10:25.286: INFO: (8) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 6.585055ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 15.265511ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 15.826386ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 15.500872ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 16.31901ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 14.344365ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 14.514672ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 15.092302ms)
Dec  5 07:10:25.294: INFO: (8) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 16.087631ms)
Dec  5 07:10:25.300: INFO: (8) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 20.21963ms)
Dec  5 07:10:25.301: INFO: (8) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 21.399153ms)
Dec  5 07:10:25.302: INFO: (8) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 22.423637ms)
Dec  5 07:10:25.303: INFO: (8) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 23.386033ms)
Dec  5 07:10:25.304: INFO: (8) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 24.837512ms)
Dec  5 07:10:25.313: INFO: (9) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 8.759718ms)
Dec  5 07:10:25.315: INFO: (9) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 9.627049ms)
Dec  5 07:10:25.316: INFO: (9) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.494779ms)
Dec  5 07:10:25.316: INFO: (9) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 11.488051ms)
Dec  5 07:10:25.317: INFO: (9) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 11.576109ms)
Dec  5 07:10:25.317: INFO: (9) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 12.503157ms)
Dec  5 07:10:25.317: INFO: (9) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 11.895694ms)
Dec  5 07:10:25.317: INFO: (9) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 12.321593ms)
Dec  5 07:10:25.317: INFO: (9) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 12.559767ms)
Dec  5 07:10:25.320: INFO: (9) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 15.179142ms)
Dec  5 07:10:25.325: INFO: (9) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 20.064542ms)
Dec  5 07:10:25.326: INFO: (9) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 21.41874ms)
Dec  5 07:10:25.326: INFO: (9) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 21.381547ms)
Dec  5 07:10:25.326: INFO: (9) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 22.13197ms)
Dec  5 07:10:25.326: INFO: (9) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 21.433366ms)
Dec  5 07:10:25.327: INFO: (9) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 21.557878ms)
Dec  5 07:10:25.338: INFO: (10) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 11.677948ms)
Dec  5 07:10:25.338: INFO: (10) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 10.453935ms)
Dec  5 07:10:25.339: INFO: (10) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 11.226028ms)
Dec  5 07:10:25.339: INFO: (10) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.756312ms)
Dec  5 07:10:25.339: INFO: (10) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 12.041747ms)
Dec  5 07:10:25.339: INFO: (10) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 11.537495ms)
Dec  5 07:10:25.339: INFO: (10) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 10.818161ms)
Dec  5 07:10:25.343: INFO: (10) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 15.79211ms)
Dec  5 07:10:25.343: INFO: (10) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 15.498867ms)
Dec  5 07:10:25.344: INFO: (10) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 15.861774ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 17.50313ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 17.690534ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 17.223651ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 17.151105ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 18.115197ms)
Dec  5 07:10:25.345: INFO: (10) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 18.306478ms)
Dec  5 07:10:25.356: INFO: (11) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.369216ms)
Dec  5 07:10:25.358: INFO: (11) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 12.615891ms)
Dec  5 07:10:25.359: INFO: (11) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 13.428143ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 14.550139ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 14.415565ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 15.058459ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 14.512081ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 14.409392ms)
Dec  5 07:10:25.361: INFO: (11) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 14.857898ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 15.591905ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 16.291912ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 15.995195ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 16.762608ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 16.764524ms)
Dec  5 07:10:25.362: INFO: (11) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 16.903961ms)
Dec  5 07:10:25.363: INFO: (11) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 17.368334ms)
Dec  5 07:10:25.370: INFO: (12) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 7.29895ms)
Dec  5 07:10:25.370: INFO: (12) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 7.198063ms)
Dec  5 07:10:25.374: INFO: (12) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 10.258266ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 10.556066ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 11.130592ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 10.308972ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 10.433308ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 11.279339ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.142035ms)
Dec  5 07:10:25.375: INFO: (12) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 10.672583ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 17.758354ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 17.956994ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 16.667291ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 18.353969ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 18.198414ms)
Dec  5 07:10:25.382: INFO: (12) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 17.380038ms)
Dec  5 07:10:25.393: INFO: (13) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 10.401625ms)
Dec  5 07:10:25.393: INFO: (13) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 9.66619ms)
Dec  5 07:10:25.395: INFO: (13) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 11.882146ms)
Dec  5 07:10:25.395: INFO: (13) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 11.857754ms)
Dec  5 07:10:25.395: INFO: (13) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 13.081431ms)
Dec  5 07:10:25.397: INFO: (13) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 14.44977ms)
Dec  5 07:10:25.399: INFO: (13) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 16.332462ms)
Dec  5 07:10:25.400: INFO: (13) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 17.670821ms)
Dec  5 07:10:25.401: INFO: (13) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 19.008765ms)
Dec  5 07:10:25.402: INFO: (13) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 20.223163ms)
Dec  5 07:10:25.401: INFO: (13) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 18.30521ms)
Dec  5 07:10:25.402: INFO: (13) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 19.089966ms)
Dec  5 07:10:25.403: INFO: (13) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 20.638926ms)
Dec  5 07:10:25.404: INFO: (13) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 21.192165ms)
Dec  5 07:10:25.405: INFO: (13) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 21.446712ms)
Dec  5 07:10:25.405: INFO: (13) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 21.471936ms)
Dec  5 07:10:25.413: INFO: (14) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 8.545254ms)
Dec  5 07:10:25.414: INFO: (14) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 8.201636ms)
Dec  5 07:10:25.414: INFO: (14) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 8.14067ms)
Dec  5 07:10:25.417: INFO: (14) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 10.992971ms)
Dec  5 07:10:25.417: INFO: (14) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 11.752038ms)
Dec  5 07:10:25.419: INFO: (14) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 12.740121ms)
Dec  5 07:10:25.419: INFO: (14) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 13.265185ms)
Dec  5 07:10:25.419: INFO: (14) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 13.508177ms)
Dec  5 07:10:25.420: INFO: (14) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 14.36761ms)
Dec  5 07:10:25.420: INFO: (14) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 14.145568ms)
Dec  5 07:10:25.420: INFO: (14) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 14.401946ms)
Dec  5 07:10:25.420: INFO: (14) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 14.829267ms)
Dec  5 07:10:25.420: INFO: (14) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 14.461974ms)
Dec  5 07:10:25.421: INFO: (14) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 14.907446ms)
Dec  5 07:10:25.424: INFO: (14) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 18.307776ms)
Dec  5 07:10:25.424: INFO: (14) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 17.67896ms)
Dec  5 07:10:25.435: INFO: (15) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 10.677651ms)
Dec  5 07:10:25.437: INFO: (15) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 11.692522ms)
Dec  5 07:10:25.437: INFO: (15) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 12.866928ms)
Dec  5 07:10:25.438: INFO: (15) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 12.86698ms)
Dec  5 07:10:25.438: INFO: (15) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 13.485262ms)
Dec  5 07:10:25.438: INFO: (15) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 13.245063ms)
Dec  5 07:10:25.438: INFO: (15) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 13.643389ms)
Dec  5 07:10:25.438: INFO: (15) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 12.747442ms)
Dec  5 07:10:25.440: INFO: (15) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 15.696562ms)
Dec  5 07:10:25.441: INFO: (15) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 16.517157ms)
Dec  5 07:10:25.442: INFO: (15) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 17.532495ms)
Dec  5 07:10:25.442: INFO: (15) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 16.612754ms)
Dec  5 07:10:25.442: INFO: (15) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 17.665814ms)
Dec  5 07:10:25.442: INFO: (15) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 18.092823ms)
Dec  5 07:10:25.443: INFO: (15) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 17.954331ms)
Dec  5 07:10:25.443: INFO: (15) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 18.401599ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 17.8017ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 18.122912ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 18.694281ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 18.367609ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 18.149763ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 18.648057ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 18.935003ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 18.194818ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 18.806792ms)
Dec  5 07:10:25.462: INFO: (16) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 18.15741ms)
Dec  5 07:10:25.471: INFO: (16) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 27.484771ms)
Dec  5 07:10:25.471: INFO: (16) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 28.09259ms)
Dec  5 07:10:25.472: INFO: (16) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 27.710421ms)
Dec  5 07:10:25.472: INFO: (16) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 28.112999ms)
Dec  5 07:10:25.472: INFO: (16) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 27.931613ms)
Dec  5 07:10:25.472: INFO: (16) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 28.196089ms)
Dec  5 07:10:25.483: INFO: (17) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 8.627287ms)
Dec  5 07:10:25.483: INFO: (17) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 8.964139ms)
Dec  5 07:10:25.483: INFO: (17) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 9.174506ms)
Dec  5 07:10:25.483: INFO: (17) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 9.482274ms)
Dec  5 07:10:25.485: INFO: (17) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 12.487621ms)
Dec  5 07:10:25.486: INFO: (17) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 12.745085ms)
Dec  5 07:10:25.486: INFO: (17) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 13.59322ms)
Dec  5 07:10:25.486: INFO: (17) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 13.008785ms)
Dec  5 07:10:25.486: INFO: (17) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 13.750485ms)
Dec  5 07:10:25.486: INFO: (17) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 13.111232ms)
Dec  5 07:10:25.489: INFO: (17) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 16.153159ms)
Dec  5 07:10:25.489: INFO: (17) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 16.212129ms)
Dec  5 07:10:25.489: INFO: (17) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 15.827762ms)
Dec  5 07:10:25.489: INFO: (17) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 15.549833ms)
Dec  5 07:10:25.491: INFO: (17) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 17.655894ms)
Dec  5 07:10:25.491: INFO: (17) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 17.811052ms)
Dec  5 07:10:25.502: INFO: (18) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 9.638386ms)
Dec  5 07:10:25.503: INFO: (18) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 10.432944ms)
Dec  5 07:10:25.503: INFO: (18) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 10.237223ms)
Dec  5 07:10:25.503: INFO: (18) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 10.572755ms)
Dec  5 07:10:25.504: INFO: (18) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 11.707654ms)
Dec  5 07:10:25.504: INFO: (18) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 11.552666ms)
Dec  5 07:10:25.507: INFO: (18) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 15.270558ms)
Dec  5 07:10:25.507: INFO: (18) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 15.327243ms)
Dec  5 07:10:25.507: INFO: (18) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 15.241961ms)
Dec  5 07:10:25.508: INFO: (18) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 16.500764ms)
Dec  5 07:10:25.511: INFO: (18) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 19.483961ms)
Dec  5 07:10:25.512: INFO: (18) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 19.336604ms)
Dec  5 07:10:25.512: INFO: (18) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 19.983851ms)
Dec  5 07:10:25.512: INFO: (18) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 20.12967ms)
Dec  5 07:10:25.512: INFO: (18) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 20.153845ms)
Dec  5 07:10:25.513: INFO: (18) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 21.516595ms)
Dec  5 07:10:25.524: INFO: (19) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname1/proxy/: foo (200; 10.127572ms)
Dec  5 07:10:25.525: INFO: (19) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname2/proxy/: tls qux (200; 10.566894ms)
Dec  5 07:10:25.525: INFO: (19) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">test<... (200; 11.118403ms)
Dec  5 07:10:25.525: INFO: (19) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname1/proxy/: foo (200; 10.855618ms)
Dec  5 07:10:25.525: INFO: (19) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh/proxy/rewriteme">test</a> (200; 11.27812ms)
Dec  5 07:10:25.533: INFO: (19) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 18.579861ms)
Dec  5 07:10:25.533: INFO: (19) /api/v1/namespaces/proxy-5299/services/proxy-service-4cn4j:portname2/proxy/: bar (200; 19.135381ms)
Dec  5 07:10:25.533: INFO: (19) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:1080/proxy/rewriteme">... (200; 18.858993ms)
Dec  5 07:10:25.533: INFO: (19) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:462/proxy/: tls qux (200; 18.970419ms)
Dec  5 07:10:25.534: INFO: (19) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 20.36987ms)
Dec  5 07:10:25.534: INFO: (19) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:460/proxy/: tls baz (200; 20.281344ms)
Dec  5 07:10:25.535: INFO: (19) /api/v1/namespaces/proxy-5299/pods/http:proxy-service-4cn4j-v59rh:162/proxy/: bar (200; 20.748281ms)
Dec  5 07:10:25.536: INFO: (19) /api/v1/namespaces/proxy-5299/services/https:proxy-service-4cn4j:tlsportname1/proxy/: tls baz (200; 21.989632ms)
Dec  5 07:10:25.536: INFO: (19) /api/v1/namespaces/proxy-5299/services/http:proxy-service-4cn4j:portname2/proxy/: bar (200; 22.156235ms)
Dec  5 07:10:25.536: INFO: (19) /api/v1/namespaces/proxy-5299/pods/proxy-service-4cn4j-v59rh:160/proxy/: foo (200; 21.761749ms)
Dec  5 07:10:25.536: INFO: (19) /api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/: <a href="/api/v1/namespaces/proxy-5299/pods/https:proxy-service-4cn4j-v59rh:443/proxy/tlsrewritem... (200; 22.15214ms)
STEP: deleting ReplicationController proxy-service-4cn4j in namespace proxy-5299, will wait for the garbage collector to delete the pods
Dec  5 07:10:25.603: INFO: Deleting ReplicationController proxy-service-4cn4j took: 11.404636ms
Dec  5 07:10:25.904: INFO: Terminating ReplicationController proxy-service-4cn4j pods took: 300.612195ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:10:35.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5299" for this suite.
Dec  5 07:10:41.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:10:41.910: INFO: namespace proxy-5299 deletion completed in 6.101661231s

â€¢ [SLOW TEST:20.091 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:10:41.912: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  5 07:10:41.945: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:10:45.818: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4838" for this suite.
Dec  5 07:10:57.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:10:57.998: INFO: namespace init-container-4838 deletion completed in 12.174717317s

â€¢ [SLOW TEST:16.087 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:10:57.998: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:10:58.062: INFO: (0) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 19.236637ms)
Dec  5 07:10:58.066: INFO: (1) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.147662ms)
Dec  5 07:10:58.070: INFO: (2) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.780111ms)
Dec  5 07:10:58.074: INFO: (3) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.406671ms)
Dec  5 07:10:58.078: INFO: (4) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.260473ms)
Dec  5 07:10:58.082: INFO: (5) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.24062ms)
Dec  5 07:10:58.085: INFO: (6) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.972156ms)
Dec  5 07:10:58.090: INFO: (7) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.401375ms)
Dec  5 07:10:58.093: INFO: (8) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.06128ms)
Dec  5 07:10:58.098: INFO: (9) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.755599ms)
Dec  5 07:10:58.101: INFO: (10) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.315436ms)
Dec  5 07:10:58.106: INFO: (11) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.261134ms)
Dec  5 07:10:58.110: INFO: (12) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.592893ms)
Dec  5 07:10:58.114: INFO: (13) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.195351ms)
Dec  5 07:10:58.118: INFO: (14) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.506752ms)
Dec  5 07:10:58.123: INFO: (15) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 5.165751ms)
Dec  5 07:10:58.127: INFO: (16) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.116375ms)
Dec  5 07:10:58.131: INFO: (17) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.86904ms)
Dec  5 07:10:58.135: INFO: (18) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.65018ms)
Dec  5 07:10:58.140: INFO: (19) /api/v1/nodes/allinone/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.348428ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:10:58.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3337" for this suite.
Dec  5 07:11:04.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:11:04.267: INFO: namespace proxy-3337 deletion completed in 6.123601448s

â€¢ [SLOW TEST:6.268 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:11:04.267: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:11:15.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7675" for this suite.
Dec  5 07:11:21.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:11:21.563: INFO: namespace resourcequota-7675 deletion completed in 6.120646407s

â€¢ [SLOW TEST:17.296 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:11:21.563: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:11:25.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9370" for this suite.
Dec  5 07:11:31.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:11:31.811: INFO: namespace kubelet-test-9370 deletion completed in 6.110512836s

â€¢ [SLOW TEST:10.248 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:11:31.815: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:11:31.860: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b" in namespace "downward-api-7216" to be "success or failure"
Dec  5 07:11:31.874: INFO: Pod "downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b": Phase="Pending", Reason="", readiness=false. Elapsed: 13.798831ms
Dec  5 07:11:33.878: INFO: Pod "downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017804179s
STEP: Saw pod success
Dec  5 07:11:33.878: INFO: Pod "downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b" satisfied condition "success or failure"
Dec  5 07:11:33.881: INFO: Trying to get logs from node worknode pod downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b container client-container: <nil>
STEP: delete the pod
Dec  5 07:11:33.921: INFO: Waiting for pod downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b to disappear
Dec  5 07:11:33.926: INFO: Pod downwardapi-volume-4d81a4ef-483a-4059-a387-9ddd20c1bc1b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:11:33.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7216" for this suite.
Dec  5 07:11:39.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:11:40.041: INFO: namespace downward-api-7216 deletion completed in 6.10936214s

â€¢ [SLOW TEST:8.227 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:11:40.042: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:11:53.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8799" for this suite.
Dec  5 07:11:59.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:11:59.365: INFO: namespace namespaces-8799 deletion completed in 6.119701202s
STEP: Destroying namespace "nsdeletetest-138" for this suite.
Dec  5 07:11:59.367: INFO: Namespace nsdeletetest-138 was already deleted
STEP: Destroying namespace "nsdeletetest-4758" for this suite.
Dec  5 07:12:05.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:05.493: INFO: namespace nsdeletetest-4758 deletion completed in 6.125461624s

â€¢ [SLOW TEST:25.451 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:12:05.499: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-453/secret-test-6abd3b96-35fa-444e-a05b-93af30c615d4
STEP: Creating a pod to test consume secrets
Dec  5 07:12:05.570: INFO: Waiting up to 5m0s for pod "pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a" in namespace "secrets-453" to be "success or failure"
Dec  5 07:12:05.581: INFO: Pod "pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.192968ms
Dec  5 07:12:07.585: INFO: Pod "pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014340887s
STEP: Saw pod success
Dec  5 07:12:07.585: INFO: Pod "pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a" satisfied condition "success or failure"
Dec  5 07:12:07.588: INFO: Trying to get logs from node worknode pod pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a container env-test: <nil>
STEP: delete the pod
Dec  5 07:12:07.622: INFO: Waiting for pod pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a to disappear
Dec  5 07:12:07.628: INFO: Pod pod-configmaps-5e5aafc8-8a30-4cb6-975f-d2a969e3440a no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:12:07.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-453" for this suite.
Dec  5 07:12:13.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:13.781: INFO: namespace secrets-453 deletion completed in 6.148107302s

â€¢ [SLOW TEST:8.282 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:12:13.783: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 07:12:13.828: INFO: Waiting up to 5m0s for pod "pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5" in namespace "emptydir-354" to be "success or failure"
Dec  5 07:12:13.837: INFO: Pod "pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5": Phase="Pending", Reason="", readiness=false. Elapsed: 8.367568ms
Dec  5 07:12:15.843: INFO: Pod "pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014656673s
STEP: Saw pod success
Dec  5 07:12:15.843: INFO: Pod "pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5" satisfied condition "success or failure"
Dec  5 07:12:15.847: INFO: Trying to get logs from node worknode pod pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5 container test-container: <nil>
STEP: delete the pod
Dec  5 07:12:15.884: INFO: Waiting for pod pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5 to disappear
Dec  5 07:12:15.913: INFO: Pod pod-9c28d2cd-ea5f-49b5-bca3-245ce8a011b5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:12:15.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-354" for this suite.
Dec  5 07:12:21.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:22.060: INFO: namespace emptydir-354 deletion completed in 6.140490124s

â€¢ [SLOW TEST:8.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:12:22.061: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-662094fe-858c-4406-a0e1-b7f3082f1329
STEP: Creating configMap with name cm-test-opt-upd-8bd61f17-c3ed-40a2-8d9e-198181c58d68
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-662094fe-858c-4406-a0e1-b7f3082f1329
STEP: Updating configmap cm-test-opt-upd-8bd61f17-c3ed-40a2-8d9e-198181c58d68
STEP: Creating configMap with name cm-test-opt-create-2da0e83a-661c-4c03-a8e1-f235fcdc7057
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:12:26.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2835" for this suite.
Dec  5 07:12:38.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:38.342: INFO: namespace projected-2835 deletion completed in 12.124012085s

â€¢ [SLOW TEST:16.281 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:12:38.343: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:12:44.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2036" for this suite.
Dec  5 07:12:50.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:50.602: INFO: namespace namespaces-2036 deletion completed in 6.122327696s
STEP: Destroying namespace "nsdeletetest-2722" for this suite.
Dec  5 07:12:50.605: INFO: Namespace nsdeletetest-2722 was already deleted
STEP: Destroying namespace "nsdeletetest-4914" for this suite.
Dec  5 07:12:56.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:12:56.732: INFO: namespace nsdeletetest-4914 deletion completed in 6.126969388s

â€¢ [SLOW TEST:18.390 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:12:56.738: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec  5 07:12:56.788: INFO: Waiting up to 5m0s for pod "var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408" in namespace "var-expansion-2628" to be "success or failure"
Dec  5 07:12:56.801: INFO: Pod "var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408": Phase="Pending", Reason="", readiness=false. Elapsed: 12.92997ms
Dec  5 07:12:58.805: INFO: Pod "var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016548017s
STEP: Saw pod success
Dec  5 07:12:58.805: INFO: Pod "var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408" satisfied condition "success or failure"
Dec  5 07:12:58.808: INFO: Trying to get logs from node worknode pod var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408 container dapi-container: <nil>
STEP: delete the pod
Dec  5 07:12:58.844: INFO: Waiting for pod var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408 to disappear
Dec  5 07:12:58.851: INFO: Pod var-expansion-c8abd191-5937-4e01-9882-b5aa075c0408 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:12:58.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2628" for this suite.
Dec  5 07:13:04.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:13:05.017: INFO: namespace var-expansion-2628 deletion completed in 6.152154591s

â€¢ [SLOW TEST:8.279 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:13:05.017: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:13:05.062: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33" in namespace "projected-9330" to be "success or failure"
Dec  5 07:13:05.075: INFO: Pod "downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33": Phase="Pending", Reason="", readiness=false. Elapsed: 12.6542ms
Dec  5 07:13:07.087: INFO: Pod "downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025534159s
Dec  5 07:13:09.099: INFO: Pod "downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.037120735s
STEP: Saw pod success
Dec  5 07:13:09.099: INFO: Pod "downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33" satisfied condition "success or failure"
Dec  5 07:13:09.102: INFO: Trying to get logs from node worknode pod downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33 container client-container: <nil>
STEP: delete the pod
Dec  5 07:13:09.141: INFO: Waiting for pod downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33 to disappear
Dec  5 07:13:09.144: INFO: Pod downwardapi-volume-ace9b4c2-6674-4e2f-9cc4-ad8a755ddd33 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:13:09.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9330" for this suite.
Dec  5 07:13:15.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:13:15.270: INFO: namespace projected-9330 deletion completed in 6.122869062s

â€¢ [SLOW TEST:10.253 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:13:15.273: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  5 07:13:15.310: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:13:30.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5126" for this suite.
Dec  5 07:13:36.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:13:36.807: INFO: namespace crd-publish-openapi-5126 deletion completed in 6.102712621s

â€¢ [SLOW TEST:21.534 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:13:36.813: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:13:37.378: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:13:40.402: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:13:40.405: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-2572-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:13:41.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2696" for this suite.
Dec  5 07:13:47.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:13:47.745: INFO: namespace webhook-2696 deletion completed in 6.161343903s
STEP: Destroying namespace "webhook-2696-markers" for this suite.
Dec  5 07:13:53.786: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:13:53.907: INFO: namespace webhook-2696-markers deletion completed in 6.161654992s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.109 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:13:53.922: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:13:53.969: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f" in namespace "downward-api-7275" to be "success or failure"
Dec  5 07:13:54.006: INFO: Pod "downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f": Phase="Pending", Reason="", readiness=false. Elapsed: 37.063014ms
Dec  5 07:13:56.024: INFO: Pod "downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.055016983s
STEP: Saw pod success
Dec  5 07:13:56.024: INFO: Pod "downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f" satisfied condition "success or failure"
Dec  5 07:13:56.029: INFO: Trying to get logs from node worknode pod downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f container client-container: <nil>
STEP: delete the pod
Dec  5 07:13:56.069: INFO: Waiting for pod downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f to disappear
Dec  5 07:13:56.079: INFO: Pod downwardapi-volume-44ffb565-4380-48cd-9d92-1b5caf3c649f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:13:56.079: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7275" for this suite.
Dec  5 07:14:02.122: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:14:02.209: INFO: namespace downward-api-7275 deletion completed in 6.122006506s

â€¢ [SLOW TEST:8.288 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:14:02.209: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1422.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-1422.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1422.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-1422.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-1422.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1422.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 07:14:04.319: INFO: DNS probes using dns-1422/dns-test-79386ab0-e1cd-4395-8fc4-5b51e4b3afe8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:14:04.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1422" for this suite.
Dec  5 07:14:10.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:14:10.460: INFO: namespace dns-1422 deletion completed in 6.102564463s

â€¢ [SLOW TEST:8.251 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:14:10.462: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-v8mw
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 07:14:10.557: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-v8mw" in namespace "subpath-1837" to be "success or failure"
Dec  5 07:14:10.562: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.346837ms
Dec  5 07:14:12.565: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 2.007701894s
Dec  5 07:14:14.570: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 4.012174334s
Dec  5 07:14:16.574: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 6.016851156s
Dec  5 07:14:18.579: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 8.021257068s
Dec  5 07:14:20.585: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 10.027852605s
Dec  5 07:14:22.589: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 12.031470836s
Dec  5 07:14:24.592: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 14.034683065s
Dec  5 07:14:26.598: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 16.040521962s
Dec  5 07:14:28.602: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 18.044904349s
Dec  5 07:14:30.615: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Running", Reason="", readiness=true. Elapsed: 20.057947387s
Dec  5 07:14:32.619: INFO: Pod "pod-subpath-test-configmap-v8mw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.062053078s
STEP: Saw pod success
Dec  5 07:14:32.619: INFO: Pod "pod-subpath-test-configmap-v8mw" satisfied condition "success or failure"
Dec  5 07:14:32.625: INFO: Trying to get logs from node worknode pod pod-subpath-test-configmap-v8mw container test-container-subpath-configmap-v8mw: <nil>
STEP: delete the pod
Dec  5 07:14:32.644: INFO: Waiting for pod pod-subpath-test-configmap-v8mw to disappear
Dec  5 07:14:32.648: INFO: Pod pod-subpath-test-configmap-v8mw no longer exists
STEP: Deleting pod pod-subpath-test-configmap-v8mw
Dec  5 07:14:32.649: INFO: Deleting pod "pod-subpath-test-configmap-v8mw" in namespace "subpath-1837"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:14:32.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1837" for this suite.
Dec  5 07:14:38.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:14:38.770: INFO: namespace subpath-1837 deletion completed in 6.110076759s

â€¢ [SLOW TEST:28.308 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:14:38.771: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 07:14:38.811: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4368'
Dec  5 07:14:38.922: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 07:14:38.923: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec  5 07:14:38.968: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-vf9lg]
Dec  5 07:14:38.968: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-vf9lg" in namespace "kubectl-4368" to be "running and ready"
Dec  5 07:14:39.010: INFO: Pod "e2e-test-httpd-rc-vf9lg": Phase="Pending", Reason="", readiness=false. Elapsed: 42.312277ms
Dec  5 07:14:41.015: INFO: Pod "e2e-test-httpd-rc-vf9lg": Phase="Pending", Reason="", readiness=false. Elapsed: 2.04668318s
Dec  5 07:14:43.019: INFO: Pod "e2e-test-httpd-rc-vf9lg": Phase="Running", Reason="", readiness=true. Elapsed: 4.051091765s
Dec  5 07:14:43.019: INFO: Pod "e2e-test-httpd-rc-vf9lg" satisfied condition "running and ready"
Dec  5 07:14:43.019: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-vf9lg]
Dec  5 07:14:43.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs rc/e2e-test-httpd-rc --namespace=kubectl-4368'
Dec  5 07:14:43.118: INFO: stderr: ""
Dec  5 07:14:43.118: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.233.218. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 192.168.233.218. Set the 'ServerName' directive globally to suppress this message\n[Thu Dec 05 07:14:40.975391 2019] [mpm_event:notice] [pid 1:tid 140035841612648] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Thu Dec 05 07:14:40.975440 2019] [core:notice] [pid 1:tid 140035841612648] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec  5 07:14:43.118: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete rc e2e-test-httpd-rc --namespace=kubectl-4368'
Dec  5 07:14:43.204: INFO: stderr: ""
Dec  5 07:14:43.204: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:14:43.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4368" for this suite.
Dec  5 07:15:11.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:15:11.309: INFO: namespace kubectl-4368 deletion completed in 28.099099916s

â€¢ [SLOW TEST:32.539 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:15:11.310: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ff652593-0b75-44fb-9a49-f5a7fb51c67b
STEP: Creating a pod to test consume secrets
Dec  5 07:15:11.354: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4" in namespace "projected-7233" to be "success or failure"
Dec  5 07:15:11.358: INFO: Pod "pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.743386ms
Dec  5 07:15:13.362: INFO: Pod "pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008345637s
STEP: Saw pod success
Dec  5 07:15:13.362: INFO: Pod "pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4" satisfied condition "success or failure"
Dec  5 07:15:13.365: INFO: Trying to get logs from node worknode pod pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:15:13.394: INFO: Waiting for pod pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4 to disappear
Dec  5 07:15:13.399: INFO: Pod pod-projected-secrets-0b61143b-79bb-4a1d-9852-11255b39acb4 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:15:13.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7233" for this suite.
Dec  5 07:15:19.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:15:19.519: INFO: namespace projected-7233 deletion completed in 6.11434461s

â€¢ [SLOW TEST:8.209 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:15:19.519: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:15:36.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7290" for this suite.
Dec  5 07:15:42.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:15:42.719: INFO: namespace resourcequota-7290 deletion completed in 6.109240071s

â€¢ [SLOW TEST:23.200 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:15:42.719: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:15:42.752: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  5 07:15:45.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-3762 create -f -'
Dec  5 07:15:45.875: INFO: stderr: ""
Dec  5 07:15:45.875: INFO: stdout: "e2e-test-crd-publish-openapi-9734-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  5 07:15:45.875: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-3762 delete e2e-test-crd-publish-openapi-9734-crds test-cr'
Dec  5 07:15:45.954: INFO: stderr: ""
Dec  5 07:15:45.954: INFO: stdout: "e2e-test-crd-publish-openapi-9734-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec  5 07:15:45.954: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-3762 apply -f -'
Dec  5 07:15:46.127: INFO: stderr: ""
Dec  5 07:15:46.127: INFO: stdout: "e2e-test-crd-publish-openapi-9734-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  5 07:15:46.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-3762 delete e2e-test-crd-publish-openapi-9734-crds test-cr'
Dec  5 07:15:46.222: INFO: stderr: ""
Dec  5 07:15:46.222: INFO: stdout: "e2e-test-crd-publish-openapi-9734-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  5 07:15:46.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-9734-crds'
Dec  5 07:15:46.359: INFO: stderr: ""
Dec  5 07:15:46.359: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9734-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:15:49.189: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3762" for this suite.
Dec  5 07:15:55.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:15:55.320: INFO: namespace crd-publish-openapi-3762 deletion completed in 6.127639678s

â€¢ [SLOW TEST:12.601 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:15:55.320: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:15:55.829: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 07:15:57.844: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126955, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126955, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126955, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711126955, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:16:00.871: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:16:00.875: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7676-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:16:02.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6004" for this suite.
Dec  5 07:16:08.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:08.269: INFO: namespace webhook-6004 deletion completed in 6.24700384s
STEP: Destroying namespace "webhook-6004-markers" for this suite.
Dec  5 07:16:14.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:14.381: INFO: namespace webhook-6004-markers deletion completed in 6.112119348s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:19.077 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:16:14.398: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  5 07:16:16.997: INFO: Successfully updated pod "labelsupdated58b0dcb-18c6-47ad-a74e-ea968f0f8209"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:16:21.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7817" for this suite.
Dec  5 07:16:33.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:33.134: INFO: namespace projected-7817 deletion completed in 12.102109565s

â€¢ [SLOW TEST:18.736 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:16:33.134: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:16:33.604: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:16:36.631: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:16:36.633: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7818-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:16:37.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5220" for this suite.
Dec  5 07:16:43.794: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:43.936: INFO: namespace webhook-5220 deletion completed in 6.163978132s
STEP: Destroying namespace "webhook-5220-markers" for this suite.
Dec  5 07:16:49.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:50.045: INFO: namespace webhook-5220-markers deletion completed in 6.108100712s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.929 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:16:50.064: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  5 07:16:50.100: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 07:16:50.113: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 07:16:50.116: INFO: 
Logging pods the kubelet thinks is on node allinone before test
Dec  5 07:16:50.137: INFO: kube-controller-manager-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.137: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec  5 07:16:50.137: INFO: coredns-5644d7b6d9-8vk79 from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.137: INFO: 	Container coredns ready: true, restart count 0
Dec  5 07:16:50.137: INFO: calico-kube-controllers-55754f75c-g2l8q from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.137: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 07:16:50.138: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:16:50.138: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 07:16:50.138: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 07:16:50.138: INFO: etcd-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.138: INFO: 	Container etcd ready: true, restart count 0
Dec  5 07:16:50.138: INFO: kube-scheduler-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.138: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec  5 07:16:50.138: INFO: coredns-5644d7b6d9-5jdzn from kube-system started at 2019-12-05 06:35:26 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.139: INFO: 	Container coredns ready: true, restart count 0
Dec  5 07:16:50.139: INFO: kube-apiserver-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.142: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec  5 07:16:50.144: INFO: calico-node-wt92j from kube-system started at 2019-12-05 06:35:16 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.144: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 07:16:50.144: INFO: kube-proxy-4g9tm from kube-system started at 2019-12-05 06:34:04 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.144: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 07:16:50.144: INFO: 
Logging pods the kubelet thinks is on node worknode before test
Dec  5 07:16:50.158: INFO: calico-node-pnldh from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.158: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 07:16:50.158: INFO: kube-proxy-x5czv from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.158: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 07:16:50.158: INFO: sonobuoy from sonobuoy started at 2019-12-05 06:49:53 +0000 UTC (1 container statuses recorded)
Dec  5 07:16:50.158: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 07:16:50.158: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:16:50.158: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 07:16:50.158: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 07:16:50.158: INFO: sonobuoy-e2e-job-6da6843aacc74c61 from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:16:50.158: INFO: 	Container e2e ready: true, restart count 0
Dec  5 07:16:50.158: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dd6860ee937ad2], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:16:51.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1583" for this suite.
Dec  5 07:16:57.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:16:57.289: INFO: namespace sched-pred-1583 deletion completed in 6.10089587s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:7.226 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:16:57.295: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:16:57.915: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 07:16:59.924: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127017, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127017, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127017, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127017, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:17:02.944: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:17:13.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-122" for this suite.
Dec  5 07:17:19.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:17:19.163: INFO: namespace webhook-122 deletion completed in 6.101734153s
STEP: Destroying namespace "webhook-122-markers" for this suite.
Dec  5 07:17:25.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:17:25.267: INFO: namespace webhook-122-markers deletion completed in 6.104174547s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:27.984 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:17:25.279: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  5 07:17:25.321: INFO: Waiting up to 5m0s for pod "pod-7846c010-bb80-45c0-81fc-fa98596dfea2" in namespace "emptydir-430" to be "success or failure"
Dec  5 07:17:25.334: INFO: Pod "pod-7846c010-bb80-45c0-81fc-fa98596dfea2": Phase="Pending", Reason="", readiness=false. Elapsed: 13.129263ms
Dec  5 07:17:27.338: INFO: Pod "pod-7846c010-bb80-45c0-81fc-fa98596dfea2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.017619324s
STEP: Saw pod success
Dec  5 07:17:27.339: INFO: Pod "pod-7846c010-bb80-45c0-81fc-fa98596dfea2" satisfied condition "success or failure"
Dec  5 07:17:27.342: INFO: Trying to get logs from node worknode pod pod-7846c010-bb80-45c0-81fc-fa98596dfea2 container test-container: <nil>
STEP: delete the pod
Dec  5 07:17:27.371: INFO: Waiting for pod pod-7846c010-bb80-45c0-81fc-fa98596dfea2 to disappear
Dec  5 07:17:27.377: INFO: Pod pod-7846c010-bb80-45c0-81fc-fa98596dfea2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:17:27.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-430" for this suite.
Dec  5 07:17:33.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:17:33.482: INFO: namespace emptydir-430 deletion completed in 6.102585553s

â€¢ [SLOW TEST:8.203 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:17:33.484: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b3d4f5e2-5244-4dd1-b8f7-7e3f053bc8f8 in namespace container-probe-1198
Dec  5 07:17:35.549: INFO: Started pod busybox-b3d4f5e2-5244-4dd1-b8f7-7e3f053bc8f8 in namespace container-probe-1198
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 07:17:35.552: INFO: Initial restart count of pod busybox-b3d4f5e2-5244-4dd1-b8f7-7e3f053bc8f8 is 0
Dec  5 07:18:23.774: INFO: Restart count of pod container-probe-1198/busybox-b3d4f5e2-5244-4dd1-b8f7-7e3f053bc8f8 is now 1 (48.221650485s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:18:23.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1198" for this suite.
Dec  5 07:18:29.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:18:29.915: INFO: namespace container-probe-1198 deletion completed in 6.110116544s

â€¢ [SLOW TEST:56.432 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:18:29.919: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:18:29.950: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:18:30.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3189" for this suite.
Dec  5 07:18:36.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:18:36.598: INFO: namespace custom-resource-definition-3189 deletion completed in 6.105738562s

â€¢ [SLOW TEST:6.679 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:18:36.598: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  5 07:18:46.744: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1205 07:18:46.744271      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:18:46.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-147" for this suite.
Dec  5 07:18:52.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:18:53.130: INFO: namespace gc-147 deletion completed in 6.383273004s

â€¢ [SLOW TEST:16.532 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:18:53.132: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  5 07:18:56.281: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:18:57.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8703" for this suite.
Dec  5 07:19:21.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:19:21.413: INFO: namespace replicaset-8703 deletion completed in 24.104391436s

â€¢ [SLOW TEST:28.281 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:19:21.414: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-796f9af3-1af8-4257-9e31-51f82ee4efa6
STEP: Creating a pod to test consume configMaps
Dec  5 07:19:21.462: INFO: Waiting up to 5m0s for pod "pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690" in namespace "configmap-8508" to be "success or failure"
Dec  5 07:19:21.469: INFO: Pod "pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690": Phase="Pending", Reason="", readiness=false. Elapsed: 7.385573ms
Dec  5 07:19:23.473: INFO: Pod "pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011076335s
STEP: Saw pod success
Dec  5 07:19:23.473: INFO: Pod "pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690" satisfied condition "success or failure"
Dec  5 07:19:23.477: INFO: Trying to get logs from node worknode pod pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 07:19:23.513: INFO: Waiting for pod pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690 to disappear
Dec  5 07:19:23.518: INFO: Pod pod-configmaps-331f69a7-aad2-4864-a118-6a0113a8b690 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:19:23.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8508" for this suite.
Dec  5 07:19:29.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:19:29.652: INFO: namespace configmap-8508 deletion completed in 6.12891581s

â€¢ [SLOW TEST:8.238 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:19:29.653: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-f069c301-d682-4e94-af24-4e5e296eb088 in namespace container-probe-2008
Dec  5 07:19:31.718: INFO: Started pod test-webserver-f069c301-d682-4e94-af24-4e5e296eb088 in namespace container-probe-2008
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 07:19:31.721: INFO: Initial restart count of pod test-webserver-f069c301-d682-4e94-af24-4e5e296eb088 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:23:32.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2008" for this suite.
Dec  5 07:23:38.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:23:38.794: INFO: namespace container-probe-2008 deletion completed in 6.115586671s

â€¢ [SLOW TEST:249.140 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:23:38.794: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  5 07:23:43.363: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3536 pod-service-account-591d4904-ed08-4ff6-a08a-de8a39114b44 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  5 07:23:43.604: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3536 pod-service-account-591d4904-ed08-4ff6-a08a-de8a39114b44 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  5 07:23:43.878: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3536 pod-service-account-591d4904-ed08-4ff6-a08a-de8a39114b44 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:23:44.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3536" for this suite.
Dec  5 07:23:50.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:23:50.280: INFO: namespace svcaccounts-3536 deletion completed in 6.102579659s

â€¢ [SLOW TEST:11.486 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:23:50.281: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:23:50.317: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  5 07:23:53.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-861 create -f -'
Dec  5 07:23:54.196: INFO: stderr: ""
Dec  5 07:23:54.196: INFO: stdout: "e2e-test-crd-publish-openapi-3451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  5 07:23:54.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-861 delete e2e-test-crd-publish-openapi-3451-crds test-cr'
Dec  5 07:23:54.275: INFO: stderr: ""
Dec  5 07:23:54.275: INFO: stdout: "e2e-test-crd-publish-openapi-3451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec  5 07:23:54.275: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-861 apply -f -'
Dec  5 07:23:54.425: INFO: stderr: ""
Dec  5 07:23:54.425: INFO: stdout: "e2e-test-crd-publish-openapi-3451-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  5 07:23:54.425: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-861 delete e2e-test-crd-publish-openapi-3451-crds test-cr'
Dec  5 07:23:54.507: INFO: stderr: ""
Dec  5 07:23:54.507: INFO: stdout: "e2e-test-crd-publish-openapi-3451-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  5 07:23:54.507: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-3451-crds'
Dec  5 07:23:54.653: INFO: stderr: ""
Dec  5 07:23:54.653: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3451-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:23:57.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-861" for this suite.
Dec  5 07:24:03.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:03.661: INFO: namespace crd-publish-openapi-861 deletion completed in 6.110872052s

â€¢ [SLOW TEST:13.380 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:03.661: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:24:07.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-9113" for this suite.
Dec  5 07:24:13.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:13.991: INFO: namespace emptydir-wrapper-9113 deletion completed in 6.170390941s

â€¢ [SLOW TEST:10.330 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:13.992: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-9f24ca5f-6afc-4fb1-a5ee-29a883dc292a
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:24:14.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9215" for this suite.
Dec  5 07:24:20.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:20.171: INFO: namespace configmap-9215 deletion completed in 6.128272568s

â€¢ [SLOW TEST:6.179 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:20.173: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-1ded98b2-c73f-4770-b72b-bab9ce8ca1c5
STEP: Creating a pod to test consume secrets
Dec  5 07:24:20.229: INFO: Waiting up to 5m0s for pod "pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a" in namespace "secrets-322" to be "success or failure"
Dec  5 07:24:20.244: INFO: Pod "pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a": Phase="Pending", Reason="", readiness=false. Elapsed: 14.81516ms
Dec  5 07:24:22.248: INFO: Pod "pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.018326742s
Dec  5 07:24:24.251: INFO: Pod "pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.022204029s
STEP: Saw pod success
Dec  5 07:24:24.252: INFO: Pod "pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a" satisfied condition "success or failure"
Dec  5 07:24:24.255: INFO: Trying to get logs from node worknode pod pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:24:24.311: INFO: Waiting for pod pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a to disappear
Dec  5 07:24:24.316: INFO: Pod pod-secrets-19ab6a9b-2956-4700-b921-35b6f63f497a no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:24:24.316: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-322" for this suite.
Dec  5 07:24:30.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:30.465: INFO: namespace secrets-322 deletion completed in 6.143527504s

â€¢ [SLOW TEST:10.293 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:30.466: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:24:30.560: INFO: Waiting up to 5m0s for pod "downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442" in namespace "downward-api-3744" to be "success or failure"
Dec  5 07:24:30.571: INFO: Pod "downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442": Phase="Pending", Reason="", readiness=false. Elapsed: 10.233895ms
Dec  5 07:24:32.575: INFO: Pod "downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014399274s
STEP: Saw pod success
Dec  5 07:24:32.575: INFO: Pod "downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442" satisfied condition "success or failure"
Dec  5 07:24:32.578: INFO: Trying to get logs from node worknode pod downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442 container client-container: <nil>
STEP: delete the pod
Dec  5 07:24:32.610: INFO: Waiting for pod downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442 to disappear
Dec  5 07:24:32.616: INFO: Pod downwardapi-volume-276e7d29-a06f-4f44-a1e3-abfb425cc442 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:24:32.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3744" for this suite.
Dec  5 07:24:38.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:38.745: INFO: namespace downward-api-3744 deletion completed in 6.123830633s

â€¢ [SLOW TEST:8.279 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:38.747: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:24:49.900: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5125" for this suite.
Dec  5 07:24:55.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:24:56.146: INFO: namespace resourcequota-5125 deletion completed in 6.243839153s

â€¢ [SLOW TEST:17.400 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:24:56.147: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:25:56.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5546" for this suite.
Dec  5 07:26:08.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:26:08.362: INFO: namespace container-probe-5546 deletion completed in 12.153923449s

â€¢ [SLOW TEST:72.216 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:26:08.363: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:26:09.025: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:26:12.081: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:26:12.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6082" for this suite.
Dec  5 07:26:18.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:26:18.314: INFO: namespace webhook-6082 deletion completed in 6.166911288s
STEP: Destroying namespace "webhook-6082-markers" for this suite.
Dec  5 07:26:24.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:26:24.453: INFO: namespace webhook-6082-markers deletion completed in 6.13892977s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.110 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:26:24.472: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-1e259163-0a7b-4496-b6de-28468ca052e3
STEP: Creating secret with name s-test-opt-upd-86f60165-5937-4471-9928-3b5d218a62d8
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1e259163-0a7b-4496-b6de-28468ca052e3
STEP: Updating secret s-test-opt-upd-86f60165-5937-4471-9928-3b5d218a62d8
STEP: Creating secret with name s-test-opt-create-7ddac13b-7454-4478-9a1b-6e0d87aa2ca6
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:26:30.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-628" for this suite.
Dec  5 07:26:42.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:26:42.872: INFO: namespace projected-628 deletion completed in 12.175859253s

â€¢ [SLOW TEST:18.399 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:26:42.876: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  5 07:26:42.999: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10543 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 07:26:42.999: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10544 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 07:26:42.999: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10545 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  5 07:26:53.041: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10560 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 07:26:53.041: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10561 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  5 07:26:53.041: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8102 /api/v1/namespaces/watch-8102/configmaps/e2e-watch-test-label-changed a19d7600-857e-4ad9-aa94-126e611b9bf1 10562 0 2019-12-05 07:26:42 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:26:53.041: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8102" for this suite.
Dec  5 07:26:59.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:26:59.181: INFO: namespace watch-8102 deletion completed in 6.135290295s

â€¢ [SLOW TEST:16.305 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:26:59.181: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1205 07:27:39.261962      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 07:27:39.262: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:27:39.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2271" for this suite.
Dec  5 07:27:47.322: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:27:47.677: INFO: namespace gc-2271 deletion completed in 8.411548586s

â€¢ [SLOW TEST:48.495 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:27:47.678: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:27:47.796: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:27:47.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3663" for this suite.
Dec  5 07:27:54.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:27:54.136: INFO: namespace custom-resource-definition-3663 deletion completed in 6.241417362s

â€¢ [SLOW TEST:6.459 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:27:54.142: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2652
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  5 07:27:54.198: INFO: Found 0 stateful pods, waiting for 3
Dec  5 07:28:04.208: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 07:28:04.208: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 07:28:04.208: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  5 07:28:04.238: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  5 07:28:14.275: INFO: Updating stateful set ss2
Dec  5 07:28:14.293: INFO: Waiting for Pod statefulset-2652/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  5 07:28:24.308: INFO: Waiting for Pod statefulset-2652/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec  5 07:28:34.414: INFO: Found 2 stateful pods, waiting for 3
Dec  5 07:28:44.422: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 07:28:44.422: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 07:28:44.422: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  5 07:28:44.449: INFO: Updating stateful set ss2
Dec  5 07:28:44.487: INFO: Waiting for Pod statefulset-2652/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  5 07:28:54.512: INFO: Updating stateful set ss2
Dec  5 07:28:54.537: INFO: Waiting for StatefulSet statefulset-2652/ss2 to complete update
Dec  5 07:28:54.537: INFO: Waiting for Pod statefulset-2652/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  5 07:29:04.544: INFO: Waiting for StatefulSet statefulset-2652/ss2 to complete update
Dec  5 07:29:04.544: INFO: Waiting for Pod statefulset-2652/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 07:29:14.546: INFO: Deleting all statefulset in ns statefulset-2652
Dec  5 07:29:14.549: INFO: Scaling statefulset ss2 to 0
Dec  5 07:29:44.579: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 07:29:44.583: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:29:44.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2652" for this suite.
Dec  5 07:29:50.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:29:50.721: INFO: namespace statefulset-2652 deletion completed in 6.110567537s

â€¢ [SLOW TEST:116.579 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:29:50.722: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:29:50.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9413" for this suite.
Dec  5 07:29:56.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:29:56.896: INFO: namespace kubelet-test-9413 deletion completed in 6.093234651s

â€¢ [SLOW TEST:6.174 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:29:56.896: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  5 07:29:56.965: INFO: Waiting up to 5m0s for pod "downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266" in namespace "downward-api-7589" to be "success or failure"
Dec  5 07:29:56.968: INFO: Pod "downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266": Phase="Pending", Reason="", readiness=false. Elapsed: 3.37704ms
Dec  5 07:29:58.975: INFO: Pod "downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009904712s
Dec  5 07:30:00.979: INFO: Pod "downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01404897s
STEP: Saw pod success
Dec  5 07:30:00.979: INFO: Pod "downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266" satisfied condition "success or failure"
Dec  5 07:30:00.983: INFO: Trying to get logs from node worknode pod downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266 container dapi-container: <nil>
STEP: delete the pod
Dec  5 07:30:01.018: INFO: Waiting for pod downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266 to disappear
Dec  5 07:30:01.023: INFO: Pod downward-api-6bbdd42d-b7a6-432a-81b6-f2f035fba266 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:30:01.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7589" for this suite.
Dec  5 07:30:07.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:30:07.135: INFO: namespace downward-api-7589 deletion completed in 6.108645663s

â€¢ [SLOW TEST:10.239 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:30:07.136: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  5 07:30:09.724: INFO: Successfully updated pod "annotationupdate59182e03-633b-4c77-9518-3f38edf251b3"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:30:13.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6859" for this suite.
Dec  5 07:30:41.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:30:41.871: INFO: namespace downward-api-6859 deletion completed in 28.109244301s

â€¢ [SLOW TEST:34.735 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:30:41.871: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:30:42.628: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 07:30:44.641: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127842, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127842, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127842, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711127842, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:30:47.661: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:30:59.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3692" for this suite.
Dec  5 07:31:05.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:31:06.022: INFO: namespace webhook-3692 deletion completed in 6.209528613s
STEP: Destroying namespace "webhook-3692-markers" for this suite.
Dec  5 07:31:12.046: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:31:12.135: INFO: namespace webhook-3692-markers deletion completed in 6.112487403s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:30.281 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:31:12.153: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 07:31:12.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9524'
Dec  5 07:31:12.276: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 07:31:12.276: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec  5 07:31:12.301: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Dec  5 07:31:12.309: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec  5 07:31:12.332: INFO: scanned /root for discovery docs: <nil>
Dec  5 07:31:12.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9524'
Dec  5 07:31:28.207: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  5 07:31:28.207: INFO: stdout: "Created e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169\nScaling up e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec  5 07:31:28.207: INFO: stdout: "Created e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169\nScaling up e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec  5 07:31:28.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9524'
Dec  5 07:31:28.273: INFO: stderr: ""
Dec  5 07:31:28.273: INFO: stdout: "e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169-q749z "
Dec  5 07:31:28.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169-q749z -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9524'
Dec  5 07:31:28.331: INFO: stderr: ""
Dec  5 07:31:28.331: INFO: stdout: "true"
Dec  5 07:31:28.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169-q749z -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9524'
Dec  5 07:31:28.391: INFO: stderr: ""
Dec  5 07:31:28.391: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec  5 07:31:28.391: INFO: e2e-test-httpd-rc-87cd0d79e1bc4d47765ec5ef8290f169-q749z is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec  5 07:31:28.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete rc e2e-test-httpd-rc --namespace=kubectl-9524'
Dec  5 07:31:28.465: INFO: stderr: ""
Dec  5 07:31:28.465: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:31:28.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9524" for this suite.
Dec  5 07:31:34.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:31:34.582: INFO: namespace kubectl-9524 deletion completed in 6.111710533s

â€¢ [SLOW TEST:22.430 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:31:34.582: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec  5 07:31:34.616: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 07:31:37.461: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:31:48.785: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-819" for this suite.
Dec  5 07:31:54.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:31:54.914: INFO: namespace crd-publish-openapi-819 deletion completed in 6.125915404s

â€¢ [SLOW TEST:20.332 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:31:54.915: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 07:31:54.953: INFO: Waiting up to 5m0s for pod "pod-cf4dd574-3346-489d-92b1-1eb0789fe058" in namespace "emptydir-5560" to be "success or failure"
Dec  5 07:31:54.968: INFO: Pod "pod-cf4dd574-3346-489d-92b1-1eb0789fe058": Phase="Pending", Reason="", readiness=false. Elapsed: 15.299792ms
Dec  5 07:31:56.973: INFO: Pod "pod-cf4dd574-3346-489d-92b1-1eb0789fe058": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019619656s
STEP: Saw pod success
Dec  5 07:31:56.973: INFO: Pod "pod-cf4dd574-3346-489d-92b1-1eb0789fe058" satisfied condition "success or failure"
Dec  5 07:31:56.976: INFO: Trying to get logs from node worknode pod pod-cf4dd574-3346-489d-92b1-1eb0789fe058 container test-container: <nil>
STEP: delete the pod
Dec  5 07:31:57.020: INFO: Waiting for pod pod-cf4dd574-3346-489d-92b1-1eb0789fe058 to disappear
Dec  5 07:31:57.025: INFO: Pod pod-cf4dd574-3346-489d-92b1-1eb0789fe058 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:31:57.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5560" for this suite.
Dec  5 07:32:03.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:32:03.145: INFO: namespace emptydir-5560 deletion completed in 6.115901141s

â€¢ [SLOW TEST:8.230 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:32:03.150: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec  5 07:32:05.707: INFO: Successfully updated pod "adopt-release-fkg5w"
STEP: Checking that the Job readopts the Pod
Dec  5 07:32:05.707: INFO: Waiting up to 15m0s for pod "adopt-release-fkg5w" in namespace "job-6987" to be "adopted"
Dec  5 07:32:05.737: INFO: Pod "adopt-release-fkg5w": Phase="Running", Reason="", readiness=true. Elapsed: 29.173318ms
Dec  5 07:32:07.740: INFO: Pod "adopt-release-fkg5w": Phase="Running", Reason="", readiness=true. Elapsed: 2.032715864s
Dec  5 07:32:07.740: INFO: Pod "adopt-release-fkg5w" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec  5 07:32:08.261: INFO: Successfully updated pod "adopt-release-fkg5w"
STEP: Checking that the Job releases the Pod
Dec  5 07:32:08.261: INFO: Waiting up to 15m0s for pod "adopt-release-fkg5w" in namespace "job-6987" to be "released"
Dec  5 07:32:08.302: INFO: Pod "adopt-release-fkg5w": Phase="Running", Reason="", readiness=true. Elapsed: 40.866744ms
Dec  5 07:32:08.302: INFO: Pod "adopt-release-fkg5w" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:32:08.302: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-6987" for this suite.
Dec  5 07:32:58.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:32:58.444: INFO: namespace job-6987 deletion completed in 50.117572366s

â€¢ [SLOW TEST:55.294 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:32:58.444: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-d931c6a6-0362-48e3-b3df-f86182b4c36e
STEP: Creating secret with name s-test-opt-upd-dcd0882d-51d4-4f5a-9a0d-1becaf566b35
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-d931c6a6-0362-48e3-b3df-f86182b4c36e
STEP: Updating secret s-test-opt-upd-dcd0882d-51d4-4f5a-9a0d-1becaf566b35
STEP: Creating secret with name s-test-opt-create-88eed529-b012-48ac-82d9-b82e986d179c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:34:27.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7888" for this suite.
Dec  5 07:34:55.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:34:55.269: INFO: namespace secrets-7888 deletion completed in 28.110077658s

â€¢ [SLOW TEST:116.825 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:34:55.269: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-2325/configmap-test-a9180792-16b2-4649-8b85-1e211eddf2f4
STEP: Creating a pod to test consume configMaps
Dec  5 07:34:55.317: INFO: Waiting up to 5m0s for pod "pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd" in namespace "configmap-2325" to be "success or failure"
Dec  5 07:34:55.320: INFO: Pod "pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd": Phase="Pending", Reason="", readiness=false. Elapsed: 3.485007ms
Dec  5 07:34:57.325: INFO: Pod "pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007912359s
Dec  5 07:34:59.329: INFO: Pod "pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011931247s
STEP: Saw pod success
Dec  5 07:34:59.329: INFO: Pod "pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd" satisfied condition "success or failure"
Dec  5 07:34:59.332: INFO: Trying to get logs from node worknode pod pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd container env-test: <nil>
STEP: delete the pod
Dec  5 07:34:59.355: INFO: Waiting for pod pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd to disappear
Dec  5 07:34:59.358: INFO: Pod pod-configmaps-904c8277-bcc0-447b-a94f-bd2484146bbd no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:34:59.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2325" for this suite.
Dec  5 07:35:05.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:35:05.455: INFO: namespace configmap-2325 deletion completed in 6.093438121s

â€¢ [SLOW TEST:10.186 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:35:05.456: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec  5 07:35:05.490: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  5 07:36:05.511: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:36:05.515: INFO: Starting informer...
STEP: Starting pod...
Dec  5 07:36:05.751: INFO: Pod is running on worknode. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec  5 07:36:05.771: INFO: Pod wasn't evicted. Proceeding
Dec  5 07:36:05.771: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec  5 07:37:20.797: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:37:20.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-6694" for this suite.
Dec  5 07:37:32.811: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:37:32.910: INFO: namespace taint-single-pod-6694 deletion completed in 12.109475071s

â€¢ [SLOW TEST:147.454 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:37:32.913: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:37:32.963: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  5 07:37:35.319: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-2017 create -f -'
Dec  5 07:37:35.649: INFO: stderr: ""
Dec  5 07:37:35.649: INFO: stdout: "e2e-test-crd-publish-openapi-6948-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  5 07:37:35.649: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-2017 delete e2e-test-crd-publish-openapi-6948-crds test-cr'
Dec  5 07:37:35.746: INFO: stderr: ""
Dec  5 07:37:35.746: INFO: stdout: "e2e-test-crd-publish-openapi-6948-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec  5 07:37:35.746: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-2017 apply -f -'
Dec  5 07:37:35.874: INFO: stderr: ""
Dec  5 07:37:35.874: INFO: stdout: "e2e-test-crd-publish-openapi-6948-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  5 07:37:35.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-2017 delete e2e-test-crd-publish-openapi-6948-crds test-cr'
Dec  5 07:37:35.989: INFO: stderr: ""
Dec  5 07:37:35.989: INFO: stdout: "e2e-test-crd-publish-openapi-6948-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec  5 07:37:35.989: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-6948-crds'
Dec  5 07:37:36.141: INFO: stderr: ""
Dec  5 07:37:36.141: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6948-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:37:38.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2017" for this suite.
Dec  5 07:37:44.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:37:44.141: INFO: namespace crd-publish-openapi-2017 deletion completed in 6.112818817s

â€¢ [SLOW TEST:11.228 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:37:44.144: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:37:44.190: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85" in namespace "security-context-test-6179" to be "success or failure"
Dec  5 07:37:44.202: INFO: Pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85": Phase="Pending", Reason="", readiness=false. Elapsed: 12.783514ms
Dec  5 07:37:46.205: INFO: Pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015719602s
Dec  5 07:37:48.211: INFO: Pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021506937s
Dec  5 07:37:48.211: INFO: Pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85" satisfied condition "success or failure"
Dec  5 07:37:48.227: INFO: Got logs for pod "busybox-privileged-false-d1173946-30f9-4ed6-8344-7c402cf4ec85": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:37:48.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6179" for this suite.
Dec  5 07:37:54.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:37:54.356: INFO: namespace security-context-test-6179 deletion completed in 6.125234747s

â€¢ [SLOW TEST:10.212 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:37:54.356: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:37:54.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-804" for this suite.
Dec  5 07:38:00.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:38:00.538: INFO: namespace services-804 deletion completed in 6.118863492s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:6.182 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:38:00.541: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1809
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 07:38:00.575: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 07:38:22.705: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.233.205 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1809 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 07:38:22.706: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 07:38:23.843: INFO: Found all expected endpoints: [netserver-0]
Dec  5 07:38:23.846: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 192.168.228.112 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1809 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 07:38:23.846: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 07:38:25.002: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:38:25.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1809" for this suite.
Dec  5 07:38:37.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:38:37.110: INFO: namespace pod-network-test-1809 deletion completed in 12.103172715s

â€¢ [SLOW TEST:36.569 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:38:37.112: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:38:53.324: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9631" for this suite.
Dec  5 07:38:59.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:38:59.488: INFO: namespace resourcequota-9631 deletion completed in 6.159973802s

â€¢ [SLOW TEST:22.376 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:38:59.489: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9301.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9301.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9301.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 07:39:01.612: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.616: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.620: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.624: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.635: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.639: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.643: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.647: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:01.654: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:06.658: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.661: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.665: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.670: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.682: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.686: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.690: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.694: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:06.701: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:11.658: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.662: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.666: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.669: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.681: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.687: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.693: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.699: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:11.714: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:16.659: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.664: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.669: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.673: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.686: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.690: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.694: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.699: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:16.707: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:21.660: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.664: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.668: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.672: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.684: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.689: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.695: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.700: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:21.710: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:26.676: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.681: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.687: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.692: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.706: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.712: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.716: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.721: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:26.733: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local jessie_udp@dns-test-service-2.dns-9301.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:31.661: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:31.668: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:31.673: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:31.679: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local from pod dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c: the server could not find the requested resource (get pods dns-test-47c13a76-c594-4804-850f-5e9ee150835c)
Dec  5 07:39:31.720: INFO: Lookups using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9301.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9301.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9301.svc.cluster.local]

Dec  5 07:39:36.714: INFO: DNS probes using dns-9301/dns-test-47c13a76-c594-4804-850f-5e9ee150835c succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:39:36.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9301" for this suite.
Dec  5 07:39:42.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:39:42.878: INFO: namespace dns-9301 deletion completed in 6.096587537s

â€¢ [SLOW TEST:43.390 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:39:42.879: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-ee5ee1a3-0f77-430b-b5cf-959df9ea834e
STEP: Creating a pod to test consume secrets
Dec  5 07:39:42.929: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e" in namespace "projected-8724" to be "success or failure"
Dec  5 07:39:42.949: INFO: Pod "pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e": Phase="Pending", Reason="", readiness=false. Elapsed: 20.471405ms
Dec  5 07:39:44.953: INFO: Pod "pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.024881302s
Dec  5 07:39:46.967: INFO: Pod "pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.038177065s
STEP: Saw pod success
Dec  5 07:39:46.967: INFO: Pod "pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e" satisfied condition "success or failure"
Dec  5 07:39:46.970: INFO: Trying to get logs from node worknode pod pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 07:39:47.009: INFO: Waiting for pod pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e to disappear
Dec  5 07:39:47.015: INFO: Pod pod-projected-secrets-804d1dc2-a6f6-4b6b-9776-fe97506a542e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:39:47.015: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8724" for this suite.
Dec  5 07:39:53.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:39:53.142: INFO: namespace projected-8724 deletion completed in 6.12212236s

â€¢ [SLOW TEST:10.263 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:39:53.145: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:39:53.484: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:39:56.512: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:39:56.516: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:39:57.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1446" for this suite.
Dec  5 07:40:03.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:40:03.289: INFO: namespace webhook-1446 deletion completed in 6.120485997s
STEP: Destroying namespace "webhook-1446-markers" for this suite.
Dec  5 07:40:09.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:40:09.408: INFO: namespace webhook-1446-markers deletion completed in 6.119034508s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:16.280 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:40:09.425: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:40:09.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-9968" for this suite.
Dec  5 07:40:15.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:40:15.586: INFO: namespace tables-9968 deletion completed in 6.114960349s

â€¢ [SLOW TEST:6.161 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:40:15.586: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  5 07:40:15.625: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-2993'
Dec  5 07:40:15.814: INFO: stderr: ""
Dec  5 07:40:15.814: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 07:40:15.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:15.968: INFO: stderr: ""
Dec  5 07:40:15.968: INFO: stdout: "update-demo-nautilus-dlbvf update-demo-nautilus-fbzw2 "
Dec  5 07:40:15.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-dlbvf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:16.069: INFO: stderr: ""
Dec  5 07:40:16.069: INFO: stdout: ""
Dec  5 07:40:16.069: INFO: update-demo-nautilus-dlbvf is created but not running
Dec  5 07:40:21.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:21.132: INFO: stderr: ""
Dec  5 07:40:21.132: INFO: stdout: "update-demo-nautilus-dlbvf update-demo-nautilus-fbzw2 "
Dec  5 07:40:21.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-dlbvf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:21.207: INFO: stderr: ""
Dec  5 07:40:21.207: INFO: stdout: "true"
Dec  5 07:40:21.207: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-dlbvf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:21.279: INFO: stderr: ""
Dec  5 07:40:21.279: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:21.279: INFO: validating pod update-demo-nautilus-dlbvf
Dec  5 07:40:21.285: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:21.285: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:21.285: INFO: update-demo-nautilus-dlbvf is verified up and running
Dec  5 07:40:21.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:21.351: INFO: stderr: ""
Dec  5 07:40:21.351: INFO: stdout: "true"
Dec  5 07:40:21.351: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:21.420: INFO: stderr: ""
Dec  5 07:40:21.420: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:21.420: INFO: validating pod update-demo-nautilus-fbzw2
Dec  5 07:40:21.431: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:21.431: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:21.431: INFO: update-demo-nautilus-fbzw2 is verified up and running
STEP: scaling down the replication controller
Dec  5 07:40:21.433: INFO: scanned /root for discovery docs: <nil>
Dec  5 07:40:21.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2993'
Dec  5 07:40:22.586: INFO: stderr: ""
Dec  5 07:40:22.586: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 07:40:22.587: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:22.662: INFO: stderr: ""
Dec  5 07:40:22.662: INFO: stdout: "update-demo-nautilus-dlbvf update-demo-nautilus-fbzw2 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  5 07:40:27.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:27.734: INFO: stderr: ""
Dec  5 07:40:27.734: INFO: stdout: "update-demo-nautilus-fbzw2 "
Dec  5 07:40:27.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:27.898: INFO: stderr: ""
Dec  5 07:40:27.898: INFO: stdout: "true"
Dec  5 07:40:27.898: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:28.004: INFO: stderr: ""
Dec  5 07:40:28.004: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:28.004: INFO: validating pod update-demo-nautilus-fbzw2
Dec  5 07:40:28.008: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:28.008: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:28.008: INFO: update-demo-nautilus-fbzw2 is verified up and running
STEP: scaling up the replication controller
Dec  5 07:40:28.010: INFO: scanned /root for discovery docs: <nil>
Dec  5 07:40:28.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2993'
Dec  5 07:40:29.124: INFO: stderr: ""
Dec  5 07:40:29.124: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 07:40:29.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:29.202: INFO: stderr: ""
Dec  5 07:40:29.202: INFO: stdout: "update-demo-nautilus-fbzw2 update-demo-nautilus-pq2vx "
Dec  5 07:40:29.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:29.263: INFO: stderr: ""
Dec  5 07:40:29.263: INFO: stdout: "true"
Dec  5 07:40:29.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:29.331: INFO: stderr: ""
Dec  5 07:40:29.331: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:29.331: INFO: validating pod update-demo-nautilus-fbzw2
Dec  5 07:40:29.334: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:29.334: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:29.334: INFO: update-demo-nautilus-fbzw2 is verified up and running
Dec  5 07:40:29.334: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-pq2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:29.429: INFO: stderr: ""
Dec  5 07:40:29.429: INFO: stdout: ""
Dec  5 07:40:29.429: INFO: update-demo-nautilus-pq2vx is created but not running
Dec  5 07:40:34.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2993'
Dec  5 07:40:34.493: INFO: stderr: ""
Dec  5 07:40:34.493: INFO: stdout: "update-demo-nautilus-fbzw2 update-demo-nautilus-pq2vx "
Dec  5 07:40:34.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:34.551: INFO: stderr: ""
Dec  5 07:40:34.551: INFO: stdout: "true"
Dec  5 07:40:34.552: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-fbzw2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:34.610: INFO: stderr: ""
Dec  5 07:40:34.610: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:34.610: INFO: validating pod update-demo-nautilus-fbzw2
Dec  5 07:40:34.614: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:34.614: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:34.614: INFO: update-demo-nautilus-fbzw2 is verified up and running
Dec  5 07:40:34.614: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-pq2vx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:34.678: INFO: stderr: ""
Dec  5 07:40:34.678: INFO: stdout: "true"
Dec  5 07:40:34.678: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-pq2vx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2993'
Dec  5 07:40:34.747: INFO: stderr: ""
Dec  5 07:40:34.747: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 07:40:34.747: INFO: validating pod update-demo-nautilus-pq2vx
Dec  5 07:40:34.753: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 07:40:34.753: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 07:40:34.753: INFO: update-demo-nautilus-pq2vx is verified up and running
STEP: using delete to clean up resources
Dec  5 07:40:34.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-2993'
Dec  5 07:40:34.829: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 07:40:34.829: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 07:40:34.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2993'
Dec  5 07:40:34.904: INFO: stderr: "No resources found in kubectl-2993 namespace.\n"
Dec  5 07:40:34.904: INFO: stdout: ""
Dec  5 07:40:34.904: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -l name=update-demo --namespace=kubectl-2993 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 07:40:34.986: INFO: stderr: ""
Dec  5 07:40:34.986: INFO: stdout: "update-demo-nautilus-fbzw2\nupdate-demo-nautilus-pq2vx\n"
Dec  5 07:40:35.487: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2993'
Dec  5 07:40:35.625: INFO: stderr: "No resources found in kubectl-2993 namespace.\n"
Dec  5 07:40:35.625: INFO: stdout: ""
Dec  5 07:40:35.626: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -l name=update-demo --namespace=kubectl-2993 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 07:40:35.793: INFO: stderr: ""
Dec  5 07:40:35.793: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:40:35.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2993" for this suite.
Dec  5 07:41:03.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:03.907: INFO: namespace kubectl-2993 deletion completed in 28.105938996s

â€¢ [SLOW TEST:48.321 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:03.907: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9163
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9163
STEP: creating replication controller externalsvc in namespace services-9163
I1205 07:41:03.982002      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9163, replica count: 2
I1205 07:41:07.034612      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec  5 07:41:07.069: INFO: Creating new exec pod
Dec  5 07:41:09.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9163 execpodmqkfw -- /bin/sh -x -c nslookup nodeport-service'
Dec  5 07:41:09.323: INFO: stderr: "+ nslookup nodeport-service\n"
Dec  5 07:41:09.323: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-9163.svc.cluster.local\tcanonical name = externalsvc.services-9163.svc.cluster.local.\nName:\texternalsvc.services-9163.svc.cluster.local\nAddress: 10.104.206.218\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9163, will wait for the garbage collector to delete the pods
Dec  5 07:41:09.383: INFO: Deleting ReplicationController externalsvc took: 5.918916ms
Dec  5 07:41:09.686: INFO: Terminating ReplicationController externalsvc pods took: 302.685101ms
Dec  5 07:41:13.926: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:41:13.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9163" for this suite.
Dec  5 07:41:20.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:20.131: INFO: namespace services-9163 deletion completed in 6.173407935s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:16.224 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:20.133: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:41:20.175: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2" in namespace "projected-9669" to be "success or failure"
Dec  5 07:41:20.197: INFO: Pod "downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2": Phase="Pending", Reason="", readiness=false. Elapsed: 21.598394ms
Dec  5 07:41:22.203: INFO: Pod "downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.027398025s
STEP: Saw pod success
Dec  5 07:41:22.203: INFO: Pod "downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2" satisfied condition "success or failure"
Dec  5 07:41:22.209: INFO: Trying to get logs from node worknode pod downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2 container client-container: <nil>
STEP: delete the pod
Dec  5 07:41:22.271: INFO: Waiting for pod downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2 to disappear
Dec  5 07:41:22.278: INFO: Pod downwardapi-volume-bcba9eac-fd06-4d3d-b7b1-80c127ffa8d2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:41:22.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9669" for this suite.
Dec  5 07:41:28.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:28.478: INFO: namespace projected-9669 deletion completed in 6.1842221s

â€¢ [SLOW TEST:8.346 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:28.479: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  5 07:41:28.519: INFO: Waiting up to 5m0s for pod "pod-559d91ec-0b88-4ccb-9416-b48824b35692" in namespace "emptydir-9151" to be "success or failure"
Dec  5 07:41:28.538: INFO: Pod "pod-559d91ec-0b88-4ccb-9416-b48824b35692": Phase="Pending", Reason="", readiness=false. Elapsed: 19.02582ms
Dec  5 07:41:30.542: INFO: Pod "pod-559d91ec-0b88-4ccb-9416-b48824b35692": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022744256s
STEP: Saw pod success
Dec  5 07:41:30.542: INFO: Pod "pod-559d91ec-0b88-4ccb-9416-b48824b35692" satisfied condition "success or failure"
Dec  5 07:41:30.545: INFO: Trying to get logs from node worknode pod pod-559d91ec-0b88-4ccb-9416-b48824b35692 container test-container: <nil>
STEP: delete the pod
Dec  5 07:41:30.583: INFO: Waiting for pod pod-559d91ec-0b88-4ccb-9416-b48824b35692 to disappear
Dec  5 07:41:30.590: INFO: Pod pod-559d91ec-0b88-4ccb-9416-b48824b35692 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:41:30.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9151" for this suite.
Dec  5 07:41:36.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:36.718: INFO: namespace emptydir-9151 deletion completed in 6.123150848s

â€¢ [SLOW TEST:8.240 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:36.721: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  5 07:41:36.767: INFO: Waiting up to 5m0s for pod "pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c" in namespace "emptydir-7414" to be "success or failure"
Dec  5 07:41:36.775: INFO: Pod "pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c": Phase="Pending", Reason="", readiness=false. Elapsed: 7.763053ms
Dec  5 07:41:38.778: INFO: Pod "pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011167765s
STEP: Saw pod success
Dec  5 07:41:38.778: INFO: Pod "pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c" satisfied condition "success or failure"
Dec  5 07:41:38.782: INFO: Trying to get logs from node worknode pod pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c container test-container: <nil>
STEP: delete the pod
Dec  5 07:41:38.816: INFO: Waiting for pod pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c to disappear
Dec  5 07:41:38.820: INFO: Pod pod-a560e046-d9a4-48b4-976e-9b90e1ea7e0c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:41:38.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7414" for this suite.
Dec  5 07:41:44.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:44.930: INFO: namespace emptydir-7414 deletion completed in 6.106207473s

â€¢ [SLOW TEST:8.209 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:44.939: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec  5 07:41:44.972: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-535733101 proxy --unix-socket=/tmp/kubectl-proxy-unix713281380/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:41:45.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1924" for this suite.
Dec  5 07:41:51.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:41:51.134: INFO: namespace kubectl-1924 deletion completed in 6.103901809s

â€¢ [SLOW TEST:6.195 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:41:51.134: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  5 07:41:51.403: INFO: Pod name wrapped-volume-race-3a3c112e-ba7c-423f-a27b-7061e592dc3d: Found 0 pods out of 5
Dec  5 07:41:56.410: INFO: Pod name wrapped-volume-race-3a3c112e-ba7c-423f-a27b-7061e592dc3d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-3a3c112e-ba7c-423f-a27b-7061e592dc3d in namespace emptydir-wrapper-3758, will wait for the garbage collector to delete the pods
Dec  5 07:42:08.512: INFO: Deleting ReplicationController wrapped-volume-race-3a3c112e-ba7c-423f-a27b-7061e592dc3d took: 16.269199ms
Dec  5 07:42:09.013: INFO: Terminating ReplicationController wrapped-volume-race-3a3c112e-ba7c-423f-a27b-7061e592dc3d pods took: 500.418558ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 07:42:48.032: INFO: Pod name wrapped-volume-race-af32c61b-deee-44f0-b10e-c694190b8859: Found 0 pods out of 5
Dec  5 07:42:53.061: INFO: Pod name wrapped-volume-race-af32c61b-deee-44f0-b10e-c694190b8859: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-af32c61b-deee-44f0-b10e-c694190b8859 in namespace emptydir-wrapper-3758, will wait for the garbage collector to delete the pods
Dec  5 07:43:05.145: INFO: Deleting ReplicationController wrapped-volume-race-af32c61b-deee-44f0-b10e-c694190b8859 took: 8.650288ms
Dec  5 07:43:05.550: INFO: Terminating ReplicationController wrapped-volume-race-af32c61b-deee-44f0-b10e-c694190b8859 pods took: 405.581603ms
STEP: Creating RC which spawns configmap-volume pods
Dec  5 07:43:47.989: INFO: Pod name wrapped-volume-race-da49c40f-bca4-4e0b-af7b-fd7a2e30ca5e: Found 0 pods out of 5
Dec  5 07:43:52.995: INFO: Pod name wrapped-volume-race-da49c40f-bca4-4e0b-af7b-fd7a2e30ca5e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-da49c40f-bca4-4e0b-af7b-fd7a2e30ca5e in namespace emptydir-wrapper-3758, will wait for the garbage collector to delete the pods
Dec  5 07:44:05.078: INFO: Deleting ReplicationController wrapped-volume-race-da49c40f-bca4-4e0b-af7b-fd7a2e30ca5e took: 6.228251ms
Dec  5 07:44:05.678: INFO: Terminating ReplicationController wrapped-volume-race-da49c40f-bca4-4e0b-af7b-fd7a2e30ca5e pods took: 600.603482ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:44:48.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3758" for this suite.
Dec  5 07:44:54.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:44:54.433: INFO: namespace emptydir-wrapper-3758 deletion completed in 6.115034681s

â€¢ [SLOW TEST:183.299 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:44:54.433: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:44:54.539: INFO: Waiting up to 5m0s for pod "downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2" in namespace "projected-675" to be "success or failure"
Dec  5 07:44:54.550: INFO: Pod "downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2": Phase="Pending", Reason="", readiness=false. Elapsed: 11.263705ms
Dec  5 07:44:56.555: INFO: Pod "downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01562976s
STEP: Saw pod success
Dec  5 07:44:56.555: INFO: Pod "downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2" satisfied condition "success or failure"
Dec  5 07:44:56.559: INFO: Trying to get logs from node worknode pod downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2 container client-container: <nil>
STEP: delete the pod
Dec  5 07:44:56.595: INFO: Waiting for pod downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2 to disappear
Dec  5 07:44:56.600: INFO: Pod downwardapi-volume-65ae8b75-455c-4662-943f-3ceae847f8a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:44:56.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-675" for this suite.
Dec  5 07:45:02.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:45:02.719: INFO: namespace projected-675 deletion completed in 6.115061612s

â€¢ [SLOW TEST:8.286 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:45:02.725: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec  5 07:45:02.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 api-versions'
Dec  5 07:45:02.835: INFO: stderr: ""
Dec  5 07:45:02.835: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:45:02.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7051" for this suite.
Dec  5 07:45:08.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:45:09.078: INFO: namespace kubectl-7051 deletion completed in 6.239049546s

â€¢ [SLOW TEST:6.354 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:45:09.079: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5029
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-5029
Dec  5 07:45:09.179: INFO: Found 0 stateful pods, waiting for 1
Dec  5 07:45:19.196: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 07:45:19.245: INFO: Deleting all statefulset in ns statefulset-5029
Dec  5 07:45:19.254: INFO: Scaling statefulset ss to 0
Dec  5 07:45:39.302: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 07:45:39.305: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:45:39.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5029" for this suite.
Dec  5 07:45:45.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:45:45.478: INFO: namespace statefulset-5029 deletion completed in 6.147744254s

â€¢ [SLOW TEST:36.399 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:45:45.479: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:45:45.574: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec  5 07:45:50.578: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 07:45:50.578: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  5 07:45:52.583: INFO: Creating deployment "test-rollover-deployment"
Dec  5 07:45:52.594: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  5 07:45:54.607: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  5 07:45:54.614: INFO: Ensure that both replica sets have 1 created replica
Dec  5 07:45:54.621: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  5 07:45:54.629: INFO: Updating deployment test-rollover-deployment
Dec  5 07:45:54.629: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  5 07:45:56.637: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  5 07:45:56.645: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  5 07:45:56.650: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 07:45:56.651: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128756, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:45:58.660: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 07:45:58.660: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128756, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:46:00.661: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 07:46:00.661: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128756, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:46:02.659: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 07:46:02.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128756, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:46:04.659: INFO: all replica sets need to contain the pod-template-hash label
Dec  5 07:46:04.659: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128756, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711128752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  5 07:46:06.659: INFO: 
Dec  5 07:46:06.659: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  5 07:46:06.669: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-5145 /apis/apps/v1/namespaces/deployment-5145/deployments/test-rollover-deployment db324ebc-4d30-4460-b287-955170fcc1e2 15122 2 2019-12-05 07:45:52 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040fc508 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-05 07:45:52 +0000 UTC,LastTransitionTime:2019-12-05 07:45:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-05 07:46:06 +0000 UTC,LastTransitionTime:2019-12-05 07:45:52 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  5 07:46:06.673: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-5145 /apis/apps/v1/namespaces/deployment-5145/replicasets/test-rollover-deployment-7d7dc6548c 00f8ce41-fec1-478a-942d-422793c4fd24 15111 2 2019-12-05 07:45:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment db324ebc-4d30-4460-b287-955170fcc1e2 0xc0040fc9c7 0xc0040fc9c8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040fca28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:46:06.673: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  5 07:46:06.673: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-5145 /apis/apps/v1/namespaces/deployment-5145/replicasets/test-rollover-controller 3447b5be-7248-40e2-8cbd-70ae5b75a16f 15120 2 2019-12-05 07:45:45 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment db324ebc-4d30-4460-b287-955170fcc1e2 0xc0040fc8f7 0xc0040fc8f8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0040fc958 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:46:06.673: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-5145 /apis/apps/v1/namespaces/deployment-5145/replicasets/test-rollover-deployment-f6c94f66c 8e686984-bc10-4307-bd06-acd65d37f73b 15074 2 2019-12-05 07:45:52 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment db324ebc-4d30-4460-b287-955170fcc1e2 0xc0040fca90 0xc0040fca91}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0040fcb08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  5 07:46:06.677: INFO: Pod "test-rollover-deployment-7d7dc6548c-wvh27" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-wvh27 test-rollover-deployment-7d7dc6548c- deployment-5145 /api/v1/namespaces/deployment-5145/pods/test-rollover-deployment-7d7dc6548c-wvh27 31cade6d-27c3-4204-a17c-c658f02ba3f4 15094 0 2019-12-05 07:45:54 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:192.168.233.223/32] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 00f8ce41-fec1-478a-942d-422793c4fd24 0xc0040fd057 0xc0040fd058}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fvvpk,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fvvpk,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fvvpk,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:45:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:45:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:45:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 07:45:54 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.223,StartTime:2019-12-05 07:45:54 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 07:45:55 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://494ac69ad1232f978a1797a106d9abdd5c84e8d376c5a2007cd6a947de9709de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.223,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:06.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5145" for this suite.
Dec  5 07:46:12.696: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:12.798: INFO: namespace deployment-5145 deletion completed in 6.117344689s

â€¢ [SLOW TEST:27.319 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:46:12.798: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:46:12.893: INFO: Waiting up to 5m0s for pod "downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9" in namespace "projected-1417" to be "success or failure"
Dec  5 07:46:12.899: INFO: Pod "downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.188368ms
Dec  5 07:46:14.905: INFO: Pod "downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012346282s
STEP: Saw pod success
Dec  5 07:46:14.905: INFO: Pod "downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9" satisfied condition "success or failure"
Dec  5 07:46:14.909: INFO: Trying to get logs from node worknode pod downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9 container client-container: <nil>
STEP: delete the pod
Dec  5 07:46:14.940: INFO: Waiting for pod downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9 to disappear
Dec  5 07:46:14.946: INFO: Pod downwardapi-volume-04f8ebe3-3765-4113-9f96-c37df76fe1a9 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:14.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1417" for this suite.
Dec  5 07:46:20.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:21.073: INFO: namespace projected-1417 deletion completed in 6.12350818s

â€¢ [SLOW TEST:8.275 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:46:21.074: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 07:46:21.173: INFO: Waiting up to 5m0s for pod "downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809" in namespace "projected-5874" to be "success or failure"
Dec  5 07:46:21.178: INFO: Pod "downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809": Phase="Pending", Reason="", readiness=false. Elapsed: 4.484398ms
Dec  5 07:46:23.218: INFO: Pod "downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809": Phase="Pending", Reason="", readiness=false. Elapsed: 2.045356816s
Dec  5 07:46:25.223: INFO: Pod "downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.049697235s
STEP: Saw pod success
Dec  5 07:46:25.223: INFO: Pod "downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809" satisfied condition "success or failure"
Dec  5 07:46:25.226: INFO: Trying to get logs from node worknode pod downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809 container client-container: <nil>
STEP: delete the pod
Dec  5 07:46:25.258: INFO: Waiting for pod downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809 to disappear
Dec  5 07:46:25.263: INFO: Pod downwardapi-volume-03465be3-6f38-47b6-9a7b-b25da5480809 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:25.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5874" for this suite.
Dec  5 07:46:31.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:31.371: INFO: namespace projected-5874 deletion completed in 6.103817309s

â€¢ [SLOW TEST:10.298 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:46:31.374: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 07:46:31.871: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 07:46:34.893: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:35.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2623" for this suite.
Dec  5 07:46:41.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:41.185: INFO: namespace webhook-2623 deletion completed in 6.147000627s
STEP: Destroying namespace "webhook-2623-markers" for this suite.
Dec  5 07:46:47.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:47.300: INFO: namespace webhook-2623-markers deletion completed in 6.114935299s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.945 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:46:47.319: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  5 07:46:50.392: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:50.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6590" for this suite.
Dec  5 07:46:56.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:46:56.572: INFO: namespace container-runtime-6590 deletion completed in 6.143887557s

â€¢ [SLOW TEST:9.253 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:46:56.573: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:46:59.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2938" for this suite.
Dec  5 07:47:27.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:47:27.789: INFO: namespace replication-controller-2938 deletion completed in 28.134593143s

â€¢ [SLOW TEST:31.216 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:47:27.790: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-15963a54-5bdf-40a3-8dc0-d7dbbfc74179
STEP: Creating a pod to test consume configMaps
Dec  5 07:47:27.833: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6" in namespace "projected-3112" to be "success or failure"
Dec  5 07:47:27.844: INFO: Pod "pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.997812ms
Dec  5 07:47:29.848: INFO: Pod "pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.014642206s
STEP: Saw pod success
Dec  5 07:47:29.848: INFO: Pod "pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6" satisfied condition "success or failure"
Dec  5 07:47:29.851: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 07:47:29.879: INFO: Waiting for pod pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6 to disappear
Dec  5 07:47:29.886: INFO: Pod pod-projected-configmaps-34d28fad-90ba-47ac-908d-eb89e03a14d6 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:47:29.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3112" for this suite.
Dec  5 07:47:35.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:47:36.090: INFO: namespace projected-3112 deletion completed in 6.199104241s

â€¢ [SLOW TEST:8.300 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:47:36.091: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475
Dec  5 07:47:36.130: INFO: Pod name my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475: Found 0 pods out of 1
Dec  5 07:47:41.142: INFO: Pod name my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475: Found 1 pods out of 1
Dec  5 07:47:41.142: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475" are running
Dec  5 07:47:41.148: INFO: Pod "my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475-gm2lc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:47:36 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:47:37 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:47:37 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-05 07:47:36 +0000 UTC Reason: Message:}])
Dec  5 07:47:41.148: INFO: Trying to dial the pod
Dec  5 07:47:46.164: INFO: Controller my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475: Got expected result from replica 1 [my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475-gm2lc]: "my-hostname-basic-1b9d6a06-bc00-4bc4-8082-2b67d29d5475-gm2lc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:47:46.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7629" for this suite.
Dec  5 07:47:52.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:47:52.304: INFO: namespace replication-controller-7629 deletion completed in 6.136421581s

â€¢ [SLOW TEST:16.214 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:47:52.307: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-4fec66b1-d3d8-4eef-a6c6-ffeba91a9680
STEP: Creating a pod to test consume configMaps
Dec  5 07:47:52.368: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80" in namespace "projected-5127" to be "success or failure"
Dec  5 07:47:52.381: INFO: Pod "pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80": Phase="Pending", Reason="", readiness=false. Elapsed: 12.325023ms
Dec  5 07:47:54.385: INFO: Pod "pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.016628623s
STEP: Saw pod success
Dec  5 07:47:54.385: INFO: Pod "pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80" satisfied condition "success or failure"
Dec  5 07:47:54.388: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 07:47:54.412: INFO: Waiting for pod pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80 to disappear
Dec  5 07:47:54.425: INFO: Pod pod-projected-configmaps-d404bfa4-d46d-483d-9357-ae1879061c80 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:47:54.425: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5127" for this suite.
Dec  5 07:48:00.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:48:00.537: INFO: namespace projected-5127 deletion completed in 6.106640175s

â€¢ [SLOW TEST:8.231 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:48:00.539: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-9ca7fa7b-7aeb-48d8-a229-2e22274d1836 in namespace container-probe-2441
Dec  5 07:48:02.593: INFO: Started pod busybox-9ca7fa7b-7aeb-48d8-a229-2e22274d1836 in namespace container-probe-2441
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 07:48:02.597: INFO: Initial restart count of pod busybox-9ca7fa7b-7aeb-48d8-a229-2e22274d1836 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:52:03.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2441" for this suite.
Dec  5 07:52:09.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:52:09.362: INFO: namespace container-probe-2441 deletion completed in 6.129417931s

â€¢ [SLOW TEST:248.823 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:52:09.363: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:52:11.579: INFO: Waiting up to 5m0s for pod "client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173" in namespace "pods-1517" to be "success or failure"
Dec  5 07:52:11.591: INFO: Pod "client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173": Phase="Pending", Reason="", readiness=false. Elapsed: 12.227154ms
Dec  5 07:52:13.594: INFO: Pod "client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015427579s
STEP: Saw pod success
Dec  5 07:52:13.594: INFO: Pod "client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173" satisfied condition "success or failure"
Dec  5 07:52:13.597: INFO: Trying to get logs from node worknode pod client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173 container env3cont: <nil>
STEP: delete the pod
Dec  5 07:52:13.639: INFO: Waiting for pod client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173 to disappear
Dec  5 07:52:13.643: INFO: Pod client-envvars-f5887479-1cf2-45bd-848f-5ab86e742173 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:52:13.643: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1517" for this suite.
Dec  5 07:52:41.660: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:52:41.750: INFO: namespace pods-1517 deletion completed in 28.103921736s

â€¢ [SLOW TEST:32.387 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:52:41.752: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-9fws
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 07:52:41.810: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-9fws" in namespace "subpath-1226" to be "success or failure"
Dec  5 07:52:41.828: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Pending", Reason="", readiness=false. Elapsed: 17.736247ms
Dec  5 07:52:43.833: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 2.022775941s
Dec  5 07:52:45.846: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 4.035938836s
Dec  5 07:52:47.851: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 6.041072791s
Dec  5 07:52:49.855: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 8.044599269s
Dec  5 07:52:51.859: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 10.048580807s
Dec  5 07:52:53.874: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 12.063729758s
Dec  5 07:52:55.879: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 14.068629687s
Dec  5 07:52:57.886: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 16.076061138s
Dec  5 07:52:59.889: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 18.079265218s
Dec  5 07:53:01.893: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Running", Reason="", readiness=true. Elapsed: 20.083206805s
Dec  5 07:53:03.897: INFO: Pod "pod-subpath-test-projected-9fws": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.086969481s
STEP: Saw pod success
Dec  5 07:53:03.897: INFO: Pod "pod-subpath-test-projected-9fws" satisfied condition "success or failure"
Dec  5 07:53:03.900: INFO: Trying to get logs from node worknode pod pod-subpath-test-projected-9fws container test-container-subpath-projected-9fws: <nil>
STEP: delete the pod
Dec  5 07:53:03.934: INFO: Waiting for pod pod-subpath-test-projected-9fws to disappear
Dec  5 07:53:03.942: INFO: Pod pod-subpath-test-projected-9fws no longer exists
STEP: Deleting pod pod-subpath-test-projected-9fws
Dec  5 07:53:03.942: INFO: Deleting pod "pod-subpath-test-projected-9fws" in namespace "subpath-1226"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:53:03.946: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1226" for this suite.
Dec  5 07:53:09.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:53:10.065: INFO: namespace subpath-1226 deletion completed in 6.112956531s

â€¢ [SLOW TEST:28.312 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:53:10.066: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:53:23.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1091" for this suite.
Dec  5 07:53:29.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:53:29.278: INFO: namespace resourcequota-1091 deletion completed in 6.103722018s

â€¢ [SLOW TEST:19.212 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:53:29.278: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  5 07:53:29.363: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:53:45.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5180" for this suite.
Dec  5 07:53:51.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:53:51.842: INFO: namespace pods-5180 deletion completed in 6.119539158s

â€¢ [SLOW TEST:22.563 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:53:51.842: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  5 07:53:53.898: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:53:53.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8838" for this suite.
Dec  5 07:53:59.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:54:00.068: INFO: namespace container-runtime-8838 deletion completed in 6.143863577s

â€¢ [SLOW TEST:8.226 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:54:00.068: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-j9sv
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 07:54:00.122: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-j9sv" in namespace "subpath-3265" to be "success or failure"
Dec  5 07:54:00.135: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Pending", Reason="", readiness=false. Elapsed: 12.4926ms
Dec  5 07:54:02.142: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 2.019687318s
Dec  5 07:54:04.146: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 4.023124735s
Dec  5 07:54:06.154: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 6.031285822s
Dec  5 07:54:08.160: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 8.037917846s
Dec  5 07:54:10.182: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 10.059664884s
Dec  5 07:54:12.198: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 12.075762584s
Dec  5 07:54:14.255: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 14.132720636s
Dec  5 07:54:16.272: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 16.149190641s
Dec  5 07:54:18.275: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 18.152779317s
Dec  5 07:54:20.279: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Running", Reason="", readiness=true. Elapsed: 20.1562831s
Dec  5 07:54:22.283: INFO: Pod "pod-subpath-test-downwardapi-j9sv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.160280971s
STEP: Saw pod success
Dec  5 07:54:22.283: INFO: Pod "pod-subpath-test-downwardapi-j9sv" satisfied condition "success or failure"
Dec  5 07:54:22.286: INFO: Trying to get logs from node worknode pod pod-subpath-test-downwardapi-j9sv container test-container-subpath-downwardapi-j9sv: <nil>
STEP: delete the pod
Dec  5 07:54:22.319: INFO: Waiting for pod pod-subpath-test-downwardapi-j9sv to disappear
Dec  5 07:54:22.325: INFO: Pod pod-subpath-test-downwardapi-j9sv no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-j9sv
Dec  5 07:54:22.325: INFO: Deleting pod "pod-subpath-test-downwardapi-j9sv" in namespace "subpath-3265"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:54:22.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3265" for this suite.
Dec  5 07:54:28.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:54:28.431: INFO: namespace subpath-3265 deletion completed in 6.095972628s

â€¢ [SLOW TEST:28.363 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:54:28.433: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 07:54:28.519: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4dd47b1f-444e-4679-88ff-da56fa80cd83", Controller:(*bool)(0xc001396386), BlockOwnerDeletion:(*bool)(0xc001396387)}}
Dec  5 07:54:28.530: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2ab790d6-9341-43e2-a0b9-d3ffb5d12a9c", Controller:(*bool)(0xc0035be88a), BlockOwnerDeletion:(*bool)(0xc0035be88b)}}
Dec  5 07:54:28.544: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"be9005d5-cb4e-47be-965c-9ecf076b3f57", Controller:(*bool)(0xc0013966d6), BlockOwnerDeletion:(*bool)(0xc0013966d7)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:54:33.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5091" for this suite.
Dec  5 07:54:39.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:54:39.670: INFO: namespace gc-5091 deletion completed in 6.104306164s

â€¢ [SLOW TEST:11.238 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:54:39.674: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  5 07:54:39.715: INFO: Waiting up to 5m0s for pod "downward-api-bef38721-d603-4573-a699-9dafb0cc2110" in namespace "downward-api-7293" to be "success or failure"
Dec  5 07:54:39.723: INFO: Pod "downward-api-bef38721-d603-4573-a699-9dafb0cc2110": Phase="Pending", Reason="", readiness=false. Elapsed: 8.623775ms
Dec  5 07:54:41.732: INFO: Pod "downward-api-bef38721-d603-4573-a699-9dafb0cc2110": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017729651s
Dec  5 07:54:43.736: INFO: Pod "downward-api-bef38721-d603-4573-a699-9dafb0cc2110": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021327635s
STEP: Saw pod success
Dec  5 07:54:43.736: INFO: Pod "downward-api-bef38721-d603-4573-a699-9dafb0cc2110" satisfied condition "success or failure"
Dec  5 07:54:43.739: INFO: Trying to get logs from node worknode pod downward-api-bef38721-d603-4573-a699-9dafb0cc2110 container dapi-container: <nil>
STEP: delete the pod
Dec  5 07:54:43.768: INFO: Waiting for pod downward-api-bef38721-d603-4573-a699-9dafb0cc2110 to disappear
Dec  5 07:54:43.772: INFO: Pod downward-api-bef38721-d603-4573-a699-9dafb0cc2110 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:54:43.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7293" for this suite.
Dec  5 07:54:49.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:54:49.899: INFO: namespace downward-api-7293 deletion completed in 6.123468187s

â€¢ [SLOW TEST:10.225 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:54:49.904: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-xjg5
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 07:54:49.960: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-xjg5" in namespace "subpath-6637" to be "success or failure"
Dec  5 07:54:49.964: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.869841ms
Dec  5 07:54:51.969: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007768464s
Dec  5 07:54:53.973: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 4.012081491s
Dec  5 07:54:55.976: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 6.015561852s
Dec  5 07:54:57.985: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 8.024243914s
Dec  5 07:54:59.992: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 10.030902585s
Dec  5 07:55:01.995: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 12.034172138s
Dec  5 07:55:04.003: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 14.042529549s
Dec  5 07:55:06.046: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 16.085129708s
Dec  5 07:55:08.058: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 18.097302795s
Dec  5 07:55:10.063: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Running", Reason="", readiness=true. Elapsed: 20.101886525s
Dec  5 07:55:12.088: INFO: Pod "pod-subpath-test-configmap-xjg5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.126787246s
STEP: Saw pod success
Dec  5 07:55:12.088: INFO: Pod "pod-subpath-test-configmap-xjg5" satisfied condition "success or failure"
Dec  5 07:55:12.091: INFO: Trying to get logs from node worknode pod pod-subpath-test-configmap-xjg5 container test-container-subpath-configmap-xjg5: <nil>
STEP: delete the pod
Dec  5 07:55:12.123: INFO: Waiting for pod pod-subpath-test-configmap-xjg5 to disappear
Dec  5 07:55:12.127: INFO: Pod pod-subpath-test-configmap-xjg5 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-xjg5
Dec  5 07:55:12.127: INFO: Deleting pod "pod-subpath-test-configmap-xjg5" in namespace "subpath-6637"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 07:55:12.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6637" for this suite.
Dec  5 07:55:18.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 07:55:18.234: INFO: namespace subpath-6637 deletion completed in 6.09976276s

â€¢ [SLOW TEST:28.330 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 07:55:18.234: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  5 07:55:18.264: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 07:55:18.274: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 07:55:18.277: INFO: 
Logging pods the kubelet thinks is on node allinone before test
Dec  5 07:55:18.295: INFO: kube-controller-manager-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec  5 07:55:18.295: INFO: coredns-5644d7b6d9-8vk79 from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container coredns ready: true, restart count 0
Dec  5 07:55:18.295: INFO: calico-kube-controllers-55754f75c-g2l8q from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 07:55:18.295: INFO: etcd-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container etcd ready: true, restart count 0
Dec  5 07:55:18.295: INFO: kube-scheduler-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec  5 07:55:18.295: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 07:55:18.295: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 07:55:18.295: INFO: coredns-5644d7b6d9-5jdzn from kube-system started at 2019-12-05 06:35:26 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container coredns ready: true, restart count 0
Dec  5 07:55:18.295: INFO: kube-apiserver-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec  5 07:55:18.295: INFO: calico-node-wt92j from kube-system started at 2019-12-05 06:35:16 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 07:55:18.295: INFO: kube-proxy-4g9tm from kube-system started at 2019-12-05 06:34:04 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.295: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 07:55:18.295: INFO: 
Logging pods the kubelet thinks is on node worknode before test
Dec  5 07:55:18.302: INFO: sonobuoy from sonobuoy started at 2019-12-05 06:49:53 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.302: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 07:55:18.302: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:55:18.302: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 07:55:18.302: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 07:55:18.302: INFO: calico-node-pnldh from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.302: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 07:55:18.302: INFO: kube-proxy-x5czv from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 07:55:18.302: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 07:55:18.302: INFO: sonobuoy-e2e-job-6da6843aacc74c61 from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 07:55:18.302: INFO: 	Container e2e ready: true, restart count 0
Dec  5 07:55:18.302: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-cf306777-56bf-41fe-8ec5-06e57684d881 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-cf306777-56bf-41fe-8ec5-06e57684d881 off the node worknode
STEP: verifying the node doesn't have the label kubernetes.io/e2e-cf306777-56bf-41fe-8ec5-06e57684d881
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:00:24.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2193" for this suite.
Dec  5 08:00:38.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:00:38.571: INFO: namespace sched-pred-2193 deletion completed in 14.124094317s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:320.337 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:00:38.576: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  5 08:00:38.634: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17091 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 08:00:38.634: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17091 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  5 08:00:48.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17105 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  5 08:00:48.655: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17105 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  5 08:00:58.665: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17119 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 08:00:58.665: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17119 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  5 08:01:08.703: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17134 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 08:01:08.703: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-a 32eaf51d-a076-4ffc-a83c-d4aeaee7470a 17134 0 2019-12-05 08:00:38 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  5 08:01:18.718: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-b a6a35326-4d9e-4ac3-a7e1-8b0bee38733b 17148 0 2019-12-05 08:01:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 08:01:18.718: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-b a6a35326-4d9e-4ac3-a7e1-8b0bee38733b 17148 0 2019-12-05 08:01:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  5 08:01:28.727: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-b a6a35326-4d9e-4ac3-a7e1-8b0bee38733b 17163 0 2019-12-05 08:01:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 08:01:28.728: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6693 /api/v1/namespaces/watch-6693/configmaps/e2e-watch-test-configmap-b a6a35326-4d9e-4ac3-a7e1-8b0bee38733b 17163 0 2019-12-05 08:01:18 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:01:38.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6693" for this suite.
Dec  5 08:01:44.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:01:44.841: INFO: namespace watch-6693 deletion completed in 6.109187801s

â€¢ [SLOW TEST:66.265 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:01:44.845: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:02:01.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9963" for this suite.
Dec  5 08:02:07.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:07.193: INFO: namespace resourcequota-9963 deletion completed in 6.123626579s

â€¢ [SLOW TEST:22.348 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:07.193: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:02:07.236: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc" in namespace "downward-api-5511" to be "success or failure"
Dec  5 08:02:07.244: INFO: Pod "downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 7.664117ms
Dec  5 08:02:09.248: INFO: Pod "downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011691951s
STEP: Saw pod success
Dec  5 08:02:09.248: INFO: Pod "downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc" satisfied condition "success or failure"
Dec  5 08:02:09.257: INFO: Trying to get logs from node worknode pod downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc container client-container: <nil>
STEP: delete the pod
Dec  5 08:02:09.317: INFO: Waiting for pod downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc to disappear
Dec  5 08:02:09.332: INFO: Pod downwardapi-volume-3b5128e2-9608-46db-bae5-45ad5c9bd5fc no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:02:09.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5511" for this suite.
Dec  5 08:02:15.367: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:15.465: INFO: namespace downward-api-5511 deletion completed in 6.124117615s

â€¢ [SLOW TEST:8.272 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:15.466: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec  5 08:02:15.505: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-7310'
Dec  5 08:02:15.787: INFO: stderr: ""
Dec  5 08:02:15.787: INFO: stdout: "pod/pause created\n"
Dec  5 08:02:15.787: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  5 08:02:15.787: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7310" to be "running and ready"
Dec  5 08:02:15.799: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 12.493602ms
Dec  5 08:02:17.804: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.017140974s
Dec  5 08:02:17.804: INFO: Pod "pause" satisfied condition "running and ready"
Dec  5 08:02:17.804: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  5 08:02:17.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 label pods pause testing-label=testing-label-value --namespace=kubectl-7310'
Dec  5 08:02:17.979: INFO: stderr: ""
Dec  5 08:02:17.979: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  5 08:02:17.979: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pod pause -L testing-label --namespace=kubectl-7310'
Dec  5 08:02:18.080: INFO: stderr: ""
Dec  5 08:02:18.081: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  5 08:02:18.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 label pods pause testing-label- --namespace=kubectl-7310'
Dec  5 08:02:18.167: INFO: stderr: ""
Dec  5 08:02:18.167: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  5 08:02:18.167: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pod pause -L testing-label --namespace=kubectl-7310'
Dec  5 08:02:18.239: INFO: stderr: ""
Dec  5 08:02:18.239: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          3s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec  5 08:02:18.239: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-7310'
Dec  5 08:02:18.361: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:02:18.361: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  5 08:02:18.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get rc,svc -l name=pause --no-headers --namespace=kubectl-7310'
Dec  5 08:02:18.546: INFO: stderr: "No resources found in kubectl-7310 namespace.\n"
Dec  5 08:02:18.546: INFO: stdout: ""
Dec  5 08:02:18.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -l name=pause --namespace=kubectl-7310 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 08:02:18.661: INFO: stderr: ""
Dec  5 08:02:18.661: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:02:18.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7310" for this suite.
Dec  5 08:02:24.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:24.782: INFO: namespace kubectl-7310 deletion completed in 6.117298054s

â€¢ [SLOW TEST:9.316 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:24.782: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec  5 08:02:25.459: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1205 08:02:25.459204      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 08:02:25.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1512" for this suite.
Dec  5 08:02:31.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:31.605: INFO: namespace gc-1512 deletion completed in 6.142119947s

â€¢ [SLOW TEST:6.823 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:31.605: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:02:32.254: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:02:35.294: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:02:35.301: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8219" for this suite.
Dec  5 08:02:41.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:41.424: INFO: namespace webhook-8219 deletion completed in 6.118520482s
STEP: Destroying namespace "webhook-8219-markers" for this suite.
Dec  5 08:02:47.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:47.564: INFO: namespace webhook-8219-markers deletion completed in 6.140331103s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:15.972 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:47.581: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-8ba12c3a-3824-4cfe-a41a-82df09394716
STEP: Creating secret with name secret-projected-all-test-volume-0af0cd5a-b037-4c07-891a-d1693d300243
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  5 08:02:47.630: INFO: Waiting up to 5m0s for pod "projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997" in namespace "projected-4954" to be "success or failure"
Dec  5 08:02:47.644: INFO: Pod "projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997": Phase="Pending", Reason="", readiness=false. Elapsed: 13.968211ms
Dec  5 08:02:49.648: INFO: Pod "projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018145684s
STEP: Saw pod success
Dec  5 08:02:49.648: INFO: Pod "projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997" satisfied condition "success or failure"
Dec  5 08:02:49.650: INFO: Trying to get logs from node worknode pod projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  5 08:02:49.676: INFO: Waiting for pod projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997 to disappear
Dec  5 08:02:49.681: INFO: Pod projected-volume-a0f72b1f-eb3a-43e5-9bb0-fc40a25e8997 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:02:49.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4954" for this suite.
Dec  5 08:02:55.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:02:55.793: INFO: namespace projected-4954 deletion completed in 6.106502372s

â€¢ [SLOW TEST:8.212 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:02:55.797: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:03:00.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6510" for this suite.
Dec  5 08:03:06.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:03:06.910: INFO: namespace watch-6510 deletion completed in 6.205395972s

â€¢ [SLOW TEST:11.113 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:03:06.912: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:03:34.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3145" for this suite.
Dec  5 08:03:40.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:03:40.479: INFO: namespace container-runtime-3145 deletion completed in 6.167784728s

â€¢ [SLOW TEST:33.567 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:03:40.479: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  5 08:03:40.595: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-899 /api/v1/namespaces/watch-899/configmaps/e2e-watch-test-resource-version 0951d2a2-11ed-448c-b668-be542b83472d 17840 0 2019-12-05 08:03:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 08:03:40.596: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-899 /api/v1/namespaces/watch-899/configmaps/e2e-watch-test-resource-version 0951d2a2-11ed-448c-b668-be542b83472d 17841 0 2019-12-05 08:03:40 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:03:40.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-899" for this suite.
Dec  5 08:03:46.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:03:46.733: INFO: namespace watch-899 deletion completed in 6.131602052s

â€¢ [SLOW TEST:6.254 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:03:46.735: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:03:47.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 08:03:49.146: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711129827, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711129827, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711129827, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711129827, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:03:52.163: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec  5 08:03:52.188: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:03:52.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5049" for this suite.
Dec  5 08:03:58.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:03:58.341: INFO: namespace webhook-5049 deletion completed in 6.134978199s
STEP: Destroying namespace "webhook-5049-markers" for this suite.
Dec  5 08:04:04.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:04.451: INFO: namespace webhook-5049-markers deletion completed in 6.108968309s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.729 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:04.465: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-170fb00d-c131-41b1-8793-03c2f105f44c
STEP: Creating a pod to test consume configMaps
Dec  5 08:04:04.514: INFO: Waiting up to 5m0s for pod "pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2" in namespace "configmap-9868" to be "success or failure"
Dec  5 08:04:04.530: INFO: Pod "pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2": Phase="Pending", Reason="", readiness=false. Elapsed: 15.841072ms
Dec  5 08:04:06.535: INFO: Pod "pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020329097s
STEP: Saw pod success
Dec  5 08:04:06.535: INFO: Pod "pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2" satisfied condition "success or failure"
Dec  5 08:04:06.540: INFO: Trying to get logs from node worknode pod pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:04:06.590: INFO: Waiting for pod pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2 to disappear
Dec  5 08:04:06.592: INFO: Pod pod-configmaps-91f3863f-e90a-4a1b-b0bb-ab1f2780ecd2 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:06.592: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9868" for this suite.
Dec  5 08:04:12.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:12.704: INFO: namespace configmap-9868 deletion completed in 6.108862725s

â€¢ [SLOW TEST:8.240 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:12.707: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-06b00d64-7587-4295-b610-b48cc2f2206b
STEP: Creating a pod to test consume configMaps
Dec  5 08:04:12.761: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92" in namespace "projected-9601" to be "success or failure"
Dec  5 08:04:12.767: INFO: Pod "pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92": Phase="Pending", Reason="", readiness=false. Elapsed: 6.147802ms
Dec  5 08:04:14.771: INFO: Pod "pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00961708s
STEP: Saw pod success
Dec  5 08:04:14.771: INFO: Pod "pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92" satisfied condition "success or failure"
Dec  5 08:04:14.774: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:04:14.802: INFO: Waiting for pod pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92 to disappear
Dec  5 08:04:14.808: INFO: Pod pod-projected-configmaps-f4322dc9-cbf2-409f-b7e7-458a100c1d92 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:14.809: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9601" for this suite.
Dec  5 08:04:20.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:20.951: INFO: namespace projected-9601 deletion completed in 6.138355023s

â€¢ [SLOW TEST:8.244 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:20.952: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-d03a5c86-9df4-49b6-93b4-81c2fd3d3e2f
STEP: Creating a pod to test consume configMaps
Dec  5 08:04:21.015: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06" in namespace "projected-6082" to be "success or failure"
Dec  5 08:04:21.023: INFO: Pod "pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06": Phase="Pending", Reason="", readiness=false. Elapsed: 8.14798ms
Dec  5 08:04:23.027: INFO: Pod "pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011230687s
STEP: Saw pod success
Dec  5 08:04:23.027: INFO: Pod "pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06" satisfied condition "success or failure"
Dec  5 08:04:23.030: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:04:23.065: INFO: Waiting for pod pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06 to disappear
Dec  5 08:04:23.071: INFO: Pod pod-projected-configmaps-4c8e5dd7-747e-4e64-9e20-ba13dd713e06 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:23.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6082" for this suite.
Dec  5 08:04:29.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:29.205: INFO: namespace projected-6082 deletion completed in 6.130259568s

â€¢ [SLOW TEST:8.253 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:29.206: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:29.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5446" for this suite.
Dec  5 08:04:35.273: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:35.366: INFO: namespace custom-resource-definition-5446 deletion completed in 6.108537258s

â€¢ [SLOW TEST:6.160 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:35.367: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:35.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7922" for this suite.
Dec  5 08:04:47.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:47.593: INFO: namespace pods-7922 deletion completed in 12.146254404s

â€¢ [SLOW TEST:12.227 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:47.597: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 08:04:47.657: INFO: Waiting up to 5m0s for pod "pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20" in namespace "emptydir-7321" to be "success or failure"
Dec  5 08:04:47.679: INFO: Pod "pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20": Phase="Pending", Reason="", readiness=false. Elapsed: 21.402937ms
Dec  5 08:04:49.683: INFO: Pod "pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.025333762s
STEP: Saw pod success
Dec  5 08:04:49.683: INFO: Pod "pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20" satisfied condition "success or failure"
Dec  5 08:04:49.686: INFO: Trying to get logs from node worknode pod pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20 container test-container: <nil>
STEP: delete the pod
Dec  5 08:04:49.724: INFO: Waiting for pod pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20 to disappear
Dec  5 08:04:49.729: INFO: Pod pod-3bb30a5d-fa09-4dc6-a82d-c173de0efe20 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:49.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7321" for this suite.
Dec  5 08:04:55.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:04:55.883: INFO: namespace emptydir-7321 deletion completed in 6.14856476s

â€¢ [SLOW TEST:8.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:04:55.888: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec  5 08:04:58.090: INFO: Pod pod-hostip-19e66d48-7c32-4357-8663-fb9fc2c1f45e has hostIP: 10.0.3.47
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:04:58.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7980" for this suite.
Dec  5 08:05:10.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:05:10.296: INFO: namespace pods-7980 deletion completed in 12.203774338s

â€¢ [SLOW TEST:14.408 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:05:10.298: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:05:26.388: INFO: Container started at 2019-12-05 08:05:11 +0000 UTC, pod became ready at 2019-12-05 08:05:26 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:05:26.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5531" for this suite.
Dec  5 08:05:38.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:05:38.501: INFO: namespace container-probe-5531 deletion completed in 12.109136025s

â€¢ [SLOW TEST:28.202 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:05:38.501: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:05:38.548: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e2640a21-1417-47b7-b631-77fc9133d767" in namespace "security-context-test-532" to be "success or failure"
Dec  5 08:05:38.562: INFO: Pod "alpine-nnp-false-e2640a21-1417-47b7-b631-77fc9133d767": Phase="Pending", Reason="", readiness=false. Elapsed: 12.515935ms
Dec  5 08:05:40.566: INFO: Pod "alpine-nnp-false-e2640a21-1417-47b7-b631-77fc9133d767": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016771644s
Dec  5 08:05:42.570: INFO: Pod "alpine-nnp-false-e2640a21-1417-47b7-b631-77fc9133d767": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020684838s
Dec  5 08:05:42.570: INFO: Pod "alpine-nnp-false-e2640a21-1417-47b7-b631-77fc9133d767" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:05:42.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-532" for this suite.
Dec  5 08:05:48.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:05:48.707: INFO: namespace security-context-test-532 deletion completed in 6.124119064s

â€¢ [SLOW TEST:10.206 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:05:48.708: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  5 08:05:48.744: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 08:05:48.755: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 08:05:48.759: INFO: 
Logging pods the kubelet thinks is on node allinone before test
Dec  5 08:05:48.784: INFO: coredns-5644d7b6d9-8vk79 from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.784: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:05:48.784: INFO: kube-controller-manager-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.784: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec  5 08:05:48.784: INFO: calico-kube-controllers-55754f75c-g2l8q from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.784: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 08:05:48.785: INFO: kube-scheduler-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.785: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec  5 08:05:48.785: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:05:48.785: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:05:48.785: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 08:05:48.785: INFO: etcd-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.785: INFO: 	Container etcd ready: true, restart count 0
Dec  5 08:05:48.785: INFO: coredns-5644d7b6d9-5jdzn from kube-system started at 2019-12-05 06:35:26 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.785: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:05:48.785: INFO: kube-apiserver-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.785: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec  5 08:05:48.786: INFO: calico-node-wt92j from kube-system started at 2019-12-05 06:35:16 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.786: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:05:48.786: INFO: kube-proxy-4g9tm from kube-system started at 2019-12-05 06:34:04 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.786: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:05:48.787: INFO: 
Logging pods the kubelet thinks is on node worknode before test
Dec  5 08:05:48.794: INFO: sonobuoy-e2e-job-6da6843aacc74c61 from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:05:48.794: INFO: 	Container e2e ready: true, restart count 0
Dec  5 08:05:48.794: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec  5 08:05:48.794: INFO: calico-node-pnldh from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.794: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:05:48.794: INFO: kube-proxy-x5czv from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.794: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:05:48.794: INFO: sonobuoy from sonobuoy started at 2019-12-05 06:49:53 +0000 UTC (1 container statuses recorded)
Dec  5 08:05:48.794: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 08:05:48.794: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:05:48.794: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:05:48.794: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-dbfff87c-69dc-42e0-8225-c63112db730e 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-dbfff87c-69dc-42e0-8225-c63112db730e off the node worknode
STEP: verifying the node doesn't have the label kubernetes.io/e2e-dbfff87c-69dc-42e0-8225-c63112db730e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:05:56.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4310" for this suite.
Dec  5 08:06:04.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:06:05.043: INFO: namespace sched-pred-4310 deletion completed in 8.116954035s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:16.336 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:06:05.044: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9413
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-9413
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-9413
Dec  5 08:06:05.101: INFO: Found 0 stateful pods, waiting for 1
Dec  5 08:06:15.105: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  5 08:06:15.108: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:06:15.390: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:06:15.390: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:06:15.390: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:06:15.394: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 08:06:25.398: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:06:25.398: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:06:25.417: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:25.417: INFO: ss-0  worknode  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:15 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:25.417: INFO: 
Dec  5 08:06:25.417: INFO: StatefulSet ss has not reached scale 3, at 1
Dec  5 08:06:26.427: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994779229s
Dec  5 08:06:27.431: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.985671525s
Dec  5 08:06:28.435: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.981540681s
Dec  5 08:06:29.442: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977743216s
Dec  5 08:06:30.446: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.97040818s
Dec  5 08:06:31.451: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.965926699s
Dec  5 08:06:32.455: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.961398984s
Dec  5 08:06:33.459: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.957100817s
Dec  5 08:06:34.463: INFO: Verifying statefulset ss doesn't scale past 3 for another 953.45463ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-9413
Dec  5 08:06:35.468: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:06:35.676: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:06:35.676: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:06:35.676: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:06:35.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:06:35.971: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  5 08:06:35.972: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:06:35.972: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:06:35.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:06:36.209: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  5 08:06:36.209: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:06:36.209: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:06:36.213: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:06:36.213: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:06:36.213: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  5 08:06:36.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:06:36.455: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:06:36.455: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:06:36.455: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:06:36.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:06:36.777: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:06:36.777: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:06:36.777: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:06:36.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-9413 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:06:37.071: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:06:37.071: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:06:37.071: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:06:37.071: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:06:37.074: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  5 08:06:47.081: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:06:47.081: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:06:47.081: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:06:47.092: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:47.092: INFO: ss-0  worknode  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:47.092: INFO: ss-1  allinone  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:47.092: INFO: ss-2  worknode  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:47.092: INFO: 
Dec  5 08:06:47.092: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 08:06:48.097: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:48.097: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:48.097: INFO: ss-1  allinone  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:48.097: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:48.097: INFO: 
Dec  5 08:06:48.097: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 08:06:49.101: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:49.101: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:49.101: INFO: ss-1  allinone  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:49.101: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:49.101: INFO: 
Dec  5 08:06:49.101: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  5 08:06:50.105: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:50.105: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:50.105: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:50.105: INFO: 
Dec  5 08:06:50.105: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:51.109: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:51.109: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:51.109: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:51.109: INFO: 
Dec  5 08:06:51.109: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:52.114: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:52.114: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:52.114: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:52.114: INFO: 
Dec  5 08:06:52.114: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:53.154: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:53.155: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:53.155: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:53.155: INFO: 
Dec  5 08:06:53.155: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:54.159: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:54.160: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:54.160: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:54.160: INFO: 
Dec  5 08:06:54.160: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:55.165: INFO: POD   NODE      PHASE    GRACE  CONDITIONS
Dec  5 08:06:55.166: INFO: ss-0  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:36 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:05 +0000 UTC  }]
Dec  5 08:06:55.166: INFO: ss-2  worknode  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-05 08:06:25 +0000 UTC  }]
Dec  5 08:06:55.166: INFO: 
Dec  5 08:06:55.166: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  5 08:06:56.200: INFO: Verifying statefulset ss doesn't scale past 0 for another 891.126951ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-9413
Dec  5 08:06:57.205: INFO: Scaling statefulset ss to 0
Dec  5 08:06:57.219: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 08:06:57.223: INFO: Deleting all statefulset in ns statefulset-9413
Dec  5 08:06:57.226: INFO: Scaling statefulset ss to 0
Dec  5 08:06:57.237: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:06:57.241: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:06:57.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9413" for this suite.
Dec  5 08:07:03.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:07:03.396: INFO: namespace statefulset-9413 deletion completed in 6.129997379s

â€¢ [SLOW TEST:58.353 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:07:03.397: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  5 08:07:03.450: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1042 /api/v1/namespaces/watch-1042/configmaps/e2e-watch-test-watch-closed 59f3d844-7793-424f-be23-669e2b1e303b 18690 0 2019-12-05 08:07:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  5 08:07:03.450: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1042 /api/v1/namespaces/watch-1042/configmaps/e2e-watch-test-watch-closed 59f3d844-7793-424f-be23-669e2b1e303b 18691 0 2019-12-05 08:07:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  5 08:07:03.464: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1042 /api/v1/namespaces/watch-1042/configmaps/e2e-watch-test-watch-closed 59f3d844-7793-424f-be23-669e2b1e303b 18692 0 2019-12-05 08:07:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  5 08:07:03.465: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-1042 /api/v1/namespaces/watch-1042/configmaps/e2e-watch-test-watch-closed 59f3d844-7793-424f-be23-669e2b1e303b 18693 0 2019-12-05 08:07:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:07:03.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1042" for this suite.
Dec  5 08:07:09.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:07:09.602: INFO: namespace watch-1042 deletion completed in 6.133196495s

â€¢ [SLOW TEST:6.205 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:07:09.602: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 08:07:09.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5632'
Dec  5 08:07:09.733: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 08:07:09.733: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec  5 08:07:11.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5632'
Dec  5 08:07:11.831: INFO: stderr: ""
Dec  5 08:07:11.831: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:07:11.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5632" for this suite.
Dec  5 08:08:39.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:08:39.948: INFO: namespace kubectl-5632 deletion completed in 1m28.112066363s

â€¢ [SLOW TEST:90.346 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:08:39.949: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec  5 08:08:39.981: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec  5 08:08:51.965: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:08:54.848: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:09:07.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9391" for this suite.
Dec  5 08:09:13.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:09:13.798: INFO: namespace crd-publish-openapi-9391 deletion completed in 6.170709588s

â€¢ [SLOW TEST:33.849 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:09:13.799: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 08:09:13.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4315'
Dec  5 08:09:13.945: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  5 08:09:13.946: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec  5 08:09:13.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete jobs e2e-test-httpd-job --namespace=kubectl-4315'
Dec  5 08:09:14.036: INFO: stderr: ""
Dec  5 08:09:14.036: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:09:14.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4315" for this suite.
Dec  5 08:09:20.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:09:20.166: INFO: namespace kubectl-4315 deletion completed in 6.125418052s

â€¢ [SLOW TEST:6.368 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:09:20.168: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:09:22.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1051" for this suite.
Dec  5 08:10:06.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:10:06.377: INFO: namespace kubelet-test-1051 deletion completed in 44.123030092s

â€¢ [SLOW TEST:46.210 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:10:06.377: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:10:06.787: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 08:10:08.797: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130206, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130206, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130206, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130206, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:10:11.844: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:10:11.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2621" for this suite.
Dec  5 08:10:17.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:10:18.006: INFO: namespace webhook-2621 deletion completed in 6.09900901s
STEP: Destroying namespace "webhook-2621-markers" for this suite.
Dec  5 08:10:24.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:10:24.108: INFO: namespace webhook-2621-markers deletion completed in 6.101652542s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.752 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:10:24.132: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:10:24.170: INFO: Waiting up to 5m0s for pod "downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4" in namespace "downward-api-3920" to be "success or failure"
Dec  5 08:10:24.178: INFO: Pod "downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.811528ms
Dec  5 08:10:26.183: INFO: Pod "downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01308643s
STEP: Saw pod success
Dec  5 08:10:26.183: INFO: Pod "downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4" satisfied condition "success or failure"
Dec  5 08:10:26.185: INFO: Trying to get logs from node worknode pod downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4 container client-container: <nil>
STEP: delete the pod
Dec  5 08:10:26.213: INFO: Waiting for pod downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4 to disappear
Dec  5 08:10:26.216: INFO: Pod downwardapi-volume-83a7aaf9-8eb5-4ccf-b64f-bc3c93da0fa4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:10:26.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3920" for this suite.
Dec  5 08:10:32.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:10:32.318: INFO: namespace downward-api-3920 deletion completed in 6.098277397s

â€¢ [SLOW TEST:8.186 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:10:32.325: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-2ee62c1f-3228-494c-aae8-9d5813d3afbc
STEP: Creating configMap with name cm-test-opt-upd-6717cf2b-540b-4302-95f2-83ad562ed2e5
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2ee62c1f-3228-494c-aae8-9d5813d3afbc
STEP: Updating configmap cm-test-opt-upd-6717cf2b-540b-4302-95f2-83ad562ed2e5
STEP: Creating configMap with name cm-test-opt-create-33ebc021-b7c6-4548-9379-28b667701f3f
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:10:36.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3117" for this suite.
Dec  5 08:10:48.508: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:10:48.593: INFO: namespace configmap-3117 deletion completed in 12.098941043s

â€¢ [SLOW TEST:16.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:10:48.595: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  5 08:10:51.173: INFO: Successfully updated pod "annotationupdatef9e8d18f-5610-4ea5-ac23-6c164bc2df14"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:10:53.190: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4103" for this suite.
Dec  5 08:11:21.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:11:21.301: INFO: namespace projected-4103 deletion completed in 28.106916763s

â€¢ [SLOW TEST:32.706 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:11:21.302: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec  5 08:11:21.346: INFO: Waiting up to 5m0s for pod "client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15" in namespace "containers-3" to be "success or failure"
Dec  5 08:11:21.353: INFO: Pod "client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15": Phase="Pending", Reason="", readiness=false. Elapsed: 6.361234ms
Dec  5 08:11:23.358: INFO: Pod "client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011497557s
STEP: Saw pod success
Dec  5 08:11:23.358: INFO: Pod "client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15" satisfied condition "success or failure"
Dec  5 08:11:23.361: INFO: Trying to get logs from node worknode pod client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15 container test-container: <nil>
STEP: delete the pod
Dec  5 08:11:23.382: INFO: Waiting for pod client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15 to disappear
Dec  5 08:11:23.388: INFO: Pod client-containers-e26c19be-e3f5-4f94-a6f5-34d7ba758d15 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:11:23.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3" for this suite.
Dec  5 08:11:29.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:11:29.492: INFO: namespace containers-3 deletion completed in 6.100412388s

â€¢ [SLOW TEST:8.190 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:11:29.493: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  5 08:11:29.535: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 08:11:29.546: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 08:11:29.549: INFO: 
Logging pods the kubelet thinks is on node allinone before test
Dec  5 08:11:29.563: INFO: kube-apiserver-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec  5 08:11:29.564: INFO: calico-node-wt92j from kube-system started at 2019-12-05 06:35:16 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:11:29.564: INFO: kube-proxy-4g9tm from kube-system started at 2019-12-05 06:34:04 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:11:29.564: INFO: kube-controller-manager-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec  5 08:11:29.564: INFO: coredns-5644d7b6d9-8vk79 from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:11:29.564: INFO: calico-kube-controllers-55754f75c-g2l8q from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 08:11:29.564: INFO: etcd-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container etcd ready: true, restart count 0
Dec  5 08:11:29.564: INFO: kube-scheduler-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec  5 08:11:29.564: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:11:29.564: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 08:11:29.564: INFO: coredns-5644d7b6d9-5jdzn from kube-system started at 2019-12-05 06:35:26 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.564: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:11:29.564: INFO: 
Logging pods the kubelet thinks is on node worknode before test
Dec  5 08:11:29.569: INFO: calico-node-pnldh from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.569: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:11:29.569: INFO: kube-proxy-x5czv from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.570: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:11:29.570: INFO: sonobuoy from sonobuoy started at 2019-12-05 06:49:53 +0000 UTC (1 container statuses recorded)
Dec  5 08:11:29.570: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 08:11:29.570: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:11:29.570: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:11:29.570: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 08:11:29.570: INFO: sonobuoy-e2e-job-6da6843aacc74c61 from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:11:29.570: INFO: 	Container e2e ready: true, restart count 0
Dec  5 08:11:29.571: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1a574146-00c0-4412-94e7-be2468776112 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-1a574146-00c0-4412-94e7-be2468776112 off the node worknode
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1a574146-00c0-4412-94e7-be2468776112
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:11:37.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5675" for this suite.
Dec  5 08:11:47.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:11:47.802: INFO: namespace sched-pred-5675 deletion completed in 10.092071563s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:18.309 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:11:47.804: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:11:47.836: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Creating first CR 
Dec  5 08:11:47.927: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:47Z generation:1 name:name1 resourceVersion:19552 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:1c300c48-db5f-4c8d-8148-02d14d1d2e14] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec  5 08:11:57.930: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:57Z generation:1 name:name2 resourceVersion:19565 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7dbdb8ba-a2a9-4cd8-bc31-d16f91c188b5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec  5 08:12:07.937: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:47Z generation:2 name:name1 resourceVersion:19580 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:1c300c48-db5f-4c8d-8148-02d14d1d2e14] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec  5 08:12:17.942: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:57Z generation:2 name:name2 resourceVersion:19594 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7dbdb8ba-a2a9-4cd8-bc31-d16f91c188b5] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec  5 08:12:27.949: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:47Z generation:2 name:name1 resourceVersion:19608 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:1c300c48-db5f-4c8d-8148-02d14d1d2e14] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec  5 08:12:37.956: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-05T08:11:57Z generation:2 name:name2 resourceVersion:19623 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7dbdb8ba-a2a9-4cd8-bc31-d16f91c188b5] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:12:48.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-2527" for this suite.
Dec  5 08:12:54.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:12:54.589: INFO: namespace crd-watch-2527 deletion completed in 6.115760457s

â€¢ [SLOW TEST:66.785 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:12:54.589: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-2718
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-2718
STEP: Deleting pre-stop pod
Dec  5 08:13:05.696: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:13:05.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-2718" for this suite.
Dec  5 08:13:49.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:13:49.899: INFO: namespace prestop-2718 deletion completed in 44.179359241s

â€¢ [SLOW TEST:55.310 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:13:49.900: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:13:49.967: INFO: Waiting up to 5m0s for pod "busybox-user-65534-86491754-3fa6-43cf-a008-73cfa9c98f4e" in namespace "security-context-test-4928" to be "success or failure"
Dec  5 08:13:49.982: INFO: Pod "busybox-user-65534-86491754-3fa6-43cf-a008-73cfa9c98f4e": Phase="Pending", Reason="", readiness=false. Elapsed: 15.325624ms
Dec  5 08:13:51.988: INFO: Pod "busybox-user-65534-86491754-3fa6-43cf-a008-73cfa9c98f4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.021232712s
Dec  5 08:13:53.993: INFO: Pod "busybox-user-65534-86491754-3fa6-43cf-a008-73cfa9c98f4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.025915907s
Dec  5 08:13:53.993: INFO: Pod "busybox-user-65534-86491754-3fa6-43cf-a008-73cfa9c98f4e" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:13:53.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4928" for this suite.
Dec  5 08:14:00.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:14:00.122: INFO: namespace security-context-test-4928 deletion completed in 6.122092498s

â€¢ [SLOW TEST:10.222 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:14:00.123: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 08:14:00.212: INFO: Number of nodes with available pods: 0
Dec  5 08:14:00.212: INFO: Node allinone is running more than one daemon pod
Dec  5 08:14:01.220: INFO: Number of nodes with available pods: 0
Dec  5 08:14:01.220: INFO: Node allinone is running more than one daemon pod
Dec  5 08:14:02.228: INFO: Number of nodes with available pods: 0
Dec  5 08:14:02.229: INFO: Node allinone is running more than one daemon pod
Dec  5 08:14:03.224: INFO: Number of nodes with available pods: 2
Dec  5 08:14:03.224: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  5 08:14:03.250: INFO: Number of nodes with available pods: 1
Dec  5 08:14:03.250: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:04.256: INFO: Number of nodes with available pods: 1
Dec  5 08:14:04.256: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:05.262: INFO: Number of nodes with available pods: 1
Dec  5 08:14:05.262: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:06.260: INFO: Number of nodes with available pods: 1
Dec  5 08:14:06.260: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:07.265: INFO: Number of nodes with available pods: 1
Dec  5 08:14:07.265: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:08.257: INFO: Number of nodes with available pods: 1
Dec  5 08:14:08.257: INFO: Node worknode is running more than one daemon pod
Dec  5 08:14:09.257: INFO: Number of nodes with available pods: 2
Dec  5 08:14:09.258: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5439, will wait for the garbage collector to delete the pods
Dec  5 08:14:09.325: INFO: Deleting DaemonSet.extensions daemon-set took: 5.654574ms
Dec  5 08:14:09.725: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.703041ms
Dec  5 08:14:15.740: INFO: Number of nodes with available pods: 0
Dec  5 08:14:15.740: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 08:14:15.744: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5439/daemonsets","resourceVersion":"19926"},"items":null}

Dec  5 08:14:15.748: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5439/pods","resourceVersion":"19926"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:14:15.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5439" for this suite.
Dec  5 08:14:21.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:14:21.896: INFO: namespace daemonsets-5439 deletion completed in 6.127913787s

â€¢ [SLOW TEST:21.773 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:14:21.898: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:14:21.947: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef" in namespace "downward-api-6734" to be "success or failure"
Dec  5 08:14:21.961: INFO: Pod "downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef": Phase="Pending", Reason="", readiness=false. Elapsed: 14.234784ms
Dec  5 08:14:23.965: INFO: Pod "downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.018011935s
STEP: Saw pod success
Dec  5 08:14:23.965: INFO: Pod "downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef" satisfied condition "success or failure"
Dec  5 08:14:23.968: INFO: Trying to get logs from node worknode pod downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef container client-container: <nil>
STEP: delete the pod
Dec  5 08:14:24.009: INFO: Waiting for pod downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef to disappear
Dec  5 08:14:24.014: INFO: Pod downwardapi-volume-c01b7bc8-d9c0-442b-af7b-77492cfe4eef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:14:24.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6734" for this suite.
Dec  5 08:14:30.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:14:30.128: INFO: namespace downward-api-6734 deletion completed in 6.106404933s

â€¢ [SLOW TEST:8.230 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:14:30.128: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  5 08:14:32.719: INFO: Successfully updated pod "pod-update-1878b17d-534a-4edd-9ed0-b0336eb6398b"
STEP: verifying the updated pod is in kubernetes
Dec  5 08:14:32.731: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:14:32.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-150" for this suite.
Dec  5 08:14:44.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:14:44.847: INFO: namespace pods-150 deletion completed in 12.110812071s

â€¢ [SLOW TEST:14.718 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:14:44.847: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  5 08:14:47.925: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:14:47.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-962" for this suite.
Dec  5 08:14:53.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:14:54.068: INFO: namespace container-runtime-962 deletion completed in 6.104159202s

â€¢ [SLOW TEST:9.221 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:14:54.071: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7592.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7592.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 08:14:58.170: INFO: DNS probes using dns-7592/dns-test-a1993bde-37b2-493a-946f-7599ac3508f4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:14:58.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7592" for this suite.
Dec  5 08:15:04.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:15:04.334: INFO: namespace dns-7592 deletion completed in 6.11140725s

â€¢ [SLOW TEST:10.263 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:15:04.334: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-5603
I1205 08:15:04.375515      20 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-5603, replica count: 1
I1205 08:15:05.426095      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1205 08:15:06.426386      20 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 08:15:06.550: INFO: Created: latency-svc-hchp4
Dec  5 08:15:06.554: INFO: Got endpoints: latency-svc-hchp4 [20.861757ms]
Dec  5 08:15:06.589: INFO: Created: latency-svc-2kc5h
Dec  5 08:15:06.589: INFO: Got endpoints: latency-svc-2kc5h [33.402211ms]
Dec  5 08:15:06.602: INFO: Created: latency-svc-6lngm
Dec  5 08:15:06.608: INFO: Got endpoints: latency-svc-6lngm [51.7091ms]
Dec  5 08:15:06.629: INFO: Created: latency-svc-h9brs
Dec  5 08:15:06.633: INFO: Got endpoints: latency-svc-h9brs [76.74366ms]
Dec  5 08:15:06.645: INFO: Created: latency-svc-nbd58
Dec  5 08:15:06.651: INFO: Got endpoints: latency-svc-nbd58 [95.281008ms]
Dec  5 08:15:06.665: INFO: Created: latency-svc-j52pt
Dec  5 08:15:06.667: INFO: Got endpoints: latency-svc-j52pt [110.886354ms]
Dec  5 08:15:06.685: INFO: Created: latency-svc-b98zt
Dec  5 08:15:06.695: INFO: Got endpoints: latency-svc-b98zt [138.726432ms]
Dec  5 08:15:06.702: INFO: Created: latency-svc-d5k8l
Dec  5 08:15:06.705: INFO: Got endpoints: latency-svc-d5k8l [148.303144ms]
Dec  5 08:15:06.729: INFO: Created: latency-svc-6gxzn
Dec  5 08:15:06.730: INFO: Got endpoints: latency-svc-6gxzn [174.132164ms]
Dec  5 08:15:06.744: INFO: Created: latency-svc-rvs56
Dec  5 08:15:06.753: INFO: Got endpoints: latency-svc-rvs56 [196.52873ms]
Dec  5 08:15:06.772: INFO: Created: latency-svc-c229m
Dec  5 08:15:06.775: INFO: Got endpoints: latency-svc-c229m [218.698979ms]
Dec  5 08:15:06.791: INFO: Created: latency-svc-cmrwk
Dec  5 08:15:06.793: INFO: Got endpoints: latency-svc-cmrwk [236.68603ms]
Dec  5 08:15:06.815: INFO: Created: latency-svc-nc2ds
Dec  5 08:15:06.817: INFO: Got endpoints: latency-svc-nc2ds [262.383519ms]
Dec  5 08:15:06.835: INFO: Created: latency-svc-5k4h7
Dec  5 08:15:06.841: INFO: Got endpoints: latency-svc-5k4h7 [284.623322ms]
Dec  5 08:15:06.848: INFO: Created: latency-svc-zf8tr
Dec  5 08:15:06.848: INFO: Got endpoints: latency-svc-zf8tr [291.518094ms]
Dec  5 08:15:06.863: INFO: Created: latency-svc-wm2lj
Dec  5 08:15:06.864: INFO: Got endpoints: latency-svc-wm2lj [307.673731ms]
Dec  5 08:15:06.884: INFO: Created: latency-svc-7898f
Dec  5 08:15:06.889: INFO: Got endpoints: latency-svc-7898f [300.346776ms]
Dec  5 08:15:06.904: INFO: Created: latency-svc-95c57
Dec  5 08:15:06.923: INFO: Got endpoints: latency-svc-95c57 [315.650409ms]
Dec  5 08:15:06.935: INFO: Created: latency-svc-6rt56
Dec  5 08:15:06.936: INFO: Got endpoints: latency-svc-6rt56 [303.835541ms]
Dec  5 08:15:06.952: INFO: Created: latency-svc-dv5pz
Dec  5 08:15:06.958: INFO: Got endpoints: latency-svc-dv5pz [306.298598ms]
Dec  5 08:15:06.972: INFO: Created: latency-svc-pl9tj
Dec  5 08:15:06.975: INFO: Got endpoints: latency-svc-pl9tj [307.831664ms]
Dec  5 08:15:06.989: INFO: Created: latency-svc-nxjz9
Dec  5 08:15:06.991: INFO: Got endpoints: latency-svc-nxjz9 [295.753226ms]
Dec  5 08:15:07.008: INFO: Created: latency-svc-wpgxq
Dec  5 08:15:07.012: INFO: Got endpoints: latency-svc-wpgxq [306.937884ms]
Dec  5 08:15:07.055: INFO: Created: latency-svc-7jh6n
Dec  5 08:15:07.056: INFO: Got endpoints: latency-svc-7jh6n [324.749421ms]
Dec  5 08:15:07.083: INFO: Created: latency-svc-dktnz
Dec  5 08:15:07.088: INFO: Created: latency-svc-mqs8w
Dec  5 08:15:07.098: INFO: Got endpoints: latency-svc-dktnz [344.953853ms]
Dec  5 08:15:07.108: INFO: Got endpoints: latency-svc-mqs8w [332.145308ms]
Dec  5 08:15:07.123: INFO: Created: latency-svc-tn2t7
Dec  5 08:15:07.123: INFO: Created: latency-svc-vfpqf
Dec  5 08:15:07.133: INFO: Got endpoints: latency-svc-vfpqf [339.99725ms]
Dec  5 08:15:07.136: INFO: Got endpoints: latency-svc-tn2t7 [318.300549ms]
Dec  5 08:15:07.150: INFO: Created: latency-svc-mc54p
Dec  5 08:15:07.164: INFO: Got endpoints: latency-svc-mc54p [322.463883ms]
Dec  5 08:15:07.166: INFO: Created: latency-svc-59gwj
Dec  5 08:15:07.179: INFO: Got endpoints: latency-svc-59gwj [329.951973ms]
Dec  5 08:15:07.184: INFO: Created: latency-svc-bkqdc
Dec  5 08:15:07.189: INFO: Got endpoints: latency-svc-bkqdc [324.374761ms]
Dec  5 08:15:07.198: INFO: Created: latency-svc-vwpht
Dec  5 08:15:07.214: INFO: Got endpoints: latency-svc-vwpht [322.692524ms]
Dec  5 08:15:07.227: INFO: Created: latency-svc-hgd98
Dec  5 08:15:07.227: INFO: Got endpoints: latency-svc-hgd98 [302.887198ms]
Dec  5 08:15:07.242: INFO: Created: latency-svc-cc468
Dec  5 08:15:07.242: INFO: Got endpoints: latency-svc-cc468 [305.611362ms]
Dec  5 08:15:07.256: INFO: Created: latency-svc-kj46k
Dec  5 08:15:07.272: INFO: Got endpoints: latency-svc-kj46k [314.056429ms]
Dec  5 08:15:07.278: INFO: Created: latency-svc-dx6j6
Dec  5 08:15:07.284: INFO: Got endpoints: latency-svc-dx6j6 [309.279122ms]
Dec  5 08:15:07.305: INFO: Created: latency-svc-2ckk6
Dec  5 08:15:07.305: INFO: Got endpoints: latency-svc-2ckk6 [313.765278ms]
Dec  5 08:15:07.317: INFO: Created: latency-svc-hfmbm
Dec  5 08:15:07.321: INFO: Got endpoints: latency-svc-hfmbm [308.742269ms]
Dec  5 08:15:07.348: INFO: Created: latency-svc-jmmqh
Dec  5 08:15:07.359: INFO: Got endpoints: latency-svc-jmmqh [302.919455ms]
Dec  5 08:15:07.367: INFO: Created: latency-svc-dcb97
Dec  5 08:15:07.371: INFO: Got endpoints: latency-svc-dcb97 [272.347167ms]
Dec  5 08:15:07.394: INFO: Created: latency-svc-wzjx9
Dec  5 08:15:07.402: INFO: Got endpoints: latency-svc-wzjx9 [294.221825ms]
Dec  5 08:15:07.412: INFO: Created: latency-svc-xqqxt
Dec  5 08:15:07.413: INFO: Got endpoints: latency-svc-xqqxt [279.378199ms]
Dec  5 08:15:07.429: INFO: Created: latency-svc-lx5p8
Dec  5 08:15:07.437: INFO: Got endpoints: latency-svc-lx5p8 [300.848187ms]
Dec  5 08:15:07.448: INFO: Created: latency-svc-spmgr
Dec  5 08:15:07.449: INFO: Got endpoints: latency-svc-spmgr [284.861352ms]
Dec  5 08:15:07.467: INFO: Created: latency-svc-2mkb4
Dec  5 08:15:07.467: INFO: Got endpoints: latency-svc-2mkb4 [288.899101ms]
Dec  5 08:15:07.478: INFO: Created: latency-svc-gz786
Dec  5 08:15:07.486: INFO: Got endpoints: latency-svc-gz786 [296.836137ms]
Dec  5 08:15:07.505: INFO: Created: latency-svc-ggmvx
Dec  5 08:15:07.511: INFO: Got endpoints: latency-svc-ggmvx [296.800434ms]
Dec  5 08:15:07.520: INFO: Created: latency-svc-pmjnd
Dec  5 08:15:07.523: INFO: Got endpoints: latency-svc-pmjnd [295.809986ms]
Dec  5 08:15:07.542: INFO: Created: latency-svc-2qr45
Dec  5 08:15:07.550: INFO: Got endpoints: latency-svc-2qr45 [306.98263ms]
Dec  5 08:15:07.561: INFO: Created: latency-svc-2kwwc
Dec  5 08:15:07.562: INFO: Got endpoints: latency-svc-2kwwc [290.388005ms]
Dec  5 08:15:07.578: INFO: Created: latency-svc-r769h
Dec  5 08:15:07.597: INFO: Created: latency-svc-68w7k
Dec  5 08:15:07.601: INFO: Created: latency-svc-czdgk
Dec  5 08:15:07.615: INFO: Got endpoints: latency-svc-r769h [330.61315ms]
Dec  5 08:15:07.634: INFO: Created: latency-svc-8t4mq
Dec  5 08:15:07.650: INFO: Created: latency-svc-6rlvr
Dec  5 08:15:07.659: INFO: Got endpoints: latency-svc-68w7k [354.491904ms]
Dec  5 08:15:07.675: INFO: Created: latency-svc-mvjc6
Dec  5 08:15:07.689: INFO: Created: latency-svc-gzlv7
Dec  5 08:15:07.705: INFO: Got endpoints: latency-svc-czdgk [384.022007ms]
Dec  5 08:15:07.715: INFO: Created: latency-svc-f2ghd
Dec  5 08:15:07.733: INFO: Created: latency-svc-gxfcr
Dec  5 08:15:07.744: INFO: Created: latency-svc-22t79
Dec  5 08:15:07.758: INFO: Created: latency-svc-ht4cf
Dec  5 08:15:07.760: INFO: Got endpoints: latency-svc-8t4mq [401.000356ms]
Dec  5 08:15:07.783: INFO: Created: latency-svc-zjgqk
Dec  5 08:15:07.793: INFO: Created: latency-svc-trq49
Dec  5 08:15:07.805: INFO: Got endpoints: latency-svc-6rlvr [433.780142ms]
Dec  5 08:15:07.812: INFO: Created: latency-svc-22s7k
Dec  5 08:15:07.823: INFO: Created: latency-svc-5bt7x
Dec  5 08:15:07.846: INFO: Created: latency-svc-9jmb8
Dec  5 08:15:07.858: INFO: Got endpoints: latency-svc-mvjc6 [455.512922ms]
Dec  5 08:15:07.867: INFO: Created: latency-svc-6dtln
Dec  5 08:15:07.909: INFO: Got endpoints: latency-svc-gzlv7 [495.176831ms]
Dec  5 08:15:07.919: INFO: Created: latency-svc-2kknv
Dec  5 08:15:07.935: INFO: Created: latency-svc-frqrh
Dec  5 08:15:07.957: INFO: Created: latency-svc-kx5b7
Dec  5 08:15:07.981: INFO: Got endpoints: latency-svc-f2ghd [543.902148ms]
Dec  5 08:15:07.991: INFO: Created: latency-svc-pljbn
Dec  5 08:15:08.010: INFO: Got endpoints: latency-svc-gxfcr [560.223208ms]
Dec  5 08:15:08.035: INFO: Created: latency-svc-rvqxf
Dec  5 08:15:08.042: INFO: Created: latency-svc-s5fj9
Dec  5 08:15:08.066: INFO: Got endpoints: latency-svc-22t79 [597.904146ms]
Dec  5 08:15:08.071: INFO: Created: latency-svc-8w2bl
Dec  5 08:15:08.095: INFO: Created: latency-svc-vn4fz
Dec  5 08:15:08.111: INFO: Got endpoints: latency-svc-ht4cf [624.773242ms]
Dec  5 08:15:08.138: INFO: Created: latency-svc-j7cmz
Dec  5 08:15:08.153: INFO: Got endpoints: latency-svc-zjgqk [641.536072ms]
Dec  5 08:15:08.177: INFO: Created: latency-svc-2mdf6
Dec  5 08:15:08.203: INFO: Got endpoints: latency-svc-trq49 [680.109346ms]
Dec  5 08:15:08.218: INFO: Created: latency-svc-bn9gj
Dec  5 08:15:08.255: INFO: Got endpoints: latency-svc-22s7k [704.564675ms]
Dec  5 08:15:08.285: INFO: Created: latency-svc-nbt56
Dec  5 08:15:08.302: INFO: Got endpoints: latency-svc-5bt7x [739.354669ms]
Dec  5 08:15:08.318: INFO: Created: latency-svc-kblfj
Dec  5 08:15:08.355: INFO: Got endpoints: latency-svc-9jmb8 [739.311463ms]
Dec  5 08:15:08.374: INFO: Created: latency-svc-mtbph
Dec  5 08:15:08.404: INFO: Got endpoints: latency-svc-6dtln [744.22357ms]
Dec  5 08:15:08.424: INFO: Created: latency-svc-9bl5x
Dec  5 08:15:08.456: INFO: Got endpoints: latency-svc-2kknv [751.381614ms]
Dec  5 08:15:08.476: INFO: Created: latency-svc-86fcd
Dec  5 08:15:08.505: INFO: Got endpoints: latency-svc-frqrh [744.959002ms]
Dec  5 08:15:08.529: INFO: Created: latency-svc-dpjch
Dec  5 08:15:08.553: INFO: Got endpoints: latency-svc-kx5b7 [748.226216ms]
Dec  5 08:15:08.574: INFO: Created: latency-svc-gmrqz
Dec  5 08:15:08.609: INFO: Got endpoints: latency-svc-pljbn [750.892816ms]
Dec  5 08:15:08.631: INFO: Created: latency-svc-q9lpv
Dec  5 08:15:08.654: INFO: Got endpoints: latency-svc-rvqxf [739.18631ms]
Dec  5 08:15:08.673: INFO: Created: latency-svc-szbzf
Dec  5 08:15:08.706: INFO: Got endpoints: latency-svc-s5fj9 [724.398693ms]
Dec  5 08:15:08.730: INFO: Created: latency-svc-drsrk
Dec  5 08:15:08.754: INFO: Got endpoints: latency-svc-8w2bl [744.162286ms]
Dec  5 08:15:08.821: INFO: Got endpoints: latency-svc-vn4fz [754.718348ms]
Dec  5 08:15:09.056: INFO: Got endpoints: latency-svc-2mdf6 [902.501677ms]
Dec  5 08:15:09.084: INFO: Created: latency-svc-mlfd8
Dec  5 08:15:09.090: INFO: Got endpoints: latency-svc-bn9gj [887.007816ms]
Dec  5 08:15:09.091: INFO: Got endpoints: latency-svc-j7cmz [979.382155ms]
Dec  5 08:15:09.099: INFO: Got endpoints: latency-svc-nbt56 [843.43542ms]
Dec  5 08:15:09.133: INFO: Got endpoints: latency-svc-mtbph [777.835214ms]
Dec  5 08:15:09.134: INFO: Got endpoints: latency-svc-kblfj [830.3823ms]
Dec  5 08:15:09.141: INFO: Created: latency-svc-wk6q7
Dec  5 08:15:09.157: INFO: Created: latency-svc-bk9kr
Dec  5 08:15:09.158: INFO: Got endpoints: latency-svc-9bl5x [754.142905ms]
Dec  5 08:15:09.174: INFO: Created: latency-svc-87kmh
Dec  5 08:15:09.188: INFO: Created: latency-svc-tszvt
Dec  5 08:15:09.202: INFO: Created: latency-svc-nt9r4
Dec  5 08:15:09.209: INFO: Got endpoints: latency-svc-86fcd [752.399063ms]
Dec  5 08:15:09.215: INFO: Created: latency-svc-gd7nf
Dec  5 08:15:09.229: INFO: Created: latency-svc-sn7sd
Dec  5 08:15:09.241: INFO: Created: latency-svc-n6j9q
Dec  5 08:15:09.251: INFO: Created: latency-svc-2z2kd
Dec  5 08:15:09.254: INFO: Got endpoints: latency-svc-dpjch [748.995233ms]
Dec  5 08:15:09.277: INFO: Created: latency-svc-hm8sx
Dec  5 08:15:09.303: INFO: Got endpoints: latency-svc-gmrqz [750.280759ms]
Dec  5 08:15:09.322: INFO: Created: latency-svc-zr24g
Dec  5 08:15:09.353: INFO: Got endpoints: latency-svc-q9lpv [743.557253ms]
Dec  5 08:15:09.369: INFO: Created: latency-svc-zvzcc
Dec  5 08:15:09.403: INFO: Got endpoints: latency-svc-szbzf [748.936415ms]
Dec  5 08:15:09.420: INFO: Created: latency-svc-qv272
Dec  5 08:15:09.457: INFO: Got endpoints: latency-svc-drsrk [750.874059ms]
Dec  5 08:15:09.486: INFO: Created: latency-svc-5tx7m
Dec  5 08:15:09.503: INFO: Got endpoints: latency-svc-mlfd8 [748.027922ms]
Dec  5 08:15:09.517: INFO: Created: latency-svc-kc2bq
Dec  5 08:15:09.555: INFO: Got endpoints: latency-svc-wk6q7 [734.293988ms]
Dec  5 08:15:09.572: INFO: Created: latency-svc-vdxng
Dec  5 08:15:09.603: INFO: Got endpoints: latency-svc-bk9kr [547.054302ms]
Dec  5 08:15:09.625: INFO: Created: latency-svc-l97k9
Dec  5 08:15:09.653: INFO: Got endpoints: latency-svc-87kmh [562.675755ms]
Dec  5 08:15:09.668: INFO: Created: latency-svc-hhzzj
Dec  5 08:15:09.704: INFO: Got endpoints: latency-svc-tszvt [613.052459ms]
Dec  5 08:15:09.736: INFO: Created: latency-svc-rs8wf
Dec  5 08:15:09.758: INFO: Got endpoints: latency-svc-nt9r4 [659.793597ms]
Dec  5 08:15:09.777: INFO: Created: latency-svc-b7kgn
Dec  5 08:15:09.812: INFO: Got endpoints: latency-svc-gd7nf [678.779835ms]
Dec  5 08:15:09.829: INFO: Created: latency-svc-z6mcd
Dec  5 08:15:09.852: INFO: Got endpoints: latency-svc-sn7sd [718.683063ms]
Dec  5 08:15:09.872: INFO: Created: latency-svc-tz222
Dec  5 08:15:09.904: INFO: Got endpoints: latency-svc-n6j9q [745.598742ms]
Dec  5 08:15:09.929: INFO: Created: latency-svc-6wpnt
Dec  5 08:15:09.956: INFO: Got endpoints: latency-svc-2z2kd [746.269882ms]
Dec  5 08:15:09.974: INFO: Created: latency-svc-fgknh
Dec  5 08:15:10.002: INFO: Got endpoints: latency-svc-hm8sx [748.194268ms]
Dec  5 08:15:10.028: INFO: Created: latency-svc-jxtc4
Dec  5 08:15:10.053: INFO: Got endpoints: latency-svc-zr24g [749.129022ms]
Dec  5 08:15:10.074: INFO: Created: latency-svc-zlrj5
Dec  5 08:15:10.104: INFO: Got endpoints: latency-svc-zvzcc [750.430677ms]
Dec  5 08:15:10.120: INFO: Created: latency-svc-x7vsv
Dec  5 08:15:10.152: INFO: Got endpoints: latency-svc-qv272 [748.789101ms]
Dec  5 08:15:10.170: INFO: Created: latency-svc-gfnj5
Dec  5 08:15:10.205: INFO: Got endpoints: latency-svc-5tx7m [747.168356ms]
Dec  5 08:15:10.226: INFO: Created: latency-svc-tx86v
Dec  5 08:15:10.252: INFO: Got endpoints: latency-svc-kc2bq [749.656148ms]
Dec  5 08:15:10.271: INFO: Created: latency-svc-fhknd
Dec  5 08:15:10.304: INFO: Got endpoints: latency-svc-vdxng [749.213579ms]
Dec  5 08:15:10.320: INFO: Created: latency-svc-6rn78
Dec  5 08:15:10.356: INFO: Got endpoints: latency-svc-l97k9 [752.579344ms]
Dec  5 08:15:10.372: INFO: Created: latency-svc-hsskp
Dec  5 08:15:10.403: INFO: Got endpoints: latency-svc-hhzzj [749.230715ms]
Dec  5 08:15:10.422: INFO: Created: latency-svc-7ggcv
Dec  5 08:15:10.454: INFO: Got endpoints: latency-svc-rs8wf [749.999822ms]
Dec  5 08:15:10.477: INFO: Created: latency-svc-q9565
Dec  5 08:15:10.503: INFO: Got endpoints: latency-svc-b7kgn [744.554758ms]
Dec  5 08:15:10.525: INFO: Created: latency-svc-sfd99
Dec  5 08:15:10.555: INFO: Got endpoints: latency-svc-z6mcd [743.535441ms]
Dec  5 08:15:10.583: INFO: Created: latency-svc-2szwd
Dec  5 08:15:10.602: INFO: Got endpoints: latency-svc-tz222 [749.981551ms]
Dec  5 08:15:10.624: INFO: Created: latency-svc-jgvrc
Dec  5 08:15:10.662: INFO: Got endpoints: latency-svc-6wpnt [757.315731ms]
Dec  5 08:15:10.685: INFO: Created: latency-svc-92qwz
Dec  5 08:15:10.711: INFO: Got endpoints: latency-svc-fgknh [754.1979ms]
Dec  5 08:15:10.755: INFO: Got endpoints: latency-svc-jxtc4 [751.714311ms]
Dec  5 08:15:10.824: INFO: Created: latency-svc-tdmvq
Dec  5 08:15:10.825: INFO: Got endpoints: latency-svc-zlrj5 [771.788559ms]
Dec  5 08:15:10.837: INFO: Created: latency-svc-pvxj2
Dec  5 08:15:10.879: INFO: Got endpoints: latency-svc-x7vsv [774.922617ms]
Dec  5 08:15:10.904: INFO: Got endpoints: latency-svc-gfnj5 [750.912193ms]
Dec  5 08:15:10.904: INFO: Created: latency-svc-bp2hp
Dec  5 08:15:10.946: INFO: Created: latency-svc-9ks54
Dec  5 08:15:10.957: INFO: Got endpoints: latency-svc-tx86v [752.742652ms]
Dec  5 08:15:10.962: INFO: Created: latency-svc-d9hv4
Dec  5 08:15:11.004: INFO: Got endpoints: latency-svc-fhknd [750.697879ms]
Dec  5 08:15:11.008: INFO: Created: latency-svc-9xtnc
Dec  5 08:15:11.029: INFO: Created: latency-svc-pkzth
Dec  5 08:15:11.057: INFO: Got endpoints: latency-svc-6rn78 [752.35788ms]
Dec  5 08:15:11.105: INFO: Created: latency-svc-x9fkg
Dec  5 08:15:11.116: INFO: Got endpoints: latency-svc-hsskp [759.89251ms]
Dec  5 08:15:11.155: INFO: Got endpoints: latency-svc-7ggcv [751.470274ms]
Dec  5 08:15:11.168: INFO: Created: latency-svc-lxl44
Dec  5 08:15:11.181: INFO: Created: latency-svc-vh4g6
Dec  5 08:15:11.205: INFO: Got endpoints: latency-svc-q9565 [749.890667ms]
Dec  5 08:15:11.221: INFO: Created: latency-svc-twhvt
Dec  5 08:15:11.254: INFO: Got endpoints: latency-svc-sfd99 [750.339212ms]
Dec  5 08:15:11.275: INFO: Created: latency-svc-sb9q2
Dec  5 08:15:11.306: INFO: Got endpoints: latency-svc-2szwd [750.372999ms]
Dec  5 08:15:11.323: INFO: Created: latency-svc-r4j4h
Dec  5 08:15:11.353: INFO: Got endpoints: latency-svc-jgvrc [750.139332ms]
Dec  5 08:15:11.368: INFO: Created: latency-svc-vvp5h
Dec  5 08:15:11.404: INFO: Got endpoints: latency-svc-92qwz [741.158084ms]
Dec  5 08:15:11.423: INFO: Created: latency-svc-bfwxh
Dec  5 08:15:11.457: INFO: Got endpoints: latency-svc-tdmvq [745.896946ms]
Dec  5 08:15:11.484: INFO: Created: latency-svc-grcp6
Dec  5 08:15:11.506: INFO: Got endpoints: latency-svc-pvxj2 [751.426893ms]
Dec  5 08:15:11.551: INFO: Created: latency-svc-ds4fn
Dec  5 08:15:11.557: INFO: Got endpoints: latency-svc-bp2hp [731.716128ms]
Dec  5 08:15:11.576: INFO: Created: latency-svc-4kkk5
Dec  5 08:15:11.603: INFO: Got endpoints: latency-svc-9ks54 [722.877977ms]
Dec  5 08:15:11.618: INFO: Created: latency-svc-7fkhs
Dec  5 08:15:11.654: INFO: Got endpoints: latency-svc-d9hv4 [749.578935ms]
Dec  5 08:15:11.674: INFO: Created: latency-svc-qct6p
Dec  5 08:15:11.704: INFO: Got endpoints: latency-svc-9xtnc [746.433541ms]
Dec  5 08:15:11.723: INFO: Created: latency-svc-j757s
Dec  5 08:15:11.754: INFO: Got endpoints: latency-svc-pkzth [750.133122ms]
Dec  5 08:15:11.787: INFO: Created: latency-svc-8lcgm
Dec  5 08:15:11.803: INFO: Got endpoints: latency-svc-x9fkg [746.24296ms]
Dec  5 08:15:11.821: INFO: Created: latency-svc-qpp4d
Dec  5 08:15:11.855: INFO: Got endpoints: latency-svc-lxl44 [739.036398ms]
Dec  5 08:15:11.870: INFO: Created: latency-svc-ksjc7
Dec  5 08:15:11.903: INFO: Got endpoints: latency-svc-vh4g6 [747.940526ms]
Dec  5 08:15:11.917: INFO: Created: latency-svc-t4bxd
Dec  5 08:15:11.953: INFO: Got endpoints: latency-svc-twhvt [747.945046ms]
Dec  5 08:15:11.969: INFO: Created: latency-svc-c69p9
Dec  5 08:15:12.002: INFO: Got endpoints: latency-svc-sb9q2 [746.933906ms]
Dec  5 08:15:12.016: INFO: Created: latency-svc-xkkzl
Dec  5 08:15:12.053: INFO: Got endpoints: latency-svc-r4j4h [746.487986ms]
Dec  5 08:15:12.077: INFO: Created: latency-svc-8gwn8
Dec  5 08:15:12.104: INFO: Got endpoints: latency-svc-vvp5h [751.108436ms]
Dec  5 08:15:12.120: INFO: Created: latency-svc-pnhhv
Dec  5 08:15:12.153: INFO: Got endpoints: latency-svc-bfwxh [749.200744ms]
Dec  5 08:15:12.167: INFO: Created: latency-svc-842gl
Dec  5 08:15:12.203: INFO: Got endpoints: latency-svc-grcp6 [745.663731ms]
Dec  5 08:15:12.219: INFO: Created: latency-svc-q4h8h
Dec  5 08:15:12.252: INFO: Got endpoints: latency-svc-ds4fn [745.766207ms]
Dec  5 08:15:12.271: INFO: Created: latency-svc-v5v22
Dec  5 08:15:12.304: INFO: Got endpoints: latency-svc-4kkk5 [746.694374ms]
Dec  5 08:15:12.327: INFO: Created: latency-svc-k9wnc
Dec  5 08:15:12.354: INFO: Got endpoints: latency-svc-7fkhs [750.884342ms]
Dec  5 08:15:12.375: INFO: Created: latency-svc-jvcg4
Dec  5 08:15:12.405: INFO: Got endpoints: latency-svc-qct6p [751.729302ms]
Dec  5 08:15:12.431: INFO: Created: latency-svc-rmbzv
Dec  5 08:15:12.453: INFO: Got endpoints: latency-svc-j757s [748.649725ms]
Dec  5 08:15:12.479: INFO: Created: latency-svc-b22xm
Dec  5 08:15:12.505: INFO: Got endpoints: latency-svc-8lcgm [751.009608ms]
Dec  5 08:15:12.532: INFO: Created: latency-svc-zfn97
Dec  5 08:15:12.553: INFO: Got endpoints: latency-svc-qpp4d [749.953107ms]
Dec  5 08:15:12.570: INFO: Created: latency-svc-b2pqq
Dec  5 08:15:12.604: INFO: Got endpoints: latency-svc-ksjc7 [748.663296ms]
Dec  5 08:15:12.632: INFO: Created: latency-svc-slln5
Dec  5 08:15:12.652: INFO: Got endpoints: latency-svc-t4bxd [749.282721ms]
Dec  5 08:15:12.670: INFO: Created: latency-svc-fdstx
Dec  5 08:15:12.703: INFO: Got endpoints: latency-svc-c69p9 [749.726415ms]
Dec  5 08:15:12.727: INFO: Created: latency-svc-rmkfq
Dec  5 08:15:12.753: INFO: Got endpoints: latency-svc-xkkzl [750.790794ms]
Dec  5 08:15:12.771: INFO: Created: latency-svc-d4rvv
Dec  5 08:15:12.803: INFO: Got endpoints: latency-svc-8gwn8 [750.343477ms]
Dec  5 08:15:12.847: INFO: Created: latency-svc-9tm4j
Dec  5 08:15:12.855: INFO: Got endpoints: latency-svc-pnhhv [751.260614ms]
Dec  5 08:15:12.891: INFO: Created: latency-svc-jkm57
Dec  5 08:15:12.904: INFO: Got endpoints: latency-svc-842gl [751.460347ms]
Dec  5 08:15:12.936: INFO: Created: latency-svc-htjcp
Dec  5 08:15:12.953: INFO: Got endpoints: latency-svc-q4h8h [750.814106ms]
Dec  5 08:15:12.967: INFO: Created: latency-svc-7nqx8
Dec  5 08:15:13.003: INFO: Got endpoints: latency-svc-v5v22 [749.887559ms]
Dec  5 08:15:13.022: INFO: Created: latency-svc-4xpvx
Dec  5 08:15:13.052: INFO: Got endpoints: latency-svc-k9wnc [747.748144ms]
Dec  5 08:15:13.073: INFO: Created: latency-svc-r8n9w
Dec  5 08:15:13.103: INFO: Got endpoints: latency-svc-jvcg4 [745.277564ms]
Dec  5 08:15:13.119: INFO: Created: latency-svc-l68rw
Dec  5 08:15:13.162: INFO: Got endpoints: latency-svc-rmbzv [755.639907ms]
Dec  5 08:15:13.189: INFO: Created: latency-svc-zlwjb
Dec  5 08:15:13.202: INFO: Got endpoints: latency-svc-b22xm [748.67752ms]
Dec  5 08:15:13.215: INFO: Created: latency-svc-lmhv2
Dec  5 08:15:13.253: INFO: Got endpoints: latency-svc-zfn97 [747.590484ms]
Dec  5 08:15:13.296: INFO: Created: latency-svc-6g9s6
Dec  5 08:15:13.308: INFO: Got endpoints: latency-svc-b2pqq [755.007624ms]
Dec  5 08:15:13.320: INFO: Created: latency-svc-qqgkw
Dec  5 08:15:13.354: INFO: Got endpoints: latency-svc-slln5 [749.662251ms]
Dec  5 08:15:13.373: INFO: Created: latency-svc-fblq7
Dec  5 08:15:13.406: INFO: Got endpoints: latency-svc-fdstx [753.947935ms]
Dec  5 08:15:13.422: INFO: Created: latency-svc-5fjcv
Dec  5 08:15:13.452: INFO: Got endpoints: latency-svc-rmkfq [749.118534ms]
Dec  5 08:15:13.475: INFO: Created: latency-svc-lj94h
Dec  5 08:15:13.503: INFO: Got endpoints: latency-svc-d4rvv [749.794114ms]
Dec  5 08:15:13.531: INFO: Created: latency-svc-lt5xn
Dec  5 08:15:13.552: INFO: Got endpoints: latency-svc-9tm4j [748.723612ms]
Dec  5 08:15:13.581: INFO: Created: latency-svc-jl24w
Dec  5 08:15:13.602: INFO: Got endpoints: latency-svc-jkm57 [746.570239ms]
Dec  5 08:15:13.622: INFO: Created: latency-svc-vgd85
Dec  5 08:15:13.656: INFO: Got endpoints: latency-svc-htjcp [750.889739ms]
Dec  5 08:15:13.674: INFO: Created: latency-svc-2tm2n
Dec  5 08:15:13.705: INFO: Got endpoints: latency-svc-7nqx8 [750.900681ms]
Dec  5 08:15:13.731: INFO: Created: latency-svc-tq95h
Dec  5 08:15:13.752: INFO: Got endpoints: latency-svc-4xpvx [749.285242ms]
Dec  5 08:15:13.768: INFO: Created: latency-svc-tjn6v
Dec  5 08:15:13.808: INFO: Got endpoints: latency-svc-r8n9w [754.996333ms]
Dec  5 08:15:13.826: INFO: Created: latency-svc-jbqdt
Dec  5 08:15:13.854: INFO: Got endpoints: latency-svc-l68rw [750.98494ms]
Dec  5 08:15:13.874: INFO: Created: latency-svc-fxt9q
Dec  5 08:15:13.904: INFO: Got endpoints: latency-svc-zlwjb [742.320211ms]
Dec  5 08:15:13.924: INFO: Created: latency-svc-5gzbr
Dec  5 08:15:13.952: INFO: Got endpoints: latency-svc-lmhv2 [750.071883ms]
Dec  5 08:15:13.971: INFO: Created: latency-svc-8hdsr
Dec  5 08:15:14.003: INFO: Got endpoints: latency-svc-6g9s6 [749.226106ms]
Dec  5 08:15:14.040: INFO: Created: latency-svc-w6nvp
Dec  5 08:15:14.055: INFO: Got endpoints: latency-svc-qqgkw [745.747394ms]
Dec  5 08:15:14.184: INFO: Created: latency-svc-kltqb
Dec  5 08:15:14.188: INFO: Got endpoints: latency-svc-5fjcv [781.857618ms]
Dec  5 08:15:14.189: INFO: Got endpoints: latency-svc-fblq7 [834.623813ms]
Dec  5 08:15:14.235: INFO: Got endpoints: latency-svc-lj94h [782.639467ms]
Dec  5 08:15:14.276: INFO: Got endpoints: latency-svc-lt5xn [772.340156ms]
Dec  5 08:15:14.331: INFO: Created: latency-svc-ktthw
Dec  5 08:15:14.355: INFO: Got endpoints: latency-svc-jl24w [801.60089ms]
Dec  5 08:15:14.356: INFO: Got endpoints: latency-svc-vgd85 [753.1682ms]
Dec  5 08:15:14.400: INFO: Created: latency-svc-c2njg
Dec  5 08:15:14.404: INFO: Got endpoints: latency-svc-2tm2n [748.496652ms]
Dec  5 08:15:14.416: INFO: Created: latency-svc-kp6rj
Dec  5 08:15:14.434: INFO: Created: latency-svc-mnx8x
Dec  5 08:15:14.447: INFO: Created: latency-svc-hqjsf
Dec  5 08:15:14.457: INFO: Created: latency-svc-pdz5x
Dec  5 08:15:14.458: INFO: Got endpoints: latency-svc-tq95h [752.724174ms]
Dec  5 08:15:14.505: INFO: Got endpoints: latency-svc-tjn6v [752.757671ms]
Dec  5 08:15:14.560: INFO: Got endpoints: latency-svc-jbqdt [752.075998ms]
Dec  5 08:15:14.605: INFO: Got endpoints: latency-svc-fxt9q [750.398057ms]
Dec  5 08:15:14.656: INFO: Got endpoints: latency-svc-5gzbr [751.360461ms]
Dec  5 08:15:14.703: INFO: Got endpoints: latency-svc-8hdsr [750.122557ms]
Dec  5 08:15:14.756: INFO: Got endpoints: latency-svc-w6nvp [753.105321ms]
Dec  5 08:15:14.806: INFO: Got endpoints: latency-svc-kltqb [750.875148ms]
Dec  5 08:15:14.854: INFO: Got endpoints: latency-svc-ktthw [665.402073ms]
Dec  5 08:15:14.905: INFO: Got endpoints: latency-svc-c2njg [716.696713ms]
Dec  5 08:15:14.954: INFO: Got endpoints: latency-svc-kp6rj [718.240902ms]
Dec  5 08:15:15.006: INFO: Got endpoints: latency-svc-mnx8x [730.292995ms]
Dec  5 08:15:15.055: INFO: Got endpoints: latency-svc-hqjsf [698.085823ms]
Dec  5 08:15:15.105: INFO: Got endpoints: latency-svc-pdz5x [749.904518ms]
Dec  5 08:15:15.105: INFO: Latencies: [33.402211ms 51.7091ms 76.74366ms 95.281008ms 110.886354ms 138.726432ms 148.303144ms 174.132164ms 196.52873ms 218.698979ms 236.68603ms 262.383519ms 272.347167ms 279.378199ms 284.623322ms 284.861352ms 288.899101ms 290.388005ms 291.518094ms 294.221825ms 295.753226ms 295.809986ms 296.800434ms 296.836137ms 300.346776ms 300.848187ms 302.887198ms 302.919455ms 303.835541ms 305.611362ms 306.298598ms 306.937884ms 306.98263ms 307.673731ms 307.831664ms 308.742269ms 309.279122ms 313.765278ms 314.056429ms 315.650409ms 318.300549ms 322.463883ms 322.692524ms 324.374761ms 324.749421ms 329.951973ms 330.61315ms 332.145308ms 339.99725ms 344.953853ms 354.491904ms 384.022007ms 401.000356ms 433.780142ms 455.512922ms 495.176831ms 543.902148ms 547.054302ms 560.223208ms 562.675755ms 597.904146ms 613.052459ms 624.773242ms 641.536072ms 659.793597ms 665.402073ms 678.779835ms 680.109346ms 698.085823ms 704.564675ms 716.696713ms 718.240902ms 718.683063ms 722.877977ms 724.398693ms 730.292995ms 731.716128ms 734.293988ms 739.036398ms 739.18631ms 739.311463ms 739.354669ms 741.158084ms 742.320211ms 743.535441ms 743.557253ms 744.162286ms 744.22357ms 744.554758ms 744.959002ms 745.277564ms 745.598742ms 745.663731ms 745.747394ms 745.766207ms 745.896946ms 746.24296ms 746.269882ms 746.433541ms 746.487986ms 746.570239ms 746.694374ms 746.933906ms 747.168356ms 747.590484ms 747.748144ms 747.940526ms 747.945046ms 748.027922ms 748.194268ms 748.226216ms 748.496652ms 748.649725ms 748.663296ms 748.67752ms 748.723612ms 748.789101ms 748.936415ms 748.995233ms 749.118534ms 749.129022ms 749.200744ms 749.213579ms 749.226106ms 749.230715ms 749.282721ms 749.285242ms 749.578935ms 749.656148ms 749.662251ms 749.726415ms 749.794114ms 749.887559ms 749.890667ms 749.904518ms 749.953107ms 749.981551ms 749.999822ms 750.071883ms 750.122557ms 750.133122ms 750.139332ms 750.280759ms 750.339212ms 750.343477ms 750.372999ms 750.398057ms 750.430677ms 750.697879ms 750.790794ms 750.814106ms 750.874059ms 750.875148ms 750.884342ms 750.889739ms 750.892816ms 750.900681ms 750.912193ms 750.98494ms 751.009608ms 751.108436ms 751.260614ms 751.360461ms 751.381614ms 751.426893ms 751.460347ms 751.470274ms 751.714311ms 751.729302ms 752.075998ms 752.35788ms 752.399063ms 752.579344ms 752.724174ms 752.742652ms 752.757671ms 753.105321ms 753.1682ms 753.947935ms 754.142905ms 754.1979ms 754.718348ms 754.996333ms 755.007624ms 755.639907ms 757.315731ms 759.89251ms 771.788559ms 772.340156ms 774.922617ms 777.835214ms 781.857618ms 782.639467ms 801.60089ms 830.3823ms 834.623813ms 843.43542ms 887.007816ms 902.501677ms 979.382155ms]
Dec  5 08:15:15.106: INFO: 50 %ile: 746.570239ms
Dec  5 08:15:15.106: INFO: 90 %ile: 754.1979ms
Dec  5 08:15:15.110: INFO: 99 %ile: 902.501677ms
Dec  5 08:15:15.110: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:15:15.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-5603" for this suite.
Dec  5 08:15:29.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:15:29.254: INFO: namespace svc-latency-5603 deletion completed in 14.138065869s

â€¢ [SLOW TEST:24.921 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:15:29.258: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:15:29.354: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec  5 08:15:31.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 create -f -'
Dec  5 08:15:32.103: INFO: stderr: ""
Dec  5 08:15:32.103: INFO: stdout: "e2e-test-crd-publish-openapi-7332-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  5 08:15:32.103: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 delete e2e-test-crd-publish-openapi-7332-crds test-foo'
Dec  5 08:15:32.175: INFO: stderr: ""
Dec  5 08:15:32.175: INFO: stdout: "e2e-test-crd-publish-openapi-7332-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec  5 08:15:32.175: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 apply -f -'
Dec  5 08:15:32.306: INFO: stderr: ""
Dec  5 08:15:32.306: INFO: stdout: "e2e-test-crd-publish-openapi-7332-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  5 08:15:32.306: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 delete e2e-test-crd-publish-openapi-7332-crds test-foo'
Dec  5 08:15:32.376: INFO: stderr: ""
Dec  5 08:15:32.376: INFO: stdout: "e2e-test-crd-publish-openapi-7332-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec  5 08:15:32.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 create -f -'
Dec  5 08:15:32.492: INFO: rc: 1
Dec  5 08:15:32.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 apply -f -'
Dec  5 08:15:32.609: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec  5 08:15:32.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 create -f -'
Dec  5 08:15:32.727: INFO: rc: 1
Dec  5 08:15:32.727: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=crd-publish-openapi-6873 apply -f -'
Dec  5 08:15:32.861: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec  5 08:15:32.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-7332-crds'
Dec  5 08:15:32.995: INFO: stderr: ""
Dec  5 08:15:32.995: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7332-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec  5 08:15:32.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-7332-crds.metadata'
Dec  5 08:15:33.129: INFO: stderr: ""
Dec  5 08:15:33.129: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7332-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec  5 08:15:33.129: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-7332-crds.spec'
Dec  5 08:15:33.255: INFO: stderr: ""
Dec  5 08:15:33.255: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7332-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec  5 08:15:33.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-7332-crds.spec.bars'
Dec  5 08:15:33.398: INFO: stderr: ""
Dec  5 08:15:33.398: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7332-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec  5 08:15:33.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 explain e2e-test-crd-publish-openapi-7332-crds.spec.bars2'
Dec  5 08:15:33.526: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:15:35.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6873" for this suite.
Dec  5 08:15:41.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:15:41.509: INFO: namespace crd-publish-openapi-6873 deletion completed in 6.135385033s

â€¢ [SLOW TEST:12.251 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:15:41.511: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec  5 08:15:41.575: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  5 08:16:41.602: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:16:41.612: INFO: Starting informer...
STEP: Starting pods...
Dec  5 08:16:41.835: INFO: Pod1 is running on worknode. Tainting Node
Dec  5 08:16:45.881: INFO: Pod2 is running on worknode. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec  5 08:16:55.715: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec  5 08:17:15.723: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:17:15.749: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9313" for this suite.
Dec  5 08:17:21.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:17:21.882: INFO: namespace taint-multiple-pods-9313 deletion completed in 6.129054387s

â€¢ [SLOW TEST:100.371 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:17:21.883: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  5 08:17:21.924: INFO: Waiting up to 5m0s for pod "downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060" in namespace "downward-api-5799" to be "success or failure"
Dec  5 08:17:21.928: INFO: Pod "downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060": Phase="Pending", Reason="", readiness=false. Elapsed: 4.071123ms
Dec  5 08:17:23.933: INFO: Pod "downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008721345s
Dec  5 08:17:25.940: INFO: Pod "downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015357115s
STEP: Saw pod success
Dec  5 08:17:25.940: INFO: Pod "downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060" satisfied condition "success or failure"
Dec  5 08:17:25.944: INFO: Trying to get logs from node worknode pod downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060 container dapi-container: <nil>
STEP: delete the pod
Dec  5 08:17:26.084: INFO: Waiting for pod downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060 to disappear
Dec  5 08:17:26.094: INFO: Pod downward-api-9fd348d4-66e3-4b19-8ba8-db0b76bfb060 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:17:26.094: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5799" for this suite.
Dec  5 08:17:32.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:17:32.224: INFO: namespace downward-api-5799 deletion completed in 6.118827531s

â€¢ [SLOW TEST:10.341 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:17:32.224: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  5 08:17:34.296: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:17:34.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8802" for this suite.
Dec  5 08:17:40.350: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:17:40.442: INFO: namespace container-runtime-8802 deletion completed in 6.109322705s

â€¢ [SLOW TEST:8.218 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:17:40.444: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec  5 08:17:40.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-6217 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec  5 08:17:40.569: INFO: stderr: ""
Dec  5 08:17:40.569: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec  5 08:17:40.569: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec  5 08:17:40.569: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-6217" to be "running and ready, or succeeded"
Dec  5 08:17:40.574: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.467449ms
Dec  5 08:17:42.577: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.00772616s
Dec  5 08:17:42.577: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec  5 08:17:42.577: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec  5 08:17:42.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217'
Dec  5 08:17:42.659: INFO: stderr: ""
Dec  5 08:17:42.659: INFO: stdout: "I1205 08:17:41.549773       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/g9nw 587\nI1205 08:17:41.752016       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/fcl 325\nI1205 08:17:41.950889       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/77jm 397\nI1205 08:17:42.151494       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/865l 482\nI1205 08:17:42.349954       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/qptj 573\nI1205 08:17:42.549996       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/7vbh 393\n"
STEP: limiting log lines
Dec  5 08:17:42.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217 --tail=1'
Dec  5 08:17:42.740: INFO: stderr: ""
Dec  5 08:17:42.740: INFO: stdout: "I1205 08:17:42.549996       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/7vbh 393\n"
STEP: limiting log bytes
Dec  5 08:17:42.740: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217 --limit-bytes=1'
Dec  5 08:17:42.808: INFO: stderr: ""
Dec  5 08:17:42.808: INFO: stdout: "I"
STEP: exposing timestamps
Dec  5 08:17:42.808: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217 --tail=1 --timestamps'
Dec  5 08:17:42.891: INFO: stderr: ""
Dec  5 08:17:42.891: INFO: stdout: "2019-12-05T08:17:42.750153747Z I1205 08:17:42.749981       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/6kbc 546\n"
STEP: restricting to a time range
Dec  5 08:17:45.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217 --since=1s'
Dec  5 08:17:45.480: INFO: stderr: ""
Dec  5 08:17:45.480: INFO: stdout: "I1205 08:17:44.550217       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/vsq 445\nI1205 08:17:44.750830       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/pgg 582\nI1205 08:17:44.950739       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/42dt 343\nI1205 08:17:45.150449       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/99z2 441\nI1205 08:17:45.352261       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/9cd 269\n"
Dec  5 08:17:45.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 logs logs-generator logs-generator --namespace=kubectl-6217 --since=24h'
Dec  5 08:17:45.556: INFO: stderr: ""
Dec  5 08:17:45.556: INFO: stdout: "I1205 08:17:41.549773       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/g9nw 587\nI1205 08:17:41.752016       1 logs_generator.go:76] 1 GET /api/v1/namespaces/kube-system/pods/fcl 325\nI1205 08:17:41.950889       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/77jm 397\nI1205 08:17:42.151494       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/ns/pods/865l 482\nI1205 08:17:42.349954       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/qptj 573\nI1205 08:17:42.549996       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/7vbh 393\nI1205 08:17:42.749981       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/6kbc 546\nI1205 08:17:42.950789       1 logs_generator.go:76] 7 PUT /api/v1/namespaces/kube-system/pods/wkw5 504\nI1205 08:17:43.150536       1 logs_generator.go:76] 8 GET /api/v1/namespaces/kube-system/pods/dz2n 498\nI1205 08:17:43.350217       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/sztg 382\nI1205 08:17:43.555100       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/kube-system/pods/cdm 353\nI1205 08:17:43.750888       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/7k7p 386\nI1205 08:17:43.950130       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/zsjg 224\nI1205 08:17:44.151574       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/wwc 299\nI1205 08:17:44.350981       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/ns/pods/brbz 241\nI1205 08:17:44.550217       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/vsq 445\nI1205 08:17:44.750830       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/ns/pods/pgg 582\nI1205 08:17:44.950739       1 logs_generator.go:76] 17 POST /api/v1/namespaces/default/pods/42dt 343\nI1205 08:17:45.150449       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/99z2 441\nI1205 08:17:45.352261       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/ns/pods/9cd 269\nI1205 08:17:45.550408       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/gvh 277\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec  5 08:17:45.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete pod logs-generator --namespace=kubectl-6217'
Dec  5 08:17:55.732: INFO: stderr: ""
Dec  5 08:17:55.733: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:17:55.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6217" for this suite.
Dec  5 08:18:01.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:18:01.840: INFO: namespace kubectl-6217 deletion completed in 6.102777543s

â€¢ [SLOW TEST:21.396 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:18:01.841: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 08:18:05.965: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:05.985: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 08:18:07.986: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:07.989: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 08:18:09.986: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:09.990: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 08:18:11.994: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:11.997: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 08:18:13.987: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:13.991: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  5 08:18:15.986: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  5 08:18:15.993: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:18:16.010: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9632" for this suite.
Dec  5 08:18:28.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:18:28.126: INFO: namespace container-lifecycle-hook-9632 deletion completed in 12.113683379s

â€¢ [SLOW TEST:26.285 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:18:28.127: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-06a3c60f-88bf-4a6a-b726-431fb2b22054 in namespace container-probe-309
Dec  5 08:18:30.185: INFO: Started pod liveness-06a3c60f-88bf-4a6a-b726-431fb2b22054 in namespace container-probe-309
STEP: checking the pod's current state and verifying that restartCount is present
Dec  5 08:18:30.188: INFO: Initial restart count of pod liveness-06a3c60f-88bf-4a6a-b726-431fb2b22054 is 0
Dec  5 08:18:48.276: INFO: Restart count of pod container-probe-309/liveness-06a3c60f-88bf-4a6a-b726-431fb2b22054 is now 1 (18.088360885s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:18:48.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-309" for this suite.
Dec  5 08:18:54.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:18:54.408: INFO: namespace container-probe-309 deletion completed in 6.102448102s

â€¢ [SLOW TEST:26.281 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:18:54.408: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 08:18:54.449: INFO: Waiting up to 5m0s for pod "pod-dfbe2b98-973c-4585-ba13-314105c6083e" in namespace "emptydir-3673" to be "success or failure"
Dec  5 08:18:54.457: INFO: Pod "pod-dfbe2b98-973c-4585-ba13-314105c6083e": Phase="Pending", Reason="", readiness=false. Elapsed: 8.101568ms
Dec  5 08:18:56.461: INFO: Pod "pod-dfbe2b98-973c-4585-ba13-314105c6083e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011687997s
STEP: Saw pod success
Dec  5 08:18:56.461: INFO: Pod "pod-dfbe2b98-973c-4585-ba13-314105c6083e" satisfied condition "success or failure"
Dec  5 08:18:56.464: INFO: Trying to get logs from node worknode pod pod-dfbe2b98-973c-4585-ba13-314105c6083e container test-container: <nil>
STEP: delete the pod
Dec  5 08:18:56.504: INFO: Waiting for pod pod-dfbe2b98-973c-4585-ba13-314105c6083e to disappear
Dec  5 08:18:56.511: INFO: Pod pod-dfbe2b98-973c-4585-ba13-314105c6083e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:18:56.511: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3673" for this suite.
Dec  5 08:19:02.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:19:02.619: INFO: namespace emptydir-3673 deletion completed in 6.103284807s

â€¢ [SLOW TEST:8.211 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:19:02.621: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  5 08:19:02.656: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  5 08:19:02.665: INFO: Waiting for terminating namespaces to be deleted...
Dec  5 08:19:02.668: INFO: 
Logging pods the kubelet thinks is on node allinone before test
Dec  5 08:19:02.695: INFO: calico-kube-controllers-55754f75c-g2l8q from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  5 08:19:02.695: INFO: etcd-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container etcd ready: true, restart count 0
Dec  5 08:19:02.695: INFO: kube-scheduler-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container kube-scheduler ready: true, restart count 0
Dec  5 08:19:02.695: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:19:02.695: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 08:19:02.695: INFO: coredns-5644d7b6d9-5jdzn from kube-system started at 2019-12-05 06:35:26 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:19:02.695: INFO: kube-apiserver-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container kube-apiserver ready: true, restart count 0
Dec  5 08:19:02.695: INFO: calico-node-wt92j from kube-system started at 2019-12-05 06:35:16 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:19:02.695: INFO: kube-proxy-4g9tm from kube-system started at 2019-12-05 06:34:04 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:19:02.695: INFO: kube-controller-manager-allinone from kube-system started at 2019-12-05 06:33:47 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container kube-controller-manager ready: true, restart count 0
Dec  5 08:19:02.695: INFO: coredns-5644d7b6d9-8vk79 from kube-system started at 2019-12-05 06:35:24 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.695: INFO: 	Container coredns ready: true, restart count 0
Dec  5 08:19:02.695: INFO: 
Logging pods the kubelet thinks is on node worknode before test
Dec  5 08:19:02.700: INFO: sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:19:02.700: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec  5 08:19:02.700: INFO: 	Container systemd-logs ready: true, restart count 0
Dec  5 08:19:02.700: INFO: calico-node-pnldh from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.700: INFO: 	Container calico-node ready: true, restart count 0
Dec  5 08:19:02.700: INFO: kube-proxy-x5czv from kube-system started at 2019-12-05 06:36:55 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.700: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  5 08:19:02.700: INFO: sonobuoy from sonobuoy started at 2019-12-05 06:49:53 +0000 UTC (1 container statuses recorded)
Dec  5 08:19:02.700: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec  5 08:19:02.700: INFO: sonobuoy-e2e-job-6da6843aacc74c61 from sonobuoy started at 2019-12-05 06:49:54 +0000 UTC (2 container statuses recorded)
Dec  5 08:19:02.700: INFO: 	Container e2e ready: true, restart count 0
Dec  5 08:19:02.700: INFO: 	Container sonobuoy-worker ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node allinone
STEP: verifying the node has the label node worknode
Dec  5 08:19:02.730: INFO: Pod calico-kube-controllers-55754f75c-g2l8q requesting resource cpu=0m on Node allinone
Dec  5 08:19:02.730: INFO: Pod calico-node-pnldh requesting resource cpu=250m on Node worknode
Dec  5 08:19:02.730: INFO: Pod calico-node-wt92j requesting resource cpu=250m on Node allinone
Dec  5 08:19:02.730: INFO: Pod coredns-5644d7b6d9-5jdzn requesting resource cpu=100m on Node allinone
Dec  5 08:19:02.730: INFO: Pod coredns-5644d7b6d9-8vk79 requesting resource cpu=100m on Node allinone
Dec  5 08:19:02.730: INFO: Pod etcd-allinone requesting resource cpu=0m on Node allinone
Dec  5 08:19:02.730: INFO: Pod kube-apiserver-allinone requesting resource cpu=250m on Node allinone
Dec  5 08:19:02.730: INFO: Pod kube-controller-manager-allinone requesting resource cpu=200m on Node allinone
Dec  5 08:19:02.730: INFO: Pod kube-proxy-4g9tm requesting resource cpu=0m on Node allinone
Dec  5 08:19:02.730: INFO: Pod kube-proxy-x5czv requesting resource cpu=0m on Node worknode
Dec  5 08:19:02.730: INFO: Pod kube-scheduler-allinone requesting resource cpu=100m on Node allinone
Dec  5 08:19:02.730: INFO: Pod sonobuoy requesting resource cpu=0m on Node worknode
Dec  5 08:19:02.730: INFO: Pod sonobuoy-e2e-job-6da6843aacc74c61 requesting resource cpu=0m on Node worknode
Dec  5 08:19:02.730: INFO: Pod sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-6mpmf requesting resource cpu=0m on Node worknode
Dec  5 08:19:02.730: INFO: Pod sonobuoy-systemd-logs-daemon-set-1c697353d3c04b86-l8wzh requesting resource cpu=0m on Node allinone
STEP: Starting Pods to consume most of the cluster CPU.
Dec  5 08:19:02.730: INFO: Creating a pod which consumes cpu=700m on Node allinone
Dec  5 08:19:02.737: INFO: Creating a pod which consumes cpu=1225m on Node worknode
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a.15dd6bc5febdebd8], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3718/filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a to worknode]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a.15dd6bc64475af49], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a.15dd6bc64702157e], Reason = [Created], Message = [Created container filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a.15dd6bc659911592], Reason = [Started], Message = [Started container filler-pod-26ae9960-4e2a-431e-94e9-018ded7bc68a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca.15dd6bc5fd4a70bb], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3718/filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca to allinone]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca.15dd6bc64a425b92], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca.15dd6bc64d8baaf2], Reason = [Created], Message = [Created container filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca.15dd6bc65b387cdc], Reason = [Started], Message = [Started container filler-pod-944ddb68-854f-430a-b609-b34ab677b1ca]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dd6bc6efb0f472], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node allinone
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node worknode
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:19:07.897: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3718" for this suite.
Dec  5 08:19:13.929: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:19:14.023: INFO: namespace sched-pred-3718 deletion completed in 6.120829804s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

â€¢ [SLOW TEST:11.402 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:19:14.024: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-43dc8d76-dc70-41d0-bccf-5a14299fd58f
STEP: Creating a pod to test consume configMaps
Dec  5 08:19:14.069: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19" in namespace "projected-9021" to be "success or failure"
Dec  5 08:19:14.088: INFO: Pod "pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19": Phase="Pending", Reason="", readiness=false. Elapsed: 18.711881ms
Dec  5 08:19:16.092: INFO: Pod "pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022264391s
STEP: Saw pod success
Dec  5 08:19:16.092: INFO: Pod "pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19" satisfied condition "success or failure"
Dec  5 08:19:16.095: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:19:16.124: INFO: Waiting for pod pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19 to disappear
Dec  5 08:19:16.132: INFO: Pod pod-projected-configmaps-7e3865aa-ee10-46eb-8e94-129a936abc19 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:19:16.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9021" for this suite.
Dec  5 08:19:22.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:19:22.234: INFO: namespace projected-9021 deletion completed in 6.098906429s

â€¢ [SLOW TEST:8.210 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:19:22.234: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-6svj
STEP: Creating a pod to test atomic-volume-subpath
Dec  5 08:19:22.284: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-6svj" in namespace "subpath-6569" to be "success or failure"
Dec  5 08:19:22.303: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Pending", Reason="", readiness=false. Elapsed: 18.662557ms
Dec  5 08:19:24.307: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 2.023281064s
Dec  5 08:19:26.311: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 4.027157834s
Dec  5 08:19:28.319: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 6.034590182s
Dec  5 08:19:30.323: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 8.039347948s
Dec  5 08:19:32.327: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 10.04299847s
Dec  5 08:19:34.335: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 12.050881136s
Dec  5 08:19:36.344: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 14.060028194s
Dec  5 08:19:38.348: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 16.064304794s
Dec  5 08:19:40.353: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 18.068794178s
Dec  5 08:19:42.358: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Running", Reason="", readiness=true. Elapsed: 20.073571947s
Dec  5 08:19:44.368: INFO: Pod "pod-subpath-test-secret-6svj": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.08389408s
STEP: Saw pod success
Dec  5 08:19:44.368: INFO: Pod "pod-subpath-test-secret-6svj" satisfied condition "success or failure"
Dec  5 08:19:44.370: INFO: Trying to get logs from node worknode pod pod-subpath-test-secret-6svj container test-container-subpath-secret-6svj: <nil>
STEP: delete the pod
Dec  5 08:19:44.399: INFO: Waiting for pod pod-subpath-test-secret-6svj to disappear
Dec  5 08:19:44.404: INFO: Pod pod-subpath-test-secret-6svj no longer exists
STEP: Deleting pod pod-subpath-test-secret-6svj
Dec  5 08:19:44.405: INFO: Deleting pod "pod-subpath-test-secret-6svj" in namespace "subpath-6569"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:19:44.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6569" for this suite.
Dec  5 08:19:50.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:19:50.510: INFO: namespace subpath-6569 deletion completed in 6.096285793s

â€¢ [SLOW TEST:28.276 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:19:50.514: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  5 08:19:50.546: INFO: PodSpec: initContainers in spec.initContainers
Dec  5 08:20:39.131: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-afad08ea-c968-4deb-9f5e-02ecd12e136b", GenerateName:"", Namespace:"init-container-5996", SelfLink:"/api/v1/namespaces/init-container-5996/pods/pod-init-afad08ea-c968-4deb-9f5e-02ecd12e136b", UID:"43964d9f-ce77-436d-8137-d441869d2d2c", ResourceVersion:"22389", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63711130790, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"546598191"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"192.168.233.244/32"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-d8w8g", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc004d672c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d8w8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d8w8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-d8w8g", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc001ea1188), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"worknode", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc002f7b3e0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ea1210)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc001ea1230)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc001ea1238), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc001ea123c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130790, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130790, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130790, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711130790, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.3.47", PodIP:"192.168.233.244", PodIPs:[]v1.PodIP{v1.PodIP{IP:"192.168.233.244"}}, StartTime:(*v1.Time)(0xc000cbd380), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003a884d0)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003a88540)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://a4f53a1b21b47ee2c99dce3ac7f8171f46326de7c0fe209a9f8b01b04c1dc303", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000cbd3c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc000cbd3a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc001ea12cf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:20:39.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5996" for this suite.
Dec  5 08:21:07.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:21:07.245: INFO: namespace init-container-5996 deletion completed in 28.105184896s

â€¢ [SLOW TEST:76.731 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:21:07.249: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5553
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  5 08:21:07.295: INFO: Found 0 stateful pods, waiting for 3
Dec  5 08:21:17.303: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:21:17.303: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:21:17.303: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:21:17.313: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-5553 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:21:17.565: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:21:17.565: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:21:17.565: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  5 08:21:17.607: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  5 08:21:27.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-5553 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:21:27.855: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:21:27.856: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:21:27.856: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

STEP: Rolling back to a previous revision
Dec  5 08:21:57.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-5553 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:21:58.149: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:21:58.149: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:21:58.149: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:22:08.186: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  5 08:22:18.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-5553 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:22:18.458: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:22:18.458: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:22:18.458: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:22:18.493: INFO: Waiting for StatefulSet statefulset-5553/ss2 to complete update
Dec  5 08:22:18.493: INFO: Waiting for Pod statefulset-5553/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec  5 08:22:18.493: INFO: Waiting for Pod statefulset-5553/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec  5 08:22:18.493: INFO: Waiting for Pod statefulset-5553/ss2-2 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec  5 08:22:28.501: INFO: Waiting for StatefulSet statefulset-5553/ss2 to complete update
Dec  5 08:22:28.501: INFO: Waiting for Pod statefulset-5553/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 08:22:38.506: INFO: Deleting all statefulset in ns statefulset-5553
Dec  5 08:22:38.509: INFO: Scaling statefulset ss2 to 0
Dec  5 08:22:58.528: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:22:58.531: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:22:58.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5553" for this suite.
Dec  5 08:23:04.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:23:04.656: INFO: namespace statefulset-5553 deletion completed in 6.106173422s

â€¢ [SLOW TEST:117.407 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:23:04.656: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-70060c15-2dad-4adf-8046-3955ef5f8430
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-70060c15-2dad-4adf-8046-3955ef5f8430
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:23:08.771: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7616" for this suite.
Dec  5 08:23:26.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:23:26.939: INFO: namespace configmap-7616 deletion completed in 18.164131843s

â€¢ [SLOW TEST:22.283 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:23:26.939: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  5 08:23:31.052: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:31.063: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:33.063: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:33.067: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:35.064: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:35.067: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:37.111: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:37.115: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:39.063: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:39.067: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:41.063: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:41.066: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:43.064: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:43.068: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:45.065: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:45.068: INFO: Pod pod-with-poststart-http-hook still exists
Dec  5 08:23:47.065: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  5 08:23:47.069: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:23:47.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1523" for this suite.
Dec  5 08:23:59.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:23:59.301: INFO: namespace container-lifecycle-hook-1523 deletion completed in 12.227632307s

â€¢ [SLOW TEST:32.362 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:23:59.303: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:23:59.353: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  5 08:23:59.360: INFO: Number of nodes with available pods: 0
Dec  5 08:23:59.360: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  5 08:23:59.379: INFO: Number of nodes with available pods: 0
Dec  5 08:23:59.379: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:00.384: INFO: Number of nodes with available pods: 0
Dec  5 08:24:00.384: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:01.384: INFO: Number of nodes with available pods: 1
Dec  5 08:24:01.384: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  5 08:24:01.407: INFO: Number of nodes with available pods: 1
Dec  5 08:24:01.407: INFO: Number of running nodes: 0, number of available pods: 1
Dec  5 08:24:02.411: INFO: Number of nodes with available pods: 0
Dec  5 08:24:02.411: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  5 08:24:02.425: INFO: Number of nodes with available pods: 0
Dec  5 08:24:02.425: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:03.454: INFO: Number of nodes with available pods: 0
Dec  5 08:24:03.454: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:04.430: INFO: Number of nodes with available pods: 0
Dec  5 08:24:04.430: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:05.435: INFO: Number of nodes with available pods: 0
Dec  5 08:24:05.436: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:06.434: INFO: Number of nodes with available pods: 0
Dec  5 08:24:06.434: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:07.429: INFO: Number of nodes with available pods: 0
Dec  5 08:24:07.429: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:08.430: INFO: Number of nodes with available pods: 0
Dec  5 08:24:08.431: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:09.430: INFO: Number of nodes with available pods: 1
Dec  5 08:24:09.430: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2148, will wait for the garbage collector to delete the pods
Dec  5 08:24:09.501: INFO: Deleting DaemonSet.extensions daemon-set took: 12.747844ms
Dec  5 08:24:09.803: INFO: Terminating DaemonSet.extensions daemon-set pods took: 302.039081ms
Dec  5 08:24:17.607: INFO: Number of nodes with available pods: 0
Dec  5 08:24:17.608: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 08:24:17.610: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2148/daemonsets","resourceVersion":"23261"},"items":null}

Dec  5 08:24:17.612: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2148/pods","resourceVersion":"23261"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:24:17.637: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2148" for this suite.
Dec  5 08:24:23.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:24:23.742: INFO: namespace daemonsets-2148 deletion completed in 6.101690953s

â€¢ [SLOW TEST:24.440 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:24:23.743: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:24:23.793: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  5 08:24:23.822: INFO: Number of nodes with available pods: 0
Dec  5 08:24:23.823: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:24.867: INFO: Number of nodes with available pods: 0
Dec  5 08:24:24.867: INFO: Node allinone is running more than one daemon pod
Dec  5 08:24:25.833: INFO: Number of nodes with available pods: 2
Dec  5 08:24:25.834: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  5 08:24:25.883: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:25.883: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:26.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:26.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:27.946: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:27.947: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:28.967: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:28.967: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:28.967: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:29.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:29.945: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:29.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:30.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:30.945: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:30.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:31.944: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:31.944: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:31.944: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:32.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:32.945: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:32.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:33.948: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:33.948: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:33.948: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:34.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:34.945: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:34.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:35.957: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:35.957: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:35.957: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:36.945: INFO: Wrong image for pod: daemon-set-6dkzf. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:36.946: INFO: Pod daemon-set-6dkzf is not available
Dec  5 08:24:36.946: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:37.945: INFO: Pod daemon-set-2s45p is not available
Dec  5 08:24:37.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:38.947: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:39.946: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:39.946: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:40.946: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:40.947: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:41.954: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:41.954: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:42.957: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:42.957: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:43.945: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:43.945: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:44.947: INFO: Wrong image for pod: daemon-set-jbc4z. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  5 08:24:44.947: INFO: Pod daemon-set-jbc4z is not available
Dec  5 08:24:45.947: INFO: Pod daemon-set-x24mr is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  5 08:24:45.970: INFO: Number of nodes with available pods: 1
Dec  5 08:24:45.970: INFO: Node worknode is running more than one daemon pod
Dec  5 08:24:46.980: INFO: Number of nodes with available pods: 1
Dec  5 08:24:46.980: INFO: Node worknode is running more than one daemon pod
Dec  5 08:24:47.980: INFO: Number of nodes with available pods: 2
Dec  5 08:24:47.980: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9737, will wait for the garbage collector to delete the pods
Dec  5 08:24:48.052: INFO: Deleting DaemonSet.extensions daemon-set took: 5.25926ms
Dec  5 08:24:48.353: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.480029ms
Dec  5 08:24:57.657: INFO: Number of nodes with available pods: 0
Dec  5 08:24:57.657: INFO: Number of running nodes: 0, number of available pods: 0
Dec  5 08:24:57.659: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9737/daemonsets","resourceVersion":"23439"},"items":null}

Dec  5 08:24:57.662: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9737/pods","resourceVersion":"23439"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:24:57.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9737" for this suite.
Dec  5 08:25:03.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:25:03.775: INFO: namespace daemonsets-9737 deletion completed in 6.102101549s

â€¢ [SLOW TEST:40.033 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:25:03.778: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-7918
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7918 to expose endpoints map[]
Dec  5 08:25:03.831: INFO: successfully validated that service multi-endpoint-test in namespace services-7918 exposes endpoints map[] (2.891728ms elapsed)
STEP: Creating pod pod1 in namespace services-7918
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7918 to expose endpoints map[pod1:[100]]
Dec  5 08:25:05.875: INFO: successfully validated that service multi-endpoint-test in namespace services-7918 exposes endpoints map[pod1:[100]] (2.032907134s elapsed)
STEP: Creating pod pod2 in namespace services-7918
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7918 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  5 08:25:07.935: INFO: successfully validated that service multi-endpoint-test in namespace services-7918 exposes endpoints map[pod1:[100] pod2:[101]] (2.052284957s elapsed)
STEP: Deleting pod pod1 in namespace services-7918
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7918 to expose endpoints map[pod2:[101]]
Dec  5 08:25:08.974: INFO: successfully validated that service multi-endpoint-test in namespace services-7918 exposes endpoints map[pod2:[101]] (1.034748186s elapsed)
STEP: Deleting pod pod2 in namespace services-7918
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-7918 to expose endpoints map[]
Dec  5 08:25:09.018: INFO: successfully validated that service multi-endpoint-test in namespace services-7918 exposes endpoints map[] (24.04408ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:25:09.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7918" for this suite.
Dec  5 08:25:21.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:25:21.165: INFO: namespace services-7918 deletion completed in 12.097922169s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:17.387 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:25:21.166: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-85a8f07d-e55b-4821-93a5-496d15aaf912
STEP: Creating a pod to test consume configMaps
Dec  5 08:25:21.216: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4" in namespace "projected-4780" to be "success or failure"
Dec  5 08:25:21.227: INFO: Pod "pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4": Phase="Pending", Reason="", readiness=false. Elapsed: 11.039813ms
Dec  5 08:25:23.232: INFO: Pod "pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.015838355s
STEP: Saw pod success
Dec  5 08:25:23.232: INFO: Pod "pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4" satisfied condition "success or failure"
Dec  5 08:25:23.235: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:25:23.285: INFO: Waiting for pod pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4 to disappear
Dec  5 08:25:23.290: INFO: Pod pod-projected-configmaps-87120f8f-4225-409c-bf48-ed584c5a89f4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:25:23.290: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4780" for this suite.
Dec  5 08:25:29.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:25:29.398: INFO: namespace projected-4780 deletion completed in 6.103477351s

â€¢ [SLOW TEST:8.232 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:25:29.399: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  5 08:25:33.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec pod-sharedvolume-ba585120-d4e0-4e9a-91c9-c0c57fcf7332 -c busybox-main-container --namespace=emptydir-8774 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  5 08:25:33.830: INFO: stderr: ""
Dec  5 08:25:33.830: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:25:33.830: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8774" for this suite.
Dec  5 08:25:39.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:25:39.943: INFO: namespace emptydir-8774 deletion completed in 6.109684276s

â€¢ [SLOW TEST:10.544 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:25:39.943: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  5 08:25:50.017: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:25:50.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1205 08:25:50.017094      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-5928" for this suite.
Dec  5 08:25:56.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:25:56.171: INFO: namespace gc-5928 deletion completed in 6.150696012s

â€¢ [SLOW TEST:16.227 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:25:56.171: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:25:56.209: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 version'
Dec  5 08:25:56.288: INFO: stderr: ""
Dec  5 08:25:56.288: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:25:56.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6476" for this suite.
Dec  5 08:26:02.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:26:02.438: INFO: namespace kubectl-6476 deletion completed in 6.143044033s

â€¢ [SLOW TEST:6.268 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:26:02.439: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-9553
STEP: creating replication controller nodeport-test in namespace services-9553
I1205 08:26:02.523634      20 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-9553, replica count: 2
Dec  5 08:26:05.574: INFO: Creating new exec pod
I1205 08:26:05.574590      20 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 08:26:08.613: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9553 execpodd9h5c -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec  5 08:26:08.832: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec  5 08:26:08.832: INFO: stdout: ""
Dec  5 08:26:08.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9553 execpodd9h5c -- /bin/sh -x -c nc -zv -t -w 2 10.111.43.196 80'
Dec  5 08:26:09.121: INFO: stderr: "+ nc -zv -t -w 2 10.111.43.196 80\nConnection to 10.111.43.196 80 port [tcp/http] succeeded!\n"
Dec  5 08:26:09.121: INFO: stdout: ""
Dec  5 08:26:09.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9553 execpodd9h5c -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.237 30829'
Dec  5 08:26:09.408: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.237 30829\nConnection to 10.0.2.237 30829 port [tcp/30829] succeeded!\n"
Dec  5 08:26:09.408: INFO: stdout: ""
Dec  5 08:26:09.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9553 execpodd9h5c -- /bin/sh -x -c nc -zv -t -w 2 10.0.3.47 30829'
Dec  5 08:26:09.652: INFO: stderr: "+ nc -zv -t -w 2 10.0.3.47 30829\nConnection to 10.0.3.47 30829 port [tcp/30829] succeeded!\n"
Dec  5 08:26:09.652: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:26:09.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9553" for this suite.
Dec  5 08:26:15.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:26:15.775: INFO: namespace services-9553 deletion completed in 6.118564323s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:13.336 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:26:15.777: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1205 08:26:21.850605      20 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  5 08:26:21.850: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:26:21.850: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3376" for this suite.
Dec  5 08:26:27.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:26:28.018: INFO: namespace gc-3376 deletion completed in 6.163921328s

â€¢ [SLOW TEST:12.241 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:26:28.019: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec  5 08:26:28.105: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 --namespace=kubectl-1281 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  5 08:26:29.737: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  5 08:26:29.737: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:26:31.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1281" for this suite.
Dec  5 08:26:37.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:26:37.892: INFO: namespace kubectl-1281 deletion completed in 6.146575909s

â€¢ [SLOW TEST:9.874 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:26:37.895: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-419ded4f-2fc9-49bd-9776-6ed6aa78dbe7
STEP: Creating a pod to test consume secrets
Dec  5 08:26:37.959: INFO: Waiting up to 5m0s for pod "pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538" in namespace "secrets-7850" to be "success or failure"
Dec  5 08:26:37.964: INFO: Pod "pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538": Phase="Pending", Reason="", readiness=false. Elapsed: 4.922952ms
Dec  5 08:26:39.967: INFO: Pod "pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007693726s
STEP: Saw pod success
Dec  5 08:26:39.967: INFO: Pod "pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538" satisfied condition "success or failure"
Dec  5 08:26:39.969: INFO: Trying to get logs from node worknode pod pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 08:26:40.000: INFO: Waiting for pod pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538 to disappear
Dec  5 08:26:40.008: INFO: Pod pod-secrets-e850b484-f034-4387-bbd1-2c6ac8b81538 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:26:40.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7850" for this suite.
Dec  5 08:26:46.071: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:26:46.203: INFO: namespace secrets-7850 deletion completed in 6.188558297s

â€¢ [SLOW TEST:8.308 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:26:46.207: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  5 08:26:50.315: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 08:26:50.322: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 08:26:52.323: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 08:26:52.333: INFO: Pod pod-with-prestop-http-hook still exists
Dec  5 08:26:54.322: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  5 08:26:54.326: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:26:54.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3536" for this suite.
Dec  5 08:27:22.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:27:22.449: INFO: namespace container-lifecycle-hook-3536 deletion completed in 28.109683569s

â€¢ [SLOW TEST:36.243 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:27:22.452: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-2c9b0489-f24a-45e5-84e1-2dead8b36074
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:27:26.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4973" for this suite.
Dec  5 08:27:54.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:27:54.715: INFO: namespace configmap-4973 deletion completed in 28.13588219s

â€¢ [SLOW TEST:32.264 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:27:54.717: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:27:54.760: INFO: Waiting up to 5m0s for pod "downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47" in namespace "projected-1581" to be "success or failure"
Dec  5 08:27:54.769: INFO: Pod "downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47": Phase="Pending", Reason="", readiness=false. Elapsed: 8.861737ms
Dec  5 08:27:56.773: INFO: Pod "downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013472768s
STEP: Saw pod success
Dec  5 08:27:56.773: INFO: Pod "downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47" satisfied condition "success or failure"
Dec  5 08:27:56.776: INFO: Trying to get logs from node worknode pod downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47 container client-container: <nil>
STEP: delete the pod
Dec  5 08:27:56.798: INFO: Waiting for pod downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47 to disappear
Dec  5 08:27:56.805: INFO: Pod downwardapi-volume-13b5d805-9741-4759-a63f-83446bfe0a47 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:27:56.805: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1581" for this suite.
Dec  5 08:28:02.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:28:02.922: INFO: namespace projected-1581 deletion completed in 6.112887006s

â€¢ [SLOW TEST:8.205 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:28:02.922: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec  5 08:28:02.973: INFO: Waiting up to 5m0s for pod "client-containers-780b97d1-b475-45a9-8403-cf4d23367345" in namespace "containers-9145" to be "success or failure"
Dec  5 08:28:02.977: INFO: Pod "client-containers-780b97d1-b475-45a9-8403-cf4d23367345": Phase="Pending", Reason="", readiness=false. Elapsed: 3.710015ms
Dec  5 08:28:05.026: INFO: Pod "client-containers-780b97d1-b475-45a9-8403-cf4d23367345": Phase="Pending", Reason="", readiness=false. Elapsed: 2.053314707s
Dec  5 08:28:07.031: INFO: Pod "client-containers-780b97d1-b475-45a9-8403-cf4d23367345": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057924748s
STEP: Saw pod success
Dec  5 08:28:07.031: INFO: Pod "client-containers-780b97d1-b475-45a9-8403-cf4d23367345" satisfied condition "success or failure"
Dec  5 08:28:07.034: INFO: Trying to get logs from node worknode pod client-containers-780b97d1-b475-45a9-8403-cf4d23367345 container test-container: <nil>
STEP: delete the pod
Dec  5 08:28:07.065: INFO: Waiting for pod client-containers-780b97d1-b475-45a9-8403-cf4d23367345 to disappear
Dec  5 08:28:07.068: INFO: Pod client-containers-780b97d1-b475-45a9-8403-cf4d23367345 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:28:07.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9145" for this suite.
Dec  5 08:28:13.087: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:28:13.187: INFO: namespace containers-9145 deletion completed in 6.115245267s

â€¢ [SLOW TEST:10.265 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:28:13.191: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec  5 08:28:13.236: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:28:16.635: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:28:28.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-886" for this suite.
Dec  5 08:28:34.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:28:35.047: INFO: namespace crd-publish-openapi-886 deletion completed in 6.160927522s

â€¢ [SLOW TEST:21.856 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:28:35.047: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:28:35.093: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f" in namespace "projected-2365" to be "success or failure"
Dec  5 08:28:35.102: INFO: Pod "downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f": Phase="Pending", Reason="", readiness=false. Elapsed: 9.465721ms
Dec  5 08:28:37.106: INFO: Pod "downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01305689s
STEP: Saw pod success
Dec  5 08:28:37.106: INFO: Pod "downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f" satisfied condition "success or failure"
Dec  5 08:28:37.109: INFO: Trying to get logs from node worknode pod downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f container client-container: <nil>
STEP: delete the pod
Dec  5 08:28:37.133: INFO: Waiting for pod downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f to disappear
Dec  5 08:28:37.138: INFO: Pod downwardapi-volume-3f85fcc3-6833-4cad-8f7f-84b3cf5b607f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:28:37.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2365" for this suite.
Dec  5 08:28:43.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:28:43.262: INFO: namespace projected-2365 deletion completed in 6.115336307s

â€¢ [SLOW TEST:8.215 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:28:43.262: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:28:43.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-304" for this suite.
Dec  5 08:28:49.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:28:49.467: INFO: namespace resourcequota-304 deletion completed in 6.13164275s

â€¢ [SLOW TEST:6.205 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:28:49.467: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:28:51.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-4698" for this suite.
Dec  5 08:29:39.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:29:39.829: INFO: namespace kubelet-test-4698 deletion completed in 48.205113002s

â€¢ [SLOW TEST:50.361 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:29:39.831: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3379
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3379
STEP: creating replication controller externalsvc in namespace services-3379
I1205 08:29:39.953675      20 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3379, replica count: 2
I1205 08:29:43.004344      20 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec  5 08:29:43.032: INFO: Creating new exec pod
Dec  5 08:29:45.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-3379 execpodfm8xw -- /bin/sh -x -c nslookup clusterip-service'
Dec  5 08:29:45.328: INFO: stderr: "+ nslookup clusterip-service\n"
Dec  5 08:29:45.328: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-3379.svc.cluster.local\tcanonical name = externalsvc.services-3379.svc.cluster.local.\nName:\texternalsvc.services-3379.svc.cluster.local\nAddress: 10.107.1.233\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3379, will wait for the garbage collector to delete the pods
Dec  5 08:29:45.392: INFO: Deleting ReplicationController externalsvc took: 9.998461ms
Dec  5 08:29:45.699: INFO: Terminating ReplicationController externalsvc pods took: 306.922435ms
Dec  5 08:29:49.945: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:29:49.965: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3379" for this suite.
Dec  5 08:29:55.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:29:56.159: INFO: namespace services-3379 deletion completed in 6.189209045s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:16.329 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:29:56.160: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-5ec444fe-36b4-4ab1-9550-7581f53f0f81
STEP: Creating a pod to test consume configMaps
Dec  5 08:29:56.218: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7" in namespace "projected-6845" to be "success or failure"
Dec  5 08:29:56.222: INFO: Pod "pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232921ms
Dec  5 08:29:58.227: INFO: Pod "pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008672091s
STEP: Saw pod success
Dec  5 08:29:58.227: INFO: Pod "pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7" satisfied condition "success or failure"
Dec  5 08:29:58.231: INFO: Trying to get logs from node worknode pod pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:29:58.272: INFO: Waiting for pod pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7 to disappear
Dec  5 08:29:58.278: INFO: Pod pod-projected-configmaps-5ef847db-301b-4e07-9529-6f4368baf5a7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:29:58.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6845" for this suite.
Dec  5 08:30:04.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:30:04.413: INFO: namespace projected-6845 deletion completed in 6.127183998s

â€¢ [SLOW TEST:8.253 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:30:04.414: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:30:04.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3" in namespace "projected-8502" to be "success or failure"
Dec  5 08:30:04.462: INFO: Pod "downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3": Phase="Pending", Reason="", readiness=false. Elapsed: 5.824802ms
Dec  5 08:30:06.466: INFO: Pod "downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009305459s
STEP: Saw pod success
Dec  5 08:30:06.466: INFO: Pod "downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3" satisfied condition "success or failure"
Dec  5 08:30:06.469: INFO: Trying to get logs from node worknode pod downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3 container client-container: <nil>
STEP: delete the pod
Dec  5 08:30:06.501: INFO: Waiting for pod downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3 to disappear
Dec  5 08:30:06.504: INFO: Pod downwardapi-volume-58c2f37e-e120-463f-8ed6-5f8f59b4f1e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:30:06.504: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8502" for this suite.
Dec  5 08:30:12.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:30:12.647: INFO: namespace projected-8502 deletion completed in 6.136914318s

â€¢ [SLOW TEST:8.233 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:30:12.649: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8581
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 08:30:12.694: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 08:30:30.814: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.233.215:8080/dial?request=hostName&protocol=udp&host=192.168.233.214&port=8081&tries=1'] Namespace:pod-network-test-8581 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:30:30.814: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:30:30.950: INFO: Waiting for endpoints: map[]
Dec  5 08:30:30.954: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.233.215:8080/dial?request=hostName&protocol=udp&host=192.168.228.84&port=8081&tries=1'] Namespace:pod-network-test-8581 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:30:30.954: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:30:31.172: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:30:31.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8581" for this suite.
Dec  5 08:30:43.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:30:43.333: INFO: namespace pod-network-test-8581 deletion completed in 12.156536105s

â€¢ [SLOW TEST:30.684 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:30:43.334: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  5 08:30:43.385: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:30:46.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6645" for this suite.
Dec  5 08:30:52.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:30:52.378: INFO: namespace init-container-6645 deletion completed in 6.117488314s

â€¢ [SLOW TEST:9.045 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:30:52.380: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  5 08:30:52.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2139'
Dec  5 08:30:52.556: INFO: stderr: ""
Dec  5 08:30:52.556: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec  5 08:30:52.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete pods e2e-test-httpd-pod --namespace=kubectl-2139'
Dec  5 08:31:05.717: INFO: stderr: ""
Dec  5 08:31:05.717: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:31:05.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2139" for this suite.
Dec  5 08:31:11.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:31:11.831: INFO: namespace kubectl-2139 deletion completed in 6.10789911s

â€¢ [SLOW TEST:19.451 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:31:11.831: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:31:12.400: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec  5 08:31:14.410: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131472, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131472, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131472, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131472, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:31:17.466: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:31:17.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7927" for this suite.
Dec  5 08:31:23.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:31:23.694: INFO: namespace webhook-7927 deletion completed in 6.138500087s
STEP: Destroying namespace "webhook-7927-markers" for this suite.
Dec  5 08:31:29.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:31:29.813: INFO: namespace webhook-7927-markers deletion completed in 6.118638026s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:17.998 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:31:29.830: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:31:40.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1021" for this suite.
Dec  5 08:31:46.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:31:47.098: INFO: namespace resourcequota-1021 deletion completed in 6.122188848s

â€¢ [SLOW TEST:17.268 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:31:47.099: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:31:47.150: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  5 08:31:51.165: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  5 08:31:51.193: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3457 /apis/apps/v1/namespaces/deployment-3457/deployments/test-cleanup-deployment bba3089a-2d85-46d2-bbe8-1a7db79126e5 25351 1 2019-12-05 08:31:51 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006bfea58 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec  5 08:31:51.202: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec  5 08:31:51.202: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec  5 08:31:51.202: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3457 /apis/apps/v1/namespaces/deployment-3457/replicasets/test-cleanup-controller 85ed4755-947e-4193-89c8-620002e9f16a 25352 1 2019-12-05 08:31:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment bba3089a-2d85-46d2-bbe8-1a7db79126e5 0xc006bfedd7 0xc006bfedd8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc006bfee38 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  5 08:31:51.210: INFO: Pod "test-cleanup-controller-sql7r" is available:
&Pod{ObjectMeta:{test-cleanup-controller-sql7r test-cleanup-controller- deployment-3457 /api/v1/namespaces/deployment-3457/pods/test-cleanup-controller-sql7r 9eecdb77-13be-4227-9381-ed71666f90e3 25347 0 2019-12-05 08:31:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[cni.projectcalico.org/podIP:192.168.233.218/32] [{apps/v1 ReplicaSet test-cleanup-controller 85ed4755-947e-4193-89c8-620002e9f16a 0xc006bff267 0xc006bff268}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-4z2x5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-4z2x5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-4z2x5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:31:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:31:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:31:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:31:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.218,StartTime:2019-12-05 08:31:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 08:31:49 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://d04a95e2917ff36049e3e52d367b296fe6da416ad8871973880a8244daa06b83,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.218,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:31:51.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3457" for this suite.
Dec  5 08:31:57.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:31:57.383: INFO: namespace deployment-3457 deletion completed in 6.143877226s

â€¢ [SLOW TEST:10.285 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:31:57.384: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  5 08:31:57.430: INFO: Waiting up to 5m0s for pod "pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c" in namespace "emptydir-2571" to be "success or failure"
Dec  5 08:31:57.438: INFO: Pod "pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c": Phase="Pending", Reason="", readiness=false. Elapsed: 8.422375ms
Dec  5 08:31:59.443: INFO: Pod "pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012858455s
STEP: Saw pod success
Dec  5 08:31:59.443: INFO: Pod "pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c" satisfied condition "success or failure"
Dec  5 08:31:59.446: INFO: Trying to get logs from node worknode pod pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c container test-container: <nil>
STEP: delete the pod
Dec  5 08:31:59.493: INFO: Waiting for pod pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c to disappear
Dec  5 08:31:59.499: INFO: Pod pod-ba255d4c-2b04-4df0-bc7b-11bb0f4d371c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:31:59.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2571" for this suite.
Dec  5 08:32:05.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:05.617: INFO: namespace emptydir-2571 deletion completed in 6.114834167s

â€¢ [SLOW TEST:8.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:32:05.618: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  5 08:32:05.664: INFO: Waiting up to 5m0s for pod "downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6" in namespace "downward-api-9680" to be "success or failure"
Dec  5 08:32:05.669: INFO: Pod "downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.638275ms
Dec  5 08:32:07.673: INFO: Pod "downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008678878s
STEP: Saw pod success
Dec  5 08:32:07.673: INFO: Pod "downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6" satisfied condition "success or failure"
Dec  5 08:32:07.676: INFO: Trying to get logs from node worknode pod downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6 container dapi-container: <nil>
STEP: delete the pod
Dec  5 08:32:07.710: INFO: Waiting for pod downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6 to disappear
Dec  5 08:32:07.714: INFO: Pod downward-api-63211f95-6290-4ed8-82ba-7ac0fb8a6ba6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:32:07.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9680" for this suite.
Dec  5 08:32:13.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:13.823: INFO: namespace downward-api-9680 deletion completed in 6.105685326s

â€¢ [SLOW TEST:8.205 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:32:13.824: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:32:14.371: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 08:32:16.382: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131534, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131534, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131534, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:32:19.447: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:32:19.495: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8274" for this suite.
Dec  5 08:32:31.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:31.614: INFO: namespace webhook-8274 deletion completed in 12.103695719s
STEP: Destroying namespace "webhook-8274-markers" for this suite.
Dec  5 08:32:37.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:37.723: INFO: namespace webhook-8274-markers deletion completed in 6.108521054s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:23.911 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:32:37.735: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-170e3840-20dc-405a-9ce6-31f047794b79
STEP: Creating a pod to test consume secrets
Dec  5 08:32:37.787: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba" in namespace "projected-8433" to be "success or failure"
Dec  5 08:32:37.801: INFO: Pod "pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba": Phase="Pending", Reason="", readiness=false. Elapsed: 13.980485ms
Dec  5 08:32:39.806: INFO: Pod "pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019764211s
Dec  5 08:32:41.810: INFO: Pod "pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023703119s
STEP: Saw pod success
Dec  5 08:32:41.810: INFO: Pod "pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba" satisfied condition "success or failure"
Dec  5 08:32:41.813: INFO: Trying to get logs from node worknode pod pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  5 08:32:41.841: INFO: Waiting for pod pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba to disappear
Dec  5 08:32:41.844: INFO: Pod pod-projected-secrets-c1969462-92b8-44fd-b1a2-f8def91137ba no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:32:41.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8433" for this suite.
Dec  5 08:32:47.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:47.997: INFO: namespace projected-8433 deletion completed in 6.150075086s

â€¢ [SLOW TEST:10.263 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:32:48.001: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec  5 08:32:48.044: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-535733101 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:32:48.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9212" for this suite.
Dec  5 08:32:54.125: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:32:54.210: INFO: namespace kubectl-9212 deletion completed in 6.099063642s

â€¢ [SLOW TEST:6.210 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:32:54.214: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-52
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-52
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-52
Dec  5 08:32:54.270: INFO: Found 0 stateful pods, waiting for 1
Dec  5 08:33:04.299: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  5 08:33:04.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:33:04.517: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:33:04.517: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:33:04.517: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:33:04.520: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  5 08:33:14.524: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:33:14.524: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:33:14.540: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999528s
Dec  5 08:33:15.546: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.993896148s
Dec  5 08:33:16.552: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.987063854s
Dec  5 08:33:17.577: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.962099692s
Dec  5 08:33:18.582: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.957367525s
Dec  5 08:33:19.586: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.953275376s
Dec  5 08:33:20.590: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.948986104s
Dec  5 08:33:21.594: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.944976899s
Dec  5 08:33:22.599: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.940610228s
Dec  5 08:33:23.603: INFO: Verifying statefulset ss doesn't scale past 1 for another 936.084892ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-52
Dec  5 08:33:24.607: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:33:24.836: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:33:24.836: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:33:24.836: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:33:24.840: INFO: Found 1 stateful pods, waiting for 3
Dec  5 08:33:34.843: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:33:34.843: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  5 08:33:34.843: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  5 08:33:34.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:33:35.098: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:33:35.098: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:33:35.098: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:33:35.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:33:35.462: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:33:35.462: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:33:35.462: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:33:35.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  5 08:33:35.772: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  5 08:33:35.772: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  5 08:33:35.772: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  5 08:33:35.772: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:33:35.775: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  5 08:33:45.782: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:33:45.782: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:33:45.782: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  5 08:33:45.800: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999447s
Dec  5 08:33:46.803: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994863843s
Dec  5 08:33:47.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990884204s
Dec  5 08:33:48.812: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.986668529s
Dec  5 08:33:49.816: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.982255435s
Dec  5 08:33:50.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975541205s
Dec  5 08:33:51.827: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.971668056s
Dec  5 08:33:52.831: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967723331s
Dec  5 08:33:53.839: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.959800015s
Dec  5 08:33:54.843: INFO: Verifying statefulset ss doesn't scale past 3 for another 956.076567ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-52
Dec  5 08:33:55.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:33:56.101: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:33:56.101: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:33:56.101: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:33:56.102: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:33:56.357: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:33:56.357: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:33:56.357: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:33:56.357: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=statefulset-52 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  5 08:33:56.567: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  5 08:33:56.567: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  5 08:33:56.567: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  5 08:33:56.567: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  5 08:34:16.586: INFO: Deleting all statefulset in ns statefulset-52
Dec  5 08:34:16.589: INFO: Scaling statefulset ss to 0
Dec  5 08:34:16.598: INFO: Waiting for statefulset status.replicas updated to 0
Dec  5 08:34:16.601: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:34:16.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-52" for this suite.
Dec  5 08:34:22.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:34:22.747: INFO: namespace statefulset-52 deletion completed in 6.122892863s

â€¢ [SLOW TEST:88.533 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:34:22.747: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-65fe91e0-1781-4c0d-bff2-a07d8198d605
STEP: Creating a pod to test consume secrets
Dec  5 08:34:22.797: INFO: Waiting up to 5m0s for pod "pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18" in namespace "secrets-5166" to be "success or failure"
Dec  5 08:34:22.802: INFO: Pod "pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18": Phase="Pending", Reason="", readiness=false. Elapsed: 5.0849ms
Dec  5 08:34:24.805: INFO: Pod "pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008177056s
STEP: Saw pod success
Dec  5 08:34:24.806: INFO: Pod "pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18" satisfied condition "success or failure"
Dec  5 08:34:24.808: INFO: Trying to get logs from node worknode pod pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18 container secret-env-test: <nil>
STEP: delete the pod
Dec  5 08:34:24.841: INFO: Waiting for pod pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18 to disappear
Dec  5 08:34:24.846: INFO: Pod pod-secrets-26535c5b-b3b4-43e3-ae7f-b8bdd582ba18 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:34:24.847: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5166" for this suite.
Dec  5 08:34:30.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:34:30.958: INFO: namespace secrets-5166 deletion completed in 6.107511886s

â€¢ [SLOW TEST:8.211 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:34:30.959: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:34:30.989: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:34:35.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6507" for this suite.
Dec  5 08:35:19.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:35:19.324: INFO: namespace pods-6507 deletion completed in 44.133384217s

â€¢ [SLOW TEST:48.366 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:35:19.327: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  5 08:35:21.414: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-535733101 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  5 08:35:36.491: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:35:36.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5653" for this suite.
Dec  5 08:35:42.512: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:35:42.623: INFO: namespace pods-5653 deletion completed in 6.125014021s

â€¢ [SLOW TEST:23.296 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:35:42.623: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  5 08:35:42.683: INFO: Waiting up to 5m0s for pod "pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1" in namespace "emptydir-100" to be "success or failure"
Dec  5 08:35:42.701: INFO: Pod "pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.400593ms
Dec  5 08:35:44.706: INFO: Pod "pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023304129s
STEP: Saw pod success
Dec  5 08:35:44.706: INFO: Pod "pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1" satisfied condition "success or failure"
Dec  5 08:35:44.710: INFO: Trying to get logs from node worknode pod pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1 container test-container: <nil>
STEP: delete the pod
Dec  5 08:35:44.743: INFO: Waiting for pod pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1 to disappear
Dec  5 08:35:44.751: INFO: Pod pod-c91ba2cb-d4d3-4e99-af08-c4bce84d90a1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:35:44.751: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-100" for this suite.
Dec  5 08:35:50.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:35:50.868: INFO: namespace emptydir-100 deletion completed in 6.111836105s

â€¢ [SLOW TEST:8.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:35:50.871: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:35:52.105: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec  5 08:35:54.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131752, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131752, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711131752, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:35:57.132: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:35:57.135: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:35:57.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-9564" for this suite.
Dec  5 08:36:03.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:36:03.940: INFO: namespace crd-webhook-9564 deletion completed in 6.122340053s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

â€¢ [SLOW TEST:13.083 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:36:03.954: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9786
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-9786
I1205 08:36:04.036520      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9786, replica count: 2
Dec  5 08:36:07.087: INFO: Creating new exec pod
I1205 08:36:07.087137      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 08:36:10.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  5 08:36:10.537: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  5 08:36:10.537: INFO: stdout: ""
Dec  5 08:36:10.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 10.102.152.175 80'
Dec  5 08:36:10.814: INFO: stderr: "+ nc -zv -t -w 2 10.102.152.175 80\nConnection to 10.102.152.175 80 port [tcp/http] succeeded!\n"
Dec  5 08:36:10.814: INFO: stdout: ""
Dec  5 08:36:10.814: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.237 32286'
Dec  5 08:36:13.063: INFO: rc: 1
Dec  5 08:36:13.063: INFO: Service reachability failing with error: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.237 32286] []  <nil>  + nc -zv -t -w 2 10.0.2.237 32286
nc: connect to 10.0.2.237 port 32286 (tcp) timed out: Operation in progress
command terminated with exit code 1
 [] <nil> 0xc005adbdd0 exit status 1 <nil> <nil> true [0xc0074d91e8 0xc0074d9200 0xc0074d9218] [0xc0074d91e8 0xc0074d9200 0xc0074d9218] [0xc0074d91f8 0xc0074d9210] [0x10efe30 0x10efe30] 0xc0032f1980 <nil>}:
Command stdout:

stderr:
+ nc -zv -t -w 2 10.0.2.237 32286
nc: connect to 10.0.2.237 port 32286 (tcp) timed out: Operation in progress
command terminated with exit code 1

error:
exit status 1
Retrying...
Dec  5 08:36:14.064: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 10.0.2.237 32286'
Dec  5 08:36:14.294: INFO: stderr: "+ nc -zv -t -w 2 10.0.2.237 32286\nConnection to 10.0.2.237 32286 port [tcp/32286] succeeded!\n"
Dec  5 08:36:14.294: INFO: stdout: ""
Dec  5 08:36:14.295: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-9786 execpodmlkmv -- /bin/sh -x -c nc -zv -t -w 2 10.0.3.47 32286'
Dec  5 08:36:14.523: INFO: stderr: "+ nc -zv -t -w 2 10.0.3.47 32286\nConnection to 10.0.3.47 32286 port [tcp/32286] succeeded!\n"
Dec  5 08:36:14.523: INFO: stdout: ""
Dec  5 08:36:14.523: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:36:14.563: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9786" for this suite.
Dec  5 08:36:20.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:36:20.688: INFO: namespace services-9786 deletion completed in 6.119167998s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:16.734 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:36:20.690: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec  5 08:36:21.254: INFO: created pod pod-service-account-defaultsa
Dec  5 08:36:21.255: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  5 08:36:21.262: INFO: created pod pod-service-account-mountsa
Dec  5 08:36:21.262: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  5 08:36:21.293: INFO: created pod pod-service-account-nomountsa
Dec  5 08:36:21.293: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  5 08:36:21.310: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  5 08:36:21.310: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  5 08:36:21.340: INFO: created pod pod-service-account-mountsa-mountspec
Dec  5 08:36:21.340: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  5 08:36:21.353: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  5 08:36:21.353: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  5 08:36:21.371: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  5 08:36:21.371: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  5 08:36:21.384: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  5 08:36:21.384: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  5 08:36:21.392: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  5 08:36:21.392: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:36:21.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-4524" for this suite.
Dec  5 08:36:35.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:36:35.584: INFO: namespace svcaccounts-4524 deletion completed in 14.161506097s

â€¢ [SLOW TEST:14.895 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:36:35.585: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:36:42.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6726" for this suite.
Dec  5 08:36:48.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:36:48.744: INFO: namespace resourcequota-6726 deletion completed in 6.107883523s

â€¢ [SLOW TEST:13.159 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:36:48.745: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-a9ea5ffa-1e62-4992-8885-03c09b8fc3b9
STEP: Creating a pod to test consume configMaps
Dec  5 08:36:48.792: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0" in namespace "configmap-3486" to be "success or failure"
Dec  5 08:36:48.796: INFO: Pod "pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.350908ms
Dec  5 08:36:50.802: INFO: Pod "pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010058478s
STEP: Saw pod success
Dec  5 08:36:50.802: INFO: Pod "pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0" satisfied condition "success or failure"
Dec  5 08:36:50.805: INFO: Trying to get logs from node worknode pod pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:36:50.830: INFO: Waiting for pod pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0 to disappear
Dec  5 08:36:50.838: INFO: Pod pod-configmaps-d4d3bfa2-1323-4c73-9ca2-ee6c93b10fa0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:36:50.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3486" for this suite.
Dec  5 08:36:56.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:36:56.946: INFO: namespace configmap-3486 deletion completed in 6.104509778s

â€¢ [SLOW TEST:8.201 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:36:56.947: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:04.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4581" for this suite.
Dec  5 08:37:11.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:37:11.097: INFO: namespace job-4581 deletion completed in 6.103595189s

â€¢ [SLOW TEST:14.150 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:37:11.098: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:37:11.144: INFO: Waiting up to 5m0s for pod "downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c" in namespace "projected-4390" to be "success or failure"
Dec  5 08:37:11.172: INFO: Pod "downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c": Phase="Pending", Reason="", readiness=false. Elapsed: 27.720649ms
Dec  5 08:37:13.182: INFO: Pod "downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.037376545s
Dec  5 08:37:15.186: INFO: Pod "downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.041475138s
STEP: Saw pod success
Dec  5 08:37:15.186: INFO: Pod "downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c" satisfied condition "success or failure"
Dec  5 08:37:15.189: INFO: Trying to get logs from node worknode pod downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c container client-container: <nil>
STEP: delete the pod
Dec  5 08:37:15.221: INFO: Waiting for pod downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c to disappear
Dec  5 08:37:15.226: INFO: Pod downwardapi-volume-36c60afd-d570-4937-8e2c-a90ad64e589c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:15.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4390" for this suite.
Dec  5 08:37:21.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:37:21.334: INFO: namespace projected-4390 deletion completed in 6.103615038s

â€¢ [SLOW TEST:10.237 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:37:21.334: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-1271dee4-ed32-4413-a3d9-f4ff8da16589
STEP: Creating a pod to test consume secrets
Dec  5 08:37:21.379: INFO: Waiting up to 5m0s for pod "pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6" in namespace "secrets-8810" to be "success or failure"
Dec  5 08:37:21.394: INFO: Pod "pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6": Phase="Pending", Reason="", readiness=false. Elapsed: 14.882813ms
Dec  5 08:37:23.400: INFO: Pod "pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020388914s
Dec  5 08:37:25.403: INFO: Pod "pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023601602s
STEP: Saw pod success
Dec  5 08:37:25.403: INFO: Pod "pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6" satisfied condition "success or failure"
Dec  5 08:37:25.407: INFO: Trying to get logs from node worknode pod pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 08:37:25.434: INFO: Waiting for pod pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6 to disappear
Dec  5 08:37:25.437: INFO: Pod pod-secrets-0cded8ce-ff0a-4bd8-b14d-9cb8d92fa7b6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:25.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8810" for this suite.
Dec  5 08:37:31.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:37:31.569: INFO: namespace secrets-8810 deletion completed in 6.126751415s

â€¢ [SLOW TEST:10.234 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:37:31.570: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 08:37:31.616: INFO: Waiting up to 5m0s for pod "pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8" in namespace "emptydir-8698" to be "success or failure"
Dec  5 08:37:31.622: INFO: Pod "pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8": Phase="Pending", Reason="", readiness=false. Elapsed: 6.461701ms
Dec  5 08:37:33.627: INFO: Pod "pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011578837s
Dec  5 08:37:35.630: INFO: Pod "pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014613849s
STEP: Saw pod success
Dec  5 08:37:35.630: INFO: Pod "pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8" satisfied condition "success or failure"
Dec  5 08:37:35.633: INFO: Trying to get logs from node worknode pod pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8 container test-container: <nil>
STEP: delete the pod
Dec  5 08:37:35.662: INFO: Waiting for pod pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8 to disappear
Dec  5 08:37:35.665: INFO: Pod pod-8dd64c2a-5056-4e32-a67a-5de3392ae6d8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:35.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8698" for this suite.
Dec  5 08:37:41.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:37:41.818: INFO: namespace emptydir-8698 deletion completed in 6.145127529s

â€¢ [SLOW TEST:10.248 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:37:41.819: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-539618e3-d4a5-4ad5-8ca5-90f25ab2e775
STEP: Creating a pod to test consume configMaps
Dec  5 08:37:41.925: INFO: Waiting up to 5m0s for pod "pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57" in namespace "configmap-25" to be "success or failure"
Dec  5 08:37:41.947: INFO: Pod "pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57": Phase="Pending", Reason="", readiness=false. Elapsed: 21.832983ms
Dec  5 08:37:43.951: INFO: Pod "pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025631526s
Dec  5 08:37:45.959: INFO: Pod "pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.033209437s
STEP: Saw pod success
Dec  5 08:37:45.959: INFO: Pod "pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57" satisfied condition "success or failure"
Dec  5 08:37:45.981: INFO: Trying to get logs from node worknode pod pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  5 08:37:46.073: INFO: Waiting for pod pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57 to disappear
Dec  5 08:37:46.083: INFO: Pod pod-configmaps-a639fda4-a4ea-4125-81b7-edd01e424d57 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:46.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-25" for this suite.
Dec  5 08:37:52.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:37:52.261: INFO: namespace configmap-25 deletion completed in 6.149053162s

â€¢ [SLOW TEST:10.442 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:37:52.261: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-7317
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7317 to expose endpoints map[]
Dec  5 08:37:52.340: INFO: successfully validated that service endpoint-test2 in namespace services-7317 exposes endpoints map[] (10.570875ms elapsed)
STEP: Creating pod pod1 in namespace services-7317
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7317 to expose endpoints map[pod1:[80]]
Dec  5 08:37:54.384: INFO: successfully validated that service endpoint-test2 in namespace services-7317 exposes endpoints map[pod1:[80]] (2.034875763s elapsed)
STEP: Creating pod pod2 in namespace services-7317
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7317 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  5 08:37:57.463: INFO: successfully validated that service endpoint-test2 in namespace services-7317 exposes endpoints map[pod1:[80] pod2:[80]] (3.071570774s elapsed)
STEP: Deleting pod pod1 in namespace services-7317
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7317 to expose endpoints map[pod2:[80]]
Dec  5 08:37:58.501: INFO: successfully validated that service endpoint-test2 in namespace services-7317 exposes endpoints map[pod2:[80]] (1.031294079s elapsed)
STEP: Deleting pod pod2 in namespace services-7317
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-7317 to expose endpoints map[]
Dec  5 08:37:58.521: INFO: successfully validated that service endpoint-test2 in namespace services-7317 exposes endpoints map[] (7.670023ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:37:58.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7317" for this suite.
Dec  5 08:38:10.576: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:38:10.670: INFO: namespace services-7317 deletion completed in 12.111632257s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:18.409 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:38:10.672: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:38:10.721: INFO: Waiting up to 5m0s for pod "downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d" in namespace "downward-api-3080" to be "success or failure"
Dec  5 08:38:10.724: INFO: Pod "downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.931989ms
Dec  5 08:38:12.727: INFO: Pod "downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00601746s
STEP: Saw pod success
Dec  5 08:38:12.727: INFO: Pod "downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d" satisfied condition "success or failure"
Dec  5 08:38:12.730: INFO: Trying to get logs from node worknode pod downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d container client-container: <nil>
STEP: delete the pod
Dec  5 08:38:12.756: INFO: Waiting for pod downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d to disappear
Dec  5 08:38:12.764: INFO: Pod downwardapi-volume-09fbce18-0c01-4cda-b858-0b4e1203ce3d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:38:12.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3080" for this suite.
Dec  5 08:38:18.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:38:18.993: INFO: namespace downward-api-3080 deletion completed in 6.221749827s

â€¢ [SLOW TEST:8.321 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:38:18.994: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  5 08:38:19.077: INFO: Waiting up to 5m0s for pod "pod-89c47c6e-3e64-4373-a6bb-5116d032aa71" in namespace "emptydir-6412" to be "success or failure"
Dec  5 08:38:19.083: INFO: Pod "pod-89c47c6e-3e64-4373-a6bb-5116d032aa71": Phase="Pending", Reason="", readiness=false. Elapsed: 5.453128ms
Dec  5 08:38:21.088: INFO: Pod "pod-89c47c6e-3e64-4373-a6bb-5116d032aa71": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010280459s
STEP: Saw pod success
Dec  5 08:38:21.088: INFO: Pod "pod-89c47c6e-3e64-4373-a6bb-5116d032aa71" satisfied condition "success or failure"
Dec  5 08:38:21.090: INFO: Trying to get logs from node worknode pod pod-89c47c6e-3e64-4373-a6bb-5116d032aa71 container test-container: <nil>
STEP: delete the pod
Dec  5 08:38:21.125: INFO: Waiting for pod pod-89c47c6e-3e64-4373-a6bb-5116d032aa71 to disappear
Dec  5 08:38:21.131: INFO: Pod pod-89c47c6e-3e64-4373-a6bb-5116d032aa71 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:38:21.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6412" for this suite.
Dec  5 08:38:27.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:38:27.274: INFO: namespace emptydir-6412 deletion completed in 6.137101944s

â€¢ [SLOW TEST:8.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:38:27.274: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3138
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3138
I1205 08:38:27.351870      20 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3138, replica count: 2
Dec  5 08:38:30.403: INFO: Creating new exec pod
I1205 08:38:30.403039      20 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  5 08:38:33.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-3138 execpodh2bwh -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  5 08:38:33.725: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  5 08:38:33.725: INFO: stdout: ""
Dec  5 08:38:33.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 exec --namespace=services-3138 execpodh2bwh -- /bin/sh -x -c nc -zv -t -w 2 10.96.188.209 80'
Dec  5 08:38:33.922: INFO: stderr: "+ nc -zv -t -w 2 10.96.188.209 80\nConnection to 10.96.188.209 80 port [tcp/http] succeeded!\n"
Dec  5 08:38:33.922: INFO: stdout: ""
Dec  5 08:38:33.922: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:38:33.954: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3138" for this suite.
Dec  5 08:38:39.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:38:40.102: INFO: namespace services-3138 deletion completed in 6.141287117s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

â€¢ [SLOW TEST:12.828 seconds]
[sig-network] Services
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:38:40.106: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  5 08:38:40.170: INFO: Waiting up to 5m0s for pod "pod-3484e117-aa09-479e-9716-4b2a32b6c5fc" in namespace "emptydir-5755" to be "success or failure"
Dec  5 08:38:40.179: INFO: Pod "pod-3484e117-aa09-479e-9716-4b2a32b6c5fc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.22547ms
Dec  5 08:38:42.185: INFO: Pod "pod-3484e117-aa09-479e-9716-4b2a32b6c5fc": Phase="Running", Reason="", readiness=true. Elapsed: 2.014917798s
Dec  5 08:38:44.197: INFO: Pod "pod-3484e117-aa09-479e-9716-4b2a32b6c5fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.027269199s
STEP: Saw pod success
Dec  5 08:38:44.197: INFO: Pod "pod-3484e117-aa09-479e-9716-4b2a32b6c5fc" satisfied condition "success or failure"
Dec  5 08:38:44.202: INFO: Trying to get logs from node worknode pod pod-3484e117-aa09-479e-9716-4b2a32b6c5fc container test-container: <nil>
STEP: delete the pod
Dec  5 08:38:44.258: INFO: Waiting for pod pod-3484e117-aa09-479e-9716-4b2a32b6c5fc to disappear
Dec  5 08:38:44.270: INFO: Pod pod-3484e117-aa09-479e-9716-4b2a32b6c5fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:38:44.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5755" for this suite.
Dec  5 08:38:50.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:38:50.390: INFO: namespace emptydir-5755 deletion completed in 6.113999602s

â€¢ [SLOW TEST:10.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:38:50.397: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-95c7fe4a-4a4f-4fff-b67c-4e4c89f6f0ef
STEP: Creating a pod to test consume secrets
Dec  5 08:38:50.445: INFO: Waiting up to 5m0s for pod "pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0" in namespace "secrets-4151" to be "success or failure"
Dec  5 08:38:50.460: INFO: Pod "pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0": Phase="Pending", Reason="", readiness=false. Elapsed: 15.444216ms
Dec  5 08:38:52.464: INFO: Pod "pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019366034s
Dec  5 08:38:54.468: INFO: Pod "pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.023284646s
STEP: Saw pod success
Dec  5 08:38:54.469: INFO: Pod "pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0" satisfied condition "success or failure"
Dec  5 08:38:54.472: INFO: Trying to get logs from node worknode pod pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0 container secret-volume-test: <nil>
STEP: delete the pod
Dec  5 08:38:54.501: INFO: Waiting for pod pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0 to disappear
Dec  5 08:38:54.505: INFO: Pod pod-secrets-f1f38f31-6a0a-4fa2-900f-1bb198d369f0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:38:54.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4151" for this suite.
Dec  5 08:39:00.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:39:00.630: INFO: namespace secrets-4151 deletion completed in 6.121172075s

â€¢ [SLOW TEST:10.233 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:39:00.630: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  5 08:39:00.695: INFO: Waiting up to 5m0s for pod "downward-api-c33df485-57b0-42f5-afa2-df92e48f6664" in namespace "downward-api-1076" to be "success or failure"
Dec  5 08:39:00.704: INFO: Pod "downward-api-c33df485-57b0-42f5-afa2-df92e48f6664": Phase="Pending", Reason="", readiness=false. Elapsed: 8.659754ms
Dec  5 08:39:02.710: INFO: Pod "downward-api-c33df485-57b0-42f5-afa2-df92e48f6664": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014651977s
Dec  5 08:39:04.713: INFO: Pod "downward-api-c33df485-57b0-42f5-afa2-df92e48f6664": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.018422902s
STEP: Saw pod success
Dec  5 08:39:04.713: INFO: Pod "downward-api-c33df485-57b0-42f5-afa2-df92e48f6664" satisfied condition "success or failure"
Dec  5 08:39:04.721: INFO: Trying to get logs from node worknode pod downward-api-c33df485-57b0-42f5-afa2-df92e48f6664 container dapi-container: <nil>
STEP: delete the pod
Dec  5 08:39:04.764: INFO: Waiting for pod downward-api-c33df485-57b0-42f5-afa2-df92e48f6664 to disappear
Dec  5 08:39:04.769: INFO: Pod downward-api-c33df485-57b0-42f5-afa2-df92e48f6664 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:39:04.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1076" for this suite.
Dec  5 08:39:10.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:39:10.939: INFO: namespace downward-api-1076 deletion completed in 6.161269247s

â€¢ [SLOW TEST:10.309 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:39:10.939: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec  5 08:39:10.976: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec  5 08:39:11.303: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec  5 08:39:18.641: INFO: Waited 5.239492042s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:39:19.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-3983" for this suite.
Dec  5 08:39:25.453: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:39:25.568: INFO: namespace aggregator-3983 deletion completed in 6.139420862s

â€¢ [SLOW TEST:14.629 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:39:25.571: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-8023, will wait for the garbage collector to delete the pods
Dec  5 08:39:27.749: INFO: Deleting Job.batch foo took: 28.639579ms
Dec  5 08:39:27.850: INFO: Terminating Job.batch foo pods took: 100.825848ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:40:04.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-8023" for this suite.
Dec  5 08:40:10.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:40:10.376: INFO: namespace job-8023 deletion completed in 6.11898998s

â€¢ [SLOW TEST:44.806 seconds]
[sig-apps] Job
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:40:10.379: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8364
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  5 08:40:10.465: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  5 08:40:30.565: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.233.203:8080/dial?request=hostName&protocol=http&host=192.168.233.202&port=8080&tries=1'] Namespace:pod-network-test-8364 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:40:30.565: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:40:30.717: INFO: Waiting for endpoints: map[]
Dec  5 08:40:30.720: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://192.168.233.203:8080/dial?request=hostName&protocol=http&host=192.168.228.97&port=8080&tries=1'] Namespace:pod-network-test-8364 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:40:30.720: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:40:30.880: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:40:30.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8364" for this suite.
Dec  5 08:40:42.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:40:43.009: INFO: namespace pod-network-test-8364 deletion completed in 12.124115491s

â€¢ [SLOW TEST:32.630 seconds]
[sig-network] Networking
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:40:43.012: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec  5 08:40:43.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 cluster-info'
Dec  5 08:40:43.113: INFO: stderr: ""
Dec  5 08:40:43.113: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:40:43.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-837" for this suite.
Dec  5 08:40:49.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:40:49.381: INFO: namespace kubectl-837 deletion completed in 6.263630247s

â€¢ [SLOW TEST:6.370 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:40:49.383: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-a05ba07b-37f4-493b-baac-ae033d89a17c
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-a05ba07b-37f4-493b-baac-ae033d89a17c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:40:53.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8108" for this suite.
Dec  5 08:41:07.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:41:07.718: INFO: namespace projected-8108 deletion completed in 14.121344073s

â€¢ [SLOW TEST:18.335 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:41:07.720: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec  5 08:41:07.766: INFO: Waiting up to 5m0s for pod "client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d" in namespace "containers-9359" to be "success or failure"
Dec  5 08:41:07.774: INFO: Pod "client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d": Phase="Pending", Reason="", readiness=false. Elapsed: 7.621125ms
Dec  5 08:41:09.780: INFO: Pod "client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013973649s
STEP: Saw pod success
Dec  5 08:41:09.780: INFO: Pod "client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d" satisfied condition "success or failure"
Dec  5 08:41:09.783: INFO: Trying to get logs from node worknode pod client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d container test-container: <nil>
STEP: delete the pod
Dec  5 08:41:09.811: INFO: Waiting for pod client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d to disappear
Dec  5 08:41:09.815: INFO: Pod client-containers-ec68b458-5099-4e01-82d7-fbea03d29a4d no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:41:09.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9359" for this suite.
Dec  5 08:41:15.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:41:15.995: INFO: namespace containers-9359 deletion completed in 6.174883174s

â€¢ [SLOW TEST:8.276 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:41:16.003: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  5 08:41:16.075: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683" in namespace "downward-api-6141" to be "success or failure"
Dec  5 08:41:16.135: INFO: Pod "downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683": Phase="Pending", Reason="", readiness=false. Elapsed: 59.590477ms
Dec  5 08:41:18.266: INFO: Pod "downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683": Phase="Pending", Reason="", readiness=false. Elapsed: 2.191406175s
Dec  5 08:41:20.272: INFO: Pod "downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.19728207s
STEP: Saw pod success
Dec  5 08:41:20.272: INFO: Pod "downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683" satisfied condition "success or failure"
Dec  5 08:41:20.275: INFO: Trying to get logs from node worknode pod downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683 container client-container: <nil>
STEP: delete the pod
Dec  5 08:41:20.316: INFO: Waiting for pod downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683 to disappear
Dec  5 08:41:20.330: INFO: Pod downwardapi-volume-c03bb453-8ab3-41d3-a2b9-043dd51b7683 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:41:20.330: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6141" for this suite.
Dec  5 08:41:26.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:41:26.489: INFO: namespace downward-api-6141 deletion completed in 6.153177415s

â€¢ [SLOW TEST:10.486 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:41:26.495: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec  5 08:41:26.552: INFO: Waiting up to 5m0s for pod "var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe" in namespace "var-expansion-4389" to be "success or failure"
Dec  5 08:41:26.572: INFO: Pod "var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe": Phase="Pending", Reason="", readiness=false. Elapsed: 19.718776ms
Dec  5 08:41:28.576: INFO: Pod "var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023532994s
STEP: Saw pod success
Dec  5 08:41:28.576: INFO: Pod "var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe" satisfied condition "success or failure"
Dec  5 08:41:28.579: INFO: Trying to get logs from node worknode pod var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe container dapi-container: <nil>
STEP: delete the pod
Dec  5 08:41:28.603: INFO: Waiting for pod var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe to disappear
Dec  5 08:41:28.609: INFO: Pod var-expansion-e1e5b0cd-45f8-4619-9eb0-7645dd06eefe no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:41:28.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4389" for this suite.
Dec  5 08:41:34.630: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:41:34.728: INFO: namespace var-expansion-4389 deletion completed in 6.110897826s

â€¢ [SLOW TEST:8.233 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:41:34.728: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  5 08:41:38.814: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:38.814: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:38.982: INFO: Exec stderr: ""
Dec  5 08:41:38.982: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:38.982: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:39.181: INFO: Exec stderr: ""
Dec  5 08:41:39.181: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:39.181: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:39.342: INFO: Exec stderr: ""
Dec  5 08:41:39.342: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:39.342: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:39.507: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  5 08:41:39.507: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:39.507: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:39.718: INFO: Exec stderr: ""
Dec  5 08:41:39.718: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:39.718: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:39.906: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  5 08:41:39.906: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:39.906: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:40.119: INFO: Exec stderr: ""
Dec  5 08:41:40.119: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:40.119: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:40.341: INFO: Exec stderr: ""
Dec  5 08:41:40.341: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:40.341: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:40.544: INFO: Exec stderr: ""
Dec  5 08:41:40.544: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-4571 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  5 08:41:40.544: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
Dec  5 08:41:40.726: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:41:40.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-4571" for this suite.
Dec  5 08:42:24.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:42:24.840: INFO: namespace e2e-kubelet-etc-hosts-4571 deletion completed in 44.108336525s

â€¢ [SLOW TEST:50.111 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:42:24.841: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  5 08:42:25.335: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  5 08:42:27.345: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711132145, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711132145, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711132145, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711132145, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  5 08:42:30.376: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec  5 08:42:32.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 attach --namespace=webhook-5321 to-be-attached-pod -i -c=container1'
Dec  5 08:42:32.506: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:42:32.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5321" for this suite.
Dec  5 08:42:44.529: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:42:44.623: INFO: namespace webhook-5321 deletion completed in 12.107003381s
STEP: Destroying namespace "webhook-5321-markers" for this suite.
Dec  5 08:42:50.644: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:42:50.727: INFO: namespace webhook-5321-markers deletion completed in 6.103437874s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

â€¢ [SLOW TEST:25.901 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:42:50.742: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4633.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4633.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4633.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4633.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4633.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4633.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  5 08:42:54.876: INFO: DNS probes using dns-4633/dns-test-3d5b19ce-1e05-4b10-a779-54bd71ee2145 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:42:54.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4633" for this suite.
Dec  5 08:43:00.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:43:01.047: INFO: namespace dns-4633 deletion completed in 6.109671159s

â€¢ [SLOW TEST:10.305 seconds]
[sig-network] DNS
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:43:01.047: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  5 08:43:01.102: INFO: (0) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 20.283468ms)
Dec  5 08:43:01.106: INFO: (1) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.380518ms)
Dec  5 08:43:01.109: INFO: (2) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.073402ms)
Dec  5 08:43:01.112: INFO: (3) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.849946ms)
Dec  5 08:43:01.115: INFO: (4) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.10163ms)
Dec  5 08:43:01.120: INFO: (5) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 4.658596ms)
Dec  5 08:43:01.124: INFO: (6) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.361329ms)
Dec  5 08:43:01.127: INFO: (7) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.930144ms)
Dec  5 08:43:01.130: INFO: (8) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.375857ms)
Dec  5 08:43:01.134: INFO: (9) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.29962ms)
Dec  5 08:43:01.137: INFO: (10) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.377115ms)
Dec  5 08:43:01.141: INFO: (11) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.214237ms)
Dec  5 08:43:01.144: INFO: (12) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.441533ms)
Dec  5 08:43:01.147: INFO: (13) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.958324ms)
Dec  5 08:43:01.150: INFO: (14) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.007384ms)
Dec  5 08:43:01.154: INFO: (15) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.957976ms)
Dec  5 08:43:01.157: INFO: (16) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 2.944728ms)
Dec  5 08:43:01.160: INFO: (17) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.155168ms)
Dec  5 08:43:01.167: INFO: (18) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 6.039268ms)
Dec  5 08:43:01.170: INFO: (19) /api/v1/nodes/allinone:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apt/">apt/</a>
<a href="auth.log">... (200; 3.4897ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:43:01.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7528" for this suite.
Dec  5 08:43:07.189: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:43:07.287: INFO: namespace proxy-7528 deletion completed in 6.113726447s

â€¢ [SLOW TEST:6.240 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:43:07.287: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:43:23.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2703" for this suite.
Dec  5 08:43:29.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:43:29.465: INFO: namespace resourcequota-2703 deletion completed in 6.096043271s

â€¢ [SLOW TEST:22.178 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:43:29.465: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec  5 08:43:29.503: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  5 08:43:29.503: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:29.693: INFO: stderr: ""
Dec  5 08:43:29.694: INFO: stdout: "service/redis-slave created\n"
Dec  5 08:43:29.694: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  5 08:43:29.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:29.855: INFO: stderr: ""
Dec  5 08:43:29.855: INFO: stdout: "service/redis-master created\n"
Dec  5 08:43:29.857: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  5 08:43:29.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:30.033: INFO: stderr: ""
Dec  5 08:43:30.033: INFO: stdout: "service/frontend created\n"
Dec  5 08:43:30.033: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  5 08:43:30.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:30.199: INFO: stderr: ""
Dec  5 08:43:30.199: INFO: stdout: "deployment.apps/frontend created\n"
Dec  5 08:43:30.200: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  5 08:43:30.200: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:30.352: INFO: stderr: ""
Dec  5 08:43:30.352: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  5 08:43:30.353: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  5 08:43:30.353: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9361'
Dec  5 08:43:30.506: INFO: stderr: ""
Dec  5 08:43:30.506: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  5 08:43:30.506: INFO: Waiting for all frontend pods to be Running.
Dec  5 08:43:35.560: INFO: Waiting for frontend to serve content.
Dec  5 08:43:35.593: INFO: Trying to add a new entry to the guestbook.
Dec  5 08:43:35.605: INFO: Verifying that added entry can be retrieved.
Dec  5 08:43:35.628: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:43:40.642: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:43:45.657: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:43:50.677: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:43:55.694: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:00.712: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:05.726: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:10.743: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:15.754: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:20.765: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:25.780: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  5 08:44:30.792: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec  5 08:44:35.805: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:35.991: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:35.991: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 08:44:35.991: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:36.172: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:36.172: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 08:44:36.173: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:36.284: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:36.284: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 08:44:36.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:36.375: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:36.375: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 08:44:36.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:36.477: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:36.477: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  5 08:44:36.478: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9361'
Dec  5 08:44:36.590: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:44:36.590: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:44:36.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9361" for this suite.
Dec  5 08:45:04.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:45:04.696: INFO: namespace kubectl-9361 deletion completed in 28.100822912s

â€¢ [SLOW TEST:95.231 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:45:04.697: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  5 08:45:04.739: INFO: Waiting up to 5m0s for pod "pod-8caaa861-8845-433a-be40-25b0619c1e52" in namespace "emptydir-1783" to be "success or failure"
Dec  5 08:45:04.754: INFO: Pod "pod-8caaa861-8845-433a-be40-25b0619c1e52": Phase="Pending", Reason="", readiness=false. Elapsed: 14.651401ms
Dec  5 08:45:06.760: INFO: Pod "pod-8caaa861-8845-433a-be40-25b0619c1e52": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020103657s
STEP: Saw pod success
Dec  5 08:45:06.760: INFO: Pod "pod-8caaa861-8845-433a-be40-25b0619c1e52" satisfied condition "success or failure"
Dec  5 08:45:06.763: INFO: Trying to get logs from node worknode pod pod-8caaa861-8845-433a-be40-25b0619c1e52 container test-container: <nil>
STEP: delete the pod
Dec  5 08:45:06.806: INFO: Waiting for pod pod-8caaa861-8845-433a-be40-25b0619c1e52 to disappear
Dec  5 08:45:06.817: INFO: Pod pod-8caaa861-8845-433a-be40-25b0619c1e52 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:45:06.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1783" for this suite.
Dec  5 08:45:12.837: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:45:12.948: INFO: namespace emptydir-1783 deletion completed in 6.126783104s

â€¢ [SLOW TEST:8.251 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:45:12.948: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  5 08:45:17.136: INFO: &Pod{ObjectMeta:{send-events-42c0b308-189e-4161-9e64-647f714e89eb  events-4827 /api/v1/namespaces/events-4827/pods/send-events-42c0b308-189e-4161-9e64-647f714e89eb 4b5959b5-4e7a-4a31-b04a-705e53e64c05 28850 0 2019-12-05 08:45:13 +0000 UTC <nil> <nil> map[name:foo time:32038587] map[cni.projectcalico.org/podIP:192.168.233.217/32] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lpkp6,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lpkp6,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lpkp6,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:worknode,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:45:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:45:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:45:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-05 08:45:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.3.47,PodIP:192.168.233.217,StartTime:2019-12-05 08:45:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-05 08:45:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://d0b0648c90521ade1341963011a2191c764d98d30148160305c1cd54837e3a0e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:192.168.233.217,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec  5 08:45:19.141: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  5 08:45:21.146: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:45:21.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-4827" for this suite.
Dec  5 08:46:05.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:46:05.259: INFO: namespace events-4827 deletion completed in 44.094930031s

â€¢ [SLOW TEST:52.311 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:46:05.260: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  5 08:46:05.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 create -f - --namespace=kubectl-9445'
Dec  5 08:46:05.418: INFO: stderr: ""
Dec  5 08:46:05.418: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  5 08:46:05.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9445'
Dec  5 08:46:05.501: INFO: stderr: ""
Dec  5 08:46:05.501: INFO: stdout: "update-demo-nautilus-2whjh update-demo-nautilus-k9cv6 "
Dec  5 08:46:05.501: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-2whjh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9445'
Dec  5 08:46:05.557: INFO: stderr: ""
Dec  5 08:46:05.558: INFO: stdout: ""
Dec  5 08:46:05.558: INFO: update-demo-nautilus-2whjh is created but not running
Dec  5 08:46:10.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9445'
Dec  5 08:46:10.750: INFO: stderr: ""
Dec  5 08:46:10.751: INFO: stdout: "update-demo-nautilus-2whjh update-demo-nautilus-k9cv6 "
Dec  5 08:46:10.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-2whjh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9445'
Dec  5 08:46:10.811: INFO: stderr: ""
Dec  5 08:46:10.812: INFO: stdout: "true"
Dec  5 08:46:10.812: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-2whjh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9445'
Dec  5 08:46:10.876: INFO: stderr: ""
Dec  5 08:46:10.876: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 08:46:10.876: INFO: validating pod update-demo-nautilus-2whjh
Dec  5 08:46:10.880: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 08:46:10.880: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 08:46:10.880: INFO: update-demo-nautilus-2whjh is verified up and running
Dec  5 08:46:10.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-k9cv6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9445'
Dec  5 08:46:10.942: INFO: stderr: ""
Dec  5 08:46:10.942: INFO: stdout: "true"
Dec  5 08:46:10.942: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods update-demo-nautilus-k9cv6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9445'
Dec  5 08:46:11.012: INFO: stderr: ""
Dec  5 08:46:11.012: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  5 08:46:11.012: INFO: validating pod update-demo-nautilus-k9cv6
Dec  5 08:46:11.023: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  5 08:46:11.023: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  5 08:46:11.023: INFO: update-demo-nautilus-k9cv6 is verified up and running
STEP: using delete to clean up resources
Dec  5 08:46:11.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 delete --grace-period=0 --force -f - --namespace=kubectl-9445'
Dec  5 08:46:11.109: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  5 08:46:11.109: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  5 08:46:11.109: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9445'
Dec  5 08:46:11.197: INFO: stderr: "No resources found in kubectl-9445 namespace.\n"
Dec  5 08:46:11.197: INFO: stdout: ""
Dec  5 08:46:11.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -l name=update-demo --namespace=kubectl-9445 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 08:46:11.259: INFO: stderr: ""
Dec  5 08:46:11.259: INFO: stdout: "update-demo-nautilus-2whjh\nupdate-demo-nautilus-k9cv6\n"
Dec  5 08:46:11.760: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-9445'
Dec  5 08:46:11.882: INFO: stderr: "No resources found in kubectl-9445 namespace.\n"
Dec  5 08:46:11.882: INFO: stdout: ""
Dec  5 08:46:11.882: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-535733101 get pods -l name=update-demo --namespace=kubectl-9445 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  5 08:46:12.007: INFO: stderr: ""
Dec  5 08:46:12.007: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:46:12.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9445" for this suite.
Dec  5 08:46:24.029: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:46:24.125: INFO: namespace kubectl-9445 deletion completed in 12.115369642s

â€¢ [SLOW TEST:18.866 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  5 08:46:24.126: INFO: >>> kubeConfig: /tmp/kubeconfig-535733101
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  5 08:46:26.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1558" for this suite.
Dec  5 08:47:10.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  5 08:47:10.337: INFO: namespace kubelet-test-1558 deletion completed in 44.116962486s

â€¢ [SLOW TEST:46.211 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSDec  5 08:47:10.339: INFO: Running AfterSuite actions on all nodes
Dec  5 08:47:10.339: INFO: Running AfterSuite actions on node 1
Dec  5 08:47:10.339: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 7028.853 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 1h57m10.256624097s
Test Suite Passed
